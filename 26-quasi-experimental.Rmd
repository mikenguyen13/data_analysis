# Quasi-Experimental Methods {#sec-quasi-experimental}

Quasi-experimental methods are widely used in causal inference when randomized experiments are not feasible. Typically, these methods rely on **pre- and post-intervention data** and attempt to identify **exogenous variation** that can be leveraged to estimate causal effects.

Great resources for causal inference include:

-   [Causal Inference Mixtape](https://mixtape.scunning.com/introduction.html)
-   [Recent Advances in Micro](https://christinecai.github.io/PublicGoods/applied_micro_methods.pdf)

The following R packages are useful for implementing quasi-experimental methods:

-   [**Econometrics**](https://cran.r-project.org/web/views/Econometrics.html): Covers a broad range of econometric techniques.
-   [**Causal Inference**](https://cran.r-project.org/web/views/CausalInference.html): Provides tools for estimating causal effects under different identification assumptions.

While internal validity ensures a credible causal effect, external validity assesses whether the findings **generalize** beyond the sample.

Key considerations:

-   Representativeness of the Sample
-   Limitations of the Design
-   Using Quasi-Experimental Results with Structural Models
    -   See [@anderson2015growth], [@einav2010beyond], and [@chung2014bonuses] for applications.

------------------------------------------------------------------------

## Identification Strategy in Quasi-Experiments

Unlike randomized experiments, quasi-experiments lack **formal statistical proof** of causality. Instead, researchers must build a **plausible argument** supported by empirical evidence.

Key components of an identification strategy:

1.  **Source of Exogenous Variation**
    -   Justify where the exogenous variation originates.
    -   Use institutional knowledge and theoretical arguments to support this claim.
2.  **Exclusion Restriction**
    -   Provide evidence that variation in the exogenous shock affects the outcome only through the proposed mechanism.
    -   This requires ruling out confounding factors.
3.  **Stable Unit Treatment Value Assumption**
    -   The treatment of unit $i$ should only affect the outcome of unit $i$.
    -   No spillovers or interference between treatment and control groups.

Every quasi-experimental method involves a **tradeoff between statistical power and support for the exogeneity assumption**. This means that researchers often discard variation in the data that does not meet the exogeneity assumption.

**Important Notes:**

-   $R^2$ is not a reliable metric in causal inference and can be misleading for model comparison [@ebbes2011sense].

-   Clustering should be determined based on the study design, not just expectations of correlation [@abadie2023should].

-   For small samples, use the wild bootstrap procedure to correct for downward bias [@cameron2008bootstrap]. See also [@cai2022implementation] for further assumptions.

------------------------------------------------------------------------

## Robustness Checks

Robustness checks are essential to demonstrate that findings are not driven by model specification choices.

Recommended robustness checks [@goldfarb2022conducting]:

1.  **Alternative Control Sets**
    -   Show results with and without controls.
    -   Examine how the estimate of interest changes.
    -   Use **Rosenbaum bounds** for formal sensitivity analysis [@altonji2005selection].
    -   In marketing applications, see [@manchanda2015social] and [@shin2012fire].
2.  **Different Functional Forms**
    -   Check whether the results hold under different model specifications (e.g., linear vs. non-linear models).
3.  **Varying Time Windows**
    -   In longitudinal settings, test different time frames to ensure robustness.
4.  **Alternative Dependent Variables**
    -   Use related outcomes or different measures of the dependent variable.
5.  **Varying Control Group Size**
    -   Compare results using **matched vs. unmatched samples** to assess sensitivity to sample selection.
6.  **Placebo Tests**
    -   Conduct placebo tests to ensure the effect is not spurious.
    -   The appropriate placebo test depends on the specific quasi-experimental method used (examples provided in later sections).

------------------------------------------------------------------------

## Establishing Mechanisms

Once the causal effect is established, the next step is to investigate how the effect operates.

1.  [Mediation] Analysis
    -   Test whether an intermediate variable explains the effect of the treatment.
2.  [Moderation] Analysis
    -   Estimate the model separately for different subgroups.
    -   Test for three-way interactions (e.g., interaction between treatment, time, and group membership in Difference-in-Differences settings).

------------------------------------------------------------------------

## Limitations of Quasi-Experiments

Researchers should explicitly discuss the limitations of their quasi-experimental approach.

Key Questions to Address:

1.  **What are the identification assumptions?**
    -   Clearly state the assumptions required for causal inference.
2.  **What are the threats to validity?**
    -   Consider potential confounders, measurement errors, and violations of SUTVA.
3.  **How do you address these threats?**
    -   Describe robustness checks and alternative specifications.
    -   Suggest directions for future research to improve causal identification.

------------------------------------------------------------------------

## Assumptions for Identifying Treatment Effects

To identify causal effects in **non-randomized studies**, we rely on three key assumptions:

1.  [Stable Unit Treatment Value Assumption](#sec-sutva) (SUTVA)
2.  Conditional Ignorability (Unconfoundedness) Assumption
3.  Overlap (Positivity) Assumption

These assumptions ensure that we can properly define and estimate causal effects, mitigating biases from confounders or selection effects.

------------------------------------------------------------------------

### **Stable Unit Treatment Value Assumption** {#sec-sutva}

SUTVA consists of two key components:

1.  **Consistency Assumption:** The treatment indicator $Z \in \{0,1\}$ adequately represents all versions of the treatment.
2.  **No Interference Assumption:** A subject's outcome depends **only** on its own treatment status and is **not affected** by the treatment assignments of other subjects.

This assumption ensures that potential outcomes are well-defined and independent of external influences, forming the foundation of Rubin's Causal Model (RCM). Violations of SUTVA can lead to biased estimators and incorrect standard errors.

------------------------------------------------------------------------

#### **Mathematical Formulation of SUTVA**

Let $Y_i(Z)$ denote the **potential outcome** for unit $i$ under treatment assignment $Z$, where $Z \in \{0,1\}$ represents a binary treatment.

SUTVA states that:

$$
Y_i(Z) = Y_i(Z, \mathbf{Z}_{-i})
$$

where $\mathbf{Z}_{-i}$ denotes the treatment assignments of all other units **except** $i$. If SUTVA holds, then:

$$
Y_i(Z) = Y_i(Z, \mathbf{Z}_{-i}) \quad \forall \mathbf{Z}_{-i}.
$$

This implies that unit $i$'s outcome depends **only** on its own treatment status and is unaffected by the treatment of others.

------------------------------------------------------------------------

#### **Implications of SUTVA**

If SUTVA holds, the [Average Treatment Effect] is well-defined as:

$$
\text{ATE} = \mathbb{E}[Y_i(1)] - \mathbb{E}[Y_i(0)].
$$

However, if SUTVA is violated, standard causal inference methods may fail. Common violations include:

-   **Interference (Spillover Effects):** The treatment of one unit influences another's outcome.
    -   Example: A marketing campaign for a product influences both treated and untreated customers through word-of-mouth effects.
    -   **Solution:** Use **spatial econometrics** or **network-based causal inference models** to account for spillovers.
-   **Treatment Inconsistency:** Multiple versions of a treatment exist but are not explicitly modeled.
    -   Example: Different incentive levels in a sales promotion may have different effects.
    -   **Solution:** Explicitly define and distinguish different treatment versions using **principal stratification**.

When SUTVA is violated, researchers should consider alternative frameworks, such as **interference-aware causal models** (e.g., spillover effects in Difference-in-Differences settings).

------------------------------------------------------------------------

#### **No Interference Assumption and Its Mathematical Implications**

##### **Definition of No Interference**

The **no interference** component of SUTVA assumes that one unit's treatment assignment does not affect another unit's outcome. In many real-world scenarios, this assumption is violated due to **spillover effects**, such as:

-   **Epidemiology**: In vaccine studies, an individual's health status may be affected by the vaccination status of their social network.
-   **Marketing Experiments**: In online advertising, one consumer's exposure to an ad campaign may influence their peers' purchasing decisions.

Formally, if interference exists, then unit $i$'s outcome depends on a **neighborhood function** $\mathcal{N}(i)$, where:

$$
Y_i(Z, \mathbf{Z}_{\mathcal{N}(i)}).
$$

If $\mathcal{N}(i) \neq \emptyset$, interference exists, and SUTVA is violated. In such cases, we must redefine treatment effects by considering **direct and indirect effects** using methodologies such as **spatial models** or **network-based causal inference**.

##### **Special Cases of Interference**

-   **Complete Interference**: Every unit's outcome is affected by all other units' treatment assignments.
-   **Partial Interference**: Interference occurs **within** subgroups but not **between** them (e.g., classrooms in an educational experiment).
-   **Network Interference**: Treatment effects propagate through a social or spatial network, requiring models like **graph-based causal inference**.

------------------------------------------------------------------------

#### **No Hidden Variations in Treatment**

The second component of SUTVA ensures that the treatment effect is **uniquely defined**, meaning there are no hidden variations in how the treatment is administered. That is, if multiple **versions** of the treatment exist (e.g., different dosages of a drug), the causal effect may **not be well-defined**.

Mathematically, if there exist multiple versions $v$ of the treatment $Z$, then the potential outcome should be indexed accordingly:

$$
Y_i(Z, v).
$$

If different versions produce different outcomes, then:

$$
Y_i(Z, v_1) \neq Y_i(Z, v_2).
$$

This violates SUTVA and requires **instrumental variables (IV)** or **latent variable models** to adjust for treatment heterogeneity.

------------------------------------------------------------------------

#### **Implications of Violating SUTVA**

If SUTVA is violated, causal inference suffers from **bias, incorrect standard errors, and ambiguous estimands**. Key consequences include:

-   **Bias in Estimators**: If interference is ignored, treatment effects are misestimated.
-   **Incorrect Standard Errors**: Standard errors may be **underestimated** (if spillovers are ignored) or **overestimated** (if hidden treatment variations exist).
-   **Ill-Defined Causal Effects**: If multiple treatment versions exist, it becomes unclear **which causal effect** is being estimated.

In such cases, alternative estimands such as **network-adjusted treatment effects** or **spatial spillover models** are needed.

------------------------------------------------------------------------

#### **Strategies to Address SUTVA Violations**

To mitigate violations of SUTVA, researchers can adopt the following techniques:

1.  **Randomized Saturation Designs**: Introduce varying treatment intensities across clusters to measure spillover effects.
2.  **Network-Based Causal Models**: Use graph theory to model interference.
3.  **Instrumental Variables (IV)**: If multiple versions of treatment exist, use an IV that isolates a single version.
4.  **Stratified Analysis**: If treatment versions differ significantly, analyze each subgroup separately.
5.  **Difference-in-Differences (DiD) with Spatial Controls**: For geographic spillovers, include spatially lagged treatment indicators.

Each of these approaches ensures that causal inferences remain valid despite potential SUTVA violations.

------------------------------------------------------------------------

### **Conditional Ignorability Assumption**

Next, we must assume that **treatment assignment is independent of the potential outcomes conditional on the observed covariates**. This assumption has several equivalent names in the causal inference literature, including **"conditional ignorability," "conditional exchangeability," "no unobserved confounding," and "no omitted variables."** In the language of **causal diagrams**, this assumption ensures that all **backdoor paths** between treatment and outcome are blocked by **observed covariates**.

Formally, we assume that treatment assignment $Z$ is independent of the potential outcomes $Y(Z)$ given a set of **observed covariates** $X$:

$$
Y(1), Y(0) \perp\!\!\!\perp Z \mid X.
$$

This means that **after conditioning on** $X$, the probability of receiving treatment is unrelated to the potential outcomes, ensuring that comparisons between treated and untreated units are **unbiased**. Below, we explore the mathematical implications, violations, and strategies for addressing violations of this assumption.

------------------------------------------------------------------------

#### **Formal Definition and Notation**

In causal inference, **treatment assignment is said to be ignorable** if, conditional on observed covariates $X$, the treatment indicator $Z$ is independent of the potential outcomes:

$$
P(Y(1), Y(0) \mid Z, X) = P(Y(1), Y(0) \mid X).
$$

Equivalently, in terms of conditional probability:

$$
P(Z = 1 \mid Y(1), Y(0), X) = P(Z = 1 \mid X).
$$

This ensures that treatment assignment is **as good as random** once we control for $X$, meaning that the probability of receiving treatment does not depend on unmeasured confounders.

A direct consequence is that we can estimate the **Average Treatment Effect (ATE)** using observational data:

$$
\mathbb{E}[Y(1) - Y(0)] = \mathbb{E}[\mathbb{E}[Y \mid Z=1, X] - \mathbb{E}[Y \mid Z=0, X]].
$$

If **ignorability holds**, standard regression models, matching, or weighting techniques (e.g., propensity score weighting) can provide **unbiased causal estimates**.

------------------------------------------------------------------------

#### **The Role of Causal Diagrams and Backdoor Paths**

In **causal diagrams** (DAGs), confounding arises when a **backdoor path** exists between treatment $Z$ and outcome $Y$. A **backdoor path** is any **non-causal** path that creates **spurious associations** between $Z$ and $Y$. The **conditional ignorability assumption** requires that all such paths be **blocked** by conditioning on a sufficient set of covariates $X$.

##### **Identifying Backdoor Paths**

Consider a simple causal diagram:

X → Z → Y X → Y

Here, $X$ is a **common cause** of both $Z$ and $Y$, creating a **backdoor path** $Z \leftarrow X \rightarrow Y$. If we fail to **control for** $X$, the estimated effect of $Z$ on $Y$ will be **biased**. However, if we **condition on** $X$, we block the backdoor path and obtain an **unbiased estimate** of the treatment effect.

##### **Sufficient Covariate Adjustment**

To satisfy the conditional ignorability assumption, researchers must identify a **sufficient set of confounders** to block all backdoor paths. This is often done using **domain knowledge** and **causal structure learning algorithms**.

-   **Minimal Sufficient Adjustment Set**: The smallest set of covariates $X$ that, when conditioned upon, satisfies ignorability.
-   **Propensity Score Methods**: Instead of adjusting directly for $X$, one can estimate the probability of treatment $P(Z=1 \mid X)$ and use **inverse probability weighting (IPW)** or **matching**.

------------------------------------------------------------------------

#### **Violations of the Ignorability Assumption**

If ignorability does **not** hold, treatment assignment depends on **unobserved confounders**, introducing **omitted variable bias**. Mathematically, if there exists an unmeasured variable $U$ such that:

$$
Y(1), Y(0) \not\perp\!\!\!\perp Z \mid X,
$$

then estimates of the treatment effect will be **biased**.

##### **Consequences of Violations**

-   **Confounded Estimates**: The estimated treatment effect captures both the causal effect and the bias from unobserved confounders.
-   **Selection Bias**: If treatment assignment is related to factors that also influence the outcome, the sample may not be representative.
-   **Overestimation or Underestimation**: Ignoring important confounders can lead to inflated or deflated estimates of treatment effects.

##### **Example of Confounding**

Consider an **observational study on smoking and lung cancer**:

Smoking → Lung Cancer Genetics → Smoking Genetics → Lung Cancer

Here, **genetics** is an unmeasured confounder affecting both **smoking** and **lung cancer**. If we do not control for genetics, the estimated effect of smoking on lung cancer will be **biased**.

------------------------------------------------------------------------

#### **Strategies to Address Violations**

If ignorability is violated due to **unobserved confounding**, several techniques can be used to mitigate bias:

1.  **Instrumental Variables (IV)**:
    -   Use a variable $W$ that affects treatment $Z$ but has **no direct effect** on $Y$, ensuring exogeneity.
    -   Example: Randomized incentives to encourage treatment uptake.
2.  **Difference-in-Differences (DiD)**:
    -   Compare changes in outcomes before and after treatment in a treated vs. control group.
    -   Requires a **parallel trends assumption**.
3.  **Regression Discontinuity (RD)**:
    -   Exploit cutoff-based treatment assignment.
    -   Example: Scholarship eligibility at a certain GPA threshold.
4.  **Propensity Score Methods**:
    -   Estimate the probability of treatment given $X$.
    -   Use **matching, inverse probability weighting (IPW), or stratification** to balance treatment groups.
5.  **Sensitivity Analysis**:
    -   Quantify how much unobserved confounding would be needed to alter conclusions.
    -   Example: **Rosenbaum's sensitivity bounds**.

------------------------------------------------------------------------

#### **Practical Considerations**

##### **How to Select Covariates** $X$?

-   **Domain Knowledge**: Consult experts to identify potential confounders.
-   **Causal Discovery Methods**: Use **Bayesian networks or structure learning** to infer relationships.
-   **Statistical Tests**: Examine balance in pre-treatment characteristics.

##### **Trade-Offs in Covariate Selection**

-   **Too Few Covariates** → Risk of **omitted variable bias**.
-   **Too Many Covariates** → **Overfitting**, loss of **efficiency** in estimation.

------------------------------------------------------------------------

### **Overlap (Positivity) Assumption**

Next, we assume that the probability of receiving treatment is strictly **greater than zero and less than one** over the support of the observed covariates $X_i$. This is known as the **overlap assumption**, also referred to as **common support** or **positivity**. Mathematically, this is written as:

$$
0 < P(Z_i = 1 \mid X_i) < 1, \quad \forall X_i.
$$

This ensures that for every possible value of $X_i$, there is **some** probability of receiving both treatment ($Z_i = 1$) and control ($Z_i = 0$). In other words, there must be **overlap** in the covariate distributions between treated and control units.

When **overlap is limited**, the **Average Treatment Effect (ATE)** may not be identifiable, even if the **Average Treatment effect on the Treated (ATT)** remains identifiable. In extreme cases, even ATT may not be identified due to severe lack of common support. In such situations, an alternative estimand can be used, such as the **Average Treatment Effect for the Overlap Population (ATO)**, which focuses on a **marginal population** where treatment is not deterministic [@li2018balancing].

------------------------------------------------------------------------

#### **Mathematical Formulation of Overlap**

The overlap assumption states that **for every possible value of the covariates** $X_i$, there exists some probability of being in both treatment groups. This prevents situations where treatment assignment is deterministic, which would make causal inference impossible.

Mathematically, overlap requires that:

$$
0 < P(Z_i = 1 \mid X_i) < 1 \quad \forall X_i.
$$

This means that:

1.  **Positivity Condition**: Every unit in the population has a **nonzero probability** of receiving treatment.
2.  **No Deterministic Treatment Assignment**: If $P(Z_i = 1 \mid X_i) = 0$ or $P(Z_i = 1 \mid X_i) = 1$ for some $X_i$, then the causal effect is **not identifiable** for those values of $X_i$.

In practical terms, if some subpopulations **always receive treatment** ($P(Z_i = 1 \mid X_i) = 1$) or **never receive treatment** ($P(Z_i = 1 \mid X_i) = 0$), then there is **no counterfactual** to compare against, making it impossible to estimate causal effects for those groups.

------------------------------------------------------------------------

#### **Implications of Violating the Overlap Assumption**

When the overlap assumption is violated, the identification of causal effects becomes problematic. Some key implications include:

1.  **Limited Generalizability of ATE**: If there is **poor overlap** in covariate distributions between treated and control units, the **Average Treatment Effect (ATE)** may not be identified.
2.  **ATT May Still Be Identifiable**: If **some** overlap exists but is limited, we may still be able to estimate the **Average Treatment Effect on the Treated (ATT)**.
3.  **Extreme Cases - No ATT Identification**: If **no** overlap exists between treated and control groups, even ATT may not be identified.
4.  **Extrapolation Bias**: In extreme cases, estimation relies on extrapolating from regions where overlap is weak, leading to **biased and unstable causal estimates**.

To illustrate, consider an observational study on the effect of an **education intervention** on academic performance. If **only students from high-income families** received the intervention ($P(Z = 1 \mid X) = 1$ for high income), then we cannot compare them to **low-income students** who never received the intervention ($P(Z = 1 \mid X) = 0$). This lack of common support prevents estimation of a valid treatment effect.

------------------------------------------------------------------------

#### **Diagnosing Overlap Violations in Practice**

Before estimating causal effects, it is crucial to assess whether the overlap assumption holds. Some common diagnostic tools include:

##### **Propensity Score Distribution**

A key approach is to **estimate the propensity score** $e(X) = P(Z = 1 \mid X)$ and visualize its distribution across treated and control units. A lack of overlap in propensity scores suggests that **some regions of** $X$ lack common support.

-   **Well-Mixed Propensity Score Distributions** → Good overlap, strong causal identification.
-   **Separated Propensity Score Distributions** → Poor overlap, potential issues with causal estimation.

##### **Standardized Mean Differences (SMD)**

Standardized mean differences compare the covariate distributions between treated and control groups. If large imbalances exist, overlap may be insufficient.

##### **Kernel Density Plots**

Plotting the kernel density of **propensity scores** can reveal whether both groups have sufficient representation across the distribution.

------------------------------------------------------------------------

#### **Strategies to Address Overlap Violations**

When overlap is weak, several strategies can be employed:

1.  **Trimming Non-Overlapping Units**
    -   Exclude observations with extreme propensity scores (e.g., those where $P(Z = 1 \mid X) \approx 0$ or $P(Z = 1 \mid X) \approx 1$).
    -   Improves robustness but reduces sample size.
2.  **Reweighting Approaches**
    -   Use **overlap weights** to emphasize the population where treatment assignment is not deterministic.
    -   The **Average Treatment Effect for the Overlap Population (ATO)** [29] estimates the effect for units where $P(Z = 1 \mid X)$ is close to 0.5.
3.  **Matching on the Propensity Score**
    -   Remove units without suitable matches from the opposite treatment group.
    -   Improves balance at the cost of excluding some observations.
4.  **Covariate Balancing Techniques**
    -   Use **entropy balancing** or **inverse probability weighting (IPW)** to adjust for limited overlap.
    -   Ensures that covariate distributions are similar across groups.
5.  **Sensitivity Analysis**
    -   Quantify how overlap violations affect causal conclusions.
    -   Example: **Rosenbaum's bounds for unmeasured confounding**.

------------------------------------------------------------------------

#### **The Average Treatment Effect for the Overlap Population**

When overlap is limited, one alternative is to estimate the **Average Treatment Effect for the Overlap Population (ATO)**. Unlike ATE, which targets the **entire population**, and ATT, which targets the **treated population**, ATO focuses on the **subset of units where treatment is not deterministic**.

Mathematically, ATO is estimated using **overlap weights**:

$$
W_i = P(Z_i = 1 \mid X_i) (1 - P(Z_i = 1 \mid X_i)).
$$

This **downweights extreme propensity scores** and ensures that inference is focused on a population where treatment was plausibly **assignable in both directions**. ATO is particularly useful when **generalizability is a concern** or when **extrapolation is unreliable**.

------------------------------------------------------------------------

## Natural Experiments

Reusing the same natural experiments for research, particularly when employing identical methods to determine the treatment effect in a given setting, can pose problems for hypothesis testing.

Simulations show that when $N_{\text{Outcome}} >> N_{\text{True effect}}$, more than 50% of statistically significant findings may be false positives [@heath2023reusing, p.2331].

**Solutions:**

-   Bonferroni correction

-   @romano2005stepwise and @romano2016efficient correction: recommended

-   @benjamini2001control correction

-   Alternatively, refer to the rules of thumb from Table AI [@heath2023reusing, p.2356].

When applying multiple testing corrections, we can either use (but they will give similar results anyway [@heath2023reusing, p.2335]):

1.  **Chronological Sequencing**: Outcomes are ordered by the date they were first reported, with multiple testing corrections applied in this sequence. This method progressively raises the statistical significance threshold as more outcomes are reviewed over time.

2.  **Best Foot Forward Policy**: Outcomes are ordered from most to least likely to be rejected based on experimental data. Used primarily in clinical trials, this approach gives priority to intended treatment effects, which are subjected to less stringent statistical requirements. New outcomes are added to the sequence as they are linked to the primary treatment effect.

```{r, warning=FALSE}
# Romano-Wolf correction
library(fixest)
library(wildrwolf)

head(iris)

fit1 <- feols(Sepal.Width ~ Sepal.Length , data = iris)
fit2 <- feols(Petal.Length ~ Sepal.Length, data = iris)
fit3 <- feols(Petal.Width ~ Sepal.Length, data = iris)

res <- rwolf(
  models = list(fit1, fit2, fit3), 
  param = "Sepal.Length",  
  B = 500
)

res
```

For all other tests, one can use `multtest::mt.rawp2adjp` which includes:

-   Bonferroni
-   @holm1979simple
-   @vsidak1967rectangular
-   @hochberg1988sharper
-   @benjamini1995controlling
-   @benjamini2001control
-   Adaptive @benjamini2000adaptive
-   Two-stage @benjamini2006adaptive

Permutation adjusted p-values for simple multiple testing procedures

```{r}
# BiocManager::install("multtest")
library(multtest)

procs <-
    c("Bonferroni",
      "Holm",
      "Hochberg",
      "SidakSS",
      "SidakSD",
      "BH",
      "BY",
      "ABH",
      "TSBH")

mt.rawp2adjp(
    # p-values
    runif(10),
    procs) |> causalverse::nice_tab()
```
