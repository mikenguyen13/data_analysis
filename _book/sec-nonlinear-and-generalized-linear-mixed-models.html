<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Nonlinear and Generalized Linear Mixed Models | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="Nonlinear Mixed Models (NLMMs) and Generalized Linear Mixed Models (GLMMs) extend traditional models by incorporating both fixed effects and random effects, allowing for greater flexibility in...">
<meta name="generator" content="bookdown 0.35 with bs4_book()">
<meta property="og:title" content="Chapter 9 Nonlinear and Generalized Linear Mixed Models | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/sec-nonlinear-and-generalized-linear-mixed-models.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="Nonlinear Mixed Models (NLMMs) and Generalized Linear Mixed Models (GLMMs) extend traditional models by incorporating both fixed effects and random effects, allowing for greater flexibility in...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 9 Nonlinear and Generalized Linear Mixed Models | A Guide on Data Analysis">
<meta name="twitter:description" content="Nonlinear Mixed Models (NLMMs) and Generalized Linear Mixed Models (GLMMs) extend traditional models by incorporating both fixed effects and random effects, allowing for greater flexibility in...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="active" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="controls.html"><span class="header-section-number">38</span> Controls</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">39</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="sec-nonlinear-and-generalized-linear-mixed-models" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models<a class="anchor" aria-label="anchor" href="#sec-nonlinear-and-generalized-linear-mixed-models"><i class="fas fa-link"></i></a>
</h1>
<p>Nonlinear Mixed Models (NLMMs) and Generalized Linear Mixed Models (GLMMs) extend traditional models by incorporating both fixed effects and random effects, allowing for greater flexibility in modeling complex data structures.</p>
<ul>
<li>NLMMs extend nonlinear models to include both fixed and random effects, accommodating nonlinear relationships in the data.</li>
<li>GLMMs extend generalized linear models to include random effects, allowing for correlated data and non-constant variance structures.</li>
</ul>
<hr>
<div id="sec-nonlinear-mixed-models" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Nonlinear Mixed Models<a class="anchor" aria-label="anchor" href="#sec-nonlinear-mixed-models"><i class="fas fa-link"></i></a>
</h2>
<p>A general form of a nonlinear mixed model is:</p>
<p><span class="math display">\[
Y_{ij} = f(\mathbf{x}_{ij}, \boldsymbol{\theta}, \boldsymbol{\alpha}_i) + \epsilon_{ij}
\]</span></p>
<p>for the <span class="math inline">\(j\)</span>-th response from the <span class="math inline">\(i\)</span>-th cluster (or subject), where:</p>
<ul>
<li>
<span class="math inline">\(i = 1, \ldots, n\)</span> (number of clusters/subjects),</li>
<li>
<span class="math inline">\(j = 1, \ldots, n_i\)</span> (number of observations per cluster),</li>
<li>
<span class="math inline">\(\boldsymbol{\theta}\)</span> represents the fixed effects,</li>
<li>
<span class="math inline">\(\boldsymbol{\alpha}_i\)</span> are the random effects for cluster <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(\mathbf{x}_{ij}\)</span> are the regressors or design variables,</li>
<li>
<span class="math inline">\(f(\cdot)\)</span> is a nonlinear mean response function,</li>
<li>
<span class="math inline">\(\epsilon_{ij}\)</span> represents the residual error, often assumed to be normally distributed with mean 0.</li>
</ul>
<p>NLMMs are particularly useful when the relationship between predictors and the response cannot be adequately captured by a linear model.</p>
<hr>
</div>
<div id="sec-generalized-linear-mixed-models" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Generalized Linear Mixed Models<a class="anchor" aria-label="anchor" href="#sec-generalized-linear-mixed-models"><i class="fas fa-link"></i></a>
</h2>
<p>GLMMs extend GLMs by incorporating random effects, which allows for modeling data with hierarchical or clustered structures.</p>
<p>The conditional distribution of <span class="math inline">\(y_i\)</span> given the random effects <span class="math inline">\(\boldsymbol{\alpha}_i\)</span> is:</p>
<p><span class="math display">\[
y_i \mid \boldsymbol{\alpha}_i \sim \text{independent } f(y_i \mid \boldsymbol{\alpha})
\]</span></p>
<p>where <span class="math inline">\(f(y_i \mid \boldsymbol{\alpha})\)</span> belongs to the exponential family of distributions:</p>
<p><span class="math display">\[
f(y_i \mid \boldsymbol{\alpha}) = \exp \left( \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} - c(y_i, \phi) \right)
\]</span></p>
<ul>
<li>
<span class="math inline">\(\theta_i\)</span> is the canonical parameter,</li>
<li>
<span class="math inline">\(a(\phi)\)</span> is a dispersion parameter,</li>
<li>
<span class="math inline">\(b(\theta_i)\)</span> and <span class="math inline">\(c(y_i, \phi)\)</span> are specific functions defining the exponential family.</li>
</ul>
<p>The conditional mean of <span class="math inline">\(y_i\)</span> is related to <span class="math inline">\(\theta_i\)</span> by:</p>
<p><span class="math display">\[
\mu_i = \frac{\partial b(\theta_i)}{\partial \theta_i}
\]</span></p>
<p>Applying a link function <span class="math inline">\(g(\cdot)\)</span>, we relate the mean response to both fixed and random effects:</p>
<p><span class="math display">\[
\begin{aligned}
E(y_i \mid \boldsymbol{\alpha}) &amp;= \mu_i \\
g(\mu_i) &amp;= \mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha}
\end{aligned}
\]</span></p>
<ul>
<li>
<span class="math inline">\(g(\cdot)\)</span> is a known link function,</li>
<li>
<span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(\mathbf{z}_i\)</span> are design matrices for fixed and random effects, respectively,</li>
<li>
<span class="math inline">\(\boldsymbol{\beta}\)</span> represents fixed effects, and <span class="math inline">\(\boldsymbol{\alpha}\)</span> represents random effects.</li>
</ul>
<p>We also specify the distribution of the random effects:</p>
<p><span class="math display">\[
\boldsymbol{\alpha} \sim f(\boldsymbol{\alpha})
\]</span></p>
<p>This distribution is often assumed to be multivariate normal (Law of large Number applies to fixed effects) but can be chosen (subjectively) based on the context.</p>
<hr>
</div>
<div id="relationship-between-nlmms-and-glmms" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Relationship Between NLMMs and GLMMs<a class="anchor" aria-label="anchor" href="#relationship-between-nlmms-and-glmms"><i class="fas fa-link"></i></a>
</h2>
<p>NLMMs can be viewed as a special case of GLMMs when the inverse link function corresponds to a nonlinear transformation of the linear predictor:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_i &amp;= \mathbf{f}(\mathbf{x}_i, \boldsymbol{\theta}, \boldsymbol{\alpha}_i) + \boldsymbol{\epsilon}_i \\
\mathbf{Y}_i &amp;= g^{-1}(\mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha}_i) + \boldsymbol{\epsilon}_i
\end{aligned}
\]</span></p>
<p>Here, <span class="math inline">\(g^{-1}(\cdot)\)</span> represents the inverse link function, corresponding to a nonlinear transformation of the fixed and random effects.</p>
<p>Note:<br>
We can’t derive the analytical formulation of the marginal distribution because nonlinear combination of normal variables is not normally distributed, even in the case of additive error (<span class="math inline">\(\epsilon_i\)</span>) and random effects (<span class="math inline">\(\alpha_i\)</span>) are both normal.</p>
<hr>
</div>
<div id="marginal-properties-of-glmms" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Marginal Properties of GLMMs<a class="anchor" aria-label="anchor" href="#marginal-properties-of-glmms"><i class="fas fa-link"></i></a>
</h2>
<div id="marginal-mean-of-y_i" class="section level3" number="9.4.1">
<h3>
<span class="header-section-number">9.4.1</span> Marginal Mean of <span class="math inline">\(y_i\)</span><a class="anchor" aria-label="anchor" href="#marginal-mean-of-y_i"><i class="fas fa-link"></i></a>
</h3>
<p>The marginal mean is obtained by integrating over the distribution of the random effects:</p>
<p><span class="math display">\[
E(y_i) = E_{\boldsymbol{\alpha}}(E(y_i \mid \boldsymbol{\alpha})) = E_{\boldsymbol{\alpha}}(\mu_i) = E\left(g^{-1}(\mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha})\right)
\]</span></p>
<p>Since <span class="math inline">\(g^{-1}(\cdot)\)</span> is nonlinear, this expectation cannot be simplified further without specific distributional assumptions.</p>
<div id="special-case-log-link-function" class="section level4" number="9.4.1.1">
<h4>
<span class="header-section-number">9.4.1.1</span> Special Case: Log Link Function<a class="anchor" aria-label="anchor" href="#special-case-log-link-function"><i class="fas fa-link"></i></a>
</h4>
<p>For a log-link function, <span class="math inline">\(g(\mu) = \log(\mu)\)</span>, the inverse link is the exponential function:</p>
<p><span class="math display">\[
E(y_i) = E\left(\exp(\mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha})\right)
\]</span></p>
<p>Using properties of the moment-generating function (MGF):</p>
<p><span class="math display">\[
E(y_i) = \exp(\mathbf{x}_i' \boldsymbol{\beta}) \cdot E\left(\exp(\mathbf{z}_i' \boldsymbol{\alpha})\right)
\]</span></p>
<p>Here, <span class="math inline">\(E(\exp(\mathbf{z}_i' \boldsymbol{\alpha}))\)</span> is the MGF of <span class="math inline">\(\boldsymbol{\alpha}\)</span> evaluated at <span class="math inline">\(\mathbf{z}_i\)</span>.</p>
<hr>
</div>
</div>
<div id="marginal-variance-of-y_i" class="section level3" number="9.4.2">
<h3>
<span class="header-section-number">9.4.2</span> Marginal Variance of <span class="math inline">\(y_i\)</span><a class="anchor" aria-label="anchor" href="#marginal-variance-of-y_i"><i class="fas fa-link"></i></a>
</h3>
<p>The variance decomposition formula applies:</p>
<p><span class="math display">\[
\begin{aligned}
\operatorname{Var}(y_i) &amp;= \operatorname{Var}_{\boldsymbol{\alpha}}\left(E(y_i \mid \boldsymbol{\alpha})\right) + E_{\boldsymbol{\alpha}}\left(\operatorname{Var}(y_i \mid \boldsymbol{\alpha})\right) \\
&amp;= \operatorname{Var}(\mu_i) + E\left(a(\phi) V(\mu_i)\right)
\end{aligned}
\]</span></p>
<p>Expressed explicitly:</p>
<p><span class="math display">\[
\operatorname{Var}(y_i) = \operatorname{Var}\left(g^{-1}(\mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha})\right) + E\left(a(\phi) V\left(g^{-1}(\mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha})\right)\right)
\]</span></p>
<p>Without specific assumptions about <span class="math inline">\(g(\cdot)\)</span> and the distribution of <span class="math inline">\(\boldsymbol{\alpha}\)</span>, this is the most general form.</p>
<hr>
</div>
<div id="marginal-covariance-of-mathbfy" class="section level3" number="9.4.3">
<h3>
<span class="header-section-number">9.4.3</span> Marginal Covariance of <span class="math inline">\(\mathbf{y}\)</span><a class="anchor" aria-label="anchor" href="#marginal-covariance-of-mathbfy"><i class="fas fa-link"></i></a>
</h3>
<p>Random effects induce correlation between observations within the same cluster. The covariance between <span class="math inline">\(y_i\)</span> and <span class="math inline">\(y_j\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
\operatorname{Cov}(y_i, y_j) &amp;= \operatorname{Cov}_{\boldsymbol{\alpha}}\left(E(y_i \mid \boldsymbol{\alpha}), E(y_j \mid \boldsymbol{\alpha})\right) + E_{\boldsymbol{\alpha}}\left(\operatorname{Cov}(y_i, y_j \mid \boldsymbol{\alpha})\right) \\
&amp;= \operatorname{Cov}(\mu_i, \mu_j) + E(0) \\
&amp;= \operatorname{Cov}\left(g^{-1}(\mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha}), g^{-1}(\mathbf{x}_j' \boldsymbol{\beta} + \mathbf{z}_j' \boldsymbol{\alpha})\right)
\end{aligned}
\]</span></p>
<p>The second term vanishes when <span class="math inline">\(y_i\)</span> and <span class="math inline">\(y_j\)</span> are conditionally independent given <span class="math inline">\(\boldsymbol{\alpha}\)</span>. This dependency structure is a hallmark of mixed models.</p>
<hr>
<p>Example: Repeated Measurements with a Poisson GLMM</p>
<p>Consider repeated count measurements for subjects:</p>
<ul>
<li>Let <span class="math inline">\(y_{ij}\)</span> be the <span class="math inline">\(j\)</span>-th count for subject <span class="math inline">\(i\)</span>.</li>
<li>Assume <span class="math inline">\(y_{ij} \mid \alpha_i \sim \text{independent } \text{Poisson}(\mu_{ij})\)</span>.</li>
</ul>
<p>The model is specified as:</p>
<p><span class="math display">\[
\log(\mu_{ij}) = \mathbf{x}_{ij}' \boldsymbol{\beta} + \alpha_i
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\alpha_i \sim \text{i.i.d. } N(0, \sigma^2_{\alpha})\)</span> represents subject-specific random effects,</li>
<li>This is a log-link GLMM with random intercepts for subjects.</li>
</ul>
<p>The inclusion of <span class="math inline">\(\alpha_i\)</span> accounts for subject-level heterogeneity, capturing unobserved variability across individuals.</p>
<hr>
</div>
</div>
<div id="estimation-in-nonlinear-and-generalized-linear-mixed-models" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> Estimation in Nonlinear and Generalized Linear Mixed Models<a class="anchor" aria-label="anchor" href="#estimation-in-nonlinear-and-generalized-linear-mixed-models"><i class="fas fa-link"></i></a>
</h2>
<p>In <a href="sec-linear-mixed-models.html#sec-linear-mixed-models">Linear Mixed Models</a>, the marginal likelihood of the observed data <span class="math inline">\(\mathbf{y}\)</span> is derived by integrating out the random effects from the hierarchical formulation:</p>
<p><span class="math display">\[
f(\mathbf{y}) = \int f(\mathbf{y} \mid \boldsymbol{\alpha}) \, f(\boldsymbol{\alpha}) \, d\boldsymbol{\alpha}
\]</span></p>
<p>For LMMs, both component distributions—</p>
<ul>
<li><p>the conditional distribution <span class="math inline">\(f(\mathbf{y} \mid \boldsymbol{\alpha})\)</span>, and</p></li>
<li><p>the random effects distribution <span class="math inline">\(f(\boldsymbol{\alpha})\)</span>—</p></li>
</ul>
<p>are typically assumed to be Gaussian with linear relationships. These assumptions imply that the marginal distribution of <span class="math inline">\(\mathbf{y}\)</span> is also Gaussian, allowing the integral to be solved analytically using properties of the multivariate normal distribution.</p>
<p>In contrast:</p>
<ul>
<li><p>For GLMMs, the conditional distribution <span class="math inline">\(f(\mathbf{y} \mid \boldsymbol{\alpha})\)</span> belongs to the exponential family but is not Gaussian in general.</p></li>
<li><p>For NLMMs, the relationship between the mean response and the random (and fixed) effects is nonlinear, complicating the integral.</p></li>
</ul>
<p>In both cases, the marginal likelihood integral:</p>
<p><span class="math display">\[
L(\boldsymbol{\beta}; \mathbf{y}) = \int f(\mathbf{y} \mid \boldsymbol{\alpha}) \, f(\boldsymbol{\alpha}) \, d\boldsymbol{\alpha}
\]</span></p>
<p>cannot be solved analytically. Consequently, estimation requires:</p>
<ul>
<li><a href="sec-nonlinear-and-generalized-linear-mixed-models.html#estimation-by-numerical-integration">Numerical Integration</a></li>
<li>Linearization of the Model</li>
<li>
</ul>
<hr>
<div id="estimation-by-numerical-integration" class="section level3" number="9.5.1">
<h3>
<span class="header-section-number">9.5.1</span> Estimation by Numerical Integration<a class="anchor" aria-label="anchor" href="#estimation-by-numerical-integration"><i class="fas fa-link"></i></a>
</h3>
<p>The marginal likelihood for parameter estimation is given by:</p>
<p><span class="math display">\[
L(\boldsymbol{\beta}; \mathbf{y}) = \int f(\mathbf{y} \mid \boldsymbol{\alpha}) \, f(\boldsymbol{\alpha}) \, d\boldsymbol{\alpha}
\]</span></p>
<p>To estimate the fixed effects <span class="math inline">\(\boldsymbol{\beta}\)</span>, we often maximize the log-likelihood:</p>
<p><span class="math display">\[
\ell(\boldsymbol{\beta}) = \log L(\boldsymbol{\beta}; \mathbf{y})
\]</span></p>
<p>Optimization requires the score function (gradient):</p>
<p><span class="math display">\[
\frac{\partial \ell(\boldsymbol{\beta})}{\partial \boldsymbol{\beta}}
\]</span></p>
<p>Since the integral in <span class="math inline">\(L(\boldsymbol{\beta}; \mathbf{y})\)</span> is generally intractable, we rely on numerical techniques to approximate it.</p>
<hr>
<div id="methods-for-numerical-integration" class="section level4" number="9.5.1.1">
<h4>
<span class="header-section-number">9.5.1.1</span> Methods for Numerical Integration<a class="anchor" aria-label="anchor" href="#methods-for-numerical-integration"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<p>Gaussian Quadrature</p>
<ul>
<li>Suitable for low-dimensional random effects (<span class="math inline">\(\dim(\boldsymbol{\alpha})\)</span> is small).</li>
<li>Approximates the integral using weighted sums of function evaluations at specific points (nodes).</li>
<li>Gauss-Hermite quadrature is commonly used when random effects are normally distributed.</li>
</ul>
<p>Limitation: Computational cost grows exponentially with the dimension of <span class="math inline">\(\boldsymbol{\alpha}\)</span> (curse of dimensionality).</p>
</li>
<li>
<p>Laplace Approximation</p>
<ul>
<li>Approximates the integral by expanding the log-likelihood around the mode of the integrand (i.e., the most likely value of <span class="math inline">\(\boldsymbol{\alpha}\)</span>).</li>
<li>Provides accurate results for moderate-sized random effects and large sample sizes.</li>
<li>First-order Laplace approximation is commonly used; higher-order versions improve accuracy but increase complexity.</li>
</ul>
<p>Key Idea: Approximate the integral as:</p>
<p><span class="math display">\[
\int e^{h(\boldsymbol{\alpha})} d\boldsymbol{\alpha} \approx e^{h(\hat{\boldsymbol{\alpha}})} \sqrt{\frac{(2\pi)^q}{|\mathbf{H}|}}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span> is the mode of <span class="math inline">\(h(\boldsymbol{\alpha})\)</span>,</li>
<li>
<span class="math inline">\(\mathbf{H}\)</span> is the Hessian matrix of second derivatives at <span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span>,</li>
<li>
<span class="math inline">\(q\)</span> is the dimension of <span class="math inline">\(\boldsymbol{\alpha}\)</span>.</li>
</ul>
</li>
<li>
<p>Monte Carlo Integration</p>
<ul>
<li>Uses random sampling to approximate the integral.</li>
<li>Importance Sampling improves efficiency by sampling from a distribution that better matches the integrand.</li>
<li>Markov Chain Monte Carlo methods, such as Gibbs sampling or Metropolis-Hastings, are used when the posterior distribution is complex.</li>
</ul>
<p>Advantage: Scales better with high-dimensional random effects compared to quadrature methods.</p>
<p>Limitation: Computationally intensive, and variance of estimates can be high without careful tuning.</p>
</li>
</ol>
<hr>
</div>
<div id="choosing-an-integration-method" class="section level4" number="9.5.1.2">
<h4>
<span class="header-section-number">9.5.1.2</span> Choosing an Integration Method<a class="anchor" aria-label="anchor" href="#choosing-an-integration-method"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="24%">
<col width="26%">
<col width="24%">
<col width="24%">
</colgroup>
<thead><tr class="header">
<th align="left">Method</th>
<th align="left">Dimensionality</th>
<th align="left">Accuracy</th>
<th align="left">Computational Cost</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Gaussian Quadrature</td>
<td align="left">Low-dimensional (<span class="math inline">\(q \leq 3\)</span>)</td>
<td align="left">High (with sufficient nodes)</td>
<td align="left">High (exponential growth with <span class="math inline">\(q\)</span>)</td>
</tr>
<tr class="even">
<td align="left">Laplace Approximation</td>
<td align="left">Moderate-dimensional</td>
<td align="left">Moderate to High</td>
<td align="left">Moderate</td>
</tr>
<tr class="odd">
<td align="left">Monte Carlo Methods</td>
<td align="left">High-dimensional</td>
<td align="left">Variable (depends on sample size)</td>
<td align="left">High (but scalable)</td>
</tr>
</tbody>
</table></div>
<ul>
<li>For small random effect dimensions, quadrature methods are effective.</li>
<li>For moderate dimensions, Laplace approximation offers a good balance.</li>
<li>For high dimensions or complex models, Monte Carlo techniques are often the method of choice.</li>
</ul>
<hr>
</div>
</div>
<div id="sec-estimation-by-linearization-glmm" class="section level3" number="9.5.2">
<h3>
<span class="header-section-number">9.5.2</span> Estimation by Linearization<a class="anchor" aria-label="anchor" href="#sec-estimation-by-linearization-glmm"><i class="fas fa-link"></i></a>
</h3>
<p>When estimating parameters in <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-nonlinear-mixed-models">NLMMs</a> and <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-generalized-linear-mixed-models">GLMMs</a>, one common and effective approach is linearization. This technique approximates the nonlinear or non-Gaussian components with linear counterparts, enabling the use of standard LMM estimation methods. Linearization not only simplifies the estimation process but also allows for leveraging well-established statistical tools and methods developed for linear models.</p>
<div id="concept-of-linearization" class="section level4" number="9.5.2.1">
<h4>
<span class="header-section-number">9.5.2.1</span> Concept of Linearization<a class="anchor" aria-label="anchor" href="#concept-of-linearization"><i class="fas fa-link"></i></a>
</h4>
<p>The core idea is to create a linearized version of the response variable, known as the <em>working response</em> or <em>pseudo-response</em>, denoted as <span class="math inline">\(\tilde{y}_i\)</span>. This pseudo-response is designed to approximate the original nonlinear relationship in a linear form, facilitating easier estimation of model parameters. The conditional mean of this pseudo-response is expressed as:</p>
<p><span class="math display">\[
E(\tilde{y}_i \mid \boldsymbol{\alpha}) = \mathbf{x}_i' \boldsymbol{\beta} + \mathbf{z}_i' \boldsymbol{\alpha}
\]</span></p>
<p>Here:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{x}_i\)</span> is the design matrix for fixed effects,</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}\)</span> represents the fixed effect parameters,</p></li>
<li><p><span class="math inline">\(\mathbf{z}_i\)</span> is the design matrix for random effects,</p></li>
<li><p><span class="math inline">\(\boldsymbol{\alpha}\)</span> denotes the random effects.</p></li>
</ul>
<p>In addition to the conditional mean, it is essential to estimate the conditional variance of the pseudo-response to fully characterize the linearized model:</p>
<p><span class="math display">\[
\operatorname{Var}(\tilde{y}_i \mid \boldsymbol{\alpha})
\]</span></p>
<p>This variance estimation ensures that the model accounts for the inherent variability in the data, maintaining the integrity of statistical inferences.</p>
</div>
<div id="application-of-linearization" class="section level4" number="9.5.2.2">
<h4>
<span class="header-section-number">9.5.2.2</span> Application of Linearization<a class="anchor" aria-label="anchor" href="#application-of-linearization"><i class="fas fa-link"></i></a>
</h4>
<p>Once linearized, the model structure closely resembles that of a <a href="(#sec-linear-mixed-models)">linear mixed model</a>, allowing us to apply standard estimation techniques from <a href="sec-linear-mixed-models.html#sec-linear-mixed-models">LMMs</a>. These techniques include methods such as MLE and REML, which are computationally efficient and statistically robust.</p>
<p>The primary difference between various linearization-based methods lies in how the linearization is performed. This often involves expanding the nonlinear function <span class="math inline">\(f(\mathbf{x}, \boldsymbol{\theta}, \boldsymbol{\alpha})\)</span> or the inverse link function <span class="math inline">\(g^{-1}(\cdot)\)</span>. The goal is to approximate these complex functions with simpler linear expressions while retaining as much of the original model’s characteristics as possible.</p>
<div id="taylor-series-expansion" class="section level5" number="9.5.2.2.1">
<h5>
<span class="header-section-number">9.5.2.2.1</span> Taylor Series Expansion<a class="anchor" aria-label="anchor" href="#taylor-series-expansion"><i class="fas fa-link"></i></a>
</h5>
<p>A widely used method for linearization is the Taylor series expansion. This approach approximates the nonlinear mean function around initial estimates of the random effects. The first-order Taylor series expansion of the nonlinear function is given by:</p>
<p><span class="math display">\[
f(\mathbf{x}_{ij}, \boldsymbol{\theta}, \boldsymbol{\alpha}_i) \approx f(\mathbf{x}_{ij}, \boldsymbol{\theta}, \hat{\boldsymbol{\alpha}}_i) + \frac{\partial f}{\partial \boldsymbol{\alpha}_i} \bigg|_{\hat{\boldsymbol{\alpha}}_i} (\boldsymbol{\alpha}_i - \hat{\boldsymbol{\alpha}}_i)
\]</span></p>
<p>In this expression:</p>
<ul>
<li><p><span class="math inline">\(f(\mathbf{x}_{ij}, \boldsymbol{\theta}, \hat{\boldsymbol{\alpha}}_i)\)</span> is the function evaluated at the initial estimates of the random effects <span class="math inline">\(\hat{\boldsymbol{\alpha}}_i\)</span>,</p></li>
<li><p><span class="math inline">\(\frac{\partial f}{\partial \boldsymbol{\alpha}_i} \big|_{\hat{\boldsymbol{\alpha}}_i}\)</span> represents the gradient (or derivative) of the function with respect to the random effects, evaluated at <span class="math inline">\(\hat{\boldsymbol{\alpha}}_i\)</span>,</p></li>
<li><p><span class="math inline">\((\boldsymbol{\alpha}_i - \hat{\boldsymbol{\alpha}}_i)\)</span> captures the deviation from the initial estimates.</p></li>
</ul>
<p>The initial estimates <span class="math inline">\(\hat{\boldsymbol{\alpha}}_i\)</span> are often set to zero for simplicity, especially in the early stages of model fitting. This approximation reduces the model to a linear form, making it amenable to standard LMM estimation techniques.</p>
</div>
<div id="advantages-and-considerations" class="section level5" number="9.5.2.2.2">
<h5>
<span class="header-section-number">9.5.2.2.2</span> Advantages and Considerations<a class="anchor" aria-label="anchor" href="#advantages-and-considerations"><i class="fas fa-link"></i></a>
</h5>
<p>Linearization offers several advantages:</p>
<ol style="list-style-type: decimal">
<li>Simplified Computation: By transforming complex nonlinear relationships into linear forms, linearization reduces computational complexity.</li>
<li>Flexibility: Despite the simplification, linearized models retain the ability to capture key features of the original data structure.</li>
<li>Statistical Robustness: The use of established LMM estimation techniques ensures robust parameter estimation.</li>
</ol>
<p>However, linearization also comes with considerations:</p>
<ul>
<li><p>Approximation Error: The accuracy of the linearized model depends on how well the linear approximation captures the original nonlinear relationship.</p></li>
<li><p>Choice of Expansion Point: The selection of initial estimates <span class="math inline">\(\hat{\boldsymbol{\alpha}}_i\)</span> can influence the quality of the approximation.</p></li>
<li><p>Higher-Order Terms: In cases where the first-order approximation is insufficient, higher-order Taylor series terms may be needed, increasing model complexity.</p></li>
</ul>
<hr>
</div>
</div>
<div id="penalized-quasi-likelihood" class="section level4" number="9.5.2.3">
<h4>
<span class="header-section-number">9.5.2.3</span> Penalized Quasi-Likelihood<a class="anchor" aria-label="anchor" href="#penalized-quasi-likelihood"><i class="fas fa-link"></i></a>
</h4>
<p>Penalized Quasi-Likelihood (PQL) is one of the most popular linearization-based estimation methods for <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-generalized-linear-mixed-models">GLMMs</a>.</p>
<p>The linearization is achieved through a first-order Taylor expansion of the inverse link function around current estimates of the parameters. The working response at the <span class="math inline">\(k\)</span>-th iteration is given by:</p>
<p><span class="math display">\[
\tilde{y}_i^{(k)} = \hat{\eta}_i^{(k-1)} + \left(y_i - \hat{\mu}_i^{(k-1)}\right) \cdot \left.\frac{d \eta}{d \mu}\right|_{\hat{\eta}_i^{(k-1)}}
\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(\eta_i = g(\mu_i)\)</span> is the linear predictor,<br>
</li>
<li>
<span class="math inline">\(\hat{\eta}_i^{(k-1)}\)</span> and <span class="math inline">\(\hat{\mu}_i^{(k-1)}\)</span> are the estimates from the previous iteration <span class="math inline">\((k-1)\)</span>,<br>
</li>
<li>
<span class="math inline">\(g(\cdot)\)</span> is the link function, and <span class="math inline">\(\mu_i = g^{-1}(\eta_i)\)</span>.</li>
</ul>
<p>PQL Estimation Algorithm</p>
<ol style="list-style-type: decimal">
<li><p>Initialization:<br>
Start with initial estimates of <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}\)</span> (commonly set to zeros).</p></li>
<li><p>Compute the Working Response:<br>
Use the formula above to compute <span class="math inline">\(\tilde{y}_i^{(k)}\)</span> based on current parameter estimates.</p></li>
<li><p>Fit a <a href="sec-linear-mixed-models.html#sec-linear-mixed-models">Linear Mixed Model</a>:<br>
Apply standard LMM estimation techniques to the pseudo-response <span class="math inline">\(\tilde{y}_i^{(k)}\)</span> to update estimates of <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{\alpha}\)</span>.</p></li>
<li><p>Update Variance Components:<br>
Estimate <span class="math inline">\(\operatorname{Var}(\tilde{y}_i \mid \boldsymbol{\alpha})\)</span> based on updated parameter estimates.</p></li>
<li><p>Iteration:<br>
Repeat steps 2–4 until the estimates converge.</p></li>
</ol>
<p>Comments on PQL:</p>
<ul>
<li>Advantages:
<ul>
<li>Easy to implement using existing LMM software.</li>
<li>Fast convergence for many practical datasets.</li>
</ul>
</li>
<li>Limitations:
<ul>
<li>Inference is only asymptotically correct due to the linearization approximation.</li>
<li>Biased estimates are common, especially:
<ul>
<li>For binomial responses with small group sizes,</li>
<li>In Bernoulli models (worst-case scenario),</li>
<li>In Poisson models with small counts. <span class="citation">(<a href="references.html#ref-faraway2016extending">Faraway 2016</a>)</span>
</li>
</ul>
</li>
<li>Hypothesis testing and confidence intervals can be unreliable.</li>
</ul>
</li>
</ul>
<hr>
</div>
<div id="generalized-estimating-equations" class="section level4" number="9.5.2.4">
<h4>
<span class="header-section-number">9.5.2.4</span> Generalized Estimating Equations<a class="anchor" aria-label="anchor" href="#generalized-estimating-equations"><i class="fas fa-link"></i></a>
</h4>
<p>Generalized Estimating Equations (GEE) offer an alternative approach to parameter estimation in models with correlated data, particularly for marginal models where the focus is on population-averaged effects rather than subject-specific effects.</p>
<p>GEE estimates are obtained by solving estimating equations rather than maximizing a likelihood function.</p>
<p>Consider a marginal generalized linear model:</p>
<p><span class="math display">\[
\operatorname{logit}(E(\mathbf{y})) = \mathbf{X} \boldsymbol{\beta}
\]</span></p>
<p>Assuming a working covariance matrix <span class="math inline">\(\mathbf{V}\)</span> for the elements of <span class="math inline">\(\mathbf{y}\)</span>, the estimating equation for <span class="math inline">\(\boldsymbol{\beta}\)</span> is:</p>
<p><span class="math display">\[
\mathbf{X}' \mathbf{V}^{-1} (\mathbf{y} - E(\mathbf{y})) = 0
\]</span></p>
<p>If <span class="math inline">\(\mathbf{V}\)</span> correctly specifies the covariance structure, the estimator is unbiased. In practice, we often assume a simple structure (e.g., independence) and obtain robust standard errors even when the covariance is misspecified.</p>
<hr>
<div id="gee-for-repeated-measures" class="section level5" number="9.5.2.4.1">
<h5>
<span class="header-section-number">9.5.2.4.1</span> GEE for Repeated Measures<a class="anchor" aria-label="anchor" href="#gee-for-repeated-measures"><i class="fas fa-link"></i></a>
</h5>
<p>Let <span class="math inline">\(y_{ij}\)</span> denote the <span class="math inline">\(j\)</span>-th measurement on the <span class="math inline">\(i\)</span>-th subject, with:</p>
<p><span class="math display">\[
\mathbf{y}_i =
\begin{pmatrix}
y_{i1} \\
\vdots \\
y_{in_i}
\end{pmatrix},
\quad
\boldsymbol{\mu}_i =
\begin{pmatrix}
\mu_{i1} \\
\vdots \\
\mu_{in_i}
\end{pmatrix},
\quad
\mathbf{x}_{ij} =
\begin{pmatrix}
X_{ij1} \\
\vdots \\
X_{ijp}
\end{pmatrix}
\]</span></p>
<p>Define the working covariance matrix of <span class="math inline">\(\mathbf{y}_i\)</span> as:</p>
<p><span class="math display">\[
\mathbf{V}_i = \operatorname{Cov}(\mathbf{y}_i)
\]</span></p>
<p>Following <span class="citation">(<a href="references.html#ref-liang1986longitudinal">Liang and Zeger 1986</a>)</span>, the GEE for estimating <span class="math inline">\(\boldsymbol{\beta}\)</span> is:</p>
<p><span class="math display">\[
S(\boldsymbol{\beta}) = \sum_{i=1}^K \frac{\partial \boldsymbol{\mu}_i'}{\partial \boldsymbol{\beta}} \, \mathbf{V}_i^{-1} (\mathbf{y}_i - \boldsymbol{\mu}_i) = 0
\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(K\)</span> is the number of subjects (or clusters),</p></li>
<li><p><span class="math inline">\(\boldsymbol{\mu}_i = E(\mathbf{y}_i)\)</span>,</p></li>
<li><p><span class="math inline">\(\mathbf{V}_i\)</span> is the working covariance matrix.</p></li>
</ul>
<hr>
</div>
<div id="working-correlation-structures" class="section level5" number="9.5.2.4.2">
<h5>
<span class="header-section-number">9.5.2.4.2</span> Working Correlation Structures<a class="anchor" aria-label="anchor" href="#working-correlation-structures"><i class="fas fa-link"></i></a>
</h5>
<p>The covariance matrix <span class="math inline">\(\mathbf{V}_i\)</span> is modeled as:</p>
<p><span class="math display">\[
\mathbf{V}_i = a(\phi) \, \mathbf{B}_i^{1/2} \, \mathbf{R}(\boldsymbol{c}) \, \mathbf{B}_i^{1/2}
\]</span></p>
<ul>
<li>
<span class="math inline">\(a(\phi)\)</span> is a dispersion parameter,</li>
<li>
<span class="math inline">\(\mathbf{B}_i\)</span> is a diagonal matrix with variance functions <span class="math inline">\(V(\mu_{ij})\)</span> on the diagonal,</li>
<li>
<span class="math inline">\(\mathbf{R}(\boldsymbol{c})\)</span> is the working correlation matrix, parameterized by <span class="math inline">\(\boldsymbol{c}\)</span>. If <span class="math inline">\(\mathbf{R}(\boldsymbol{c})\)</span> is the true correlation matrix of <span class="math inline">\(\mathbf{y}_i\)</span>, then <span class="math inline">\(\mathbf{V}_i\)</span> is the true covariance matrix.</li>
</ul>
<p>Common Working Correlation Structures:</p>
<ul>
<li>Independence: <span class="math inline">\(\mathbf{R} = \mathbf{I}\)</span> (simplest, but ignores correlation).</li>
<li>Exchangeable: Constant correlation between all pairs within a cluster.</li>
<li>Autoregressive (AR(1)): Correlation decreases with time lag.</li>
<li>Unstructured: Each pair has its own correlation parameter.</li>
</ul>
<hr>
</div>
<div id="iterative-algorithm-for-gee-estimation" class="section level5" number="9.5.2.4.3">
<h5>
<span class="header-section-number">9.5.2.4.3</span> Iterative Algorithm for GEE Estimation<a class="anchor" aria-label="anchor" href="#iterative-algorithm-for-gee-estimation"><i class="fas fa-link"></i></a>
</h5>
<ol style="list-style-type: decimal">
<li>
<p>Initialization:</p>
<ul>
<li>Compute an initial estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span> using a GLM under the independence assumption (<span class="math inline">\(\mathbf{R} = \mathbf{I}\)</span>).</li>
</ul>
</li>
<li>
<p>Estimate the Working Correlation Matrix:</p>
<ul>
<li>Based on residuals from the initial fit, estimate <span class="math inline">\(\mathbf{R}(\boldsymbol{c})\)</span>.</li>
</ul>
</li>
<li>
<p>Update the Covariance Matrix:</p>
<ul>
<li>Calculate <span class="math inline">\(\hat{\mathbf{V}}_i\)</span> using the updated working correlation matrix.</li>
</ul>
</li>
<li>
<p>Update <span class="math inline">\(\boldsymbol{\beta}\)</span>:</p>
<p><span class="math display">\[
\boldsymbol{\beta}^{(r+1)} = \boldsymbol{\beta}^{(r)} + \left(\sum_{i=1}^K \frac{\partial \boldsymbol{\mu}_i'}{\partial \boldsymbol{\beta}} \, \hat{\mathbf{V}}_i^{-1} \, \frac{\partial \boldsymbol{\mu}_i}{\partial \boldsymbol{\beta}} \right)^{-1}
\left( \sum_{i=1}^K \frac{\partial \boldsymbol{\mu}_i'}{\partial \boldsymbol{\beta}} \, \hat{\mathbf{V}}_i^{-1} (\mathbf{y}_i - \boldsymbol{\mu}_i) \right)
\]</span></p>
</li>
<li>
<p>Iteration:</p>
<ul>
<li>Repeat steps 2–4 until convergence (i.e., when changes in <span class="math inline">\(\boldsymbol{\beta}\)</span> are negligible).</li>
</ul>
</li>
</ol>
<hr>
<p>Comments on GEE:</p>
<ul>
<li>Advantages:
<ul>
<li>Provides consistent estimates of <span class="math inline">\(\boldsymbol{\beta}\)</span> even if the working correlation matrix is misspecified.</li>
<li>Robust standard errors (also known as “sandwich” estimators) account for potential misspecification.</li>
</ul>
</li>
<li>Limitations:
<ul>
<li>Not a likelihood-based method, so likelihood-ratio tests are not appropriate.</li>
<li>Efficiency loss if the working correlation matrix is poorly specified.</li>
<li>Estimation of random effects is not possible—GEE focuses on marginal (population-averaged) effects.</li>
</ul>
</li>
</ul>
<hr>
</div>
</div>
</div>
<div id="estimation-by-bayesian-hierarchical-models" class="section level3" number="9.5.3">
<h3>
<span class="header-section-number">9.5.3</span> Estimation by Bayesian Hierarchical Models<a class="anchor" aria-label="anchor" href="#estimation-by-bayesian-hierarchical-models"><i class="fas fa-link"></i></a>
</h3>
<p>Bayesian methods provide a flexible framework for estimating parameters in <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-nonlinear-mixed-models">NLMMs</a> and <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-generalized-linear-mixed-models">GLMMs</a>. Unlike frequentist approaches that rely on MLE or linearization techniques, Bayesian estimation fully incorporates prior information and naturally accounts for uncertainty in both parameter estimation and predictions.</p>
<p>In the Bayesian context, we are interested in the posterior distribution of the model parameters, given the observed data <span class="math inline">\(\mathbf{y}\)</span>:</p>
<p><span class="math display">\[
f(\boldsymbol{\alpha}, \boldsymbol{\beta} \mid \mathbf{y}) \propto f(\mathbf{y} \mid \boldsymbol{\alpha}, \boldsymbol{\beta}) \, f(\boldsymbol{\alpha}) \, f(\boldsymbol{\beta})
\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(f(\mathbf{y} \mid \boldsymbol{\alpha}, \boldsymbol{\beta})\)</span> is the likelihood of the data,</li>
<li>
<span class="math inline">\(f(\boldsymbol{\alpha})\)</span> is the prior distribution for the random effects,</li>
<li>
<span class="math inline">\(f(\boldsymbol{\beta})\)</span> is the prior distribution for the fixed effects,</li>
<li>
<span class="math inline">\(f(\boldsymbol{\alpha}, \boldsymbol{\beta} \mid \mathbf{y})\)</span> is the posterior distribution, which combines prior beliefs with observed data.</li>
</ul>
<p><strong>Advantages of Bayesian Estimation</strong></p>
<ul>
<li>
<strong>No Need for Simplifying Approximations:</strong> Bayesian methods do not require linearization or asymptotic approximations.</li>
<li>
<strong>Full Uncertainty Quantification:</strong> Provides credible intervals for parameters and predictive distributions for new data.</li>
<li>
<strong>Flexible Modeling:</strong> Easily accommodates complex hierarchical structures, non-standard distributions, and prior information.</li>
</ul>
<p><strong>Computational Challenges</strong></p>
<p>Despite its advantages, Bayesian estimation can be computationally intensive and complex, especially for high-dimensional models. Key implementation issues include:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Non-Valid Joint Distributions:</strong><br>
In some hierarchical models, specifying valid joint distributions for the data, random effects, and parameters can be challenging.</p></li>
<li><p><strong>Constraints from Mean-Variance Relationships:</strong><br>
The inherent relationship between the mean and variance in GLMMs, combined with random effects, imposes constraints on the marginal covariance structure.</p></li>
<li><p><strong>Computational Intensity:</strong><br>
Fitting Bayesian models often requires advanced numerical techniques like Markov Chain Monte Carlo, which can be slow to converge, especially for large datasets or complex models.</p></li>
</ol>
<hr>
<div id="bayesian-estimation-methods" class="section level4" number="9.5.3.1">
<h4>
<span class="header-section-number">9.5.3.1</span> Bayesian Estimation Methods<a class="anchor" aria-label="anchor" href="#bayesian-estimation-methods"><i class="fas fa-link"></i></a>
</h4>
<p>Bayesian estimation can proceed through two general approaches:</p>
<ol style="list-style-type: decimal">
<li><strong>Approximating the Objective Function (Marginal Likelihood)</strong></li>
</ol>
<p>The marginal likelihood is typically intractable because it requires integrating over random effects:</p>
<p><span class="math display">\[
f(\mathbf{y} \mid \boldsymbol{\beta}) = \int f(\mathbf{y} \mid \boldsymbol{\alpha}, \boldsymbol{\beta}) \, f(\boldsymbol{\alpha}) \, d\boldsymbol{\alpha}
\]</span></p>
<p>Since this integral cannot be solved analytically, we approximate it using the following methods:</p>
<ul>
<li>
<p><strong>Laplace Approximation</strong></p>
<ul>
<li><p>Approximates the integral by expanding the log-likelihood around the mode of the integrand.</p></li>
<li><p>Provides an efficient, asymptotically accurate approximation when the posterior is approximately Gaussian near its mode.</p></li>
</ul>
</li>
<li>
<p><strong>Quadrature Methods</strong></p>
<ul>
<li><p><strong>Gaussian quadrature</strong> (e.g., Gauss-Hermite quadrature) is effective for low-dimensional random effects.</p></li>
<li><p>Approximates the integral by summing weighted evaluations of the function at specific points.</p></li>
</ul>
</li>
<li>
<p><strong>Monte Carlo Integration</strong></p>
<ul>
<li><p>Uses random sampling to approximate the integral.</p></li>
<li><p><strong>Importance sampling</strong> improves efficiency by drawing samples from a distribution that closely resembles the target distribution.</p></li>
</ul>
</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Approximating the Model (Linearization)</strong></li>
</ol>
<p>Alternatively, we can approximate the model itself using <strong>Taylor series linearization</strong> around current estimates of the parameters. This approach simplifies the model, making Bayesian estimation computationally more feasible, though at the cost of some approximation error.</p>
<hr>
</div>
<div id="markov-chain-monte-carlo-methods" class="section level4" number="9.5.3.2">
<h4>
<span class="header-section-number">9.5.3.2</span> Markov Chain Monte Carlo Methods<a class="anchor" aria-label="anchor" href="#markov-chain-monte-carlo-methods"><i class="fas fa-link"></i></a>
</h4>
<p>The most common approach for fully Bayesian estimation is <strong>MCMC</strong>, which generates samples from the posterior distribution through iterative simulation. Popular MCMC algorithms include:</p>
<ul>
<li><p><strong>Gibbs Sampling:</strong><br>
Efficient when full conditional distributions are available in closed form.</p></li>
<li><p><strong>Metropolis-Hastings Algorithm:</strong><br>
More general and flexible, used when full conditionals are not easily sampled.</p></li>
<li><p><strong>Hamiltonian Monte Carlo (HMC):</strong><br>
Implemented in packages like <code>Stan</code>, provides faster convergence for complex models by leveraging gradient information.</p></li>
</ul>
<p>The posterior distribution is then approximated using the generated samples:</p>
<p><span class="math display">\[
f(\boldsymbol{\alpha}, \boldsymbol{\beta} \mid \mathbf{y}) \approx \frac{1}{N} \sum_{i=1}^N \delta(\boldsymbol{\alpha} - \boldsymbol{\alpha}^{(i)}, \boldsymbol{\beta} - \boldsymbol{\beta}^{(i)})
\]</span></p>
<p>Where <span class="math inline">\(N\)</span> is the number of MCMC samples and <span class="math inline">\(\delta(\cdot)\)</span> is the Dirac delta function.</p>
<hr>
</div>
</div>
<div id="practical-implementation-in-r" class="section level3" number="9.5.4">
<h3>
<span class="header-section-number">9.5.4</span> Practical Implementation in R<a class="anchor" aria-label="anchor" href="#practical-implementation-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>Several R packages facilitate Bayesian estimation for GLMMs and NLMMs:</p>
<ul>
<li>
<strong>GLMM Estimation:</strong>
<ul>
<li>
<code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html">MASS::glmmPQL</a></code> — Penalized Quasi-Likelihood for GLMMs.</li>
<li>
<code><a href="https://rdrr.io/pkg/lme4/man/glmer.html">lme4::glmer</a></code> — Frequentist estimation for GLMMs using Laplace approximation.</li>
<li>
<code>glmmTMB</code> — Handles complex random effects structures efficiently.</li>
</ul>
</li>
<li>
<strong>NLMM Estimation:</strong>
<ul>
<li>
<code><a href="https://rdrr.io/pkg/nlme/man/nlme.html">nlme::nlme</a></code> — Nonlinear mixed-effects modeling.</li>
<li>
<code><a href="https://rdrr.io/pkg/lme4/man/nlmer.html">lme4::nlmer</a></code> — Extends <code>lme4</code> for nonlinear mixed models.</li>
<li>
<code><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brms::brm</a></code> — Bayesian estimation via <code>Stan</code>, supporting NLMMs.</li>
</ul>
</li>
<li>
<strong>Bayesian Estimation:</strong>
<ul>
<li>
<code>MCMCglmm</code> — Implements MCMC algorithms for GLMMs.</li>
<li>
<code><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brms::brm</a></code> — High-level interface for Bayesian regression models, leveraging <code>Stan</code> for efficient MCMC sampling.</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Example: Non-Gaussian Repeated Measurements</strong></p>
<p>Consider the case of <strong>repeated measurements</strong>:</p>
<ul>
<li>
<strong>If the data are Gaussian:</strong> Use <a href="sec-linear-mixed-models.html#sec-linear-mixed-models">Linear Mixed Models</a>.</li>
<li>
<strong>If the data are non-Gaussian:</strong> Use <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-nonlinear-and-generalized-linear-mixed-models">Nonlinear and Generalized Linear Mixed Models</a>.</li>
</ul>
</div>
</div>
<div id="application-nonlinear-and-generalized-linear-mixed-models" class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> Application: Nonlinear and Generalized Linear Mixed Models<a class="anchor" aria-label="anchor" href="#application-nonlinear-and-generalized-linear-mixed-models"><i class="fas fa-link"></i></a>
</h2>
<div id="binomial-data-cbpp-dataset" class="section level3" number="9.6.1">
<h3>
<span class="header-section-number">9.6.1</span> Binomial Data: CBPP Dataset<a class="anchor" aria-label="anchor" href="#binomial-data-cbpp-dataset"><i class="fas fa-link"></i></a>
</h3>
<p>We will use the <strong>CBPP dataset</strong> from the <code>lme4</code> package to demonstrate different estimation approaches for binomial mixed models.</p>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">cbpp</span>, package <span class="op">=</span> <span class="st">"lme4"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">cbpp</span><span class="op">)</span></span>
<span><span class="co">#&gt;   herd incidence size period</span></span>
<span><span class="co">#&gt; 1    1         2   14      1</span></span>
<span><span class="co">#&gt; 2    1         3   12      2</span></span>
<span><span class="co">#&gt; 3    1         4    9      3</span></span>
<span><span class="co">#&gt; 4    1         0    5      4</span></span>
<span><span class="co">#&gt; 5    2         3   22      1</span></span>
<span><span class="co">#&gt; 6    2         1   18      2</span></span></code></pre></div>
<p>The data contain information about contagious bovine pleuropneumonia (CBPP) cases across different herds and periods.</p>
<ol style="list-style-type: decimal">
<li><strong>Penalized Quasi-Likelihood</strong></li>
</ol>
<p><strong>Pros:</strong></p>
<ul>
<li><p>Linearizes the response to create a pseudo-response, similar to linear mixed models.</p></li>
<li><p>Computationally efficient.</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li><p>Biased for binary or Poisson data with small counts.</p></li>
<li><p>Random effects must be interpreted on the link scale.</p></li>
<li><p>AIC/BIC values are not interpretable since PQL does not rely on full likelihood.</p></li>
</ul>
<div class="sourceCode" id="cb337"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span></span>
<span><span class="va">pql_cbpp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html">glmmPQL</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span>,</span>
<span>    random  <span class="op">=</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">|</span> <span class="va">herd</span>,</span>
<span>    data    <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>    family  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">pql_cbpp</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed-effects model fit by maximum likelihood</span></span>
<span><span class="co">#&gt;   Data: cbpp </span></span>
<span><span class="co">#&gt;   AIC BIC logLik</span></span>
<span><span class="co">#&gt;    NA  NA     NA</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Formula: ~1 | herd</span></span>
<span><span class="co">#&gt;         (Intercept) Residual</span></span>
<span><span class="co">#&gt; StdDev:   0.5563535 1.184527</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Variance function:</span></span>
<span><span class="co">#&gt;  Structure: fixed weights</span></span>
<span><span class="co">#&gt;  Formula: ~invwt </span></span>
<span><span class="co">#&gt; Fixed effects:  cbind(incidence, size - incidence) ~ period </span></span>
<span><span class="co">#&gt;                 Value Std.Error DF   t-value p-value</span></span>
<span><span class="co">#&gt; (Intercept) -1.327364 0.2390194 38 -5.553372  0.0000</span></span>
<span><span class="co">#&gt; period2     -1.016126 0.3684079 38 -2.758156  0.0089</span></span>
<span><span class="co">#&gt; period3     -1.149984 0.3937029 38 -2.920944  0.0058</span></span>
<span><span class="co">#&gt; period4     -1.605217 0.5178388 38 -3.099839  0.0036</span></span>
<span><span class="co">#&gt;  Correlation: </span></span>
<span><span class="co">#&gt;         (Intr) perid2 perid3</span></span>
<span><span class="co">#&gt; period2 -0.399              </span></span>
<span><span class="co">#&gt; period3 -0.373  0.260       </span></span>
<span><span class="co">#&gt; period4 -0.282  0.196  0.182</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Standardized Within-Group Residuals:</span></span>
<span><span class="co">#&gt;        Min         Q1        Med         Q3        Max </span></span>
<span><span class="co">#&gt; -2.0591168 -0.6493095 -0.2747620  0.5170492  2.6187632 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Observations: 56</span></span>
<span><span class="co">#&gt; Number of Groups: 15</span></span></code></pre></div>
<p>Interpretation</p>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">0.556</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.743684</span></span></code></pre></div>
<p>The above result shows how herd-specific odds vary, accounting for random effects.</p>
<p>The fixed effects are interpreted similarly to logistic regression. For example, with the logit link:</p>
<ul>
<li>The <strong>log odds</strong> of having a case in <strong>period 2</strong> are <strong>-1.016</strong> less than in <strong>period 1</strong> (baseline).</li>
</ul>
<div class="sourceCode" id="cb339"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">pql_cbpp</span><span class="op">)</span><span class="op">$</span><span class="va">tTable</span></span>
<span><span class="co">#&gt;                 Value Std.Error DF   t-value      p-value</span></span>
<span><span class="co">#&gt; (Intercept) -1.327364 0.2390194 38 -5.553372 2.333216e-06</span></span>
<span><span class="co">#&gt; period2     -1.016126 0.3684079 38 -2.758156 8.888179e-03</span></span>
<span><span class="co">#&gt; period3     -1.149984 0.3937029 38 -2.920944 5.843007e-03</span></span>
<span><span class="co">#&gt; period4     -1.605217 0.5178388 38 -3.099839 3.637000e-03</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><strong>Numerical Integration with <code>glmer</code></strong></li>
</ol>
<p><strong>Pros:</strong></p>
<ul>
<li>More accurate estimation since the method directly integrates over random effects.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li><p>Computationally more expensive, especially with high-dimensional random effects.</p></li>
<li><p>May struggle with convergence for complex models.</p></li>
</ul>
<div class="sourceCode" id="cb340"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">numint_cbpp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">herd</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">numint_cbpp</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace</span></span>
<span><span class="co">#&gt;   Approximation) [glmerMod]</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; Formula: cbind(incidence, size - incidence) ~ period + (1 | herd)</span></span>
<span><span class="co">#&gt;    Data: cbpp</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    194.1    204.2    -92.0    184.1       51 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -2.3816 -0.7889 -0.2026  0.5142  2.8791 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  herd   (Intercept) 0.4123   0.6421  </span></span>
<span><span class="co">#&gt; Number of obs: 56, groups:  herd, 15</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  -1.3983     0.2312  -6.048 1.47e-09 ***</span></span>
<span><span class="co">#&gt; period2      -0.9919     0.3032  -3.272 0.001068 ** </span></span>
<span><span class="co">#&gt; period3      -1.1282     0.3228  -3.495 0.000474 ***</span></span>
<span><span class="co">#&gt; period4      -1.5797     0.4220  -3.743 0.000182 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;         (Intr) perid2 perid3</span></span>
<span><span class="co">#&gt; period2 -0.363              </span></span>
<span><span class="co">#&gt; period3 -0.340  0.280       </span></span>
<span><span class="co">#&gt; period4 -0.260  0.213  0.198</span></span></code></pre></div>
<p><strong>Comparing PQL and Numerical Integration</strong></p>
<p>For small datasets, the difference between PQL and numerical integration may be minimal.</p>
<div class="sourceCode" id="cb341"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://rbenchmark.googlecode.com">rbenchmark</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rbenchmark/man/benchmark.html">benchmark</a></span><span class="op">(</span></span>
<span>    <span class="st">"PQL (MASS)"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html">glmmPQL</a></span><span class="op">(</span></span>
<span>            <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span>,</span>
<span>            random <span class="op">=</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">|</span> <span class="va">herd</span>,</span>
<span>            data <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>            family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span>,</span>
<span>            verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>        <span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>    <span class="st">"Numerical Integration (lme4)"</span> <span class="op">=</span> <span class="op">{</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span><span class="op">(</span></span>
<span>            <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">herd</span><span class="op">)</span>,</span>
<span>            data <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>            family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span>        <span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>    replications <span class="op">=</span> <span class="fl">50</span>,</span>
<span>    columns <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"test"</span>, <span class="st">"replications"</span>, <span class="st">"elapsed"</span>, <span class="st">"relative"</span><span class="op">)</span>,</span>
<span>    order <span class="op">=</span> <span class="st">"relative"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;                           test replications elapsed relative</span></span>
<span><span class="co">#&gt; 1                   PQL (MASS)           50    4.87    1.000</span></span>
<span><span class="co">#&gt; 2 Numerical Integration (lme4)           50    9.05    1.858</span></span></code></pre></div>
<p><strong>Improving Accuracy with Gauss-Hermite Quadrature</strong></p>
<p>Setting <code>nAGQ &gt; 1</code> increases the accuracy of the likelihood approximation:</p>
<div class="sourceCode" id="cb342"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">numint_cbpp_GH</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">herd</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span>,</span>
<span>    nAGQ <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">numint_cbpp_GH</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">-</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">numint_cbpp</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#&gt;   (Intercept)       period2       period3       period4 </span></span>
<span><span class="co">#&gt; -0.0008808634  0.0005160912  0.0004066218  0.0002644629</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Bayesian Approach with <code>MCMCglmm</code></strong></li>
</ol>
<p><strong>Pros:</strong></p>
<ul>
<li><p>Incorporates prior information and handles complex models with intractable likelihoods.</p></li>
<li><p>Provides full posterior distributions for parameters.</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Computationally intensive, especially with large datasets or complex hierarchical structures.</li>
</ul>
<div class="sourceCode" id="cb343"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MCMCglmm</span><span class="op">)</span></span>
<span><span class="va">Bayes_cbpp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MCMCglmm/man/MCMCglmm.html">MCMCglmm</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span>,</span>
<span>    random <span class="op">=</span> <span class="op">~</span> <span class="va">herd</span>,</span>
<span>    data <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>    family <span class="op">=</span> <span class="st">"multinomial2"</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Bayes_cbpp</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Iterations = 3001:12991</span></span>
<span><span class="co">#&gt;  Thinning interval  = 10</span></span>
<span><span class="co">#&gt;  Sample size  = 1000 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  DIC: 537.6654 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  G-structure:  ~herd</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      post.mean  l-95% CI u-95% CI eff.samp</span></span>
<span><span class="co">#&gt; herd   0.01489 7.096e-17  0.07232    229.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  R-structure:  ~units</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       post.mean l-95% CI u-95% CI eff.samp</span></span>
<span><span class="co">#&gt; units     1.102   0.3434    2.138    273.3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Location effects: cbind(incidence, size - incidence) ~ period </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    </span></span>
<span><span class="co">#&gt; (Intercept)   -1.5324  -2.2186  -0.9049    908.6 &lt;0.001 ***</span></span>
<span><span class="co">#&gt; period2       -1.2938  -2.3859  -0.2230    858.2  0.028 *  </span></span>
<span><span class="co">#&gt; period3       -1.4065  -2.4900  -0.2594    761.9  0.008 ** </span></span>
<span><span class="co">#&gt; period4       -1.9772  -3.2968  -0.7241    468.4 &lt;0.001 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<ul>
<li>
<code>MCMCglmm</code> fits a residual variance component (useful with dispersion issues).</li>
</ul>
<p>Variance Component Analysis</p>
<div class="sourceCode" id="cb344"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># explains less variability</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">Bayes_cbpp</span><span class="op">$</span><span class="va">VCV</span>, <span class="fl">2</span>, <span class="va">sd</span><span class="op">)</span></span>
<span><span class="co">#&gt;       herd      units </span></span>
<span><span class="co">#&gt; 0.06693913 0.49363796</span></span></code></pre></div>
<p>Posterior Summaries</p>
<div class="sourceCode" id="cb345"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Bayes_cbpp</span><span class="op">)</span><span class="op">$</span><span class="va">solutions</span></span>
<span><span class="co">#&gt;             post.mean  l-95% CI   u-95% CI eff.samp pMCMC</span></span>
<span><span class="co">#&gt; (Intercept) -1.532403 -2.218564 -0.9048971 908.6403 0.001</span></span>
<span><span class="co">#&gt; period2     -1.293835 -2.385898 -0.2230115 858.1893 0.028</span></span>
<span><span class="co">#&gt; period3     -1.406481 -2.489974 -0.2593996 761.8712 0.008</span></span>
<span><span class="co">#&gt; period4     -1.977166 -3.296802 -0.7240878 468.3743 0.001</span></span></code></pre></div>
<p>MCMC Diagnostics</p>
<div class="sourceCode" id="cb346"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lattice.r-forge.r-project.org/">lattice</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lattice/man/xyplot.html">xyplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/mcmc.html">as.mcmc</a></span><span class="op">(</span><span class="va">Bayes_cbpp</span><span class="op">$</span><span class="va">Sol</span><span class="op">)</span>, layout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-11-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>There is no trend (i.e., well-mixed).</p>
<div class="sourceCode" id="cb347"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lattice/man/xyplot.html">xyplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/mcmc.html">as.mcmc</a></span><span class="op">(</span><span class="va">Bayes_cbpp</span><span class="op">$</span><span class="va">VCV</span><span class="op">)</span>, layout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-12-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>For the herd variable, many of the values are 0, which suggests a problem. To address the instability in the herd effect sampling, we can either:</p>
<ul>
<li><p>Modify prior distributions,</p></li>
<li><p>Increase the number of iterations</p></li>
</ul>
<div class="sourceCode" id="cb348"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Bayes_cbpp2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MCMCglmm/man/MCMCglmm.html">MCMCglmm</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">incidence</span>, <span class="va">size</span> <span class="op">-</span> <span class="va">incidence</span><span class="op">)</span> <span class="op">~</span> <span class="va">period</span>,</span>
<span>    random <span class="op">=</span> <span class="op">~</span> <span class="va">herd</span>,</span>
<span>    data <span class="op">=</span> <span class="va">cbpp</span>,</span>
<span>    family <span class="op">=</span> <span class="st">"multinomial2"</span>,</span>
<span>    nitt <span class="op">=</span> <span class="fl">20000</span>,</span>
<span>    burnin <span class="op">=</span> <span class="fl">10000</span>,</span>
<span>    prior <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>G <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>V <span class="op">=</span> <span class="fl">1</span>, nu <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lattice/man/xyplot.html">xyplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/mcmc.html">as.mcmc</a></span><span class="op">(</span><span class="va">Bayes_cbpp2</span><span class="op">$</span><span class="va">VCV</span><span class="op">)</span>, layout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-13-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>To change the shape of priors, in <code>MCMCglmm</code> use:</p>
<ul>
<li><p><code>V</code> controls for the location of the distribution (default = 1)</p></li>
<li><p><code>nu</code> controls for the concentration around V (default = 0)</p></li>
</ul>
</div>
<div id="count-data-owl-dataset" class="section level3" number="9.6.2">
<h3>
<span class="header-section-number">9.6.2</span> Count Data: Owl Dataset<a class="anchor" aria-label="anchor" href="#count-data-owl-dataset"><i class="fas fa-link"></i></a>
</h3>
<p>We’ll now model count data using the <strong>Owl dataset</strong></p>
<div class="sourceCode" id="cb349"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/glmmTMB/glmmTMB">glmmTMB</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Owls</span>, package <span class="op">=</span> <span class="st">"glmmTMB"</span><span class="op">)</span></span>
<span><span class="va">Owls</span> <span class="op">&lt;-</span> <span class="va">Owls</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html">rename</a></span><span class="op">(</span>Ncalls <span class="op">=</span> <span class="va">SiblingNegotiation</span><span class="op">)</span></span></code></pre></div>
<ol style="list-style-type: decimal">
<li><strong>Poisson GLMM</strong></li>
</ol>
<p>Modeling call counts with a Poisson distribution:</p>
<p>In a typical Poisson model, the Poisson mean <span class="math inline">\(\lambda\)</span> is modeled as: <span class="math display">\[
\log(\lambda) = x' \beta
\]</span> However, if the response variable represents a rate (e.g., counts per <strong>BroodSize</strong>), we can model it as: <span class="math display">\[
\log\left(\frac{\lambda}{b}\right) = x' \beta
\]</span> This is equivalent to: <span class="math display">\[
\log(\lambda) = \log(b) + x' \beta
\]</span> where <span class="math inline">\(b\)</span> represents <strong>BroodSize</strong>. In this formulation, we “offset” the mean by including the logarithm of <span class="math inline">\(b\)</span> as an offset term in the model. This adjustment accounts for the varying exposure or denominator in rate-based responses.</p>
<div class="sourceCode" id="cb350"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">owls_glmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span><span class="op">(</span></span>
<span>    <span class="va">Ncalls</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BroodSize</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="va">FoodTreatment</span> <span class="op">*</span> <span class="va">SexParent</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Nest</span><span class="op">)</span>,</span>
<span>    family <span class="op">=</span> <span class="va">poisson</span>,</span>
<span>    data <span class="op">=</span> <span class="va">Owls</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">owls_glmer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace</span></span>
<span><span class="co">#&gt;   Approximation) [glmerMod]</span></span>
<span><span class="co">#&gt;  Family: poisson  ( log )</span></span>
<span><span class="co">#&gt; Formula: Ncalls ~ offset(log(BroodSize)) + FoodTreatment * SexParent +  </span></span>
<span><span class="co">#&gt;     (1 | Nest)</span></span>
<span><span class="co">#&gt;    Data: Owls</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   5212.8   5234.8  -2601.4   5202.8      594 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -3.5529 -1.7971 -0.6842  1.2689 11.4312 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  Nest   (Intercept) 0.2063   0.4542  </span></span>
<span><span class="co">#&gt; Number of obs: 599, groups:  Nest, 27</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                                     Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)                          0.65585    0.09567   6.855 7.12e-12 ***</span></span>
<span><span class="co">#&gt; FoodTreatmentSatiated               -0.65612    0.05606 -11.705  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; SexParentMale                       -0.03705    0.04501  -0.823   0.4104    </span></span>
<span><span class="co">#&gt; FoodTreatmentSatiated:SexParentMale  0.13135    0.07036   1.867   0.0619 .  </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;             (Intr) FdTrtS SxPrnM</span></span>
<span><span class="co">#&gt; FdTrtmntStt -0.225              </span></span>
<span><span class="co">#&gt; SexParentMl -0.292  0.491       </span></span>
<span><span class="co">#&gt; FdTrtmS:SPM  0.170 -0.768 -0.605</span></span></code></pre></div>
<ul>
<li>Nest explains a relatively large proportion of the variability (its standard deviation is larger than some coefficients).</li>
<li>The model fit isn’t great (deviance of 5202 on 594 df).</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Negative Binomial Model</strong></li>
</ol>
<p>Addressing overdispersion using the negative binomial distribution:</p>
<div class="sourceCode" id="cb351"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">owls_glmerNB</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.nb.html">glmer.nb</a></span><span class="op">(</span></span>
<span>    <span class="va">Ncalls</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BroodSize</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="va">FoodTreatment</span> <span class="op">*</span> <span class="va">SexParent</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Nest</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">Owls</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">owls_glmerNB</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace</span></span>
<span><span class="co">#&gt;   Approximation) [glmerMod]</span></span>
<span><span class="co">#&gt;  Family: Negative Binomial(0.8423)  ( log )</span></span>
<span><span class="co">#&gt; Formula: Ncalls ~ offset(log(BroodSize)) + FoodTreatment * SexParent +  </span></span>
<span><span class="co">#&gt;     (1 | Nest)</span></span>
<span><span class="co">#&gt;    Data: Owls</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3495.6   3522.0  -1741.8   3483.6      593 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -0.8859 -0.7737 -0.2701  0.4443  6.1432 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  Nest   (Intercept) 0.1245   0.3529  </span></span>
<span><span class="co">#&gt; Number of obs: 599, groups:  Nest, 27</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                                     Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)                          0.69005    0.13400   5.149 2.61e-07 ***</span></span>
<span><span class="co">#&gt; FoodTreatmentSatiated               -0.76657    0.16509  -4.643 3.43e-06 ***</span></span>
<span><span class="co">#&gt; SexParentMale                       -0.02605    0.14575  -0.179    0.858    </span></span>
<span><span class="co">#&gt; FoodTreatmentSatiated:SexParentMale  0.15680    0.20513   0.764    0.445    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;             (Intr) FdTrtS SxPrnM</span></span>
<span><span class="co">#&gt; FdTrtmntStt -0.602              </span></span>
<span><span class="co">#&gt; SexParentMl -0.683  0.553       </span></span>
<span><span class="co">#&gt; FdTrtmS:SPM  0.450 -0.744 -0.671</span></span></code></pre></div>
<p>There is an improvement using negative binomial considering over-dispersion</p>
<div class="sourceCode" id="cb352"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">Owls</span><span class="op">$</span><span class="va">Ncalls</span>,breaks<span class="op">=</span><span class="fl">30</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-17-1.png" width="90%" style="display: block; margin: auto;"></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Zero-Inflated Model</strong></li>
</ol>
<p>Handling excess zeros with a zero-inflated Poisson model:</p>
<div class="sourceCode" id="cb353"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/glmmTMB/glmmTMB">glmmTMB</a></span><span class="op">)</span></span>
<span><span class="va">owls_glmm</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/glmmTMB.html">glmmTMB</a></span><span class="op">(</span></span>
<span>        <span class="va">Ncalls</span> <span class="op">~</span> <span class="va">FoodTreatment</span> <span class="op">*</span> <span class="va">SexParent</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BroodSize</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>            <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Nest</span><span class="op">)</span>,</span>
<span>        ziformula <span class="op">=</span>  <span class="op">~</span> <span class="fl">0</span>,</span>
<span>        family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/nbinom2.html">nbinom2</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"log"</span><span class="op">)</span>,</span>
<span>        data <span class="op">=</span> <span class="va">Owls</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">owls_glmm_zi</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/glmmTMB.html">glmmTMB</a></span><span class="op">(</span></span>
<span>        <span class="va">Ncalls</span> <span class="op">~</span> <span class="va">FoodTreatment</span> <span class="op">*</span> <span class="va">SexParent</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BroodSize</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>            <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Nest</span><span class="op">)</span>,</span>
<span>        ziformula <span class="op">=</span>  <span class="op">~</span> <span class="fl">1</span>,</span>
<span>        family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/nbinom2.html">nbinom2</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"log"</span><span class="op">)</span>,</span>
<span>        data <span class="op">=</span> <span class="va">Owls</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Scale Arrival time to use as a covariate for zero-inflation parameter</span></span>
<span><span class="va">Owls</span><span class="op">$</span><span class="va">ArrivalTime</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">Owls</span><span class="op">$</span><span class="va">ArrivalTime</span><span class="op">)</span></span>
<span><span class="va">owls_glmm_zi_cov</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/glmmTMB.html">glmmTMB</a></span><span class="op">(</span></span>
<span>    <span class="va">Ncalls</span> <span class="op">~</span> <span class="va">FoodTreatment</span> <span class="op">*</span> <span class="va">SexParent</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/offset.html">offset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">BroodSize</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Nest</span><span class="op">)</span>,</span>
<span>    ziformula <span class="op">=</span>  <span class="op">~</span> <span class="va">ArrivalTime</span>,</span>
<span>    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/glmmTMB/man/nbinom2.html">nbinom2</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"log"</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">Owls</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">owls_glmm</span>, <span class="va">owls_glmm_zi</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;              Df      AIC      BIC    logLik deviance    Chisq Chi Df</span></span>
<span><span class="co">#&gt; owls_glmm     6 3495.610 3521.981 -1741.805 3483.610       NA     NA</span></span>
<span><span class="co">#&gt; owls_glmm_zi  7 3431.646 3462.413 -1708.823 3417.646 65.96373      1</span></span>
<span><span class="co">#&gt;                Pr(&gt;Chisq)</span></span>
<span><span class="co">#&gt; owls_glmm              NA</span></span>
<span><span class="co">#&gt; owls_glmm_zi 4.592983e-16</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">owls_glmm_zi</span>, <span class="va">owls_glmm_zi_cov</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                  Df      AIC      BIC    logLik deviance    Chisq Chi Df</span></span>
<span><span class="co">#&gt; owls_glmm_zi      7 3431.646 3462.413 -1708.823 3417.646       NA     NA</span></span>
<span><span class="co">#&gt; owls_glmm_zi_cov  8 3422.532 3457.694 -1703.266 3406.532 11.11411      1</span></span>
<span><span class="co">#&gt;                    Pr(&gt;Chisq)</span></span>
<span><span class="co">#&gt; owls_glmm_zi               NA</span></span>
<span><span class="co">#&gt; owls_glmm_zi_cov 0.0008567362</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">owls_glmm_zi_cov</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Family: nbinom2  ( log )</span></span>
<span><span class="co">#&gt; Formula:          </span></span>
<span><span class="co">#&gt; Ncalls ~ FoodTreatment * SexParent + offset(log(BroodSize)) +      (1 | Nest)</span></span>
<span><span class="co">#&gt; Zero inflation:          ~ArrivalTime</span></span>
<span><span class="co">#&gt; Data: Owls</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;   3422.5   3457.7  -1703.3   3406.5      591 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Conditional model:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  Nest   (Intercept) 0.07487  0.2736  </span></span>
<span><span class="co">#&gt; Number of obs: 599, groups:  Nest, 27</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Dispersion parameter for nbinom2 family (): 2.22 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Conditional model:</span></span>
<span><span class="co">#&gt;                                     Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)                          0.84778    0.09961   8.511  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; FoodTreatmentSatiated               -0.39529    0.13742  -2.877  0.00402 ** </span></span>
<span><span class="co">#&gt; SexParentMale                       -0.07025    0.10435  -0.673  0.50079    </span></span>
<span><span class="co">#&gt; FoodTreatmentSatiated:SexParentMale  0.12388    0.16449   0.753  0.45138    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Zero-inflation model:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  -1.3018     0.1261  -10.32  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; ArrivalTime   0.3545     0.1074    3.30 0.000966 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p><code>glmmTMB</code> can handle ZIP GLMMs since it adds automatic differentiation to existing estimation strategies.</p>
<p>We can see ZIP GLMM with an arrival time covariate on the zero is best.</p>
<ul>
<li><p>Arrival time has a positive effect on observing a nonzero number of calls</p></li>
<li><p>Interactions are non significant, the food treatment is significant (fewer calls after eating)</p></li>
<li><p>Nest variability is large in magnitude (without this, the parameter estimates change)</p></li>
</ul>
</div>
<div id="binomial-example-gotway-hessian-fly-data" class="section level3" number="9.6.3">
<h3>
<span class="header-section-number">9.6.3</span> Binomial Example: Gotway Hessian Fly Data<a class="anchor" aria-label="anchor" href="#binomial-example-gotway-hessian-fly-data"><i class="fas fa-link"></i></a>
</h3>
<p>We will analyze the <strong>Gotway Hessian Fly</strong> dataset from the <code>agridat</code> package to model binomial outcomes using both frequentist and Bayesian approaches.</p>
<div id="data-visualization" class="section level4" number="9.6.3.1">
<h4>
<span class="header-section-number">9.6.3.1</span> Data Visualization<a class="anchor" aria-label="anchor" href="#data-visualization"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb354"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kwstat.github.io/agridat/">agridat</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.r-project.org">spaMM</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">gotway.hessianfly</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="va">gotway.hessianfly</span></span>
<span><span class="va">dat</span><span class="op">$</span><span class="va">prop</span> <span class="op">&lt;-</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span> <span class="op">/</span> <span class="va">dat</span><span class="op">$</span><span class="va">n</span>  <span class="co"># Proportion of successes</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">lat</span>, y <span class="op">=</span> <span class="va">long</span>, fill <span class="op">=</span> <span class="va">prop</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_tile</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html">scale_fill_gradient</a></span><span class="op">(</span>low <span class="op">=</span> <span class="st">'white'</span>, high <span class="op">=</span> <span class="st">'black'</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="va">gen</span>, color <span class="op">=</span> <span class="va">block</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">'Gotway Hessian Fly: Proportion of Infestation'</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-19-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="model-specification-2" class="section level4" number="9.6.3.2">
<h4>
<span class="header-section-number">9.6.3.2</span> Model Specification<a class="anchor" aria-label="anchor" href="#model-specification-2"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p>Fixed Effects (<span class="math inline">\(\boldsymbol{\beta}\)</span>): Genotype (<code>gen</code>)</p></li>
<li><p>Random Effects (<span class="math inline">\(\boldsymbol{\alpha}\)</span>): Block (<code>block</code>), accounting for spatial or experimental design variability</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><strong>Frequentist Approach with <code>glmer</code></strong></li>
</ol>
<div class="sourceCode" id="cb355"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flymodel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">~</span> <span class="va">gen</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">block</span><span class="op">)</span>,</span>
<span>    data   <span class="op">=</span> <span class="va">dat</span>,</span>
<span>    family <span class="op">=</span> <span class="va">binomial</span>,</span>
<span>    nAGQ   <span class="op">=</span> <span class="fl">5</span>  <span class="co"># Using adaptive Gauss-Hermite quadrature for accuracy</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">flymodel</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Adaptive</span></span>
<span><span class="co">#&gt;   Gauss-Hermite Quadrature, nAGQ = 5) [glmerMod]</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; Formula: cbind(y, n - y) ~ gen + (1 | block)</span></span>
<span><span class="co">#&gt;    Data: dat</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    162.2    198.9    -64.1    128.2       47 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.38644 -1.01188  0.09631  1.03468  2.75479 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  block  (Intercept) 0.001022 0.03196 </span></span>
<span><span class="co">#&gt; Number of obs: 64, groups:  block, 4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)   1.5035     0.3914   3.841 0.000122 ***</span></span>
<span><span class="co">#&gt; genG02       -0.1939     0.5302  -0.366 0.714644    </span></span>
<span><span class="co">#&gt; genG03       -0.5408     0.5103  -1.060 0.289260    </span></span>
<span><span class="co">#&gt; genG04       -1.4342     0.4714  -3.043 0.002346 ** </span></span>
<span><span class="co">#&gt; genG05       -0.2037     0.5429  -0.375 0.707486    </span></span>
<span><span class="co">#&gt; genG06       -0.9783     0.5046  -1.939 0.052533 .  </span></span>
<span><span class="co">#&gt; genG07       -0.6041     0.5111  -1.182 0.237235    </span></span>
<span><span class="co">#&gt; genG08       -1.6774     0.4907  -3.418 0.000630 ***</span></span>
<span><span class="co">#&gt; genG09       -1.3984     0.4725  -2.960 0.003078 ** </span></span>
<span><span class="co">#&gt; genG10       -0.6817     0.5333  -1.278 0.201181    </span></span>
<span><span class="co">#&gt; genG11       -1.4630     0.4843  -3.021 0.002522 ** </span></span>
<span><span class="co">#&gt; genG12       -1.4591     0.4918  -2.967 0.003010 ** </span></span>
<span><span class="co">#&gt; genG13       -3.5528     0.6600  -5.383 7.31e-08 ***</span></span>
<span><span class="co">#&gt; genG14       -2.5073     0.5264  -4.763 1.90e-06 ***</span></span>
<span><span class="co">#&gt; genG15       -2.0872     0.4851  -4.302 1.69e-05 ***</span></span>
<span><span class="co">#&gt; genG16       -2.9697     0.5383  -5.517 3.46e-08 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><p>The <strong>fixed effects</strong> (<code>gen</code>) indicate how different genotypes influence the infestation probability.</p></li>
<li><p>The <strong>random effect</strong> for <code>block</code> captures variability due to experimental blocks, improving model robustness.</p></li>
<li><p><strong>Odds Ratios:</strong> Exponentiating coefficients helps interpret the impact on infestation odds.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Bayesian Approach with <code>MCMCglmm</code></strong></li>
</ol>
<div class="sourceCode" id="cb356"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MCMCglmm</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">coda</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Bayes_flymodel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MCMCglmm/man/MCMCglmm.html">MCMCglmm</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">~</span> <span class="va">gen</span>,</span>
<span>    random  <span class="op">=</span> <span class="op">~</span> <span class="va">block</span>,</span>
<span>    data    <span class="op">=</span> <span class="va">dat</span>,</span>
<span>    family  <span class="op">=</span> <span class="st">"multinomial2"</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Bayes_flymodel</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Iterations = 3001:12991</span></span>
<span><span class="co">#&gt;  Thinning interval  = 10</span></span>
<span><span class="co">#&gt;  Sample size  = 1000 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  DIC: 877.8705 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  G-structure:  ~block</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       post.mean  l-95% CI u-95% CI eff.samp</span></span>
<span><span class="co">#&gt; block  0.009321 4.231e-17  0.02219    567.6</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  R-structure:  ~units</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       post.mean l-95% CI u-95% CI eff.samp</span></span>
<span><span class="co">#&gt; units    0.9798   0.2854    1.814    396.9</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Location effects: cbind(y, n - y) ~ gen </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             post.mean l-95% CI u-95% CI eff.samp  pMCMC    </span></span>
<span><span class="co">#&gt; (Intercept)    1.9453   0.5506   3.2689    891.7  0.002 ** </span></span>
<span><span class="co">#&gt; genG02        -0.3978  -2.0200   1.3991   1000.0  0.644    </span></span>
<span><span class="co">#&gt; genG03        -0.6869  -2.3681   1.3375   1000.0  0.456    </span></span>
<span><span class="co">#&gt; genG04        -1.7906  -3.6153  -0.1204   1000.0  0.040 *  </span></span>
<span><span class="co">#&gt; genG05        -0.3365  -2.2415   1.4151   1142.5  0.746    </span></span>
<span><span class="co">#&gt; genG06        -1.2958  -3.0881   0.4852   1000.0  0.168    </span></span>
<span><span class="co">#&gt; genG07        -0.7078  -2.3546   1.1984    906.0  0.446    </span></span>
<span><span class="co">#&gt; genG08        -2.0808  -3.7943  -0.2088    903.2  0.016 *  </span></span>
<span><span class="co">#&gt; genG09        -1.8410  -3.7099  -0.1652    887.7  0.036 *  </span></span>
<span><span class="co">#&gt; genG10        -0.8309  -2.6624   0.9302   1000.0  0.376    </span></span>
<span><span class="co">#&gt; genG11        -1.9500  -3.7212  -0.2839    820.7  0.018 *  </span></span>
<span><span class="co">#&gt; genG12        -1.9456  -3.5689  -0.1417    855.6  0.026 *  </span></span>
<span><span class="co">#&gt; genG13        -4.4209  -6.4504  -2.5177    753.9 &lt;0.001 ***</span></span>
<span><span class="co">#&gt; genG14        -3.1814  -4.8420  -1.2142    820.9 &lt;0.001 ***</span></span>
<span><span class="co">#&gt; genG15        -2.7887  -4.4517  -0.9149   1000.0 &lt;0.001 ***</span></span>
<span><span class="co">#&gt; genG16        -3.8646  -5.6545  -1.7410    814.7 &lt;0.001 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p><strong>MCMC Diagnostics</strong></p>
<ul>
<li><p><strong>Trace Plot:</strong> Checks for chain mixing and convergence.</p></li>
<li><p><strong>Autocorrelation Plot:</strong> Evaluates dependency between MCMC samples.</p></li>
</ul>
<div class="sourceCode" id="cb357"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Trace plot for the first fixed effect</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Bayes_flymodel</span><span class="op">$</span><span class="va">Sol</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>,</span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">Bayes_flymodel</span><span class="op">$</span><span class="va">Sol</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-22-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb358"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Autocorrelation plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/autocorr.plot.html">autocorr.plot</a></span><span class="op">(</span><span class="va">Bayes_flymodel</span><span class="op">$</span><span class="va">Sol</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>,</span>
<span>              main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">Bayes_flymodel</span><span class="op">$</span><span class="va">Sol</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-22-2.png" width="90%" style="display: block; margin: auto;"></div>
<p>Bayesian Interpretation:</p>
<ul>
<li><p><strong>Posterior Means:</strong> Represent the central tendency of the parameter estimates.</p></li>
<li><p><strong>Credible Intervals:</strong> Unlike frequentist confidence intervals, they can be interpreted directly as the probability that the parameter lies within the interval.</p></li>
</ul>
</div>
</div>
<div id="nonlinear-mixed-model-yellow-poplar-data" class="section level3" number="9.6.4">
<h3>
<span class="header-section-number">9.6.4</span> Nonlinear Mixed Model: Yellow Poplar Data<a class="anchor" aria-label="anchor" href="#nonlinear-mixed-model-yellow-poplar-data"><i class="fas fa-link"></i></a>
</h3>
<p>This dataset comes from <span class="citation">Schabenberger and Pierce (<a href="references.html#ref-Schabenberger_2001">2001</a>)</span></p>
<div id="data-preparation" class="section level4" number="9.6.4.1">
<h4>
<span class="header-section-number">9.6.4.1</span> Data Preparation<a class="anchor" aria-label="anchor" href="#data-preparation"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb359"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"images/YellowPoplarData_r.txt"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">dat2</span><span class="op">)</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'tn'</span>, <span class="st">'k'</span>, <span class="st">'dbh'</span>, <span class="st">'totht'</span>, <span class="st">'dob'</span>, <span class="st">'ht'</span>, <span class="st">'maxd'</span>, <span class="st">'cumv'</span><span class="op">)</span></span>
<span><span class="va">dat2</span><span class="op">$</span><span class="va">t</span> <span class="op">&lt;-</span> <span class="va">dat2</span><span class="op">$</span><span class="va">dob</span> <span class="op">/</span> <span class="va">dat2</span><span class="op">$</span><span class="va">dbh</span></span>
<span><span class="va">dat2</span><span class="op">$</span><span class="va">r</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">dat2</span><span class="op">$</span><span class="va">dob</span> <span class="op">/</span> <span class="va">dat2</span><span class="op">$</span><span class="va">totht</span></span></code></pre></div>
</div>
<div id="data-visualization-1" class="section level4" number="9.6.4.2">
<h4>
<span class="header-section-number">9.6.4.2</span> Data Visualization<a class="anchor" aria-label="anchor" href="#data-visualization-1"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb360"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">dat2</span> <span class="op">&lt;-</span> <span class="va">dat2</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">tn</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    z <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span></span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">74</span> <span class="op">~</span> <span class="st">'a: 0-74ft'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">88</span> <span class="op">~</span> <span class="st">'b: 74-88'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">95</span> <span class="op">~</span> <span class="st">'c: 88-95'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">99</span> <span class="op">~</span> <span class="st">'d: 95-99'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">104</span> <span class="op">~</span> <span class="st">'e: 99-104'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">109</span> <span class="op">~</span> <span class="st">'f: 104-109'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">115</span> <span class="op">~</span> <span class="st">'g: 109-115'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">120</span> <span class="op">~</span> <span class="st">'h: 115-120'</span>,</span>
<span>        <span class="va">totht</span> <span class="op">&lt;</span> <span class="fl">140</span> <span class="op">~</span> <span class="st">'i: 120-150'</span>,</span>
<span>        <span class="cn">TRUE</span> <span class="op">~</span> <span class="st">'j: 150+'</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">dat2</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">r</span>, y <span class="op">=</span> <span class="va">cumv</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/vars.html">vars</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Cumulative Volume vs. Relative Height by Tree Height Group"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-24-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="model-specification-3" class="section level4" number="9.6.4.3">
<h4>
<span class="header-section-number">9.6.4.3</span> Model Specification<a class="anchor" aria-label="anchor" href="#model-specification-3"><i class="fas fa-link"></i></a>
</h4>
<p>The proposed <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-nonlinear-mixed-models">Nonlinear Mixed Model</a> is: <span class="math display">\[
V_{ij} = \left(\beta_0 + (\beta_1 + b_{1i})\frac{D_i^2 H_i}{1000}\right) \exp\left[-(\beta_2 + b_{2i}) t_{ij} \exp(\beta_3 t_{ij})\right] + e_{ij}
\]</span> Where:</p>
<ul>
<li><p><span class="math inline">\(b_{1i}, b_{2i}\)</span> are random effects for tree <span class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(e_{ij}\)</span> are residual errors.</p></li>
</ul>
</div>
<div id="fitting-the-nonlinear-mixed-model" class="section level4" number="9.6.4.4">
<h4>
<span class="header-section-number">9.6.4.4</span> Fitting the Nonlinear Mixed Model<a class="anchor" aria-label="anchor" href="#fitting-the-nonlinear-mixed-model"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb361"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/nlme/">nlme</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/nlme.html">nlme</a></span><span class="op">(</span></span>
<span>    <span class="va">cumv</span> <span class="op">~</span> <span class="op">(</span><span class="va">b0</span> <span class="op">+</span> <span class="op">(</span><span class="va">b1</span> <span class="op">+</span> <span class="va">u1</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">dbh</span><span class="op">^</span><span class="fl">2</span> <span class="op">*</span> <span class="va">totht</span> <span class="op">/</span> <span class="fl">1000</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> </span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="op">(</span><span class="va">b2</span> <span class="op">+</span> <span class="va">u2</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">t</span> <span class="op">/</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">b3</span> <span class="op">*</span> <span class="va">t</span><span class="op">)</span><span class="op">)</span>, </span>
<span>    data <span class="op">=</span> <span class="va">dat2</span>,</span>
<span>    fixed <span class="op">=</span> <span class="va">b0</span> <span class="op">+</span> <span class="va">b1</span> <span class="op">+</span> <span class="va">b2</span> <span class="op">+</span> <span class="va">b3</span> <span class="op">~</span> <span class="fl">1</span>,</span>
<span>    random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/pdDiag.html">pdDiag</a></span><span class="op">(</span><span class="va">u1</span> <span class="op">+</span> <span class="va">u2</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span>,  <span class="co"># Uncorrelated random effects</span></span>
<span>    groups <span class="op">=</span> <span class="op">~</span> <span class="va">tn</span>,                 <span class="co"># Grouping by tree</span></span>
<span>    start <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>fixed <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>b0 <span class="op">=</span> <span class="fl">0.25</span>, b1 <span class="op">=</span> <span class="fl">2.3</span>, b2 <span class="op">=</span> <span class="fl">2.87</span>, b3 <span class="op">=</span> <span class="fl">6.7</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">tmp</span><span class="op">)</span></span>
<span><span class="co">#&gt; Nonlinear mixed-effects model fit by maximum likelihood</span></span>
<span><span class="co">#&gt;   Model: cumv ~ (b0 + (b1 + u1) * (dbh^2 * totht/1000)) * exp(-(b2 + u2) *      (t/1000) * exp(b3 * t)) </span></span>
<span><span class="co">#&gt;   Data: dat2 </span></span>
<span><span class="co">#&gt;        AIC      BIC    logLik</span></span>
<span><span class="co">#&gt;   31103.73 31151.33 -15544.86</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Formula: list(u1 ~ 1, u2 ~ 1)</span></span>
<span><span class="co">#&gt;  Level: tn</span></span>
<span><span class="co">#&gt;  Structure: Diagonal</span></span>
<span><span class="co">#&gt;                u1       u2 Residual</span></span>
<span><span class="co">#&gt; StdDev: 0.1508094 0.447829 2.226361</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:  b0 + b1 + b2 + b3 ~ 1 </span></span>
<span><span class="co">#&gt;       Value  Std.Error   DF  t-value p-value</span></span>
<span><span class="co">#&gt; b0 0.249386 0.12894686 6297   1.9340  0.0532</span></span>
<span><span class="co">#&gt; b1 2.288832 0.01266804 6297 180.6777  0.0000</span></span>
<span><span class="co">#&gt; b2 2.500497 0.05606686 6297  44.5985  0.0000</span></span>
<span><span class="co">#&gt; b3 6.848871 0.02140677 6297 319.9395  0.0000</span></span>
<span><span class="co">#&gt;  Correlation: </span></span>
<span><span class="co">#&gt;    b0     b1     b2    </span></span>
<span><span class="co">#&gt; b1 -0.639              </span></span>
<span><span class="co">#&gt; b2  0.054  0.056       </span></span>
<span><span class="co">#&gt; b3 -0.011 -0.066 -0.850</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Standardized Within-Group Residuals:</span></span>
<span><span class="co">#&gt;           Min            Q1           Med            Q3           Max </span></span>
<span><span class="co">#&gt; -6.694575e+00 -3.081861e-01 -8.907041e-05  3.469469e-01  7.855665e+00 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Observations: 6636</span></span>
<span><span class="co">#&gt; Number of Groups: 336</span></span>
<span><span class="fu">nlme</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/intervals.html">intervals</a></span><span class="op">(</span><span class="va">tmp</span><span class="op">)</span></span>
<span><span class="co">#&gt; Approximate 95% confidence intervals</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Fixed effects:</span></span>
<span><span class="co">#&gt;           lower      est.     upper</span></span>
<span><span class="co">#&gt; b0 -0.003317833 0.2493858 0.5020894</span></span>
<span><span class="co">#&gt; b1  2.264006069 2.2888323 2.3136585</span></span>
<span><span class="co">#&gt; b2  2.390620116 2.5004971 2.6103742</span></span>
<span><span class="co">#&gt; b3  6.806919325 6.8488712 6.8908232</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Random Effects:</span></span>
<span><span class="co">#&gt;   Level: tn </span></span>
<span><span class="co">#&gt;            lower      est.     upper</span></span>
<span><span class="co">#&gt; sd(u1) 0.1376068 0.1508094 0.1652787</span></span>
<span><span class="co">#&gt; sd(u2) 0.4056207 0.4478290 0.4944295</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Within-group standard error:</span></span>
<span><span class="co">#&gt;    lower     est.    upper </span></span>
<span><span class="co">#&gt; 2.187259 2.226361 2.266161</span></span></code></pre></div>
</div>
<div id="interpretation" class="section level4" number="9.6.4.5">
<h4>
<span class="header-section-number">9.6.4.5</span> Interpretation:<a class="anchor" aria-label="anchor" href="#interpretation"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Fixed Effects (</strong><span class="math inline">\(\beta\)</span>): Describe the average growth pattern across all trees.</p></li>
<li><p><strong>Random Effects (</strong><span class="math inline">\(b_i\)</span>): Capture tree-specific deviations from the average trend.</p></li>
</ul>
<p>This result is a bit different from the original study because of different implementation of nonlinear mixed models.</p>
</div>
<div id="visualizing-model-predictions" class="section level4" number="9.6.4.6">
<h4>
<span class="header-section-number">9.6.4.6</span> Visualizing Model Predictions<a class="anchor" aria-label="anchor" href="#visualizing-model-predictions"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb362"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prediction function</span></span>
<span><span class="va">nlmmfn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fixed</span>, <span class="va">rand</span>, <span class="va">dbh</span>, <span class="va">totht</span>, <span class="va">t</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="op">(</span><span class="va">fixed</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="op">(</span><span class="va">fixed</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">rand</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">dbh</span> <span class="op">^</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">totht</span> <span class="op">/</span> <span class="fl">1000</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="op">(</span><span class="va">fixed</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="va">rand</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">t</span> <span class="op">/</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">fixed</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="op">*</span> <span class="va">t</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Function to generate plots for selected trees</span></span>
<span><span class="va">plot_tree</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">tree_id</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>dob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">dat2</span><span class="op">$</span><span class="va">dob</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">tn</span> <span class="op">&lt;-</span> <span class="va">tree_id</span></span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">dbh</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">dat2</span><span class="op">$</span><span class="va">dbh</span><span class="op">[</span><span class="va">dat2</span><span class="op">$</span><span class="va">tn</span> <span class="op">==</span> <span class="va">tree_id</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">t</span> <span class="op">&lt;-</span> <span class="va">pred</span><span class="op">$</span><span class="va">dob</span> <span class="op">/</span> <span class="va">pred</span><span class="op">$</span><span class="va">dbh</span></span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">totht</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">dat2</span><span class="op">$</span><span class="va">totht</span><span class="op">[</span><span class="va">dat2</span><span class="op">$</span><span class="va">tn</span> <span class="op">==</span> <span class="va">tree_id</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">r</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">pred</span><span class="op">$</span><span class="va">dob</span> <span class="op">/</span> <span class="va">pred</span><span class="op">$</span><span class="va">totht</span></span>
<span>    </span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">with_random</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tmp</span>, <span class="va">pred</span><span class="op">)</span></span>
<span>    <span class="va">pred</span><span class="op">$</span><span class="va">without_random</span> <span class="op">&lt;-</span></span>
<span>        <span class="fu">nlmmfn</span><span class="op">(</span><span class="va">tmp</span><span class="op">$</span><span class="va">coefficients</span><span class="op">$</span><span class="va">fixed</span>,</span>
<span>               <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>               <span class="va">pred</span><span class="op">$</span><span class="va">dbh</span>,</span>
<span>               <span class="va">pred</span><span class="op">$</span><span class="va">totht</span>,</span>
<span>               <span class="va">pred</span><span class="op">$</span><span class="va">t</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">pred</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">r</span>, y <span class="op">=</span> <span class="va">with_random</span>, color <span class="op">=</span> <span class="st">'With Random Effects'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">r</span>, y <span class="op">=</span> <span class="va">without_random</span>, color <span class="op">=</span> <span class="st">'Without Random Effects'</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">dat2</span><span class="op">[</span><span class="va">dat2</span><span class="op">$</span><span class="va">tn</span> <span class="op">==</span> <span class="va">tree_id</span>,<span class="op">]</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">r</span>, y <span class="op">=</span> <span class="va">cumv</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">'Tree'</span>, <span class="va">tree_id</span><span class="op">)</span>, colour <span class="op">=</span> <span class="st">""</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"bottom"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Plotting for selected trees</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu">plot_tree</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu">plot_tree</span><span class="op">(</span><span class="fl">151</span><span class="op">)</span></span>
<span><span class="va">p3</span> <span class="op">&lt;-</span> <span class="fu">plot_tree</span><span class="op">(</span><span class="fl">279</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html">plot_grid</a></span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, <span class="va">p3</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="09-nonlinear_generalized_linear_mixed_files/figure-html/unnamed-chunk-26-1.png" width="90%" style="display: block; margin: auto;"></div>
<ul>
<li><p><strong>Red Line:</strong> Model predictions with tree-specific random effects.</p></li>
<li><p><strong>Teal Line:</strong> Model predictions based only on fixed effects (ignoring tree-specific variation).</p></li>
<li><p><strong>Dots:</strong> Observed cumulative volume for each tree.</p></li>
</ul>
</div>
</div>
</div>
<div id="summary-1" class="section level2" number="9.7">
<h2>
<span class="header-section-number">9.7</span> Summary<a class="anchor" aria-label="anchor" href="#summary-1"><i class="fas fa-link"></i></a>
</h2>
<div class="inline-figure"><img src="images/umbrella_of_models.PNG" style="width:100.0%"></div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></div>
<div class="next"><a href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-nonlinear-and-generalized-linear-mixed-models"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="nav-link" href="#sec-nonlinear-mixed-models"><span class="header-section-number">9.1</span> Nonlinear Mixed Models</a></li>
<li><a class="nav-link" href="#sec-generalized-linear-mixed-models"><span class="header-section-number">9.2</span> Generalized Linear Mixed Models</a></li>
<li><a class="nav-link" href="#relationship-between-nlmms-and-glmms"><span class="header-section-number">9.3</span> Relationship Between NLMMs and GLMMs</a></li>
<li>
<a class="nav-link" href="#marginal-properties-of-glmms"><span class="header-section-number">9.4</span> Marginal Properties of GLMMs</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#marginal-mean-of-y_i"><span class="header-section-number">9.4.1</span> Marginal Mean of \(y_i\)</a></li>
<li><a class="nav-link" href="#marginal-variance-of-y_i"><span class="header-section-number">9.4.2</span> Marginal Variance of \(y_i\)</a></li>
<li><a class="nav-link" href="#marginal-covariance-of-mathbfy"><span class="header-section-number">9.4.3</span> Marginal Covariance of \(\mathbf{y}\)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#estimation-in-nonlinear-and-generalized-linear-mixed-models"><span class="header-section-number">9.5</span> Estimation in Nonlinear and Generalized Linear Mixed Models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#estimation-by-numerical-integration"><span class="header-section-number">9.5.1</span> Estimation by Numerical Integration</a></li>
<li><a class="nav-link" href="#sec-estimation-by-linearization-glmm"><span class="header-section-number">9.5.2</span> Estimation by Linearization</a></li>
<li><a class="nav-link" href="#estimation-by-bayesian-hierarchical-models"><span class="header-section-number">9.5.3</span> Estimation by Bayesian Hierarchical Models</a></li>
<li><a class="nav-link" href="#practical-implementation-in-r"><span class="header-section-number">9.5.4</span> Practical Implementation in R</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#application-nonlinear-and-generalized-linear-mixed-models"><span class="header-section-number">9.6</span> Application: Nonlinear and Generalized Linear Mixed Models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#binomial-data-cbpp-dataset"><span class="header-section-number">9.6.1</span> Binomial Data: CBPP Dataset</a></li>
<li><a class="nav-link" href="#count-data-owl-dataset"><span class="header-section-number">9.6.2</span> Count Data: Owl Dataset</a></li>
<li><a class="nav-link" href="#binomial-example-gotway-hessian-fly-data"><span class="header-section-number">9.6.3</span> Binomial Example: Gotway Hessian Fly Data</a></li>
<li><a class="nav-link" href="#nonlinear-mixed-model-yellow-poplar-data"><span class="header-section-number">9.6.4</span> Nonlinear Mixed Model: Yellow Poplar Data</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-1"><span class="header-section-number">9.7</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/09-nonlinear_generalized_linear_mixed.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/09-nonlinear_generalized_linear_mixed.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-03-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
