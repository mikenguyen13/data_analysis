<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Non-linear Regression | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="Definition: models in which the derivatives of the mean function with respect to the parameters depend on one or more of the parameters. To approximate data, we can approximate the function by a...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 6 Non-linear Regression | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/non-linear-regression.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="Definition: models in which the derivatives of the mean function with respect to the parameters depend on one or more of the parameters. To approximate data, we can approximate the function by a...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Non-linear Regression | A Guide on Data Analysis">
<meta name="twitter:description" content="Definition: models in which the derivatives of the mean function with respect to the parameters depend on one or more of the parameters. To approximate data, we can approximate the function by a...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/proj4js-2.3.15/proj4.js"></script><link href="libs/highcharts-9.3.1/css/motion.css" rel="stylesheet">
<script src="libs/highcharts-9.3.1/highcharts.js"></script><script src="libs/highcharts-9.3.1/highcharts-3d.js"></script><script src="libs/highcharts-9.3.1/highcharts-more.js"></script><script src="libs/highcharts-9.3.1/modules/stock.js"></script><script src="libs/highcharts-9.3.1/modules/map.js"></script><script src="libs/highcharts-9.3.1/modules/data.js"></script><script src="libs/highcharts-9.3.1/modules/exporting.js"></script><script src="libs/highcharts-9.3.1/modules/offline-exporting.js"></script><script src="libs/highcharts-9.3.1/modules/drilldown.js"></script><script src="libs/highcharts-9.3.1/modules/item-series.js"></script><script src="libs/highcharts-9.3.1/modules/overlapping-datalabels.js"></script><script src="libs/highcharts-9.3.1/modules/annotations.js"></script><script src="libs/highcharts-9.3.1/modules/export-data.js"></script><script src="libs/highcharts-9.3.1/modules/funnel.js"></script><script src="libs/highcharts-9.3.1/modules/heatmap.js"></script><script src="libs/highcharts-9.3.1/modules/treemap.js"></script><script src="libs/highcharts-9.3.1/modules/sankey.js"></script><script src="libs/highcharts-9.3.1/modules/dependency-wheel.js"></script><script src="libs/highcharts-9.3.1/modules/organization.js"></script><script src="libs/highcharts-9.3.1/modules/solid-gauge.js"></script><script src="libs/highcharts-9.3.1/modules/streamgraph.js"></script><script src="libs/highcharts-9.3.1/modules/sunburst.js"></script><script src="libs/highcharts-9.3.1/modules/vector.js"></script><script src="libs/highcharts-9.3.1/modules/wordcloud.js"></script><script src="libs/highcharts-9.3.1/modules/xrange.js"></script><script src="libs/highcharts-9.3.1/modules/tilemap.js"></script><script src="libs/highcharts-9.3.1/modules/venn.js"></script><script src="libs/highcharts-9.3.1/modules/gantt.js"></script><script src="libs/highcharts-9.3.1/modules/timeline.js"></script><script src="libs/highcharts-9.3.1/modules/parallel-coordinates.js"></script><script src="libs/highcharts-9.3.1/modules/bullet.js"></script><script src="libs/highcharts-9.3.1/modules/coloraxis.js"></script><script src="libs/highcharts-9.3.1/modules/dumbbell.js"></script><script src="libs/highcharts-9.3.1/modules/lollipop.js"></script><script src="libs/highcharts-9.3.1/modules/series-label.js"></script><script src="libs/highcharts-9.3.1/plugins/motion.js"></script><script src="libs/highcharts-9.3.1/custom/reset.js"></script><script src="libs/highcharts-9.3.1/modules/boost.js"></script><script src="libs/highchart-binding-0.9.4/highchart.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-stat.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="active" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="model-specification.html"><span class="header-section-number">10</span> Model Specification</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">11</span> Imputation (Missing Data)</a></li>
<li><a class="" href="data.html"><span class="header-section-number">12</span> Data</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">13</span> Hypothesis Testing</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">14</span> Prediction and Estimation</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">15</span> Moderation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="causal-inference.html"><span class="header-section-number">16</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="experimental-design.html"><span class="header-section-number">17</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">18</span> Sampling</a></li>
<li><a class="" href="analysis-of-variance-anova.html"><span class="header-section-number">19</span> Analysis of Variance (ANOVA)</a></li>
<li><a class="" href="multivariate-methods.html"><span class="header-section-number">20</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="quasi-experimental.html"><span class="header-section-number">21</span> Quasi-experimental</a></li>
<li><a class="" href="regression-discontinuity.html"><span class="header-section-number">22</span> Regression Discontinuity</a></li>
<li><a class="" href="difference-in-differences.html"><span class="header-section-number">23</span> Difference-in-differences</a></li>
<li><a class="" href="synthetic-control.html"><span class="header-section-number">24</span> Synthetic Control</a></li>
<li><a class="" href="event-studies.html"><span class="header-section-number">25</span> Event Studies</a></li>
<li><a class="" href="matching-methods.html"><span class="header-section-number">26</span> Matching Methods</a></li>
<li><a class="" href="interrupted-time-series.html"><span class="header-section-number">27</span> Interrupted Time Series</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">28</span> Endogeneity</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">29</span> Mediation</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">30</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">31</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">32</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">33</span> Sensitivity Analysis/ Robustness Check</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="non-linear-regression" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Non-linear Regression<a class="anchor" aria-label="anchor" href="#non-linear-regression"><i class="fas fa-link"></i></a>
</h1>
<p><strong>Definition</strong>: models in which the derivatives of the mean function with respect to the parameters depend on one or more of the parameters.</p>
<p>To approximate data, we can approximate the function</p>
<ul>
<li>by a high-order polynomial</li>
<li>by a linear model (e.g., a Taylor expansion around X’s)</li>
<li>a collection of locally linear models or basis function</li>
</ul>
<p>but it would not easy to interpret, or not enough data, or can’t interpret them globally.</p>
<p><strong>intrinsically nonlinear</strong> models:</p>
<p><span class="math display">\[
Y_i = f(\mathbf{x_i;\theta}) + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(f(\mathbf{x_i;\theta})\)</span> is a nonlinear function relating <span class="math inline">\(E(Y_i)\)</span> to the independent variables <span class="math inline">\(x_i\)</span></p>
<ul>
<li>
<span class="math inline">\(\mathbf{x}_i\)</span> is a k x 1 vector of independent variables (fixed).</li>
<li>
<span class="math inline">\(\mathbf{\theta}\)</span> is a p x 1 vector of parameters.</li>
<li>
<span class="math inline">\(\epsilon_i\)</span>s are iid variables mean 0 and variance <span class="math inline">\(\sigma^2\)</span>. (sometimes it’s normal).</li>
</ul>
<div id="inference-1" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Inference<a class="anchor" aria-label="anchor" href="#inference-1"><i class="fas fa-link"></i></a>
</h2>
<p>Since <span class="math inline">\(Y_i = f(\mathbf{x}_i,\theta) + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i \sim iid(0,\sigma^2)\)</span>. We can obtain <span class="math inline">\(\hat{\theta}\)</span> by minimizing <span class="math inline">\(\sum_{i=1}^{n}(Y_i - f(x_i,\theta))^2\)</span> and estimate <span class="math inline">\(s^2 = \hat{\sigma}^2_{\epsilon}=\frac{\sum_{i=1}^{n}(Y_i - f(x_i,\theta))^2}{n-p}\)</span></p>
<div id="linear-function-of-the-parameters" class="section level3" number="6.1.1">
<h3>
<span class="header-section-number">6.1.1</span> Linear Function of the Parameters<a class="anchor" aria-label="anchor" href="#linear-function-of-the-parameters"><i class="fas fa-link"></i></a>
</h3>
<p>If we assume <span class="math inline">\(\epsilon_i \sim N(0,\sigma^2)\)</span>, then</p>
<p><span class="math display">\[
\hat{\theta} \sim AN(\mathbf{\theta},\sigma^2[\mathbf{F}(\theta)'\mathbf{F}(\theta)]^{-1})
\]</span></p>
<p>where An = asymptotic normality</p>
<p>Asymptotic means we have enough data to make inference (As your sample size increases, this becomes more and more accurate (to the true value)).</p>
<p>Since we want to do inference on linear combinations of parameters or contrasts.</p>
<p>If we have <span class="math inline">\(\mathbf{\theta} = (\theta_0,\theta_1,\theta_2)'\)</span> and we want to look at <span class="math inline">\(\theta_1 - \theta_2\)</span>; we can define vector <span class="math inline">\(\mathbf{a} = (0,1,-1)'\)</span>, consider inference for <span class="math inline">\(\mathbf{a'\theta}\)</span></p>
<p>Rules for expectation and variance of a fixed vector <span class="math inline">\(\mathbf{a}\)</span> and random vector <span class="math inline">\(\mathbf{Z}\)</span>;</p>
<p><span class="math display">\[
E(\mathbf{a'Z}) = \mathbf{a'}E(\mathbf{Z}) \\
var(\mathbf{a'Z}) = \mathbf{a'}var(\mathbf{Z}) \mathbf{a}
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\mathbf{a'\hat{\theta}} \sim AN(\mathbf{a'\theta},\sigma^2\mathbf{a'[F(\theta)'F(\theta)]^{-1}a})
\]</span></p>
<p>and <span class="math inline">\(\mathbf{a'\hat{\theta}}\)</span> is asymptotically independent of <span class="math inline">\(s^2\)</span> (to order 1/n) then</p>
<p><span class="math display">\[
\frac{\mathbf{a'\hat{\theta}-a'\theta}}{s(\mathbf{a'[F(\theta)'F(\theta)]^{-1}a})^{1/2}} \sim t_{n-p}
\]</span></p>
<p>to construct <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math inline">\(\mathbf{a'\theta}\)</span></p>
<p><span class="math display">\[
\mathbf{a'\theta} \pm t_{(1-\alpha/2,n-p)}s(\mathbf{a'[F(\theta)'F(\theta)]^{-1}a})^{1/2}
\]</span></p>
<p>Suppose <span class="math inline">\(\mathbf{a'} = (0,...,j,...,0)\)</span>. Then, a confidence interval for the jth element of <span class="math inline">\(\mathbf{\theta}\)</span> is</p>
<p><span class="math display">\[
\hat{\theta}_j \pm t_{(1-\alpha/2,n-p)}s\sqrt{\hat{c}^{j}}
\]</span></p>
<p>where <span class="math inline">\(\hat{c}^{j}\)</span> is the jth diagonal element of <span class="math inline">\([\mathbf{F(\hat{\theta})'F(\hat{\theta})}]^{-1}\)</span></p>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#set a seed value </span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">23</span><span class="op">)</span>

<span class="co">#Generate x as 100 integers using seq function</span>
<span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span>,<span class="fl">1</span><span class="op">)</span>

<span class="co">#Generate y as a*e^(bx)+c</span>
<span class="va">y</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">20</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0.005</span>,<span class="fl">0.075</span><span class="op">)</span><span class="op">*</span><span class="va">x</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">101</span>,<span class="fl">0</span>,<span class="fl">5</span><span class="op">)</span>

<span class="co"># visualize</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-1-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co">#define our data frame</span>
<span class="va">datf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span>

<span class="co">#define our model function</span>
<span class="va">mod</span> <span class="op">=</span><span class="kw">function</span><span class="op">(</span><span class="va">a</span>,<span class="va">b</span>,<span class="va">x</span><span class="op">)</span> <span class="va">a</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">b</span><span class="op">*</span><span class="va">x</span><span class="op">)</span></code></pre></div>
<p>In this example, we can get the starting values by using linearized version of the function <span class="math inline">\(\log y = \log a + b x\)</span>. Then, we can fit a linear regression to this and use our estimates as starting values</p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#get starting values by linearizing</span>
<span class="va">lin_mod</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">~</span><span class="va">x</span>,data<span class="op">=</span><span class="va">datf</span><span class="op">)</span>

<span class="co">#convert the a parameter back from the log scale; b is ok </span>
<span class="va">astrt</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">lin_mod</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>
<span class="va">bstrt</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">lin_mod</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">astrt</span>,<span class="va">bstrt</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 14.07964761  0.01855635</span></code></pre></div>
<p>with <code>nls</code>, we can fit the nonlinear model via least squares</p>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nlin_mod</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu">mod</span><span class="op">(</span><span class="va">a</span>, <span class="va">b</span>, <span class="va">x</span><span class="op">)</span>,
               start <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>a <span class="op">=</span> <span class="va">astrt</span>, b <span class="op">=</span> <span class="va">bstrt</span><span class="op">)</span>,
               data <span class="op">=</span> <span class="va">datf</span><span class="op">)</span>

<span class="co">#look at model fit summary</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">nlin_mod</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: y ~ mod(a, b, x)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;    Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; a 13.603909   0.165390   82.25   &lt;2e-16 ***</span>
<span class="co">#&gt; b  0.019110   0.000153  124.90   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 1.542 on 99 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 3 </span>
<span class="co">#&gt; Achieved convergence tolerance: 7.006e-07</span>

<span class="co">#add prediction to plot</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/predict.html">predict</a></span><span class="op">(</span><span class="va">nlin_mod</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-3-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="nonlinear" class="section level3" number="6.1.2">
<h3>
<span class="header-section-number">6.1.2</span> Nonlinear<a class="anchor" aria-label="anchor" href="#nonlinear"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose that <span class="math inline">\(h(\theta)\)</span> is a nonlinear function of the parameters. We can use Taylor series about <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[
h(\hat{\theta}) \approx h(\theta) + \mathbf{h}'[\hat{\theta}-\theta]
\]</span></p>
<p>where <span class="math inline">\(\mathbf{h} = (\frac{\partial h}{\partial \theta_1},...,\frac{\partial h}{\partial \theta_p})'\)</span></p>
<p>with</p>
<p><span class="math display">\[
E( \hat{\theta}) \approx \theta \\
var(\hat{\theta}) \approx  \sigma^2[\mathbf{F(\theta)'F(\theta)}]^{-1} \\
E(h(\hat{\theta})) \approx h(\theta) \\
var(h(\hat{\theta})) \approx \sigma^2 \mathbf{h'[F(\theta)'F(\theta)]^{-1}h}
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
h(\hat{\theta}) \sim AN(h(\theta),\sigma^2\mathbf{h'[F(\theta)'F(\theta)]^{-1}h})
\]</span></p>
<p>and an approximate <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math inline">\(h(\theta)\)</span> is</p>
<p><span class="math display">\[
h(\hat{\theta}) \pm t_{(1-\alpha/2;n-p)}s(\mathbf{h'[F(\theta)'F(\theta)]^{-1}h})^{1/2}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{h}\)</span> and <span class="math inline">\(\mathbf{F}(\theta)\)</span> are evaluated at <span class="math inline">\(\hat{\theta}\)</span></p>
<p>Regarding <strong>prediction interval</strong> for Y at <span class="math inline">\(x=x_0\)</span></p>
<p><span class="math display">\[
Y_0 = f(x_0;\theta) + \epsilon_0, \epsilon_0 \sim N(0,\sigma^2) \\
\hat{Y}_0 = f(x_0,\hat{\theta})
\]</span></p>
<p>As <span class="math inline">\(n \to \infty\)</span>, <span class="math inline">\(\hat{\theta} \to \theta\)</span>, so we</p>
<p><span class="math display">\[
f(x_0, \hat{\theta}) \approx f(x_0,\theta) + \mathbf{f}_0(\mathbf{\theta})'[\hat{\theta}-\theta]
\]</span></p>
<p>where</p>
<p><span class="math display">\[
f_0(\theta)= (\frac{\partial f(x_0,\theta)}{\partial \theta_1},..,\frac{\partial f(x_0,\theta)}{\partial \theta_p})'
\]</span></p>
<p>(note: this <span class="math inline">\(f_0(\theta)\)</span> is different from <span class="math inline">\(f(\theta)\)</span>).</p>
<p><span class="math display">\[
Y_0 - \hat{Y}_0 \approx Y_0  - f(x_0,\theta) - f_0(\theta)'[\hat{\theta}-\theta]  \\
= \epsilon_0 - f_0(\theta)'[\hat{\theta}-\theta]
\]</span></p>
<p><span class="math display">\[
E(Y_0 - \hat{Y}_0) \approx E(\epsilon_0)E(\hat{\theta}-\theta) = 0 \\
var(Y_0 - \hat{Y}_0) \approx var(\epsilon_0 - \mathbf{(f_0(\theta)'[\hat{\theta}-\theta])}) \\
= \sigma^2 + \sigma^2 \mathbf{f_0 (\theta)'[F(\theta)'F(\theta)]^{-1}f_0(\theta)} \\
= \sigma^2 (1 + \mathbf{f_0 (\theta)'[F(\theta)'F(\theta)]^{-1}f_0(\theta)})
\]</span></p>
<p>Hence, combining</p>
<p><span class="math display">\[
Y_0 - \hat{Y}_0 \sim AN (0,\sigma^2 (1 + \mathbf{f_0 (\theta)'[F(\theta)'F(\theta)]^{-1}f_0(\theta)}))
\]</span></p>
<p>Note:</p>
<p>Confidence intervals for the mean response <span class="math inline">\(Y_i\)</span> (which is different from prediction intervals) can be obtained similarly.</p>
</div>
</div>
<div id="non-linear-least-squares" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Non-linear Least Squares<a class="anchor" aria-label="anchor" href="#non-linear-least-squares"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>The LS estimate of <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\hat{\theta}\)</span> is the set of parameters that minimizes the residual sum of squares:<br><span class="math display">\[
S(\hat{\theta}) = SSE(\hat{\theta}) = \sum_{i=1}^{n}\{Y_i - f(\mathbf{x_i};\hat{\theta})\}^2
\]</span>
</li>
<li>to obtain the solution, we can consider the partial derivatives of <span class="math inline">\(S(\theta)\)</span> with respect to each <span class="math inline">\(\theta_j\)</span> and set them to 0, which gives a system of p equations. Each normal equation is <span class="math display">\[
\frac{\partial S(\theta)}{\partial \theta_j} = -2\sum_{i=1}^{n}\{Y_i -f(\mathbf{x}_i;\theta)\}[\frac{\partial(\mathbf{x}_i;\theta)}{\partial \theta_j}] = 0
\]</span>
</li>
<li>but we can’t obtain a solution directly/analytically for this equation.</li>
</ul>
<p><strong>Numerical Solutions</strong></p>
<ul>
<li>
<p>Grid search</p>
<ul>
<li>A “grid” of possible parameter values and see which one minimize the residual sum of squares.</li>
<li>finer grid = greater accuracy</li>
<li>could be inefficient, and hard when p is large.</li>
</ul>
</li>
<li>
<p>Gauss-Newton Algorithm</p>
<ul>
<li>we have an initial estimate of <span class="math inline">\(\theta\)</span> denoted as <span class="math inline">\(\hat{\theta}^{(0)}\)</span>
</li>
<li>use a Taylor expansions of <span class="math inline">\(f(\mathbf{x}_i;\theta)\)</span> as a function of <span class="math inline">\(\theta\)</span> about the point <span class="math inline">\(\hat{\theta}^{(0)}\)</span>
</li>
</ul>
</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp;= f(x_i;\theta) + \epsilon_i \\
&amp;= f(x_i;\theta) + \sum_{j=1}^{p}\{\frac{\partial f(x_i;\theta)}{\partial \theta_j}\}_{\theta = \hat{\theta}^{(0)}} (\theta_j - \hat{\theta}^{(0)}) + \text{remainder} + \epsilon_i
\end{aligned}
\]</span></p>
<p>Equivalently,</p>
<p>In matrix notation,</p>
<p><span class="math display">\[
\mathbf{Y} =
\left[
\begin{array}
{c}
Y_1 \\
. \\
Y_n
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{f}(\hat{\theta}^{(0)}) =
\left[
\begin{array}
{c}
f(\mathbf{x_1,\hat{\theta}}^{(0)}) \\
. \\
f(\mathbf{x_n,\hat{\theta}}^{(0)})
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{\epsilon} =
\left[
\begin{array}
{c}
\epsilon_1 \\
. \\
\epsilon_n
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{F}(\hat{\theta}^{(0)}) =
\left[
\begin{array}
{ccc}
\frac{\partial f(x_1,\mathbf{\theta})}{\partial \theta_1} &amp; ... &amp; \frac{\partial f(x_1,\mathbf{\theta})}{\partial \theta_p}\\
. &amp; . &amp; . \\
\frac{\partial f(x_n,\mathbf{\theta})}{\partial \theta_1} &amp; ... &amp; \frac{\partial f(x_n,\mathbf{\theta})}{\partial \theta_p}
\end{array} \right]_{\theta = \hat{\theta}^{(0)}}
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{f}(\hat{\theta}^{(0)}) + \mathbf{F}(\hat{\theta}^{(0)})(\theta - \hat{\theta}^{(0)}) + \epsilon + \text{remainder}
\]</span></p>
<p>where we assume that the remainder is small and the error term is only assumed to be iid with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>We can rewrite the above equation as</p>
<p><span class="math display">\[
\mathbf{Y} - \mathbf{f}(\hat{\theta}^{(0)}) \approx \mathbf{F}(\hat{\theta}^{(0)})(\theta - \hat{\theta}^{(0)}) + \epsilon
\]</span></p>
<p>where it is in the form of linear model. After we solve for <span class="math inline">\((\theta - \hat{\theta}^{(0)})\)</span> and let it equal to <span class="math inline">\(\hat{\delta}^{(1)}\)</span><br>
Then we new estimate is given by adding the Gauss increment adjustment to the initial estimate <span class="math inline">\(\hat{\theta}^{(1)} = \hat{\theta}^{(0)} + \hat{\delta}^{(1)}\)</span><br>
We can repeat this process.</p>
<p>Gauss-Newton Algorithm Steps:</p>
<ol style="list-style-type: decimal">
<li>initial estimate <span class="math inline">\(\hat{\theta}^{(0)}\)</span>, set j = 0</li>
<li>Taylor series expansion and calculate <span class="math inline">\(\mathbf{f}(\hat{\theta}^{(j)})\)</span> and <span class="math inline">\(\mathbf{F}(\hat{\theta}^{(j)})\)</span>
</li>
<li>Use OLS to get <span class="math inline">\(\hat{\delta}^{(j+1)}\)</span>
</li>
<li>get the new estimate <span class="math inline">\(\hat{\theta}^{(j+1)}\)</span>, return to step 2</li>
<li>continue until “convergence”</li>
<li>With the final parameter estimate <span class="math inline">\(\hat{\theta}\)</span>, we can estimate <span class="math inline">\(\sigma^2\)</span> if <span class="math inline">\(\epsilon \sim (\mathbf{0}, \sigma^2 \mathbf{I})\)</span> by</li>
</ol>
<p><span class="math display">\[
\hat{\sigma}^2= \frac{1}{n-p}(\mathbf{Y}-\mathbf{f}(x;\hat{\theta}))'(\mathbf{Y}-\mathbf{f}(x;\hat{\theta}))
\]</span></p>
<p><br></p>
<p><strong>Criteria for convergence</strong></p>
<ol style="list-style-type: decimal">
<li>Minor change in the objective function (SSE = residual sum of squares)<br><span class="math display">\[
\frac{|SSE(\hat{\theta}^{(j+1)})-SSE(\hat{\theta}^{(j)})|}{SSE(\hat{\theta}^{(j)})} &lt; \gamma_1
\]</span>
</li>
<li>Minor change in the parameter estimates<br><span class="math display">\[
|\hat{\theta}^{(j+1)}-\hat{\theta}^{(j)}| &lt; \gamma_2
\]</span>
</li>
<li>“residual projection” criterion of <span class="citation">(<a href="references.html#ref-Bates_1981" role="doc-biblioref">Bates and Watts 1981</a>)</span>
</li>
</ol>
<div id="alternative-of-gauss-newton-algorithm" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> Alternative of Gauss-Newton Algorithm<a class="anchor" aria-label="anchor" href="#alternative-of-gauss-newton-algorithm"><i class="fas fa-link"></i></a>
</h3>
<div id="gauss-newton-algorithm" class="section level4" number="6.2.1.1">
<h4>
<span class="header-section-number">6.2.1.1</span> Gauss-Newton Algorithm<a class="anchor" aria-label="anchor" href="#gauss-newton-algorithm"><i class="fas fa-link"></i></a>
</h4>
<p>Normal equations:</p>
<p><span class="math display">\[
\frac{\partial SSE(\theta)}{\partial \theta} = 2\mathbf{F}(\theta)'[\mathbf{Y}-\mathbf{f}(\theta)]
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta}^{(j+1)} &amp;= \hat{\theta}^{(j)} + \hat{\delta}^{(j+1)} \\
&amp;= \hat{\theta}^{(j)} + [\mathbf{F}((\hat{\theta})^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\mathbf{F}(\hat{\theta})^{(j)} \\
&amp;= \hat{\theta}^{(j)} - \frac{1}{2}[\mathbf{F}(\hat{\theta}^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\frac{\partial SSE(\hat{\theta}^{(j)})}{\partial \theta}
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\frac{\partial SSE(\hat{\theta}^{(j)})}{\partial \theta}\)</span> is a gradient vecotr (points in the direction in which the SSE increases most rapidly). This path is known as steepest ascent.<br>
</li>
<li>
<span class="math inline">\([\mathbf{F}(\hat{\theta}^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\)</span> indicates how far to move<br>
</li>
<li>
<span class="math inline">\(-1/2\)</span>: indicator of the direction of steepest descent.</li>
</ul>
</div>
<div id="modified-gauss-newton-algorithm" class="section level4" number="6.2.1.2">
<h4>
<span class="header-section-number">6.2.1.2</span> Modified Gauss-Newton Algorithm<a class="anchor" aria-label="anchor" href="#modified-gauss-newton-algorithm"><i class="fas fa-link"></i></a>
</h4>
<p>To avoid overstepping (the local min), we can use the modified Gauss-Newton Algorithm. We define a new proposal for <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} + \alpha_j \hat{\delta}^{(j+1)}, 0 &lt; \alpha_j &lt; 1
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\alpha_j\)</span> (called the “learning rate”): is used to modify the step length.</li>
</ul>
<p>We could also have <span class="math inline">\(\alpha *1/2\)</span>, but typically it is assumed to be absorbed into the learning rate.</p>
<p>A way to choose <span class="math inline">\(\alpha_j\)</span>, we can use <strong>step halving</strong></p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} + \frac{1}{2^k}\hat{\delta}^{(j+1)}
\]</span></p>
<p>where</p>
<ul>
<li>k is the smallest non-negative integer such that<br><span class="math display">\[
SSE(\hat{\theta}^{(j)}+\frac{1}{2^k}\hat{\delta}^{(j+1)}) &lt; SSE(\hat{\theta}^{(j)})
\]</span> which means we try <span class="math inline">\(\hat{\delta}^{(j+1)}\)</span>, then <span class="math inline">\(\hat{\delta}^{(j+1)}/2\)</span>, <span class="math inline">\(\hat{\delta}^{(j+1)}/4\)</span>, etc.</li>
</ul>
<p>The most general form of the convergence algorithm is</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j \mathbf{A}_j \frac{\partial Q(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\mathbf{A}_j\)</span> is a positive definite matrix<br>
</li>
<li>
<span class="math inline">\(\alpha_j\)</span> is the learning rate<br>
</li>
<li>
<span class="math inline">\(\frac{\partial Q(\hat{\theta}^{(j)})}{\partial \theta}\)</span>is the gradient based on some objective function Q (a function of <span class="math inline">\(\theta\)</span>), which is typically the SSE in nonlinear regression applications (e.g., cross-entropy for classification).</li>
</ul>
<p>Refer back to the <strong>Modified Gauss-Newton Algorithm</strong>, we can see it is in this form</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} =\hat{\theta}^{(j)} - \alpha_j[\mathbf{F}(\hat{\theta}^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\frac{\partial SSE(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>where Q = SSE, <span class="math inline">\([\mathbf{F}(\hat{\theta}^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})]^{-1} = \mathbf{A}\)</span></p>
</div>
<div id="steepest-descent" class="section level4" number="6.2.1.3">
<h4>
<span class="header-section-number">6.2.1.3</span> Steepest Descent<a class="anchor" aria-label="anchor" href="#steepest-descent"><i class="fas fa-link"></i></a>
</h4>
<p>(also known just “gradient descent”)</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j \mathbf{I}_{p \times p}\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<ul>
<li>slow to converge, moves rapidly initially.<br>
</li>
<li>could be use for starting values</li>
</ul>
</div>
<div id="levenberg--marquardt" class="section level4" number="6.2.1.4">
<h4>
<span class="header-section-number">6.2.1.4</span> Levenberg -Marquardt<a class="anchor" aria-label="anchor" href="#levenberg--marquardt"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j [\mathbf{F}(\hat{\theta}^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})+ \tau \mathbf{I}_{p \times p}]\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>which is a compromise between the <a href="non-linear-regression.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a> and the <a href="non-linear-regression.html#steepest-descent">Steepest Descent</a>.</p>
<ul>
<li>best when <span class="math inline">\(\mathbf{F}(\hat{\theta}^{(j)})'\mathbf{F}(\hat{\theta}^{(j)})\)</span> is nearly singular (<span class="math inline">\(\mathbf{F}(\hat{\theta}^{(j)})\)</span> isn’t of full rank)<br>
</li>
<li>similar to ridge regression<br>
</li>
<li>If <span class="math inline">\(SSE(\hat{\theta}^{(j+1)}) &lt; SSE(\hat{\theta}^{(j)})\)</span>, then <span class="math inline">\(\tau= \tau/10\)</span> for the next iteration. Otherwise, <span class="math inline">\(\tau = 10 \tau\)</span>
</li>
</ul>
</div>
<div id="newton-raphson" class="section level4" number="6.2.1.5">
<h4>
<span class="header-section-number">6.2.1.5</span> Newton-Raphson<a class="anchor" aria-label="anchor" href="#newton-raphson"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j [\frac{\partial^2Q(\hat{\theta}^{(j)})}{\partial \theta \partial \theta'}]^{-1}\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>The <strong>Hessian matrix</strong> can be rewritten as:</p>
<p><span class="math display">\[
\frac{ \partial^2Q(\hat{ \theta}^{(j)})}{ \partial \theta \partial \theta'} = 2 \mathbf{F}((\hat{ \theta})^{(j)})' \mathbf{F} ( \hat{\theta}^{(j)}) - 2\sum_{i=1}^{n} [Y_i - f(x_i;\theta)] \frac{\partial^2f(x_i;\theta)}{\partial \theta \partial \theta'}
\]</span></p>
<p>which contains the same term that <a href="non-linear-regression.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a>, combined with one containing the second partial derivatives of f(). (methods that require the second derivatives of the objective function are known as “second-order methods”.)<br>
However, the last term <span class="math inline">\(\frac{\partial^2f(x_i;\theta)}{\partial \theta \partial \theta'}\)</span> can sometimes be nonsingular.</p>
</div>
<div id="quasi-newton" class="section level4" number="6.2.1.6">
<h4>
<span class="header-section-number">6.2.1.6</span> Quasi-Newton<a class="anchor" aria-label="anchor" href="#quasi-newton"><i class="fas fa-link"></i></a>
</h4>
<p>update <span class="math inline">\(\theta\)</span> according to</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j \mathbf{H}_j^{-1}\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>where <span class="math inline">\(H_j\)</span> is a symmetric positive definite approximation to the Hessian, which gets closer as <span class="math inline">\(j \to \infty\)</span>.</p>
<ul>
<li>
<span class="math inline">\(\mathbf{H}_j\)</span> is computed iteratively<br>
</li>
<li>AMong first-order methods(where only first derivatives are required), this method performs best.</li>
</ul>
</div>
<div id="derivative-free-methods" class="section level4" number="6.2.1.7">
<h4>
<span class="header-section-number">6.2.1.7</span> Derivative Free Methods<a class="anchor" aria-label="anchor" href="#derivative-free-methods"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<strong>secant Method</strong>: like <a href="non-linear-regression.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a>, but calculates the derivatives numerically from past iterations.<br>
</li>
<li>
<strong>Simplex Methods</strong><br>
</li>
<li>
<strong>Genetic Algorithm</strong><br>
</li>
<li>
<strong>Differential Evolution Algorithms</strong><br>
</li>
<li>
<strong>Particle Swarm Optimization</strong><br>
</li>
<li><strong>Ant Colony Optimization</strong></li>
</ul>
</div>
</div>
<div id="practical-considerations" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> Practical Considerations<a class="anchor" aria-label="anchor" href="#practical-considerations"><i class="fas fa-link"></i></a>
</h3>
<p>To converge, algorithm need good initial estimates.</p>
<ul>
<li>
<p>Starting values:</p>
<ul>
<li>Prior or theoretical info<br>
</li>
<li>A grid search or a graph of <span class="math inline">\(SSE(\theta)\)</span><br>
</li>
<li>could also use OLS to get starting values.<br>
</li>
<li>Model interpretation: if you have some idea regarding the form of the objective function, then you can try to guess the initial value.<br>
</li>
<li>Expected Value Parameterization<br>
</li>
</ul>
</li>
<li>
<p>Constrained Parameters: (constraints on parameters like <span class="math inline">\(\theta_i&gt;a,a&lt; \theta_i &lt;b\)</span>)</p>
<ul>
<li>fit the model first to see if the converged parameter estimates satisfy the constraints.</li>
<li>if they dont’ satisfy, then try re-parameterizing</li>
</ul>
</li>
</ul>
<div id="failure-to-converge" class="section level4" number="6.2.2.1">
<h4>
<span class="header-section-number">6.2.2.1</span> Failure to converge<a class="anchor" aria-label="anchor" href="#failure-to-converge"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<span class="math inline">\(SSE(\theta)\)</span> may be “flat” in a neighborhood of the minimum.<br>
</li>
<li>You can try different or “better” starting values.<br>
</li>
<li>Might suggest the model is too complex for the data, might consider simpler model.</li>
</ul>
</div>
<div id="convergence-to-a-local-minimum" class="section level4" number="6.2.2.2">
<h4>
<span class="header-section-number">6.2.2.2</span> Convergence to a Local Minimum<a class="anchor" aria-label="anchor" href="#convergence-to-a-local-minimum"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>Linear least squares has the property that <span class="math inline">\(SSE(\theta) = \mathbf{(Y-X\beta)'(Y-X\beta)}\)</span>, which is quadratic and has a unique minimum (or maximum).</li>
<li>Nonlinear east squares need not have a unique minimum</li>
<li>Using different starting values can help</li>
<li>If the dimension of <span class="math inline">\(\theta\)</span> is low, graph <span class="math inline">\(SSE(\theta)\)</span> as a function of <span class="math inline">\(\theta_i\)</span>
</li>
<li>Different algorithm can help (e.g., genetic algorithm, particle swarm)</li>
</ul>
<p>To converge, algorithms need good initial estimates.</p>
<ul>
<li>
<p>Starting values:</p>
<ul>
<li>prior or theoretical info</li>
<li>A grid search or a graph</li>
<li>OLS estimates as starting values</li>
<li>Model interpretation</li>
<li>Expected Value Parameterization</li>
</ul>
</li>
<li>
<p>Constrained Parameters:</p>
<ul>
<li>try the model without the constraints first.</li>
<li>If the resulted parameter estimates does not satisfy the constraint, try re-parameterizing</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Grid search</span>
<span class="co">#choose grid of a and b values</span>
<span class="va">aseq</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">18</span>,<span class="fl">.2</span><span class="op">)</span>
<span class="va">bseq</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">.001</span>,<span class="fl">.075</span>,<span class="fl">.001</span><span class="op">)</span>

<span class="va">na</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">aseq</span><span class="op">)</span>
<span class="va">nb</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">bseq</span><span class="op">)</span>
<span class="va">SSout</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">na</span><span class="op">*</span><span class="va">nb</span>,<span class="fl">3</span><span class="op">)</span> <span class="co">#matrix to save output</span>
<span class="va">cnt</span> <span class="op">=</span> <span class="fl">0</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">k</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">na</span><span class="op">)</span><span class="op">{</span>
   <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">nb</span><span class="op">)</span><span class="op">{</span>
      <span class="va">cnt</span> <span class="op">=</span> <span class="va">cnt</span><span class="op">+</span><span class="fl">1</span>
      <span class="va">ypred</span> <span class="op">=</span> <span class="fu">mod</span><span class="op">(</span><span class="va">aseq</span><span class="op">[</span><span class="va">k</span><span class="op">]</span>,<span class="va">bseq</span><span class="op">[</span><span class="va">j</span><span class="op">]</span>,<span class="va">x</span><span class="op">)</span> <span class="co">#evaluate model w/ these parms</span>
      <span class="va">ss</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">ypred</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>  <span class="co">#this is our SSE objective function</span>
      <span class="co">#save values of a, b, and SSE</span>
      <span class="va">SSout</span><span class="op">[</span><span class="va">cnt</span>,<span class="fl">1</span><span class="op">]</span><span class="op">=</span><span class="va">aseq</span><span class="op">[</span><span class="va">k</span><span class="op">]</span>
      <span class="va">SSout</span><span class="op">[</span><span class="va">cnt</span>,<span class="fl">2</span><span class="op">]</span><span class="op">=</span><span class="va">bseq</span><span class="op">[</span><span class="va">j</span><span class="op">]</span>
      <span class="va">SSout</span><span class="op">[</span><span class="va">cnt</span>,<span class="fl">3</span><span class="op">]</span><span class="op">=</span><span class="va">ss</span>
   <span class="op">}</span>
<span class="op">}</span>
<span class="co">#find minimum SSE and associated a,b values</span>
<span class="va">mn_indx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">SSout</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span><span class="op">)</span>
<span class="va">astrt</span> <span class="op">=</span> <span class="va">SSout</span><span class="op">[</span><span class="va">mn_indx</span>,<span class="fl">1</span><span class="op">]</span>
<span class="va">bstrt</span> <span class="op">=</span> <span class="va">SSout</span><span class="op">[</span><span class="va">mn_indx</span>,<span class="fl">2</span><span class="op">]</span>
<span class="co">#now, run nls function with these starting values</span>
<span class="va">nlin_modG</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="fu">mod</span><span class="op">(</span><span class="va">a</span>,<span class="va">b</span>,<span class="va">x</span><span class="op">)</span>,start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="va">astrt</span>,b<span class="op">=</span><span class="va">bstrt</span><span class="op">)</span><span class="op">)</span> 

<span class="va">nlin_modG</span>
<span class="co">#&gt; Nonlinear regression model</span>
<span class="co">#&gt;   model: y ~ mod(a, b, x)</span>
<span class="co">#&gt;    data: parent.frame()</span>
<span class="co">#&gt;        a        b </span>
<span class="co">#&gt; 13.60391  0.01911 </span>
<span class="co">#&gt;  residual sum-of-squares: 235.5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 3 </span>
<span class="co">#&gt; Achieved convergence tolerance: 2.293e-07</span>
<span class="co"># Note, the package `nls_multstart` will allow you to do a grid search without programming your own loop</span></code></pre></div>
<p>For prediction interval</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">plotFit</span><span class="op">(</span>
  <span class="va">nlin_modG</span>,
  interval <span class="op">=</span> <span class="st">"both"</span>,
  pch <span class="op">=</span> <span class="fl">19</span>,
  shade <span class="op">=</span> <span class="cn">TRUE</span>,
  col.conf <span class="op">=</span> <span class="st">"skyblue4"</span>,
  col.pred <span class="op">=</span> <span class="st">"lightskyblue2"</span>,
  data <span class="op">=</span> <span class="va">datf</span>
<span class="op">)</span>  </code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Based on the forms of your function, you can also have programmed starting values from <code>nls</code> function (e.e.g, logistic growth, asymptotic regression, etc).</p>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/apropos.html">apropos</a></span><span class="op">(</span><span class="st">"^SS"</span><span class="op">)</span>
<span class="co">#&gt;  [1] "ss"          "SSasymp"     "SSasympOff"  "SSasympOrig" "SSbiexp"    </span>
<span class="co">#&gt;  [6] "SSD"         "SSfol"       "SSfpl"       "SSgompertz"  "SSlogis"    </span>
<span class="co">#&gt; [11] "SSmicmen"    "SSout"       "SSweibull"</span></code></pre></div>
<p>For example, a logistic growth model:</p>
<p><span class="math display">\[
P = \frac{K}{1+ exp(P_0+ rt)} + \epsilon
\]</span></p>
<p>where</p>
<ul>
<li>P = population at time t</li>
<li>K = carrying capacity</li>
<li>r = population growth rate</li>
</ul>
<p>but in <code>R</code> you have slight different parameterization:</p>
<p><span class="math display">\[
P = \frac{asym}{1 + exp(\frac{xmid - t}{scal})}
\]</span></p>
<p>where</p>
<ul>
<li>asym = carrying capacity</li>
<li>xmid = the x value at the inflection point of the curve</li>
<li>scal = scaling parameter.</li>
</ul>
<p>Hence, you have</p>
<ul>
<li>K = asym</li>
<li>r = -1/scal</li>
<li><span class="math inline">\(P_0 = -rxmid\)</span></li>
</ul>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># simulated data</span>
<span class="va">time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">15</span>, <span class="fl">20</span>, <span class="fl">25</span>, <span class="fl">30</span>, <span class="fl">35</span><span class="op">)</span>
<span class="va">population</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2.8</span>, <span class="fl">4.2</span>, <span class="fl">3.5</span>, <span class="fl">6.3</span>, <span class="fl">15.7</span>, <span class="fl">21.3</span>, <span class="fl">23.7</span>, <span class="fl">25.1</span>, <span class="fl">25.8</span>, <span class="fl">25.9</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">time</span>, <span class="va">population</span>, las <span class="op">=</span> <span class="fl">1</span>, pch <span class="op">=</span> <span class="fl">16</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-7-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># model fitting</span>
<span class="va">logisticModelSS</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">population</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/SSlogis.html">SSlogis</a></span><span class="op">(</span><span class="va">time</span>, <span class="va">Asym</span>, <span class="va">xmid</span>, <span class="va">scal</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">logisticModelSS</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: population ~ SSlogis(time, Asym, xmid, scal)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;      Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; Asym  25.5029     0.3666   69.56 3.34e-11 ***</span>
<span class="co">#&gt; xmid   8.7347     0.3007   29.05 1.48e-08 ***</span>
<span class="co">#&gt; scal   3.6353     0.2186   16.63 6.96e-07 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.6528 on 7 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 1 </span>
<span class="co">#&gt; Achieved convergence tolerance: 1.908e-06</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logisticModelSS</span><span class="op">)</span>
<span class="co">#&gt;      Asym      xmid      scal </span>
<span class="co">#&gt; 25.502890  8.734698  3.635333</span></code></pre></div>
<p>Other parameterization</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#convert to other parameterization</span>
<span class="va">Ks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logisticModelSS</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
<span class="va">rs</span> <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logisticModelSS</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span>
<span class="va">Pos</span> <span class="op">=</span> <span class="op">-</span> <span class="va">rs</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logisticModelSS</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>
<span class="co">#let's refit with these parameters</span>
<span class="va">logisticModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">population</span> <span class="op">~</span> <span class="va">K</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">Po</span> <span class="op">+</span> <span class="va">r</span> <span class="op">*</span> <span class="va">time</span><span class="op">)</span><span class="op">)</span>,start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>Po<span class="op">=</span><span class="va">Pos</span>,r<span class="op">=</span><span class="va">rs</span>,K<span class="op">=</span><span class="va">Ks</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">logisticModel</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: population ~ K/(1 + exp(Po + r * time))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;    Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; Po  2.40272    0.12702   18.92 2.87e-07 ***</span>
<span class="co">#&gt; r  -0.27508    0.01654  -16.63 6.96e-07 ***</span>
<span class="co">#&gt; K  25.50289    0.36665   69.56 3.34e-11 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.6528 on 7 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 0 </span>
<span class="co">#&gt; Achieved convergence tolerance: 1.924e-06</span></code></pre></div>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#note: initial values =  solution (highly unusual, but ok)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">time</span>, <span class="va">population</span>, las <span class="op">=</span> <span class="fl">1</span>, pch <span class="op">=</span> <span class="fl">16</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">time</span>, <span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/predict.html">predict</a></span><span class="op">(</span><span class="va">logisticModel</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-9-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>If can also define your own self-starting fucntion if your models are uncommon (built in <code>nls</code>)</p>
<p>Example is based on <span class="citation">(<a href="references.html#ref-Schabenberger_2001" role="doc-biblioref">Schabenberger and Pierce 2001</a>)</span></p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#Load data</span>
<span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"images/dat.txt"</span>, header <span class="op">=</span> <span class="cn">T</span><span class="op">)</span>
<span class="co"># plot</span>
<span class="va">dat.plot</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="va">no3</span>,
    y <span class="op">=</span> <span class="va">ryp</span>,
    color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">depth</span><span class="op">)</span>
  <span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">'Depth (cm)'</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">'Soil NO3'</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">'relative yield percent'</span><span class="op">)</span>
<span class="va">dat.plot</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-10-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The suggested model (known as plateau model) is</p>
<p><span class="math display">\[
E(Y_{ij}) = (\beta_{0j} + \beta_{1j}N_{ij})I_{N_{ij}\le \alpha_j} + (\beta_{0j} + \beta_{1j}\alpha_j)I_{N_{ij} &gt; \alpha_j}
\]</span></p>
<p>where</p>
<ul>
<li>N is an observation</li>
<li>i is a particular observation</li>
<li>j = 1,2 corresponding to depths (30,60)</li>
</ul>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#First define model as a function</span>
<span class="va">nonlinModel</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">predictor</span>,<span class="va">b0</span>,<span class="va">b1</span>,<span class="va">alpha</span><span class="op">)</span><span class="op">{</span>
  <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fifelse.html">ifelse</a></span><span class="op">(</span><span class="va">predictor</span><span class="op">&lt;=</span><span class="va">alpha</span>, 
         <span class="va">b0</span><span class="op">+</span><span class="va">b1</span><span class="op">*</span><span class="va">predictor</span>, <span class="co">#if observation less than cutoff simple linear model</span>
         <span class="va">b0</span><span class="op">+</span><span class="va">b1</span><span class="op">*</span><span class="va">alpha</span><span class="op">)</span> <span class="co">#otherwise flat line</span>
<span class="op">}</span></code></pre></div>
<p>define <code>selfStart</code> function. Because we defined our model to be linear in the first part and then plateau (remain constant) we can use the first half of our predictors (sorted by increasing value) to get an initial estimate for the slope and intercept of the model, and the last predictor value (alpha) can be the starting value for the plateau parameter.</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nonlinModelInit</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mCall</span>,<span class="va">LHS</span>,<span class="va">data</span><span class="op">)</span><span class="op">{</span>
  <span class="co">#sort data by increasing predictor value - </span>
  <span class="co">#done so we can just use the low level no3 conc to fit a simple model</span>
  <span class="va">xy</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sortedXyData.html">sortedXyData</a></span><span class="op">(</span><span class="va">mCall</span><span class="op">[[</span><span class="st">'predictor'</span><span class="op">]</span><span class="op">]</span>,<span class="va">LHS</span>,<span class="va">data</span><span class="op">)</span>
  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">xy</span><span class="op">)</span>
  <span class="co">#For the first half of the data a simple linear model is fit</span>
  <span class="va">lmFit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">xy</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">n</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>,<span class="st">'y'</span><span class="op">]</span><span class="op">~</span><span class="va">xy</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">n</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>,<span class="st">'x'</span><span class="op">]</span><span class="op">)</span>
  <span class="va">b0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lmFit</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>
  <span class="va">b1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lmFit</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>
  <span class="co">#for the cut off to the flat part select the last x value used in creating linear model</span>
  <span class="va">alpha</span> <span class="op">&lt;-</span> <span class="va">xy</span><span class="op">[</span><span class="op">(</span><span class="va">n</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>,<span class="st">'x'</span><span class="op">]</span>
  <span class="va">value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">b0</span>,<span class="va">b1</span>,<span class="va">alpha</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">value</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">mCall</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'b0'</span>,<span class="st">'b1'</span>,<span class="st">'alpha'</span><span class="op">)</span><span class="op">]</span>
  <span class="va">value</span>
<span class="op">}</span></code></pre></div>
<p>combine model and custom function to calculate starting values.</p>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">SS_nonlinModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/selfStart.html">selfStart</a></span><span class="op">(</span><span class="va">nonlinModel</span>,<span class="va">nonlinModelInit</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'b0'</span>,<span class="st">'b1'</span>,<span class="st">'alpha'</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#Above code defined model and selfStart now just need to call it for each of the depths</span>
<span class="va">sep30_nls</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">ryp</span> <span class="op">~</span> <span class="fu">SS_nonlinModel</span><span class="op">(</span>predictor <span class="op">=</span> <span class="va">no3</span>, <span class="va">b0</span>, <span class="va">b1</span>, <span class="va">alpha</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">[</span><span class="va">dat</span><span class="op">$</span><span class="va">depth</span> <span class="op">==</span>
                                                                         <span class="fl">30</span>, <span class="op">]</span><span class="op">)</span>

<span class="va">sep60_nls</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">ryp</span> <span class="op">~</span> <span class="fu">SS_nonlinModel</span><span class="op">(</span>predictor <span class="op">=</span> <span class="va">no3</span>, <span class="va">b0</span>, <span class="va">b1</span>, <span class="va">alpha</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">[</span><span class="va">dat</span><span class="op">$</span><span class="va">depth</span> <span class="op">==</span>
                                                                         <span class="fl">60</span>, <span class="op">]</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="fu">plotFit</span><span class="op">(</span>
  <span class="va">sep30_nls</span>,
  interval <span class="op">=</span> <span class="st">"both"</span>,
  pch <span class="op">=</span> <span class="fl">19</span>,
  shade <span class="op">=</span> <span class="cn">TRUE</span>,
  col.conf <span class="op">=</span> <span class="st">"skyblue4"</span>,
  col.pred <span class="op">=</span> <span class="st">"lightskyblue2"</span>,
  data <span class="op">=</span> <span class="va">dat</span><span class="op">[</span><span class="va">dat</span><span class="op">$</span><span class="va">depth</span> <span class="op">==</span> <span class="fl">30</span>, <span class="op">]</span>,
  main <span class="op">=</span> <span class="st">'Results 30 cm depth'</span>,
  ylab <span class="op">=</span> <span class="st">'relative yield percent'</span>,
  xlab <span class="op">=</span> <span class="st">'Soil NO3 concentration'</span>,
  xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">120</span><span class="op">)</span>
<span class="op">)</span>
<span class="fu">plotFit</span><span class="op">(</span>
  <span class="va">sep60_nls</span>,
  interval <span class="op">=</span> <span class="st">"both"</span>,
  pch <span class="op">=</span> <span class="fl">19</span>,
  shade <span class="op">=</span> <span class="cn">TRUE</span>,
  col.conf <span class="op">=</span> <span class="st">"lightpink4"</span>,
  col.pred <span class="op">=</span> <span class="st">"lightpink2"</span>,
  data <span class="op">=</span> <span class="va">dat</span><span class="op">[</span><span class="va">dat</span><span class="op">$</span><span class="va">depth</span> <span class="op">==</span> <span class="fl">60</span>, <span class="op">]</span>,
  main <span class="op">=</span> <span class="st">'Results 60 cm depth'</span>,
  ylab <span class="op">=</span> <span class="st">'relative yield percent'</span>,
  xlab <span class="op">=</span> <span class="st">'Soil NO3 concentration'</span>,
  xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">120</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-14-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">sep30_nls</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: ryp ~ SS_nonlinModel(predictor = no3, b0, b1, alpha)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; b0     15.1943     2.9781   5.102 6.89e-07 ***</span>
<span class="co">#&gt; b1      3.5760     0.1853  19.297  &lt; 2e-16 ***</span>
<span class="co">#&gt; alpha  23.1324     0.5098  45.373  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 8.258 on 237 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 6 </span>
<span class="co">#&gt; Achieved convergence tolerance: 3.608e-09</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">sep60_nls</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: ryp ~ SS_nonlinModel(predictor = no3, b0, b1, alpha)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; b0      5.4519     2.9785    1.83   0.0684 .  </span>
<span class="co">#&gt; b1      5.6820     0.2529   22.46   &lt;2e-16 ***</span>
<span class="co">#&gt; alpha  16.2863     0.2818   57.80   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 7.427 on 237 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 5 </span>
<span class="co">#&gt; Achieved convergence tolerance: 8.571e-09</span></code></pre></div>
<p>Instead of modeling the depths model separately we model them together - so there is a common slope, intercept, and plateau.</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="va">red_nls</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">ryp</span> <span class="op">~</span> <span class="fu">SS_nonlinModel</span><span class="op">(</span>predictor <span class="op">=</span> <span class="va">no3</span>, <span class="va">b0</span>, <span class="va">b1</span>, <span class="va">alpha</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">red_nls</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: ryp ~ SS_nonlinModel(predictor = no3, b0, b1, alpha)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; b0      8.7901     2.7688   3.175   0.0016 ** </span>
<span class="co">#&gt; b1      4.8995     0.2207  22.203   &lt;2e-16 ***</span>
<span class="co">#&gt; alpha  18.0333     0.3242  55.630   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 9.13 on 477 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 7 </span>
<span class="co">#&gt; Achieved convergence tolerance: 7.126e-09</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="fu">plotFit</span><span class="op">(</span>
  <span class="va">red_nls</span>,
  interval <span class="op">=</span> <span class="st">"both"</span>,
  pch <span class="op">=</span> <span class="fl">19</span>,
  shade <span class="op">=</span> <span class="cn">TRUE</span>,
  col.conf <span class="op">=</span> <span class="st">"lightblue4"</span>,
  col.pred <span class="op">=</span> <span class="st">"lightblue2"</span>,
  data <span class="op">=</span> <span class="va">dat</span>,
  main <span class="op">=</span> <span class="st">'Results combined'</span>,
  ylab <span class="op">=</span> <span class="st">'relative yield percent'</span>,
  xlab <span class="op">=</span> <span class="st">'Soil NO3 concentration'</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/reduce-model-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Examine residual values for the combined model.</p>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/aursiber/nlstools">nlstools</a></span><span class="op">)</span>
<span class="co">#using nlstools nlsResiduals function to get some quick residual plots</span>
<span class="co">#can also use test.nlsResiduals(resid)</span>
<span class="co"># https://www.rdocumentation.org/packages/nlstools/versions/1.0-2</span>
<span class="va">resid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlstools/man/nlsResiduals.html">nlsResiduals</a></span><span class="op">(</span><span class="va">red_nls</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">resid</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/reduce-model-resid-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>can we test whether the parameters for the two soil depth fits are significantly different? To know if the combined model is appropriate, we consider a parameterization where we let the parameters for the 60cm model be equal to the parameters from the 30cm model plus some increment:</p>
<p><span class="math display">\[
\beta_{02} = \beta_{01} + d_0 \\
\beta_{12} = \beta_{11} + d_1 \\
\alpha_{2} = \alpha_{1} + d_a
\]</span></p>
<p>We can implement this in the following function:</p>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="va">nonlinModelF</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">predictor</span>,<span class="va">soildep</span>,<span class="va">b01</span>,<span class="va">b11</span>,<span class="va">a1</span>,<span class="va">d0</span>,<span class="va">d1</span>,<span class="va">da</span><span class="op">)</span><span class="op">{</span>
   <span class="va">b02</span> <span class="op">=</span> <span class="va">b01</span> <span class="op">+</span> <span class="va">d0</span> <span class="co">#make 60cm parms = 30cm parms + increment</span>
   <span class="va">b12</span> <span class="op">=</span> <span class="va">b11</span> <span class="op">+</span> <span class="va">d1</span>
   <span class="va">a2</span> <span class="op">=</span> <span class="va">a1</span> <span class="op">+</span> <span class="va">da</span>
   
   <span class="va">y1</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fifelse.html">ifelse</a></span><span class="op">(</span><span class="va">predictor</span><span class="op">&lt;=</span><span class="va">a1</span>, 
         <span class="va">b01</span><span class="op">+</span><span class="va">b11</span><span class="op">*</span><span class="va">predictor</span>, <span class="co">#if observation less than cutoff simple linear model</span>
         <span class="va">b01</span><span class="op">+</span><span class="va">b11</span><span class="op">*</span><span class="va">a1</span><span class="op">)</span> <span class="co">#otherwise flat line</span>
   <span class="va">y2</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fifelse.html">ifelse</a></span><span class="op">(</span><span class="va">predictor</span><span class="op">&lt;=</span><span class="va">a2</span>, 
               <span class="va">b02</span><span class="op">+</span><span class="va">b12</span><span class="op">*</span><span class="va">predictor</span>, 
               <span class="va">b02</span><span class="op">+</span><span class="va">b12</span><span class="op">*</span><span class="va">a2</span><span class="op">)</span> 
   <span class="va">y</span> <span class="op">=</span>  <span class="va">y1</span><span class="op">*</span><span class="op">(</span><span class="va">soildep</span> <span class="op">==</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span> <span class="va">y2</span><span class="op">*</span><span class="op">(</span><span class="va">soildep</span> <span class="op">==</span> <span class="fl">60</span><span class="op">)</span>  <span class="co">#combine models</span>
   <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Starting values are easy now because we fit each model individually.</p>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="va">Soil_full</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">ryp</span><span class="op">~</span><span class="fu">nonlinModelF</span><span class="op">(</span>predictor<span class="op">=</span><span class="va">no3</span>,soildep<span class="op">=</span><span class="va">depth</span>,<span class="va">b01</span>,<span class="va">b11</span>,<span class="va">a1</span>,<span class="va">d0</span>,<span class="va">d1</span>,<span class="va">da</span><span class="op">)</span>,
              data<span class="op">=</span><span class="va">dat</span>,
              start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>b01<span class="op">=</span><span class="fl">15.2</span>,b11<span class="op">=</span><span class="fl">3.58</span>,a1<span class="op">=</span><span class="fl">23.13</span>,d0<span class="op">=</span><span class="op">-</span><span class="fl">9.74</span>,d1<span class="op">=</span><span class="fl">2.11</span>,da<span class="op">=</span><span class="op">-</span><span class="fl">6.85</span><span class="op">)</span><span class="op">)</span> 

<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Soil_full</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Formula: ryp ~ nonlinModelF(predictor = no3, soildep = depth, b01, b11, </span>
<span class="co">#&gt;     a1, d0, d1, da)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Parameters:</span>
<span class="co">#&gt;     Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; b01  15.1943     2.8322   5.365 1.27e-07 ***</span>
<span class="co">#&gt; b11   3.5760     0.1762  20.291  &lt; 2e-16 ***</span>
<span class="co">#&gt; a1   23.1324     0.4848  47.711  &lt; 2e-16 ***</span>
<span class="co">#&gt; d0   -9.7424     4.2357  -2.300   0.0219 *  </span>
<span class="co">#&gt; d1    2.1060     0.3203   6.575 1.29e-10 ***</span>
<span class="co">#&gt; da   -6.8461     0.5691 -12.030  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 7.854 on 474 degrees of freedom</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 1 </span>
<span class="co">#&gt; Achieved convergence tolerance: 3.742e-06</span></code></pre></div>
<p>So, the increment parameters, <span class="math inline">\(d_1\)</span>,<span class="math inline">\(d_2\)</span>,<span class="math inline">\(d_a\)</span> are all significantly different from 0, suggesting that we should have two models here.</p>
</div>
</div>
<div id="modelestiamtion-adequcy" class="section level3" number="6.2.3">
<h3>
<span class="header-section-number">6.2.3</span> Model/Estiamtion Adequcy<a class="anchor" aria-label="anchor" href="#modelestiamtion-adequcy"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">(<a href="references.html#ref-Bates_1980" role="doc-biblioref">Bates and Watts 1980</a>)</span> assess nonlinearity in terms of 2 components of curvature:</p>
<ul>
<li>
<p><strong>Intrinsic nonlinearity</strong>: the degree of bending and twisting in <span class="math inline">\(f(\theta)\)</span>; our estimation approach assumes that hte true function is relatively flat (planar) in the neighborhood fo <span class="math inline">\(\hat{\theta}\)</span>, which would not be true if <span class="math inline">\(f()\)</span> has a lot of “bending” int he neighborhood of <span class="math inline">\(\hat{\theta}\)</span> (independent of parameterizaiton)</p>
<ul>
<li><p>If bad, the distribution of residuals will be seriously distorted</p></li>
<li><p>slow to converge</p></li>
<li><p>difficult to identify ( could use this function <code>rms.curve</code>)</p></li>
<li>
<p>Solution:</p>
<ul>
<li>could use higher order Taylor expansions estimation</li>
<li>Bayesian method</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Parameter effects nonlinearity</strong>: degree to which curvature (nonlinearity) is affected by choice of <span class="math inline">\(\theta\)</span> (data dependent; dependent on parameterization)</p>
<ul>
<li>leads to problems with inferecne on <span class="math inline">\(\hat{\theta}\)</span>
</li>
<li>
<code>rms.curve</code> in <code>MASS</code> can identify</li>
<li>bootstrap-based inference can also be used</li>
<li>Solution: try to reparaemterize.</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#check parameter effects and intrinsic curvature</span>

<span class="va">modD</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/deriv.html">deriv3</a></span><span class="op">(</span><span class="op">~</span> <span class="va">a</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">b</span><span class="op">*</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"a"</span>,<span class="st">"b"</span><span class="op">)</span>,<span class="kw">function</span><span class="op">(</span><span class="va">a</span>,<span class="va">b</span>,<span class="va">x</span><span class="op">)</span> <span class="cn">NULL</span><span class="op">)</span>

<span class="va">nlin_modD</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="fu">modD</span><span class="op">(</span><span class="va">a</span>,<span class="va">b</span>,<span class="va">x</span><span class="op">)</span>,start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="va">astrt</span>,b<span class="op">=</span><span class="va">bstrt</span><span class="op">)</span>,data<span class="op">=</span><span class="va">datf</span><span class="op">)</span>

<span class="fu">rms.curv</span><span class="op">(</span><span class="va">nlin_modD</span><span class="op">)</span>
<span class="co">#&gt; Parameter effects: c^theta x sqrt(F) = 0.0626 </span>
<span class="co">#&gt;         Intrinsic: c^iota  x sqrt(F) = 0.0062</span></code></pre></div>
<p>In linear model, we have <a href="linear-regression.html#linear-regression">Linear Regression</a>, we have goodness of fit measure as <span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
R^2 = \frac{SSR}{SSTO} = 1- \frac{SSE}{SSTO} \\
= \frac{\sum_{i=1}^n (\hat{Y}_i- \bar{Y})^2}{\sum_{i=1}^n (Y_i- \bar{Y})^2} = 1- \frac{\sum_{i=1}^n ({Y}_i- \hat{Y})^2}{\sum_{i=1}^n (Y_i- \bar{Y})^2}
\]</span></p>
<p>but not valid in the nonlinear case because the error sum of squares and model sum of squares do not add to the total corrected sum of squares</p>
<p><span class="math display">\[
SSR + SSE \neq SST
\]</span></p>
<p>but we can use pseudo-<span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
R^2_{pseudo} = 1 - \frac{\sum_{i=1}^n ({Y}_i- \hat{Y})^2}{\sum_{i=1}^n (Y_i- \bar{Y})^2}
\]</span></p>
<p>But we can’t interpret this as the proportion of variability explained by the model. We should use as a relative comparison of different models.</p>
<p><strong>Residual Plots</strong>: standardize, similar to OLS. useful when the intrinsic curvature is small:</p>
<p>The studentized residuals</p>
<p><span class="math display">\[
r_i = \frac{e_i}{s\sqrt{1-\hat{c}_i}}
\]</span></p>
<p>where <span class="math inline">\(\hat{c}_i\)</span>is the i-th diagonal of <span class="math inline">\(\mathbf{\hat{H}= F(\hat{\theta})[F(\hat{\theta})'F(\hat{\theta})]^{-1}F(\hat{\theta})'}\)</span></p>
<p>We could have problems of</p>
<ul>
<li><p>Collinearity: the condition number of <span class="math inline">\(\mathbf{[F(\hat{\theta})'F(\hat{\theta})]^{-1}}\)</span> should be less than 30. Follow <span class="citation">(<a href="references.html#ref-Magel_1987" role="doc-biblioref">Magel and Hertsgaard 1987</a>)</span>; reparameterize if possible</p></li>
<li><p>Leverage: Like <a href="linear-regression.html#ordinary-least-squares">OLS</a>, but consider <span class="math inline">\(\mathbf{\hat{H}= F(\hat{\theta})[F(\hat{\theta})'F(\hat{\theta})]^{-1}F(\hat{\theta})'}\)</span> (also known as “tangent plant hat matrix”) <span class="citation">(<a href="references.html#ref-Laurent_1992" role="doc-biblioref">Laurent and Cook 1992</a>)</span></p></li>
<li><p>Heterogeneous Errors: weighted Non-linear Least Squares</p></li>
<li>
<p>Correlated Errors:</p>
<ul>
<li>Generalized Nonlinear Least Squares</li>
<li>Nonlinear Mixed Models</li>
<li>Bayesian methods</li>
</ul>
</li>
</ul>
</div>
<div id="application-1" class="section level3" number="6.2.4">
<h3>
<span class="header-section-number">6.2.4</span> Application<a class="anchor" aria-label="anchor" href="#application-1"><i class="fas fa-link"></i></a>
</h3>
<p><span class="math display">\[
y_i = \frac{\theta_0 + \theta_1 x_i}{1 + \theta_2 \exp(0.4 x_i)} + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(i = 1,..,n\)</span></p>
<p>Get the starting values</p>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-18-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>We notice that <span class="math inline">\(Y_{max} = \theta_0 + \theta_1 x_i\)</span> in which we can find x_i from data</p>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt; [1] 2.6722</span>
<span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">]</span>
<span class="co">#&gt; [1] 0.0094</span></code></pre></div>
<p>hence, x = 0.0094 when y = 2.6722 when we have the first equation as</p>
<p><span class="math display">\[
2.6722 = \theta_0 + 0.0094 \theta_1 \\
\theta_0 + 0.0094 \theta_1 + 0 \theta_2 = 2.6722
\]</span></p>
<p>Secondly, we notice that we can obtain the “average” of y when</p>
<p><span class="math display">\[
1+ \theta_2 exp(0.4 x) = 2
\]</span></p>
<p>then we can find this average numbers of x and y</p>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span> <span class="co">#find mean y</span>
<span class="co">#&gt; [1] -0.0747864</span>
<span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">-</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">]</span> <span class="co"># find y closest to its mean</span>
<span class="co">#&gt; [1] -0.0773</span>

<span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">-</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">]</span> <span class="co">#find x closest to the mean y</span>
<span class="co">#&gt; [1] 11.0648</span></code></pre></div>
<p>we have the second equation</p>
<p><span class="math display">\[
1 + \theta_2 exp(0.4*11.0648) = 2 \\
0 \theta_1 + 0 \theta_1 + 83.58967 \theta_2 = 1
\]</span></p>
<p>Thirdly, we can plug in the value of x closest to 1 to find the value of y</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">]</span> <span class="co"># find value of x closet to 1</span>
<span class="co">#&gt; [1] 0.9895</span>
<span class="fu"><a href="https://rdrr.io/r/base/match.html">match</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>, <span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="co"># find index of x closest to 1</span>
<span class="co">#&gt; [1] 14</span>
<span class="va">my_data</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/match.html">match</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>, <span class="va">my_data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">]</span><span class="co"># find y value</span>
<span class="co">#&gt; [1] 1.4577</span></code></pre></div>
<p>hence we have</p>
<p><span class="math display">\[
1.457 = \frac{\theta_0 + \theta_1*0.9895}{1 + \theta_2 exp(0.4*0.9895)} \\
1.457 + 2.164479 *\theta_2 = \theta_0 + \theta_1*0.9895 \\
\theta_0 + \theta_1*0.9895 -  2.164479 *\theta_2 = 1.457
\]</span></p>
<p>with 3 equations, we can solve them to get the starting value for <span class="math inline">\(\theta_0,\theta_1, \theta_2\)</span></p>
<p><span class="math display">\[
\theta_0 + 0.0094 \theta_1 + 0 \theta_2 = 2.6722 \\
0 \theta_1 + 0 \theta_1 + 83.58967 \theta_2 = 1 \\
\theta_0 + \theta_1*0.9895 -  2.164479 *\theta_2 = 1.457
\]</span></p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/friendly/matlib">matlib</a></span><span class="op">)</span> 
<span class="va">A</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0.0094</span>, <span class="fl">0</span>, <span class="fl">0</span>,<span class="fl">0</span>, <span class="fl">83.58967</span>, <span class="fl">1</span>, <span class="fl">0.9895</span>, <span class="op">-</span> <span class="fl">2.164479</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">3</span>, ncol <span class="op">=</span> <span class="fl">3</span>, byrow <span class="op">=</span> <span class="cn">T</span><span class="op">)</span>
<span class="va">b</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2.6722</span>,<span class="fl">1</span>,<span class="fl">1.457</span> <span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/matlib/man/showEqn.html">showEqn</a></span><span class="op">(</span><span class="va">A</span>, <span class="va">b</span><span class="op">)</span>
<span class="co">#&gt; 0*x1 + 0.0094*x2        + 0*x3  =  2.6722 </span>
<span class="co">#&gt; 0*x1      + 0*x2 + 83.58967*x3  =       1 </span>
<span class="co">#&gt; 1*x1 + 0.9895*x2 - 2.164479*x3  =   1.457</span>
<span class="fu"><a href="https://rdrr.io/pkg/matlib/man/Solve.html">Solve</a></span><span class="op">(</span><span class="va">A</span>, <span class="va">b</span>, fractions <span class="op">=</span> <span class="cn">F</span><span class="op">)</span>
<span class="co">#&gt; x1      =  -279.80879739 </span>
<span class="co">#&gt;   x2    =   284.27659574 </span>
<span class="co">#&gt;     x3  =      0.0119632</span></code></pre></div>
<p>Construct manually <a href="non-linear-regression.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a></p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co">#starting value</span>
<span class="va">theta_0_strt</span> <span class="op">=</span> <span class="op">-</span><span class="fl">279.80879739</span> 
<span class="va">theta_1_strt</span> <span class="op">=</span>  <span class="fl">284.27659574</span> 
<span class="va">theta_2_strt</span> <span class="op">=</span> <span class="fl">0.0119632</span> 

<span class="co">#model</span>
<span class="va">mod_4</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta_0</span>,<span class="va">theta_1</span>,<span class="va">theta_2</span>,<span class="va">x</span><span class="op">)</span><span class="op">{</span>
    <span class="op">(</span><span class="va">theta_0</span> <span class="op">+</span> <span class="va">theta_1</span><span class="op">*</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">+</span> <span class="va">theta_2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">0.4</span><span class="op">*</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span>

<span class="co">#define a function</span>
<span class="va">f_4</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="op">(</span><span class="va">theta_0</span> <span class="op">+</span> <span class="va">theta_1</span><span class="op">*</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span><span class="op">+</span> <span class="va">theta_2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">0.4</span><span class="op">*</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="co">#take the first derivative</span>
<span class="va">df_4.d_theta_0</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/deriv.html">D</a></span><span class="op">(</span><span class="va">f_4</span>,<span class="st">'theta_0'</span><span class="op">)</span>

<span class="va">df_4.d_theta_1</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/deriv.html">D</a></span><span class="op">(</span><span class="va">f_4</span>,<span class="st">'theta_1'</span><span class="op">)</span>

<span class="va">df_4.d_theta_2</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/deriv.html">D</a></span><span class="op">(</span><span class="va">f_4</span>,<span class="st">'theta_2'</span><span class="op">)</span>

<span class="co"># save the result of all iterations</span>
<span class="va">theta_vec</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">theta_0_strt</span>,<span class="va">theta_1_strt</span>,<span class="va">theta_2_strt</span><span class="op">)</span><span class="op">)</span>
<span class="va">delta</span><span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="cn">NA</span>, nrow<span class="op">=</span><span class="fl">3</span>,ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>

<span class="va">f_theta</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/eval.html">eval</a></span><span class="op">(</span><span class="va">f_4</span>,<span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">my_data</span><span class="op">$</span><span class="va">x</span>,theta_0 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">]</span>,theta_1 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">1</span><span class="op">]</span>,theta_2 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">3</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="va">i</span> <span class="op">=</span> <span class="fl">1</span>

<span class="kw">repeat</span> <span class="op">{</span>
    <span class="va">F_theta_0</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>
        <span class="fu"><a href="https://rdrr.io/r/base/eval.html">eval</a></span><span class="op">(</span>
            <span class="va">df_4.d_theta_0</span>,
            <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>
                x <span class="op">=</span> <span class="va">my_data</span><span class="op">$</span><span class="va">x</span>,
                theta_0 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">1</span>, <span class="va">i</span><span class="op">]</span>,
                theta_1 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">2</span>, <span class="va">i</span><span class="op">]</span>,
                theta_2 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">3</span>, <span class="va">i</span><span class="op">]</span>
            <span class="op">)</span>
        <span class="op">)</span>,
        <span class="fu"><a href="https://rdrr.io/r/base/eval.html">eval</a></span><span class="op">(</span>
            <span class="va">df_4.d_theta_1</span>,
            <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>
                x <span class="op">=</span> <span class="va">my_data</span><span class="op">$</span><span class="va">x</span>,
                theta_0 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">1</span>, <span class="va">i</span><span class="op">]</span>,
                theta_1 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">2</span>, <span class="va">i</span><span class="op">]</span>,
                theta_2 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">3</span>, <span class="va">i</span><span class="op">]</span>
            <span class="op">)</span>
        <span class="op">)</span>,
        <span class="fu"><a href="https://rdrr.io/r/base/eval.html">eval</a></span><span class="op">(</span>
            <span class="va">df_4.d_theta_2</span>,
            <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>
                x <span class="op">=</span> <span class="va">my_data</span><span class="op">$</span><span class="va">x</span>,
                theta_0 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">1</span>, <span class="va">i</span><span class="op">]</span>,
                theta_1 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">2</span>, <span class="va">i</span><span class="op">]</span>,
                theta_2 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">3</span>, <span class="va">i</span><span class="op">]</span>
            <span class="op">)</span>
        <span class="op">)</span>
    <span class="op">)</span><span class="op">)</span>
    <span class="va">delta</span><span class="op">[</span>, <span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">F_theta_0</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">F_theta_0</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">F_theta_0</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">f_theta</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span><span class="op">)</span>
    <span class="va">theta_vec</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">theta_vec</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="cn">NA</span>, nrow <span class="op">=</span> <span class="fl">3</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
    <span class="va">theta_vec</span><span class="op">[</span>, <span class="va">i</span><span class="op">+</span><span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span>, <span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="va">delta</span><span class="op">[</span>, <span class="va">i</span><span class="op">]</span>
    <span class="va">i</span> <span class="op">=</span> <span class="va">i</span> <span class="op">+</span> <span class="fl">1</span>
    
    <span class="va">f_theta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">f_theta</span>, <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/eval.html">eval</a></span><span class="op">(</span>
        <span class="va">f_4</span>,
        <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>
            x <span class="op">=</span> <span class="va">my_data</span><span class="op">$</span><span class="va">x</span>,
            theta_0 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">1</span>, <span class="va">i</span><span class="op">]</span>,
            theta_1 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">2</span>, <span class="va">i</span><span class="op">]</span>,
            theta_2 <span class="op">=</span> <span class="va">theta_vec</span><span class="op">[</span><span class="fl">3</span>, <span class="va">i</span><span class="op">]</span>
        <span class="op">)</span>
    <span class="op">)</span><span class="op">)</span><span class="op">)</span>
    <span class="va">delta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">delta</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="cn">NA</span>, nrow <span class="op">=</span> <span class="fl">3</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
    
    <span class="co">#convergence criteria based on SSE</span>
    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">f_theta</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">f_theta</span><span class="op">[</span>,<span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">f_theta</span><span class="op">[</span>,<span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">&lt;</span><span class="fl">0.001</span><span class="op">)</span><span class="op">{</span>
        <span class="kw">break</span>
    <span class="op">}</span>
<span class="op">}</span>
<span class="va">delta</span>
<span class="co">#&gt;               [,1]        [,2]        [,3]       [,4]       [,5]       [,6]</span>
<span class="co">#&gt; [1,]  2.811840e+02 -0.03929013  0.43160654  0.6904856  0.6746748  0.4056460</span>
<span class="co">#&gt; [2,] -2.846545e+02  0.03198446 -0.16403964 -0.2895487 -0.2933345 -0.1734087</span>
<span class="co">#&gt; [3,] -1.804567e-05  0.01530258  0.05137285  0.1183271  0.1613129  0.1160404</span>
<span class="co">#&gt;             [,7] [,8]</span>
<span class="co">#&gt; [1,]  0.09517681   NA</span>
<span class="co">#&gt; [2,] -0.03928239   NA</span>
<span class="co">#&gt; [3,]  0.03004911   NA</span>
<span class="va">theta_vec</span>
<span class="co">#&gt;              [,1]        [,2]        [,3]        [,4]       [,5]       [,6]</span>
<span class="co">#&gt; [1,] -279.8087974  1.37521388  1.33592375  1.76753029  2.4580158  3.1326907</span>
<span class="co">#&gt; [2,]  284.2765957 -0.37788712 -0.34590266 -0.50994230 -0.7994910 -1.0928255</span>
<span class="co">#&gt; [3,]    0.0119632  0.01194515  0.02724773  0.07862059  0.1969477  0.3582607</span>
<span class="co">#&gt;            [,7]       [,8]</span>
<span class="co">#&gt; [1,]  3.5383367  3.6335135</span>
<span class="co">#&gt; [2,] -1.2662342 -1.3055166</span>
<span class="co">#&gt; [3,]  0.4743011  0.5043502</span>

<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">f_theta</span><span class="op">)</span>
<span class="co">#&gt;           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]</span>
<span class="co">#&gt; [1,] -273.8482 1.355410 1.297194 1.633802 2.046023 2.296554 2.389041 2.404144</span>
<span class="co">#&gt; [2,] -209.0859 1.268192 1.216738 1.514575 1.863098 2.059505 2.126009 2.135969</span>
<span class="co">#&gt; [3,] -190.3323 1.242916 1.193433 1.480136 1.810629 1.992095 2.051603 2.060202</span>
<span class="co">#&gt; [4,] -177.1891 1.225196 1.177099 1.456024 1.774000 1.945197 1.999945 2.007625</span>
<span class="co">#&gt; [5,] -148.5872 1.186618 1.141549 1.403631 1.694715 1.844154 1.888953 1.894730</span>
<span class="co">#&gt; [6,] -119.9585 1.147980 1.105961 1.351301 1.615968 1.744450 1.779859 1.783866</span>

<span class="co"># estimate sigma^2 </span>

<span class="va">sigma2</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">)</span> <span class="op">-</span> <span class="fl">3</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="op">(</span><span class="va">f_theta</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">f_theta</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span>
    <span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="op">(</span><span class="va">f_theta</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">f_theta</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="co"># p = 3</span>
<span class="va">sigma2</span>
<span class="co">#&gt;           [,1]</span>
<span class="co">#&gt; [1,] 0.0801686</span></code></pre></div>
<p>After 8 iterations, my function has converged. And objective function value at convergence is</p>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">my_data</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">f_theta</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt; [1] 19.80165</span></code></pre></div>
<p>and the parameters of <span class="math inline">\(\theta\)</span>s are</p>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">theta_vec</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">theta_vec</span><span class="op">)</span><span class="op">]</span>
<span class="co">#&gt; [1]  3.6335135 -1.3055166  0.5043502</span></code></pre></div>
<p>and the asymptotic variance covariance matrix is</p>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">sigma2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/as.matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html">crossprod</a></span><span class="op">(</span><span class="va">F_theta_0</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;             [,1]        [,2]        [,3]</span>
<span class="co">#&gt; [1,]  0.11552571 -0.04817428  0.02685848</span>
<span class="co">#&gt; [2,] -0.04817428  0.02100861 -0.01158212</span>
<span class="co">#&gt; [3,]  0.02685848 -0.01158212  0.00703916</span></code></pre></div>
<p>Issue that I encounter in this problem was that it was very sensitive to starting values. when I tried the value of 1 for all <span class="math inline">\(\theta\)</span>s, I have vastly different parameter estimates. Then, I try to use the model interpretation to try to find reasonable starting values.</p>
<p>Check with predefined function in nls</p>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nlin_4</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/nls.html">nls</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu">mod_4</span><span class="op">(</span><span class="va">theta_0</span>,<span class="va">theta_1</span>, <span class="va">theta_2</span>, <span class="va">x</span><span class="op">)</span>, start <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>theta_0<span class="op">=</span><span class="op">-</span><span class="fl">279.80879739</span> ,theta_1<span class="op">=</span><span class="fl">284.27659574</span> , theta_2<span class="op">=</span><span class="fl">0.0119632</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span>
<span class="va">nlin_4</span>
<span class="co">#&gt; Nonlinear regression model</span>
<span class="co">#&gt;   model: y ~ mod_4(theta_0, theta_1, theta_2, x)</span>
<span class="co">#&gt;    data: my_data</span>
<span class="co">#&gt; theta_0 theta_1 theta_2 </span>
<span class="co">#&gt;  3.6359 -1.3064  0.5053 </span>
<span class="co">#&gt;  residual sum-of-squares: 19.8</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of iterations to convergence: 9 </span>
<span class="co">#&gt; Achieved convergence tolerance: 2.294e-07</span></code></pre></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></div>
<div class="next"><a href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#non-linear-regression"><span class="header-section-number">6</span> Non-linear Regression</a></li>
<li>
<a class="nav-link" href="#inference-1"><span class="header-section-number">6.1</span> Inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-function-of-the-parameters"><span class="header-section-number">6.1.1</span> Linear Function of the Parameters</a></li>
<li><a class="nav-link" href="#nonlinear"><span class="header-section-number">6.1.2</span> Nonlinear</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#non-linear-least-squares"><span class="header-section-number">6.2</span> Non-linear Least Squares</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#alternative-of-gauss-newton-algorithm"><span class="header-section-number">6.2.1</span> Alternative of Gauss-Newton Algorithm</a></li>
<li><a class="nav-link" href="#practical-considerations"><span class="header-section-number">6.2.2</span> Practical Considerations</a></li>
<li><a class="nav-link" href="#modelestiamtion-adequcy"><span class="header-section-number">6.2.3</span> Model/Estiamtion Adequcy</a></li>
<li><a class="nav-link" href="#application-1"><span class="header-section-number">6.2.4</span> Application</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/06-nonlinear-regession.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/06-nonlinear-regession.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2022-09-24.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
