### Decision-Maker IV

**Examiner designs**, **judge IV designs**, and **leniency IV** refer to a family of instrumental variable strategies that exploit quasi-random assignment of decision-makers (such as judges or examiners) to observational units. These designs are used to identify causal effects in settings where controlled experiments are not feasible.

**Examiner/judge IV design** is an approach where the instrument is the identity or behavior of an assigned decision-maker (an "examiner" or a judge). The classic setup arises in courts: cases are typically assigned to judges in a manner that is as good as random (often conditional on timing or location), and different judges have systematically different propensities to rule harshly or leniently. This means that, purely by the luck of the draw, otherwise-similar individuals may receive different treatments (e.g. a longer vs. shorter sentence) depending on which judge they happen to get. In such a design, the judge assignment (or a function of it) serves as an instrumental variable for the treatment of interest (like sentence length). The key insight is that *who* the examiner/judge is can be treated as an exogenous shock that influences the treatment but is (ideally) unrelated to the person's own characteristics.

The term **judge IV design** specifically refers to using judges in legal settings as instruments. This approach rose to prominence through studies of the criminal justice system; a well-known early example is @kling2006incarceration, who used randomly assigned judges to instrument for incarceration length when studying its effect on later earnings. More generally, the literature often calls this the **"judge leniency" design**, because it leverages differences in judges' leniency/harshness. Importantly, the same idea extends beyond literal judges. *Examiners* in various administrative or medical contexts can play an analogous role. For instance, bureaucrats evaluating benefit claims, patent examiners reviewing applications, or physicians making discretionary treatment decisions can all act like "judges" whose assignment is as-good-as-random and whose leniency varies. In these non-court contexts, researchers sometimes use the term **examiner design** as a more general label, but it is essentially the same IV strategy. In summary, whether we say *examiner design*, *judge IV*, or *judge leniency IV*, we are usually referring to the same identification strategy -- using the quasi-random assignment of a decision-maker with varying tendencies as an instrument.

**How the design is structured:** In practice, one can implement this IV in a couple of ways. One method is to include dummy variables for each judge/examiner as instruments (since each judge is a distinct source of variation). Another common approach is to construct a **leniency measure** for each decision-maker -- for example, the judge's historical rate of granting the treatment -- and use that as a single continuous instrument. The latter approach (using a summary measure of leniency) is popular because it reduces dimensionality and mitigates weak-instrument concerns when there are many judges. For instance, instead of having 50 separate judge dummies, one can calculate each judge's leave-one-out approval or sentencing rate and use that number as the instrument. This "leave-one-out" or jackknife approach ensures the measure for each judge is calculated excluding the case in question (avoiding mechanical endogeneity). Overall, the examiner/judge IV design turns the naturally occurring randomness in examiner assignment into a source of exogenous variation: who you were randomly assigned to becomes the instrument for the treatment you received.

#### Achieving Identification with a Leniency IV

The examiner/judge design is a powerful way to achieve identification in observational data. It rests on the core requirements for a valid instrumental variable:

-   **Quasi-Random Assignment (Exogeneity):** Because examiners or judges are assigned to cases essentially at random (often by rotation, scheduling, or lottery), the particular decision-maker an individual gets is independent of that individual's characteristics. This approximates the randomness of an experiment. As long as assignment is truly random (or as-good-as-random after conditioning on any known factors like time or location), the examiner identity is uncorrelated with unobserved confounders. In other words, which judge you draw should have no direct bearing on your outcome except through the judge's decision. This satisfies the **exogeneity** condition for an IV.

-   **Instrument Relevance:** Different examiners have different propensities to deliver the treatment. Some judges are more severe (more likely to incarcerate or give long sentences), while others are more lenient; some doctors are more likely to prescribe an intensive treatment, etc. This translates into substantial variation in the probability of treatment based solely on who the case was assigned to. For example, in the patent context, being assigned a lenient patent examiner vs. a strict one can significantly change the probability of a patent grant [@farre2020patent].

-   **Exclusion Restriction:** The IV assumption is that the assigned examiner affects the outcome *only* through the treatment itself. In a judge design, this means the "type of judge you are assigned" should impact the defendant's future outcomes solely via the judge's decision (e.g. incarceration or release), not through any other channel. For instance, a harsh judge might send you to prison; a lenient judge might not -- that difference can affect your future, but we assume that it's only the incarceration that matters for your future outcome, not any direct effect of interacting with a harsh vs. nice judge per se. This exclusion restriction is more plausible when the decision-maker has no direct interaction with the individual beyond making the decision. Researchers take care to argue that conditional on the controls and the treatment itself, the identity of the examiner has no independent effect on outcomes. If these conditions (relevance and exogeneity/exclusion) hold, then the variation in treatment induced by examiner assignment can be used to consistently estimate the causal effect of the treatment.

By meeting these conditions, examiner/judge IV designs create a natural experiment. Essentially, they compare outcomes between individuals who, by random luck, received different treatment assignments (e.g. one was incarcerated, another not) due to differing examiner leniency, despite those individuals being comparable in expectation. This helps isolate the causal impact of the treatment from confounding factors. Notably, the estimates from such designs often correspond to a **local average treatment effect (LATE)** for those cases whose treatment status is swayed by the examiner's leniency -- for example, the "marginal" defendants who would be incarcerated by a strict judge but released by a lenient judge. In sum, these designs allow researchers to **mimic a randomized experiment** within observational data by leveraging institutional randomness (who gets assigned to whom) as an instrument.

#### Leniency IV: Clarifying the Terminology

The term **leniency IV** refers to this same instrumental variable strategy, emphasizing the role of the examiner's *leniency* (or strictness). In many studies, the instrument is literally a measure of how lenient the assigned judge or examiner tends to be. For example, in a Social Security Disability study, researchers *"exploit variation in examiners' allowance rates as an instrument for benefit receipt."* [@maestas2013does]. Here, an examiner's *allowance rate* (the fraction of cases they approve) is a direct quantification of their leniency, and this serves as the instrumental variable. Similarly, one can define a judge's leniency as the percentage of past defendants that judge jailed or the average sentence length they give, and use that as the IV. The phrase "leniency design" or **leniency instrument** simply underscores that it's the lenient vs. strict tendencies of the decision-maker that provide the exogenous variation.

A leniency IV design typically involves constructing an instrument like *"the leave-out mean decision rate of the assigned examiner."* This could be, for instance, the fraction of previous similar cases that the examiner approved (excluding the current case). That number captures how lenient or strict they generally are. Because assignment is random, some individuals get a high-leniency examiner and others a low-leniency examiner, creating exogenous variation in treatment. By comparing outcomes across these, one can identify the causal effect of the treatment. The term "leniency" highlights that it's the discretionary toughness of the examiner that we're leveraging.

#### Examples of Examiner/Judge IV Designs in Research

Many influential studies across economics and related fields have employed examiner or judge IV designs to answer causal questions. Below are several prominent examples illustrating the range of applications and findings:

-   **Criminal Sentencing and Recidivism:** In his seminal study, @kling2006incarceration examined the effect of incarceration length on ex-prisoners' labor market outcomes. He used the random assignment of judges as an instrument, capitalizing on the fact that some judges are harsher (give longer sentences) and others more lenient. This judge IV strategy has since been used extensively to study how prison time impacts future criminal behavior and employment.

-   **Pre-Trial Detention Decisions:** The leniency design is also applied to bail and pre-trial release. @dobbie2018effects use the fact that arraignment judges vary in their tendency to set bail (versus release defendants) as an instrument to study the impact of pre-trial detention on defendants' case outcomes and future behavior. Because defendants are quasi-randomly assigned to bail judges, this approach isolates how being jailed before trial causally affects outcomes like conviction or re-offense. These authors and others find, for example, that having a more lenient bail judge (who releases you pre-trial) leads to better long-run outcomes compared to a strict judge, indicating that pre-trial detention can have harmful causal effects.

-   **Juvenile Incarceration and Life Outcomes:** In a related vein, @aizer2015juvenile studied the effect of juvenile detention on high school completion and adult crime. They leveraged the random assignment of juvenile court judges, where some judges were more likely to incarcerate young offenders than others. This judge IV design revealed large negative causal impacts of juvenile incarceration on educational attainment and an increase in adult crime, evidence that sentencing leniency in youth can dramatically alter life trajectories (results consistent with the general pattern found in other judge IV studies of incarceration). This application illustrates how *judicial decisions* in youth have been treated as natural experiments.

-   **Disability Insurance and Labor Supply:** In the realm of social insurance, @maestas2013does used an examiner design to determine whether receiving disability benefits discourages work. Each disability claim is assigned to a disability examiner, and some examiners approve benefits at higher rates than others. By using the quasi-random examiner assignment as an instrument, they found that for applicants on the margin of eligibility, receiving Disability Insurance caused a significant reduction in employment compared to if they had been denied. They report that about 23% of applicants are affected by which examiner they get, and those who were allowed benefits due to a lenient examiner would have had substantially higher employment rates had they instead been assigned a stricter examiner (and thus been denied). This study is a prime example of using **medical or administrative examiner assignments** to identify a policy's effect.

-   **Patent Grants and Innovation:** Examiner designs are not limited to courts or social programs; they have been applied in innovation economics as well. @farre2020patent analyze the value of obtaining a patent for startups by exploiting the U.S. Patent Office's quasi-random assignment of applications to patent examiners. Some patent examiners are much more lenient (more likely to grant a patent) than others, effectively creating a "patent lottery". The authors use examiner leniency as an instrument for whether a startup's patent is approved. They find striking results: startups that "won" the lottery by drawing a lenient examiner had **55% higher employment growth and 80% higher sales** five years later on average, compared to similar startups that ended up with a strict examiner and thus didn't get the patent. This suggests that patent grants have a large causal impact on firm growth. This study showcases an **examiner design** in a *regulatory/innovation* setting -- the term *leniency IV* in this case refers to the examiner's propensity to allow patents.

-   **Business Accelerators and Firm Growth:** In an entrepreneurial finance context, @gonzalez2021identifying evaluate the impact of getting accepted into a business accelerator. Admission to the accelerator was determined by panels of judges scoring startup applicants, and the judges' scoring leniency varied randomly across groups. The researchers exploit this by constructing an instrument based on the *generosity of the judges' scores* for each applicant. They find that participating in the accelerator had a dramatic effect: startups that just made it in (thanks to generous-scoring judges) grew about **166% more** in revenue than those that just missed the cutoff. This is an example of a "judge leniency" design outside of a courtroom -- here the "judges" were competition evaluators, and their leniency in scoring provided the exogenous variation in program entry. It demonstrates that the examiner/judge IV approach can be applied to settings like business program evaluations or any scenario with selection committees.

These examples illustrate how examiner/judge (leniency) IV designs have been used in a wide array of empirical settings: from judicial decisions about bail, sentencing, and juvenile detention, to administrative adjudications on disability and bankruptcy, to regulatory approvals like patents, to evaluation panels in business or education contexts. In each case, the randomness of assignment and the differing "strictness" of the decision-makers create a natural experiment that researchers harness to estimate causal effects.

**Why are these designs so valuable?** They allow analysts to address the problem of unobserved heterogeneity or selection bias in observational data. Normally, people who receive a treatment (go to prison, get a benefit, win an award) may differ systematically from those who don't, confounding simple comparisons. But if an outside examiner's quasi-random decision determines who gets the treatment, we have a credible instrument to break that link. As one article notes, this approach has become quite popular as a reliable way to recover causal effects, even as many other attempted instruments face skepticism. The trade-off is that one must have a context where such random examiner assignment occurs and must carefully check the assumptions (e.g. truly random assignment, no direct effect of the examiner on outcomes aside from via treatment). When those conditions are met, examiner and judge IV designs provide compelling evidence on causal relationships that would be hard to identify otherwise.

#### Examples in Marketing

In marketing research, analogous setups can be constructed by identifying quasi-random sources of variation in decision-makers' behaviors---such as sales representatives, regional managers, or customer service agents---who differ systematically in their tendency to approve discounts, upgrade customers, or resolve complaints favorably. These agents' "leniency" can serve as an instrument for treatment assignment, enabling researchers to isolate causal effects in observational data where randomization is infeasible.

This analogical use of judge leniency introduces a powerful framework for addressing endogeneity in business contexts, allowing us to disentangle the effect of marketing actions (e.g., discounts, loyalty offers) from the confounding influence of customer selection or targeting bias.

| **Judge Analog**   | **Case Analog**            | **Instrument / Causal Variation**        | **Use Case / Research Question**          | **Potential Outcomes**         |
|--------------|--------------|---------------|---------------|--------------|
| Ad reviewer        | Submitted ad               | Reviewer identity, shift rotation        | Effect of ad rejection or delay on sales  | CTR, sales, acquisition        |
| Search ranker      | Product view/visit         | Random tie-breaking in rank              | Impact of product ranking on behavior     | Purchases, engagement          |
| Sales rep          | Customer inquiry           | Agent assignment variation               | Salesperson influence on conversion       | Conversion, satisfaction       |
| CSR rep            | Complaint or service issue | Shift schedule, escalation rules         | Does service response tone affect churn?  | Retention, NPS                 |
| Matching algorithm | Influencer-brand pairing   | Batch assignment randomness              | Does match quality affect campaign ROI?   | ROI, awareness                 |
| Moderator          | User post / ad             | Moderator stringency variation           | Enforcement effect on trust and activity  | Engagement, advertiser trust   |
| Grant reviewer     | Startup or proposal        | Panel assignment, reviewer fixed effects | Causal effect of grant approval on growth | Marketing scaling, performance |
