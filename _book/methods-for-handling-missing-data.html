<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11.4 Methods for Handling Missing Data | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="11.4 Methods for Handling Missing Data | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11.4 Methods for Handling Missing Data | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2025-01-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="diagnosing-the-missing-data-mechanism.html"/>
<link rel="next" href="evaluation-of-imputation-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="how-to-cite-this-book.html"><a href="how-to-cite-this-book.html"><i class="fa fa-check"></i>How to cite this book</a></li>
<li class="chapter" data-level="" data-path="more-books.html"><a href="more-books.html"><i class="fa fa-check"></i>More books</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="general-recommendations.html"><a href="general-recommendations.html"><i class="fa fa-check"></i><b>1.1</b> General Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="matrix-theory.html"><a href="matrix-theory.html"><i class="fa fa-check"></i><b>2.1</b> Matrix Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="matrix-theory.html"><a href="matrix-theory.html#rank-of-a-matrix"><i class="fa fa-check"></i><b>2.1.1</b> Rank of a Matrix</a></li>
<li class="chapter" data-level="2.1.2" data-path="matrix-theory.html"><a href="matrix-theory.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>2.1.2</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="2.1.3" data-path="matrix-theory.html"><a href="matrix-theory.html#definiteness-of-a-matrix"><i class="fa fa-check"></i><b>2.1.3</b> Definiteness of a Matrix</a></li>
<li class="chapter" data-level="2.1.4" data-path="matrix-theory.html"><a href="matrix-theory.html#matrix-calculus"><i class="fa fa-check"></i><b>2.1.4</b> Matrix Calculus</a></li>
<li class="chapter" data-level="2.1.5" data-path="matrix-theory.html"><a href="matrix-theory.html#optimization-in-scalar-and-vector-spaces"><i class="fa fa-check"></i><b>2.1.5</b> Optimization in Scalar and Vector Spaces</a></li>
<li class="chapter" data-level="2.1.6" data-path="matrix-theory.html"><a href="matrix-theory.html#cholesky-decomposition"><i class="fa fa-check"></i><b>2.1.6</b> Cholesky Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#axioms-and-theorems-of-probability"><i class="fa fa-check"></i><b>2.2.1</b> Axioms and Theorems of Probability</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.3" data-path="probability-theory.html"><a href="probability-theory.html#random-variable"><i class="fa fa-check"></i><b>2.2.3</b> Random Variable</a></li>
<li class="chapter" data-level="2.2.4" data-path="probability-theory.html"><a href="probability-theory.html#moment-generating-function"><i class="fa fa-check"></i><b>2.2.4</b> Moment Generating Function</a></li>
<li class="chapter" data-level="2.2.5" data-path="probability-theory.html"><a href="probability-theory.html#moments"><i class="fa fa-check"></i><b>2.2.5</b> Moments</a></li>
<li class="chapter" data-level="2.2.6" data-path="probability-theory.html"><a href="probability-theory.html#skewness"><i class="fa fa-check"></i><b>2.2.6</b> Skewness</a></li>
<li class="chapter" data-level="2.2.7" data-path="probability-theory.html"><a href="probability-theory.html#kurtosis"><i class="fa fa-check"></i><b>2.2.7</b> Kurtosis</a></li>
<li class="chapter" data-level="2.2.8" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>2.2.8</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="general-math.html"><a href="general-math.html"><i class="fa fa-check"></i><b>2.3</b> General Math</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="general-math.html"><a href="general-math.html#number-sets"><i class="fa fa-check"></i><b>2.3.1</b> Number Sets</a></li>
<li class="chapter" data-level="2.3.2" data-path="general-math.html"><a href="general-math.html#summation-notation-and-series"><i class="fa fa-check"></i><b>2.3.2</b> Summation Notation and Series</a></li>
<li class="chapter" data-level="2.3.3" data-path="general-math.html"><a href="general-math.html#taylor-expansion"><i class="fa fa-check"></i><b>2.3.3</b> Taylor Expansion</a></li>
<li class="chapter" data-level="2.3.4" data-path="general-math.html"><a href="general-math.html#law-of-large-numbers"><i class="fa fa-check"></i><b>2.3.4</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="2.3.5" data-path="general-math.html"><a href="general-math.html#convergence"><i class="fa fa-check"></i><b>2.3.5</b> Convergence</a></li>
<li class="chapter" data-level="2.3.6" data-path="general-math.html"><a href="general-math.html#sufficient-statistics-and-likelihood"><i class="fa fa-check"></i><b>2.3.6</b> Sufficient Statistics and Likelihood</a></li>
<li class="chapter" data-level="2.3.7" data-path="general-math.html"><a href="general-math.html#parameter-transformations"><i class="fa fa-check"></i><b>2.3.7</b> Parameter Transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-importexport.html"><a href="data-importexport.html"><i class="fa fa-check"></i><b>2.4</b> Data Import/Export</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="data-importexport.html"><a href="data-importexport.html#medium-size"><i class="fa fa-check"></i><b>2.4.1</b> Medium size</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-importexport.html"><a href="data-importexport.html#large-size"><i class="fa fa-check"></i><b>2.4.2</b> Large size</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2.5</b> Data Manipulation</a></li>
</ul></li>
<li class="part"><span><b>I. BASIC</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="numerical-measures.html"><a href="numerical-measures.html"><i class="fa fa-check"></i><b>3.1</b> Numerical Measures</a></li>
<li class="chapter" data-level="3.2" data-path="graphical-measures.html"><a href="graphical-measures.html"><i class="fa fa-check"></i><b>3.2</b> Graphical Measures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="graphical-measures.html"><a href="graphical-measures.html#shape"><i class="fa fa-check"></i><b>3.2.1</b> Shape</a></li>
<li class="chapter" data-level="3.2.2" data-path="graphical-measures.html"><a href="graphical-measures.html#scatterplot"><i class="fa fa-check"></i><b>3.2.2</b> Scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="normality-assessment.html"><a href="normality-assessment.html"><i class="fa fa-check"></i><b>3.3</b> Normality Assessment</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normality-assessment.html"><a href="normality-assessment.html#graphical-assessment"><i class="fa fa-check"></i><b>3.3.1</b> Graphical Assessment</a></li>
<li class="chapter" data-level="3.3.2" data-path="normality-assessment.html"><a href="normality-assessment.html#summary-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html"><i class="fa fa-check"></i><b>3.4</b> Bivariate Statistics</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#two-continuous"><i class="fa fa-check"></i><b>3.4.1</b> Two Continuous</a></li>
<li class="chapter" data-level="3.4.2" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#categorical-and-continuous"><i class="fa fa-check"></i><b>3.4.2</b> Categorical and Continuous</a></li>
<li class="chapter" data-level="3.4.3" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#two-discrete"><i class="fa fa-check"></i><b>3.4.3</b> Two Discrete</a></li>
<li class="chapter" data-level="3.4.4" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#general-approach-to-bivariate-statistics"><i class="fa fa-check"></i><b>3.4.4</b> General Approach to Bivariate Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistical-inference.html"><a href="basic-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html"><i class="fa fa-check"></i><b>4.1</b> Hypothesis Testing Framework</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>4.1.1</b> Null and Alternative Hypotheses</a></li>
<li class="chapter" data-level="4.1.2" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.2</b> Errors in Hypothesis Testing</a></li>
<li class="chapter" data-level="4.1.3" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#the-role-of-distributions-in-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.3</b> The Role of Distributions in Hypothesis Testing</a></li>
<li class="chapter" data-level="4.1.4" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#the-test-statistic"><i class="fa fa-check"></i><b>4.1.4</b> The Test Statistic</a></li>
<li class="chapter" data-level="4.1.5" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#critical-values-and-rejection-regions-1"><i class="fa fa-check"></i><b>4.1.5</b> Critical Values and Rejection Regions</a></li>
<li class="chapter" data-level="4.1.6" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#visualizing-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.6</b> Visualizing Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html"><i class="fa fa-check"></i><b>4.2</b> Key Concepts and Definitions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html#random-sample"><i class="fa fa-check"></i><b>4.2.1</b> Random Sample</a></li>
<li class="chapter" data-level="4.2.2" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html#sample-statistics"><i class="fa fa-check"></i><b>4.2.2</b> Sample Statistics</a></li>
<li class="chapter" data-level="4.2.3" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html#distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>4.2.3</b> Distribution of the Sample Mean</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>4.3</b> One-Sample Inference</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-single-mean"><i class="fa fa-check"></i><b>4.3.1</b> For Single Mean</a></li>
<li class="chapter" data-level="4.3.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-difference-of-means-independent-samples"><i class="fa fa-check"></i><b>4.3.2</b> For Difference of Means, Independent Samples</a></li>
<li class="chapter" data-level="4.3.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-difference-of-means-paired-samples"><i class="fa fa-check"></i><b>4.3.3</b> For Difference of Means, Paired Samples</a></li>
<li class="chapter" data-level="4.3.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-difference-of-two-proportions"><i class="fa fa-check"></i><b>4.3.4</b> For Difference of Two Proportions</a></li>
<li class="chapter" data-level="4.3.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-single-proportion"><i class="fa fa-check"></i><b>4.3.5</b> For Single Proportion</a></li>
<li class="chapter" data-level="4.3.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-single-variance"><i class="fa fa-check"></i><b>4.3.6</b> For Single Variance</a></li>
<li class="chapter" data-level="4.3.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#non-parametric-tests"><i class="fa fa-check"></i><b>4.3.7</b> Non-parametric Tests</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>4.4</b> Two-Sample Inference</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#for-means"><i class="fa fa-check"></i><b>4.4.1</b> For Means</a></li>
<li class="chapter" data-level="4.4.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#for-variances"><i class="fa fa-check"></i><b>4.4.2</b> For Variances</a></li>
<li class="chapter" data-level="4.4.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#power"><i class="fa fa-check"></i><b>4.4.3</b> Power</a></li>
<li class="chapter" data-level="4.4.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#matched-pair-designs"><i class="fa fa-check"></i><b>4.4.4</b> Matched Pair Designs</a></li>
<li class="chapter" data-level="4.4.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#nonparametric-tests-for-two-samples"><i class="fa fa-check"></i><b>4.4.5</b> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>4.5</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#association-tests"><i class="fa fa-check"></i><b>4.5.1</b> Association Tests</a></li>
<li class="chapter" data-level="4.5.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-association"><i class="fa fa-check"></i><b>4.5.2</b> Ordinal Association</a></li>
<li class="chapter" data-level="4.5.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-trend"><i class="fa fa-check"></i><b>4.5.3</b> Ordinal Trend</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html"><i class="fa fa-check"></i><b>4.6</b> Divergence Metrics and Tests for Comparing Distributions</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#kolmogorov-smirnov-test-1"><i class="fa fa-check"></i><b>4.6.1</b> Kolmogorov-Smirnov Test</a></li>
<li class="chapter" data-level="4.6.2" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#anderson-darling-test-1"><i class="fa fa-check"></i><b>4.6.2</b> Anderson-Darling Test</a></li>
<li class="chapter" data-level="4.6.3" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>4.6.3</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="4.6.4" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#cramér-von-mises-test"><i class="fa fa-check"></i><b>4.6.4</b> Cramér-von Mises Test</a></li>
<li class="chapter" data-level="4.6.5" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#kullback-leibler-divergence"><i class="fa fa-check"></i><b>4.6.5</b> Kullback-Leibler Divergence</a></li>
<li class="chapter" data-level="4.6.6" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#jensen-shannon-divergence"><i class="fa fa-check"></i><b>4.6.6</b> Jensen-Shannon Divergence</a></li>
<li class="chapter" data-level="4.6.7" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#hellinger-distance"><i class="fa fa-check"></i><b>4.6.7</b> Hellinger Distance</a></li>
<li class="chapter" data-level="4.6.8" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#bhattacharyya-distance"><i class="fa fa-check"></i><b>4.6.8</b> Bhattacharyya Distance</a></li>
<li class="chapter" data-level="4.6.9" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#wasserstein-distance"><i class="fa fa-check"></i><b>4.6.9</b> Wasserstein Distance</a></li>
<li class="chapter" data-level="4.6.10" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#energy-distance"><i class="fa fa-check"></i><b>4.6.10</b> Energy Distance</a></li>
<li class="chapter" data-level="4.6.11" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#total-variation-distance"><i class="fa fa-check"></i><b>4.6.11</b> Total Variation Distance</a></li>
<li class="chapter" data-level="4.6.12" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#summary"><i class="fa fa-check"></i><b>4.6.12</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II. REGRESSION</b></span></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5.1</b> Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#simple-regression-basic-model"><i class="fa fa-check"></i><b>5.1.1</b> Simple Regression (Basic) Model</a></li>
<li class="chapter" data-level="5.1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.2</b> Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5.2</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#infeasible-generalized-least-squares"><i class="fa fa-check"></i><b>5.2.1</b> Infeasible Generalized Least Squares</a></li>
<li class="chapter" data-level="5.2.2" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#feasible-generalized-least-squares"><i class="fa fa-check"></i><b>5.2.2</b> Feasible Generalized Least Squares</a></li>
<li class="chapter" data-level="5.2.3" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#weighted-least-squares"><i class="fa fa-check"></i><b>5.2.3</b> Weighted Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html"><i class="fa fa-check"></i><b>5.3</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#motivation-for-mle"><i class="fa fa-check"></i><b>5.3.1</b> Motivation for MLE</a></li>
<li class="chapter" data-level="5.3.2" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#key-quantities-for-inference"><i class="fa fa-check"></i><b>5.3.2</b> Key Quantities for Inference</a></li>
<li class="chapter" data-level="5.3.3" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#assumptions-of-mle"><i class="fa fa-check"></i><b>5.3.3</b> Assumptions of MLE</a></li>
<li class="chapter" data-level="5.3.4" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#properties-of-mle"><i class="fa fa-check"></i><b>5.3.4</b> Properties of MLE</a></li>
<li class="chapter" data-level="5.3.5" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#practical-considerations"><i class="fa fa-check"></i><b>5.3.5</b> Practical Considerations</a></li>
<li class="chapter" data-level="5.3.6" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#comparison-of-mle-and-ols"><i class="fa fa-check"></i><b>5.3.6</b> Comparison of MLE and OLS</a></li>
<li class="chapter" data-level="5.3.7" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#applications-of-mle"><i class="fa fa-check"></i><b>5.3.7</b> Applications of MLE</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html"><i class="fa fa-check"></i><b>5.4</b> Penalized (Regularized) Estimators</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#motivation-for-penalized-estimators"><i class="fa fa-check"></i><b>5.4.1</b> Motivation for Penalized Estimators</a></li>
<li class="chapter" data-level="5.4.2" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#ridge-regression"><i class="fa fa-check"></i><b>5.4.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="5.4.3" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#lasso-regression"><i class="fa fa-check"></i><b>5.4.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="5.4.4" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#elastic-net"><i class="fa fa-check"></i><b>5.4.4</b> Elastic Net</a></li>
<li class="chapter" data-level="5.4.5" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#tuning-parameter-selection"><i class="fa fa-check"></i><b>5.4.5</b> Tuning Parameter Selection</a></li>
<li class="chapter" data-level="5.4.6" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#properties-of-penalized-estimators"><i class="fa fa-check"></i><b>5.4.6</b> Properties of Penalized Estimators</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="robust-estimators.html"><a href="robust-estimators.html"><i class="fa fa-check"></i><b>5.5</b> Robust Estimators</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="robust-estimators.html"><a href="robust-estimators.html#motivation-for-robust-estimation"><i class="fa fa-check"></i><b>5.5.1</b> Motivation for Robust Estimation</a></li>
<li class="chapter" data-level="5.5.2" data-path="robust-estimators.html"><a href="robust-estimators.html#m-estimators"><i class="fa fa-check"></i><b>5.5.2</b> <span class="math inline">\(M\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.3" data-path="robust-estimators.html"><a href="robust-estimators.html#r-estimators"><i class="fa fa-check"></i><b>5.5.3</b> <span class="math inline">\(R\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.4" data-path="robust-estimators.html"><a href="robust-estimators.html#l-estimators"><i class="fa fa-check"></i><b>5.5.4</b> <span class="math inline">\(L\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.5" data-path="robust-estimators.html"><a href="robust-estimators.html#least-trimmed-squares-lts"><i class="fa fa-check"></i><b>5.5.5</b> Least Trimmed Squares (LTS)</a></li>
<li class="chapter" data-level="5.5.6" data-path="robust-estimators.html"><a href="robust-estimators.html#s-estimators"><i class="fa fa-check"></i><b>5.5.6</b> <span class="math inline">\(S\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.7" data-path="robust-estimators.html"><a href="robust-estimators.html#mm-estimators"><i class="fa fa-check"></i><b>5.5.7</b> <span class="math inline">\(MM\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.8" data-path="robust-estimators.html"><a href="robust-estimators.html#practical-considerations-1"><i class="fa fa-check"></i><b>5.5.8</b> Practical Considerations</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="partial-least-squares.html"><a href="partial-least-squares.html"><i class="fa fa-check"></i><b>5.6</b> Partial Least Squares</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="partial-least-squares.html"><a href="partial-least-squares.html#motivation-for-pls"><i class="fa fa-check"></i><b>5.6.1</b> Motivation for PLS</a></li>
<li class="chapter" data-level="5.6.2" data-path="partial-least-squares.html"><a href="partial-least-squares.html#steps-to-construct-pls-components"><i class="fa fa-check"></i><b>5.6.2</b> Steps to Construct PLS Components</a></li>
<li class="chapter" data-level="5.6.3" data-path="partial-least-squares.html"><a href="partial-least-squares.html#properties-of-pls"><i class="fa fa-check"></i><b>5.6.3</b> Properties of PLS</a></li>
<li class="chapter" data-level="5.6.4" data-path="partial-least-squares.html"><a href="partial-least-squares.html#comparison-with-related-methods"><i class="fa fa-check"></i><b>5.6.4</b> Comparison with Related Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Non-Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>6.1</b> Inference</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="inference.html"><a href="inference.html#linear-function-of-the-parameters"><i class="fa fa-check"></i><b>6.1.1</b> Linear Function of the Parameters</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference.html"><a href="inference.html#nonlinear-functions-of-parameters"><i class="fa fa-check"></i><b>6.1.2</b> Nonlinear Functions of Parameters</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html"><i class="fa fa-check"></i><b>6.2</b> Non-linear Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#iterative-optimization-nonlinear-regression"><i class="fa fa-check"></i><b>6.2.1</b> Iterative Optimization</a></li>
<li class="chapter" data-level="6.2.2" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#derivative-free"><i class="fa fa-check"></i><b>6.2.2</b> Derivative-Free</a></li>
<li class="chapter" data-level="6.2.3" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#stochastic-heuristic-nolinear-regression"><i class="fa fa-check"></i><b>6.2.3</b> Stochastic Heuristic</a></li>
<li class="chapter" data-level="6.2.4" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#linearization-nonlinear-regression-optimization"><i class="fa fa-check"></i><b>6.2.4</b> Linearization</a></li>
<li class="chapter" data-level="6.2.5" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#hybrid-nonlinear-regression-optimization"><i class="fa fa-check"></i><b>6.2.5</b> Hybrid</a></li>
<li class="chapter" data-level="6.2.6" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#comparison-of-nonlinear-optimizers"><i class="fa fa-check"></i><b>6.2.6</b> Comparison of Nonlinear Optimizers</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html"><i class="fa fa-check"></i><b>6.3</b> Practical Considerations</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#selecting-starting-values"><i class="fa fa-check"></i><b>6.3.1</b> Selecting Starting Values</a></li>
<li class="chapter" data-level="6.3.2" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#handling-constrained-parameters"><i class="fa fa-check"></i><b>6.3.2</b> Handling Constrained Parameters</a></li>
<li class="chapter" data-level="6.3.3" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#failure-to-converge"><i class="fa fa-check"></i><b>6.3.3</b> Failure to Converge</a></li>
<li class="chapter" data-level="6.3.4" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#convergence-to-a-local-minimum"><i class="fa fa-check"></i><b>6.3.4</b> Convergence to a Local Minimum</a></li>
<li class="chapter" data-level="6.3.5" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#model-adequacy-and-estimation-considerations"><i class="fa fa-check"></i><b>6.3.5</b> Model Adequacy and Estimation Considerations</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="application.html"><a href="application.html"><i class="fa fa-check"></i><b>6.4</b> Application</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="application.html"><a href="application.html#nonlinear-estimation-using-gauss-newton-algorithm"><i class="fa fa-check"></i><b>6.4.1</b> Nonlinear Estimation Using Gauss-Newton Algorithm</a></li>
<li class="chapter" data-level="6.4.2" data-path="application.html"><a href="application.html#logistic-growth-model"><i class="fa fa-check"></i><b>6.4.2</b> Logistic Growth Model</a></li>
<li class="chapter" data-level="6.4.3" data-path="application.html"><a href="application.html#nonlinear-plateau-model"><i class="fa fa-check"></i><b>6.4.3</b> Nonlinear Plateau Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="logistic-regression-1.html"><a href="logistic-regression-1.html"><i class="fa fa-check"></i><b>7.1</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="logistic-regression-1.html"><a href="logistic-regression-1.html#application-1"><i class="fa fa-check"></i><b>7.1.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probit-regression.html"><a href="probit-regression.html"><i class="fa fa-check"></i><b>7.2</b> Probit Regression</a></li>
<li class="chapter" data-level="7.3" data-path="binomial-regression.html"><a href="binomial-regression.html"><i class="fa fa-check"></i><b>7.3</b> Binomial Regression</a></li>
<li class="chapter" data-level="7.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>7.4</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="poisson-regression.html"><a href="poisson-regression.html#application-2"><i class="fa fa-check"></i><b>7.4.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="negative-binomial-regression.html"><a href="negative-binomial-regression.html"><i class="fa fa-check"></i><b>7.5</b> Negative Binomial Regression</a></li>
<li class="chapter" data-level="7.6" data-path="multinomial.html"><a href="multinomial.html"><i class="fa fa-check"></i><b>7.6</b> Multinomial</a></li>
<li class="chapter" data-level="7.7" data-path="generalization.html"><a href="generalization.html"><i class="fa fa-check"></i><b>7.7</b> Generalization</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="generalization.html"><a href="generalization.html#estimation"><i class="fa fa-check"></i><b>7.7.1</b> Estimation</a></li>
<li class="chapter" data-level="7.7.2" data-path="generalization.html"><a href="generalization.html#inference-1"><i class="fa fa-check"></i><b>7.7.2</b> Inference</a></li>
<li class="chapter" data-level="7.7.3" data-path="generalization.html"><a href="generalization.html#deviance"><i class="fa fa-check"></i><b>7.7.3</b> Deviance</a></li>
<li class="chapter" data-level="7.7.4" data-path="generalization.html"><a href="generalization.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.7.4</b> Diagnostic Plots</a></li>
<li class="chapter" data-level="7.7.5" data-path="generalization.html"><a href="generalization.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.7.5</b> Goodness of Fit</a></li>
<li class="chapter" data-level="7.7.6" data-path="generalization.html"><a href="generalization.html#over-dispersion"><i class="fa fa-check"></i><b>7.7.6</b> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>8</b> Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dependent-data.html"><a href="dependent-data.html"><i class="fa fa-check"></i><b>8.1</b> Dependent Data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="dependent-data.html"><a href="dependent-data.html#random-intercepts-model"><i class="fa fa-check"></i><b>8.1.1</b> Random-Intercepts Model</a></li>
<li class="chapter" data-level="8.1.2" data-path="dependent-data.html"><a href="dependent-data.html#covariance-models"><i class="fa fa-check"></i><b>8.1.2</b> Covariance Models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="estimation-1.html"><a href="estimation-1.html"><i class="fa fa-check"></i><b>8.2</b> Estimation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="estimation-1.html"><a href="estimation-1.html#estimating-mathbfv"><i class="fa fa-check"></i><b>8.2.1</b> Estimating <span class="math inline">\(\mathbf{V}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inference-2.html"><a href="inference-2.html"><i class="fa fa-check"></i><b>8.3</b> Inference</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="inference-2.html"><a href="inference-2.html#parameters-beta"><i class="fa fa-check"></i><b>8.3.1</b> Parameters <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="8.3.2" data-path="inference-2.html"><a href="inference-2.html#variance-components"><i class="fa fa-check"></i><b>8.3.2</b> Variance Components</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="information-criteria-1.html"><a href="information-criteria-1.html"><i class="fa fa-check"></i><b>8.4</b> Information Criteria</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="information-criteria-1.html"><a href="information-criteria-1.html#akaikes-information-criteria-aic"><i class="fa fa-check"></i><b>8.4.1</b> Akaike’s Information Criteria (AIC)</a></li>
<li class="chapter" data-level="8.4.2" data-path="information-criteria-1.html"><a href="information-criteria-1.html#corrected-aic-aicc"><i class="fa fa-check"></i><b>8.4.2</b> Corrected AIC (AICC)</a></li>
<li class="chapter" data-level="8.4.3" data-path="information-criteria-1.html"><a href="information-criteria-1.html#bayesian-information-criteria-bic"><i class="fa fa-check"></i><b>8.4.3</b> Bayesian Information Criteria (BIC)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="split-plot-designs.html"><a href="split-plot-designs.html"><i class="fa fa-check"></i><b>8.5</b> Split-Plot Designs</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="split-plot-designs.html"><a href="split-plot-designs.html#application-3"><i class="fa fa-check"></i><b>8.5.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="repeated-measures-in-mixed-models.html"><a href="repeated-measures-in-mixed-models.html"><i class="fa fa-check"></i><b>8.6</b> Repeated Measures in Mixed Models</a></li>
<li class="chapter" data-level="8.7" data-path="unbalanced-or-unequally-spaced-data.html"><a href="unbalanced-or-unequally-spaced-data.html"><i class="fa fa-check"></i><b>8.7</b> Unbalanced or Unequally Spaced Data</a></li>
<li class="chapter" data-level="8.8" data-path="application-4.html"><a href="application-4.html"><i class="fa fa-check"></i><b>8.8</b> Application</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="application-4.html"><a href="application-4.html#example-1-pulps"><i class="fa fa-check"></i><b>8.8.1</b> Example 1 (Pulps)</a></li>
<li class="chapter" data-level="8.8.2" data-path="application-4.html"><a href="application-4.html#example-2-rats"><i class="fa fa-check"></i><b>8.8.2</b> Example 2 (Rats)</a></li>
<li class="chapter" data-level="8.8.3" data-path="application-4.html"><a href="application-4.html#example-3-agridat"><i class="fa fa-check"></i><b>8.8.3</b> Example 3 (Agridat)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="nonlinear-and-generalized-linear-mixed-models.html"><a href="nonlinear-and-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9</b> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimation-2.html"><a href="estimation-2.html"><i class="fa fa-check"></i><b>9.1</b> Estimation</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="estimation-2.html"><a href="estimation-2.html#estimation-by-numerical-integration"><i class="fa fa-check"></i><b>9.1.1</b> Estimation by Numerical Integration</a></li>
<li class="chapter" data-level="9.1.2" data-path="estimation-2.html"><a href="estimation-2.html#estimation-by-linearization"><i class="fa fa-check"></i><b>9.1.2</b> Estimation by Linearization</a></li>
<li class="chapter" data-level="9.1.3" data-path="estimation-2.html"><a href="estimation-2.html#estimation-by-bayesian-hierarchical-models"><i class="fa fa-check"></i><b>9.1.3</b> Estimation by Bayesian Hierarchical Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="application-5.html"><a href="application-5.html"><i class="fa fa-check"></i><b>9.2</b> Application</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="application-5.html"><a href="application-5.html#binomial-cbpp-data"><i class="fa fa-check"></i><b>9.2.1</b> Binomial (CBPP Data)</a></li>
<li class="chapter" data-level="9.2.2" data-path="application-5.html"><a href="application-5.html#count-owl-data"><i class="fa fa-check"></i><b>9.2.2</b> Count (Owl Data)</a></li>
<li class="chapter" data-level="9.2.3" data-path="application-5.html"><a href="application-5.html#binomial"><i class="fa fa-check"></i><b>9.2.3</b> Binomial</a></li>
<li class="chapter" data-level="9.2.4" data-path="application-5.html"><a href="application-5.html#example-from-schabenberger_2001-section-8.4.1"><i class="fa fa-check"></i><b>9.2.4</b> Example from <span class="citation">(Schabenberger and Pierce 2001)</span> section 8.4.1</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>9.3</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III. RAMIFICATIONS</b></span></li>
<li class="chapter" data-level="10" data-path="model-specification.html"><a href="model-specification.html"><i class="fa fa-check"></i><b>10</b> Model Specification</a>
<ul>
<li class="chapter" data-level="10.1" data-path="nested-model.html"><a href="nested-model.html"><i class="fa fa-check"></i><b>10.1</b> Nested Model</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="nested-model.html"><a href="nested-model.html#chow-test"><i class="fa fa-check"></i><b>10.1.1</b> Chow test</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="non-nested-model.html"><a href="non-nested-model.html"><i class="fa fa-check"></i><b>10.2</b> Non-Nested Model</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="non-nested-model.html"><a href="non-nested-model.html#davidson-mackinnon-test"><i class="fa fa-check"></i><b>10.2.1</b> Davidson-Mackinnon test</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html"><i class="fa fa-check"></i><b>10.3</b> Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#breusch-pagan-test"><i class="fa fa-check"></i><b>10.3.1</b> Breusch-Pagan test</a></li>
<li class="chapter" data-level="10.3.2" data-path="heteroskedasticity.html"><a href="heteroskedasticity.html#white-test"><i class="fa fa-check"></i><b>10.3.2</b> White test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="imputation-missing-data.html"><a href="imputation-missing-data.html"><i class="fa fa-check"></i><b>11</b> Imputation (Missing Data)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html"><i class="fa fa-check"></i><b>11.1</b> Introduction to Missing Data</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#types-of-imputation"><i class="fa fa-check"></i><b>11.1.1</b> Types of Imputation</a></li>
<li class="chapter" data-level="11.1.2" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#when-and-why-to-use-imputation"><i class="fa fa-check"></i><b>11.1.2</b> When and Why to Use Imputation</a></li>
<li class="chapter" data-level="11.1.3" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#importance-of-missing-data-treatment-in-statistical-modeling"><i class="fa fa-check"></i><b>11.1.3</b> Importance of Missing Data Treatment in Statistical Modeling</a></li>
<li class="chapter" data-level="11.1.4" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#prevalence-of-missing-data-across-domains"><i class="fa fa-check"></i><b>11.1.4</b> Prevalence of Missing Data Across Domains</a></li>
<li class="chapter" data-level="11.1.5" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#practical-considerations-for-imputation"><i class="fa fa-check"></i><b>11.1.5</b> Practical Considerations for Imputation</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html"><i class="fa fa-check"></i><b>11.2</b> Theoretical Foundations of Missing Data</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html#definition-and-classification-of-missing-data"><i class="fa fa-check"></i><b>11.2.1</b> Definition and Classification of Missing Data</a></li>
<li class="chapter" data-level="11.2.2" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>11.2.2</b> Missing Data Mechanisms</a></li>
<li class="chapter" data-level="11.2.3" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html#relationship-between-mechanisms-and-ignorability"><i class="fa fa-check"></i><b>11.2.3</b> Relationship Between Mechanisms and Ignorability</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html"><i class="fa fa-check"></i><b>11.3</b> Diagnosing the Missing Data Mechanism</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html#descriptive-methods"><i class="fa fa-check"></i><b>11.3.1</b> Descriptive Methods</a></li>
<li class="chapter" data-level="11.3.2" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html#statistical-tests-for-missing-data-mechanisms"><i class="fa fa-check"></i><b>11.3.2</b> Statistical Tests for Missing Data Mechanisms</a></li>
<li class="chapter" data-level="11.3.3" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html#assessing-mar-and-mnar"><i class="fa fa-check"></i><b>11.3.3</b> Assessing MAR and MNAR</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html"><i class="fa fa-check"></i><b>11.4</b> Methods for Handling Missing Data</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#basic-methods"><i class="fa fa-check"></i><b>11.4.1</b> Basic Methods</a></li>
<li class="chapter" data-level="11.4.2" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#single-imputation-techniques"><i class="fa fa-check"></i><b>11.4.2</b> Single Imputation Techniques</a></li>
<li class="chapter" data-level="11.4.3" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#machine-learning-and-modern-approaches"><i class="fa fa-check"></i><b>11.4.3</b> Machine Learning and Modern Approaches</a></li>
<li class="chapter" data-level="11.4.4" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#multiple-imputation"><i class="fa fa-check"></i><b>11.4.4</b> Multiple Imputation</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html"><i class="fa fa-check"></i><b>11.5</b> Evaluation of Imputation Methods</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#statistical-metrics-for-assessing-imputation-quality"><i class="fa fa-check"></i><b>11.5.1</b> Statistical Metrics for Assessing Imputation Quality</a></li>
<li class="chapter" data-level="11.5.2" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#bias-variance-tradeoff-in-imputation"><i class="fa fa-check"></i><b>11.5.2</b> Bias-Variance Tradeoff in Imputation</a></li>
<li class="chapter" data-level="11.5.3" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>11.5.3</b> Sensitivity Analysis</a></li>
<li class="chapter" data-level="11.5.4" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#validation-using-simulated-data-and-real-world-case-studies"><i class="fa fa-check"></i><b>11.5.4</b> Validation Using Simulated Data and Real-World Case Studies</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="criteria-for-choosing-an-effective-approach.html"><a href="criteria-for-choosing-an-effective-approach.html"><i class="fa fa-check"></i><b>11.6</b> Criteria for Choosing an Effective Approach</a></li>
<li class="chapter" data-level="11.7" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html"><i class="fa fa-check"></i><b>11.7</b> Challenges and Ethical Considerations</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html#challenges-in-high-dimensional-data"><i class="fa fa-check"></i><b>11.7.1</b> Challenges in High-Dimensional Data</a></li>
<li class="chapter" data-level="11.7.2" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html#missing-data-in-big-data-contexts"><i class="fa fa-check"></i><b>11.7.2</b> Missing Data in Big Data Contexts</a></li>
<li class="chapter" data-level="11.7.3" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html#ethical-concerns"><i class="fa fa-check"></i><b>11.7.3</b> Ethical Concerns</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html"><i class="fa fa-check"></i><b>11.8</b> Emerging Trends in Missing Data Handling</a>
<ul>
<li class="chapter" data-level="11.8.1" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#advances-in-neural-network-approaches"><i class="fa fa-check"></i><b>11.8.1</b> Advances in Neural Network Approaches</a></li>
<li class="chapter" data-level="11.8.2" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#integration-with-reinforcement-learning"><i class="fa fa-check"></i><b>11.8.2</b> Integration with Reinforcement Learning</a></li>
<li class="chapter" data-level="11.8.3" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#synthetic-data-generation-for-missing-data"><i class="fa fa-check"></i><b>11.8.3</b> Synthetic Data Generation for Missing Data</a></li>
<li class="chapter" data-level="11.8.4" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#federated-learning-and-privacy-preserving-imputation"><i class="fa fa-check"></i><b>11.8.4</b> Federated Learning and Privacy-Preserving Imputation</a></li>
<li class="chapter" data-level="11.8.5" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#imputation-in-streaming-and-online-data-environments"><i class="fa fa-check"></i><b>11.8.5</b> Imputation in Streaming and Online Data Environments</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html"><i class="fa fa-check"></i><b>11.9</b> Application of Imputation in R</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#visualizing-missing-data"><i class="fa fa-check"></i><b>11.9.1</b> Visualizing Missing Data</a></li>
<li class="chapter" data-level="11.9.2" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#how-many-imputations"><i class="fa fa-check"></i><b>11.9.2</b> How Many Imputations?</a></li>
<li class="chapter" data-level="11.9.3" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#generating-missing-data-for-demonstration"><i class="fa fa-check"></i><b>11.9.3</b> Generating Missing Data for Demonstration</a></li>
<li class="chapter" data-level="11.9.4" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#imputation-with-mean-median-and-mode"><i class="fa fa-check"></i><b>11.9.4</b> Imputation with Mean, Median, and Mode</a></li>
<li class="chapter" data-level="11.9.5" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#k-nearest-neighbors-knn-imputation"><i class="fa fa-check"></i><b>11.9.5</b> K-Nearest Neighbors (KNN) Imputation</a></li>
<li class="chapter" data-level="11.9.6" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#imputation-with-decision-trees-rpart"><i class="fa fa-check"></i><b>11.9.6</b> Imputation with Decision Trees (rpart)</a></li>
<li class="chapter" data-level="11.9.7" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#mice-multivariate-imputation-via-chained-equations"><i class="fa fa-check"></i><b>11.9.7</b> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li class="chapter" data-level="11.9.8" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#amelia"><i class="fa fa-check"></i><b>11.9.8</b> Amelia</a></li>
<li class="chapter" data-level="11.9.9" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#missforest"><i class="fa fa-check"></i><b>11.9.9</b> missForest</a></li>
<li class="chapter" data-level="11.9.10" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#hmisc"><i class="fa fa-check"></i><b>11.9.10</b> Hmisc</a></li>
<li class="chapter" data-level="11.9.11" data-path="application-of-imputation-in-r.html"><a href="application-of-imputation-in-r.html#mi"><i class="fa fa-check"></i><b>11.9.11</b> mi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>12</b> Data</a>
<ul>
<li class="chapter" data-level="12.1" data-path="cross-sectional.html"><a href="cross-sectional.html"><i class="fa fa-check"></i><b>12.1</b> Cross-Sectional</a></li>
<li class="chapter" data-level="12.2" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>12.2</b> Time Series</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="time-series.html"><a href="time-series.html#deterministic-time-trend"><i class="fa fa-check"></i><b>12.2.1</b> Deterministic Time trend</a></li>
<li class="chapter" data-level="12.2.2" data-path="time-series.html"><a href="time-series.html#feedback-effect"><i class="fa fa-check"></i><b>12.2.2</b> Feedback Effect</a></li>
<li class="chapter" data-level="12.2.3" data-path="time-series.html"><a href="time-series.html#dynamic-specification"><i class="fa fa-check"></i><b>12.2.3</b> Dynamic Specification</a></li>
<li class="chapter" data-level="12.2.4" data-path="time-series.html"><a href="time-series.html#dynamically-complete"><i class="fa fa-check"></i><b>12.2.4</b> Dynamically Complete</a></li>
<li class="chapter" data-level="12.2.5" data-path="time-series.html"><a href="time-series.html#highly-persistent-data"><i class="fa fa-check"></i><b>12.2.5</b> Highly Persistent Data</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html"><i class="fa fa-check"></i><b>12.3</b> Repeated Cross Sections</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html#pooled-cross-section"><i class="fa fa-check"></i><b>12.3.1</b> Pooled Cross Section</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>12.4</b> Panel Data</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="panel-data.html"><a href="panel-data.html#pooled-ols-estimator"><i class="fa fa-check"></i><b>12.4.1</b> Pooled OLS Estimator</a></li>
<li class="chapter" data-level="12.4.2" data-path="panel-data.html"><a href="panel-data.html#individual-specific-effects-model"><i class="fa fa-check"></i><b>12.4.2</b> Individual-specific effects model</a></li>
<li class="chapter" data-level="12.4.3" data-path="panel-data.html"><a href="panel-data.html#tests-for-assumptions"><i class="fa fa-check"></i><b>12.4.3</b> Tests for Assumptions</a></li>
<li class="chapter" data-level="12.4.4" data-path="panel-data.html"><a href="panel-data.html#model-selection"><i class="fa fa-check"></i><b>12.4.4</b> Model Selection</a></li>
<li class="chapter" data-level="12.4.5" data-path="panel-data.html"><a href="panel-data.html#summary-2"><i class="fa fa-check"></i><b>12.4.5</b> Summary</a></li>
<li class="chapter" data-level="12.4.6" data-path="panel-data.html"><a href="panel-data.html#application-6"><i class="fa fa-check"></i><b>12.4.6</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="variable-transformation.html"><a href="variable-transformation.html"><i class="fa fa-check"></i><b>13</b> Variable Transformation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="continuous-variables.html"><a href="continuous-variables.html"><i class="fa fa-check"></i><b>13.1</b> Continuous Variables</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="continuous-variables.html"><a href="continuous-variables.html#standardization"><i class="fa fa-check"></i><b>13.1.1</b> Standardization</a></li>
<li class="chapter" data-level="13.1.2" data-path="continuous-variables.html"><a href="continuous-variables.html#min-max-scaling"><i class="fa fa-check"></i><b>13.1.2</b> Min-max scaling</a></li>
<li class="chapter" data-level="13.1.3" data-path="continuous-variables.html"><a href="continuous-variables.html#square-rootcube-root"><i class="fa fa-check"></i><b>13.1.3</b> Square Root/Cube Root</a></li>
<li class="chapter" data-level="13.1.4" data-path="continuous-variables.html"><a href="continuous-variables.html#logarithmic"><i class="fa fa-check"></i><b>13.1.4</b> Logarithmic</a></li>
<li class="chapter" data-level="13.1.5" data-path="continuous-variables.html"><a href="continuous-variables.html#exponential"><i class="fa fa-check"></i><b>13.1.5</b> Exponential</a></li>
<li class="chapter" data-level="13.1.6" data-path="continuous-variables.html"><a href="continuous-variables.html#power-1"><i class="fa fa-check"></i><b>13.1.6</b> Power</a></li>
<li class="chapter" data-level="13.1.7" data-path="continuous-variables.html"><a href="continuous-variables.html#inversereciprocal"><i class="fa fa-check"></i><b>13.1.7</b> Inverse/Reciprocal</a></li>
<li class="chapter" data-level="13.1.8" data-path="continuous-variables.html"><a href="continuous-variables.html#hyperbolic-arcsine"><i class="fa fa-check"></i><b>13.1.8</b> Hyperbolic arcsine</a></li>
<li class="chapter" data-level="13.1.9" data-path="continuous-variables.html"><a href="continuous-variables.html#ordered-quantile-norm"><i class="fa fa-check"></i><b>13.1.9</b> Ordered Quantile Norm</a></li>
<li class="chapter" data-level="13.1.10" data-path="continuous-variables.html"><a href="continuous-variables.html#arcsinh"><i class="fa fa-check"></i><b>13.1.10</b> Arcsinh</a></li>
<li class="chapter" data-level="13.1.11" data-path="continuous-variables.html"><a href="continuous-variables.html#lambert-w-x-f-transformation"><i class="fa fa-check"></i><b>13.1.11</b> Lambert W x F Transformation</a></li>
<li class="chapter" data-level="13.1.12" data-path="continuous-variables.html"><a href="continuous-variables.html#inverse-hyperbolic-sine-ihs-transformation"><i class="fa fa-check"></i><b>13.1.12</b> Inverse Hyperbolic Sine (IHS) transformation</a></li>
<li class="chapter" data-level="13.1.13" data-path="continuous-variables.html"><a href="continuous-variables.html#box-cox-transformation"><i class="fa fa-check"></i><b>13.1.13</b> Box-Cox Transformation</a></li>
<li class="chapter" data-level="13.1.14" data-path="continuous-variables.html"><a href="continuous-variables.html#yeo-johnson-transformation"><i class="fa fa-check"></i><b>13.1.14</b> Yeo-Johnson Transformation</a></li>
<li class="chapter" data-level="13.1.15" data-path="continuous-variables.html"><a href="continuous-variables.html#rankgauss"><i class="fa fa-check"></i><b>13.1.15</b> RankGauss</a></li>
<li class="chapter" data-level="13.1.16" data-path="continuous-variables.html"><a href="continuous-variables.html#summary-3"><i class="fa fa-check"></i><b>13.1.16</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="categorical-variables.html"><a href="categorical-variables.html"><i class="fa fa-check"></i><b>13.2</b> Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="types-of-hypothesis-testing.html"><a href="types-of-hypothesis-testing.html"><i class="fa fa-check"></i><b>14.1</b> Types of hypothesis testing</a></li>
<li class="chapter" data-level="14.2" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>14.2</b> Wald test</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="wald-test.html"><a href="wald-test.html#multiple-hypothesis"><i class="fa fa-check"></i><b>14.2.1</b> Multiple Hypothesis</a></li>
<li class="chapter" data-level="14.2.2" data-path="wald-test.html"><a href="wald-test.html#linear-combination"><i class="fa fa-check"></i><b>14.2.2</b> Linear Combination</a></li>
<li class="chapter" data-level="14.2.3" data-path="wald-test.html"><a href="wald-test.html#estimate-difference-in-coefficients"><i class="fa fa-check"></i><b>14.2.3</b> Estimate Difference in Coefficients</a></li>
<li class="chapter" data-level="14.2.4" data-path="wald-test.html"><a href="wald-test.html#application-7"><i class="fa fa-check"></i><b>14.2.4</b> Application</a></li>
<li class="chapter" data-level="14.2.5" data-path="wald-test.html"><a href="wald-test.html#nonlinear"><i class="fa fa-check"></i><b>14.2.5</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="the-likelihood-ratio-test.html"><a href="the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>14.3</b> The likelihood ratio test</a></li>
<li class="chapter" data-level="14.4" data-path="lagrange-multiplier-score.html"><a href="lagrange-multiplier-score.html"><i class="fa fa-check"></i><b>14.4</b> Lagrange Multiplier (Score)</a></li>
<li class="chapter" data-level="14.5" data-path="two-one-sided-tests-tost-equivalence-testing.html"><a href="two-one-sided-tests-tost-equivalence-testing.html"><i class="fa fa-check"></i><b>14.5</b> Two One-Sided Tests (TOST) Equivalence Testing</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="marginal-effects.html"><a href="marginal-effects.html"><i class="fa fa-check"></i><b>15</b> Marginal Effects</a>
<ul>
<li class="chapter" data-level="15.1" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>15.1</b> Delta Method</a></li>
<li class="chapter" data-level="15.2" data-path="average-marginal-effect-algorithm.html"><a href="average-marginal-effect-algorithm.html"><i class="fa fa-check"></i><b>15.2</b> Average Marginal Effect Algorithm</a></li>
<li class="chapter" data-level="15.3" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i><b>15.3</b> Packages</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="packages.html"><a href="packages.html#marginaleffects"><i class="fa fa-check"></i><b>15.3.1</b> MarginalEffects</a></li>
<li class="chapter" data-level="15.3.2" data-path="packages.html"><a href="packages.html#margins"><i class="fa fa-check"></i><b>15.3.2</b> margins</a></li>
<li class="chapter" data-level="15.3.3" data-path="packages.html"><a href="packages.html#mfx"><i class="fa fa-check"></i><b>15.3.3</b> mfx</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="prediction-and-estimation.html"><a href="prediction-and-estimation.html"><i class="fa fa-check"></i><b>16</b> Prediction and Estimation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="prediction-2.html"><a href="prediction-2.html"><i class="fa fa-check"></i><b>16.1</b> Prediction</a></li>
<li class="chapter" data-level="16.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>16.2</b> Parameter Estimation</a></li>
<li class="chapter" data-level="16.3" data-path="causation-versus-prediction.html"><a href="causation-versus-prediction.html"><i class="fa fa-check"></i><b>16.3</b> Causation versus Prediction</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="moderation.html"><a href="moderation.html"><i class="fa fa-check"></i><b>17</b> Moderation</a>
<ul>
<li class="chapter" data-level="17.1" data-path="emmeans-package.html"><a href="emmeans-package.html"><i class="fa fa-check"></i><b>17.1</b> emmeans package</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="emmeans-package.html"><a href="emmeans-package.html#continuous-by-continuous"><i class="fa fa-check"></i><b>17.1.1</b> Continuous by continuous</a></li>
<li class="chapter" data-level="17.1.2" data-path="emmeans-package.html"><a href="emmeans-package.html#continuous-by-categorical"><i class="fa fa-check"></i><b>17.1.2</b> Continuous by categorical</a></li>
<li class="chapter" data-level="17.1.3" data-path="emmeans-package.html"><a href="emmeans-package.html#categorical-by-categorical"><i class="fa fa-check"></i><b>17.1.3</b> Categorical by categorical</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="probmod-package.html"><a href="probmod-package.html"><i class="fa fa-check"></i><b>17.2</b> probmod package</a></li>
<li class="chapter" data-level="17.3" data-path="interactions-package.html"><a href="interactions-package.html"><i class="fa fa-check"></i><b>17.3</b> interactions package</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="interactions-package.html"><a href="interactions-package.html#continuous-interaction"><i class="fa fa-check"></i><b>17.3.1</b> Continuous interaction</a></li>
<li class="chapter" data-level="17.3.2" data-path="interactions-package.html"><a href="interactions-package.html#categorical-interaction"><i class="fa fa-check"></i><b>17.3.2</b> Categorical interaction</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="interactionr-package.html"><a href="interactionr-package.html"><i class="fa fa-check"></i><b>17.4</b> interactionR package</a></li>
<li class="chapter" data-level="17.5" data-path="sjplot-package.html"><a href="sjplot-package.html"><i class="fa fa-check"></i><b>17.5</b> sjPlot package</a></li>
</ul></li>
<li class="part"><span><b>IV. CAUSAL INFERENCE</b></span></li>
<li class="chapter" data-level="18" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>18</b> Causal Inference</a>
<ul>
<li class="chapter" data-level="18.1" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html"><i class="fa fa-check"></i><b>18.1</b> Treatment effect types</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#average-treatment-effects"><i class="fa fa-check"></i><b>18.1.1</b> Average Treatment Effects</a></li>
<li class="chapter" data-level="18.1.2" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#conditional-average-treatment-effects"><i class="fa fa-check"></i><b>18.1.2</b> Conditional Average Treatment Effects</a></li>
<li class="chapter" data-level="18.1.3" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#intent-to-treat-effects"><i class="fa fa-check"></i><b>18.1.3</b> Intent-to-treat Effects</a></li>
<li class="chapter" data-level="18.1.4" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#local-average-treatment-effects"><i class="fa fa-check"></i><b>18.1.4</b> Local Average Treatment Effects</a></li>
<li class="chapter" data-level="18.1.5" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#population-vs.-sample-average-treatment-effects"><i class="fa fa-check"></i><b>18.1.5</b> Population vs. Sample Average Treatment Effects</a></li>
<li class="chapter" data-level="18.1.6" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#average-treatment-effects-on-the-treated-and-control"><i class="fa fa-check"></i><b>18.1.6</b> Average Treatment Effects on the Treated and Control</a></li>
<li class="chapter" data-level="18.1.7" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#quantile-average-treatment-effects"><i class="fa fa-check"></i><b>18.1.7</b> Quantile Average Treatment Effects</a></li>
<li class="chapter" data-level="18.1.8" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#mediation-effects"><i class="fa fa-check"></i><b>18.1.8</b> Mediation Effects</a></li>
<li class="chapter" data-level="18.1.9" data-path="treatment-effect-types.html"><a href="treatment-effect-types.html#log-odds-treatment-effects"><i class="fa fa-check"></i><b>18.1.9</b> Log-odds Treatment Effects</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>A. EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="19" data-path="experimental-design.html"><a href="experimental-design.html"><i class="fa fa-check"></i><b>19</b> Experimental Design</a>
<ul>
<li class="chapter" data-level="19.1" data-path="notes.html"><a href="notes.html"><i class="fa fa-check"></i><b>19.1</b> Notes</a></li>
<li class="chapter" data-level="19.2" data-path="semi-random-experiment.html"><a href="semi-random-experiment.html"><i class="fa fa-check"></i><b>19.2</b> Semi-random Experiment</a></li>
<li class="chapter" data-level="19.3" data-path="rerandomization.html"><a href="rerandomization.html"><i class="fa fa-check"></i><b>19.3</b> Rerandomization</a></li>
<li class="chapter" data-level="19.4" data-path="two-stage-randomized-experiments-with-interference-and-noncompliance.html"><a href="two-stage-randomized-experiments-with-interference-and-noncompliance.html"><i class="fa fa-check"></i><b>19.4</b> Two-Stage Randomized Experiments with Interference and Noncompliance</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>20</b> Sampling</a>
<ul>
<li class="chapter" data-level="20.1" data-path="simple-sampling.html"><a href="simple-sampling.html"><i class="fa fa-check"></i><b>20.1</b> Simple Sampling</a></li>
<li class="chapter" data-level="20.2" data-path="stratified-sampling.html"><a href="stratified-sampling.html"><i class="fa fa-check"></i><b>20.2</b> Stratified Sampling</a></li>
<li class="chapter" data-level="20.3" data-path="unequal-probability-sampling.html"><a href="unequal-probability-sampling.html"><i class="fa fa-check"></i><b>20.3</b> Unequal Probability Sampling</a></li>
<li class="chapter" data-level="20.4" data-path="balanced-sampling.html"><a href="balanced-sampling.html"><i class="fa fa-check"></i><b>20.4</b> Balanced Sampling</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="balanced-sampling.html"><a href="balanced-sampling.html#cube"><i class="fa fa-check"></i><b>20.4.1</b> Cube</a></li>
<li class="chapter" data-level="20.4.2" data-path="balanced-sampling.html"><a href="balanced-sampling.html#stratification"><i class="fa fa-check"></i><b>20.4.2</b> Stratification</a></li>
<li class="chapter" data-level="20.4.3" data-path="balanced-sampling.html"><a href="balanced-sampling.html#cluster"><i class="fa fa-check"></i><b>20.4.3</b> Cluster</a></li>
<li class="chapter" data-level="20.4.4" data-path="balanced-sampling.html"><a href="balanced-sampling.html#two-stage"><i class="fa fa-check"></i><b>20.4.4</b> Two-stage</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>21</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="21.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html"><i class="fa fa-check"></i><b>21.1</b> Completely Randomized Design (CRD)</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model"><i class="fa fa-check"></i><b>21.1.1</b> Single Factor Fixed Effects Model</a></li>
<li class="chapter" data-level="21.1.2" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-random-effects-model"><i class="fa fa-check"></i><b>21.1.2</b> Single Factor Random Effects Model</a></li>
<li class="chapter" data-level="21.1.3" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova"><i class="fa fa-check"></i><b>21.1.3</b> Two Factor Fixed Effect ANOVA</a></li>
<li class="chapter" data-level="21.1.4" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-random-effects-anova"><i class="fa fa-check"></i><b>21.1.4</b> Two-Way Random Effects ANOVA</a></li>
<li class="chapter" data-level="21.1.5" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova"><i class="fa fa-check"></i><b>21.1.5</b> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html"><i class="fa fa-check"></i><b>21.2</b> Nonparametric ANOVA</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#kruskal-wallis"><i class="fa fa-check"></i><b>21.2.1</b> Kruskal-Wallis</a></li>
<li class="chapter" data-level="21.2.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#friedman-test"><i class="fa fa-check"></i><b>21.2.2</b> Friedman Test</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html"><i class="fa fa-check"></i><b>21.3</b> Sample Size Planning for ANOVA</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#balanced-designs"><i class="fa fa-check"></i><b>21.3.1</b> Balanced Designs</a></li>
<li class="chapter" data-level="21.3.2" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#randomized-block-experiments"><i class="fa fa-check"></i><b>21.3.2</b> Randomized Block Experiments</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html"><i class="fa fa-check"></i><b>21.4</b> Randomized Block Designs</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html#tukey-test-of-additivity"><i class="fa fa-check"></i><b>21.4.1</b> Tukey Test of Additivity</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="nested-designs.html"><a href="nested-designs.html"><i class="fa fa-check"></i><b>21.5</b> Nested Designs</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="nested-designs.html"><a href="nested-designs.html#two-factor-nested-designs"><i class="fa fa-check"></i><b>21.5.1</b> Two-Factor Nested Designs</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html"><i class="fa fa-check"></i><b>21.6</b> Single Factor Covariance Model</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="multivariate-methods.html"><a href="multivariate-methods.html"><i class="fa fa-check"></i><b>22</b> Multivariate Methods</a>
<ul>
<li class="chapter" data-level="22.0.1" data-path="multivariate-methods.html"><a href="multivariate-methods.html#properties-of-mvn"><i class="fa fa-check"></i><b>22.0.1</b> Properties of MVN</a></li>
<li class="chapter" data-level="22.0.2" data-path="multivariate-methods.html"><a href="multivariate-methods.html#mean-vector-inference"><i class="fa fa-check"></i><b>22.0.2</b> Mean Vector Inference</a></li>
<li class="chapter" data-level="22.0.3" data-path="multivariate-methods.html"><a href="multivariate-methods.html#general-hypothesis-testing"><i class="fa fa-check"></i><b>22.0.3</b> General Hypothesis Testing</a></li>
<li class="chapter" data-level="22.1" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>22.1</b> MANOVA</a>
<ul>
<li class="chapter" data-level="22.1.1" data-path="manova.html"><a href="manova.html#testing-general-hypotheses"><i class="fa fa-check"></i><b>22.1.1</b> Testing General Hypotheses</a></li>
<li class="chapter" data-level="22.1.2" data-path="manova.html"><a href="manova.html#profile-analysis"><i class="fa fa-check"></i><b>22.1.2</b> Profile Analysis</a></li>
<li class="chapter" data-level="22.1.3" data-path="manova.html"><a href="manova.html#summary-5"><i class="fa fa-check"></i><b>22.1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i><b>22.2</b> Principal Components</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="principal-components.html"><a href="principal-components.html#population-principal-components"><i class="fa fa-check"></i><b>22.2.1</b> Population Principal Components</a></li>
<li class="chapter" data-level="22.2.2" data-path="principal-components.html"><a href="principal-components.html#sample-principal-components"><i class="fa fa-check"></i><b>22.2.2</b> Sample Principal Components</a></li>
<li class="chapter" data-level="22.2.3" data-path="principal-components.html"><a href="principal-components.html#application-8"><i class="fa fa-check"></i><b>22.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>22.3</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="22.3.1" data-path="factor-analysis.html"><a href="factor-analysis.html#methods-of-estimation"><i class="fa fa-check"></i><b>22.3.1</b> Methods of Estimation</a></li>
<li class="chapter" data-level="22.3.2" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-rotation"><i class="fa fa-check"></i><b>22.3.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="22.3.3" data-path="factor-analysis.html"><a href="factor-analysis.html#estimation-of-factor-scores"><i class="fa fa-check"></i><b>22.3.3</b> Estimation of Factor Scores</a></li>
<li class="chapter" data-level="22.3.4" data-path="factor-analysis.html"><a href="factor-analysis.html#model-diagnostic"><i class="fa fa-check"></i><b>22.3.4</b> Model Diagnostic</a></li>
<li class="chapter" data-level="22.3.5" data-path="factor-analysis.html"><a href="factor-analysis.html#application-9"><i class="fa fa-check"></i><b>22.3.5</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>22.4</b> Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="22.4.1" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#known-populations"><i class="fa fa-check"></i><b>22.4.1</b> Known Populations</a></li>
<li class="chapter" data-level="22.4.2" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#probabilities-of-misclassification"><i class="fa fa-check"></i><b>22.4.2</b> Probabilities of Misclassification</a></li>
<li class="chapter" data-level="22.4.3" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#unknown-populations-nonparametric-discrimination"><i class="fa fa-check"></i><b>22.4.3</b> Unknown Populations/ Nonparametric Discrimination</a></li>
<li class="chapter" data-level="22.4.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#application-10"><i class="fa fa-check"></i><b>22.4.4</b> Application</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>B. QUASI-EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="23" data-path="quasi-experimental.html"><a href="quasi-experimental.html"><i class="fa fa-check"></i><b>23</b> Quasi-experimental</a>
<ul>
<li class="chapter" data-level="23.1" data-path="natural-experiments.html"><a href="natural-experiments.html"><i class="fa fa-check"></i><b>23.1</b> Natural Experiments</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html"><i class="fa fa-check"></i><b>24</b> Regression Discontinuity</a>
<ul>
<li class="chapter" data-level="24.1" data-path="estimation-and-inference.html"><a href="estimation-and-inference.html"><i class="fa fa-check"></i><b>24.1</b> Estimation and Inference</a>
<ul>
<li class="chapter" data-level="24.1.1" data-path="estimation-and-inference.html"><a href="estimation-and-inference.html#local-randomization-based"><i class="fa fa-check"></i><b>24.1.1</b> Local Randomization-based</a></li>
<li class="chapter" data-level="24.1.2" data-path="estimation-and-inference.html"><a href="estimation-and-inference.html#continuity-based"><i class="fa fa-check"></i><b>24.1.2</b> Continuity-based</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="specification-checks.html"><a href="specification-checks.html"><i class="fa fa-check"></i><b>24.2</b> Specification Checks</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="specification-checks.html"><a href="specification-checks.html#balance-checks"><i class="fa fa-check"></i><b>24.2.1</b> Balance Checks</a></li>
<li class="chapter" data-level="24.2.2" data-path="specification-checks.html"><a href="specification-checks.html#sortingbunchingmanipulation"><i class="fa fa-check"></i><b>24.2.2</b> Sorting/Bunching/Manipulation</a></li>
<li class="chapter" data-level="24.2.3" data-path="specification-checks.html"><a href="specification-checks.html#placebo-tests"><i class="fa fa-check"></i><b>24.2.3</b> Placebo Tests</a></li>
<li class="chapter" data-level="24.2.4" data-path="specification-checks.html"><a href="specification-checks.html#sensitivity-to-bandwidth-choice"><i class="fa fa-check"></i><b>24.2.4</b> Sensitivity to Bandwidth Choice</a></li>
<li class="chapter" data-level="24.2.5" data-path="specification-checks.html"><a href="specification-checks.html#manipulation-robust-regression-discontinuity-bounds"><i class="fa fa-check"></i><b>24.2.5</b> Manipulation Robust Regression Discontinuity Bounds</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="fuzzy-rd-design.html"><a href="fuzzy-rd-design.html"><i class="fa fa-check"></i><b>24.3</b> Fuzzy RD Design</a></li>
<li class="chapter" data-level="24.4" data-path="regression-kink-design.html"><a href="regression-kink-design.html"><i class="fa fa-check"></i><b>24.4</b> Regression Kink Design</a></li>
<li class="chapter" data-level="24.5" data-path="multi-cutoff.html"><a href="multi-cutoff.html"><i class="fa fa-check"></i><b>24.5</b> Multi-cutoff</a></li>
<li class="chapter" data-level="24.6" data-path="multi-score.html"><a href="multi-score.html"><i class="fa fa-check"></i><b>24.6</b> Multi-score</a></li>
<li class="chapter" data-level="24.7" data-path="steps-for-sharp-rd.html"><a href="steps-for-sharp-rd.html"><i class="fa fa-check"></i><b>24.7</b> Steps for Sharp RD</a></li>
<li class="chapter" data-level="24.8" data-path="steps-for-fuzzy-rd.html"><a href="steps-for-fuzzy-rd.html"><i class="fa fa-check"></i><b>24.8</b> Steps for Fuzzy RD</a></li>
<li class="chapter" data-level="24.9" data-path="steps-for-rdit-regression-discontinuity-in-time.html"><a href="steps-for-rdit-regression-discontinuity-in-time.html"><i class="fa fa-check"></i><b>24.9</b> Steps for RDiT (Regression Discontinuity in Time)</a></li>
<li class="chapter" data-level="24.10" data-path="evaluation-of-an-rd.html"><a href="evaluation-of-an-rd.html"><i class="fa fa-check"></i><b>24.10</b> Evaluation of an RD</a></li>
<li class="chapter" data-level="24.11" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>24.11</b> Applications</a>
<ul>
<li class="chapter" data-level="24.11.1" data-path="applications.html"><a href="applications.html#example-1-1"><i class="fa fa-check"></i><b>24.11.1</b> Example 1</a></li>
<li class="chapter" data-level="24.11.2" data-path="applications.html"><a href="applications.html#example-2"><i class="fa fa-check"></i><b>24.11.2</b> Example 2</a></li>
<li class="chapter" data-level="24.11.3" data-path="applications.html"><a href="applications.html#example-3"><i class="fa fa-check"></i><b>24.11.3</b> Example 3</a></li>
<li class="chapter" data-level="24.11.4" data-path="applications.html"><a href="applications.html#example-4"><i class="fa fa-check"></i><b>24.11.4</b> Example 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="synthetic-difference-in-differences.html"><a href="synthetic-difference-in-differences.html"><i class="fa fa-check"></i><b>25</b> Synthetic Difference-in-Differences</a>
<ul>
<li class="chapter" data-level="25.1" data-path="understanding.html"><a href="understanding.html"><i class="fa fa-check"></i><b>25.1</b> Understanding</a></li>
<li class="chapter" data-level="25.2" data-path="application-11.html"><a href="application-11.html"><i class="fa fa-check"></i><b>25.2</b> Application</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="application-11.html"><a href="application-11.html#block-treatment"><i class="fa fa-check"></i><b>25.2.1</b> Block Treatment</a></li>
<li class="chapter" data-level="25.2.2" data-path="application-11.html"><a href="application-11.html#staggered-adoption"><i class="fa fa-check"></i><b>25.2.2</b> Staggered Adoption</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="difference-in-differences.html"><a href="difference-in-differences.html"><i class="fa fa-check"></i><b>26</b> Difference-in-differences</a>
<ul>
<li class="chapter" data-level="26.1" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>26.1</b> Visualization</a></li>
<li class="chapter" data-level="26.2" data-path="simple-dif-n-dif.html"><a href="simple-dif-n-dif.html"><i class="fa fa-check"></i><b>26.2</b> Simple Dif-n-dif</a></li>
<li class="chapter" data-level="26.3" data-path="notes-1.html"><a href="notes-1.html"><i class="fa fa-check"></i><b>26.3</b> Notes</a></li>
<li class="chapter" data-level="26.4" data-path="standard-errors-2.html"><a href="standard-errors-2.html"><i class="fa fa-check"></i><b>26.4</b> Standard Errors</a></li>
<li class="chapter" data-level="26.5" data-path="examples.html"><a href="examples.html"><i class="fa fa-check"></i><b>26.5</b> Examples</a>
<ul>
<li class="chapter" data-level="26.5.1" data-path="examples.html"><a href="examples.html#example-by-doleac2020unintended"><i class="fa fa-check"></i><b>26.5.1</b> Example by <span class="citation">Doleac and Hansen (2020)</span></a></li>
<li class="chapter" data-level="26.5.2" data-path="examples.html"><a href="examples.html#example-from-princeton"><i class="fa fa-check"></i><b>26.5.2</b> Example from Princeton</a></li>
<li class="chapter" data-level="26.5.3" data-path="examples.html"><a href="examples.html#example-by-card1993minimum"><i class="fa fa-check"></i><b>26.5.3</b> Example by <span class="citation">Card and Krueger (1993)</span></a></li>
<li class="chapter" data-level="26.5.4" data-path="examples.html"><a href="examples.html#example-by-butcher2014effects"><i class="fa fa-check"></i><b>26.5.4</b> Example by <span class="citation">Butcher, McEwan, and Weerapana (2014)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.6" data-path="one-difference.html"><a href="one-difference.html"><i class="fa fa-check"></i><b>26.6</b> One Difference</a></li>
<li class="chapter" data-level="26.7" data-path="two-way-fixed-effects.html"><a href="two-way-fixed-effects.html"><i class="fa fa-check"></i><b>26.7</b> Two-way Fixed-effects</a></li>
<li class="chapter" data-level="26.8" data-path="multiple-periods-and-variation-in-treatment-timing.html"><a href="multiple-periods-and-variation-in-treatment-timing.html"><i class="fa fa-check"></i><b>26.8</b> Multiple periods and variation in treatment timing</a></li>
<li class="chapter" data-level="26.9" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html"><i class="fa fa-check"></i><b>26.9</b> Staggered Dif-n-dif</a>
<ul>
<li class="chapter" data-level="26.9.1" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#stacked-did"><i class="fa fa-check"></i><b>26.9.1</b> Stacked DID</a></li>
<li class="chapter" data-level="26.9.2" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#goodman-bacon-decomposition"><i class="fa fa-check"></i><b>26.9.2</b> Goodman-Bacon Decomposition</a></li>
<li class="chapter" data-level="26.9.3" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#did-with-in-and-out-treatment-condition"><i class="fa fa-check"></i><b>26.9.3</b> DID with in and out treatment condition</a></li>
<li class="chapter" data-level="26.9.4" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#gardner2022two-and-borusyak2021revisiting"><i class="fa fa-check"></i><b>26.9.4</b> <span class="citation">Gardner (2022)</span> and <span class="citation">Borusyak, Jaravel, and Spiess (2021)</span></a></li>
<li class="chapter" data-level="26.9.5" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#de2020two"><i class="fa fa-check"></i><b>26.9.5</b> <span class="citation">Clément De Chaisemartin and d’Haultfoeuille (2020)</span></a></li>
<li class="chapter" data-level="26.9.6" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#callaway2021difference"><i class="fa fa-check"></i><b>26.9.6</b> <span class="citation">Callaway and Sant’Anna (2021)</span></a></li>
<li class="chapter" data-level="26.9.7" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#sun2021estimating"><i class="fa fa-check"></i><b>26.9.7</b> <span class="citation">L. Sun and Abraham (2021)</span></a></li>
<li class="chapter" data-level="26.9.8" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#wooldridge2022simple"><i class="fa fa-check"></i><b>26.9.8</b> <span class="citation">Wooldridge (2022)</span></a></li>
<li class="chapter" data-level="26.9.9" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#doubly-robust-did"><i class="fa fa-check"></i><b>26.9.9</b> Doubly Robust DiD</a></li>
<li class="chapter" data-level="26.9.10" data-path="staggered-dif-n-dif.html"><a href="staggered-dif-n-dif.html#augmentedforward-did"><i class="fa fa-check"></i><b>26.9.10</b> Augmented/Forward DID</a></li>
</ul></li>
<li class="chapter" data-level="26.10" data-path="multiple-treatments.html"><a href="multiple-treatments.html"><i class="fa fa-check"></i><b>26.10</b> Multiple Treatments</a></li>
<li class="chapter" data-level="26.11" data-path="mediation-under-did.html"><a href="mediation-under-did.html"><i class="fa fa-check"></i><b>26.11</b> Mediation Under DiD</a></li>
<li class="chapter" data-level="26.12" data-path="assumptions-1.html"><a href="assumptions-1.html"><i class="fa fa-check"></i><b>26.12</b> Assumptions</a>
<ul>
<li class="chapter" data-level="26.12.1" data-path="assumptions-1.html"><a href="assumptions-1.html#prior-parallel-trends-test"><i class="fa fa-check"></i><b>26.12.1</b> Prior Parallel Trends Test</a></li>
<li class="chapter" data-level="26.12.2" data-path="assumptions-1.html"><a href="assumptions-1.html#placebo-test-1"><i class="fa fa-check"></i><b>26.12.2</b> Placebo Test</a></li>
<li class="chapter" data-level="26.12.3" data-path="assumptions-1.html"><a href="assumptions-1.html#assumption-violations"><i class="fa fa-check"></i><b>26.12.3</b> Assumption Violations</a></li>
<li class="chapter" data-level="26.12.4" data-path="assumptions-1.html"><a href="assumptions-1.html#robustness-checks"><i class="fa fa-check"></i><b>26.12.4</b> Robustness Checks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="changes-in-changes.html"><a href="changes-in-changes.html"><i class="fa fa-check"></i><b>27</b> Changes-in-Changes</a>
<ul>
<li class="chapter" data-level="27.1" data-path="application-12.html"><a href="application-12.html"><i class="fa fa-check"></i><b>27.1</b> Application</a>
<ul>
<li class="chapter" data-level="27.1.1" data-path="application-12.html"><a href="application-12.html#ecic-package"><i class="fa fa-check"></i><b>27.1.1</b> ECIC package</a></li>
<li class="chapter" data-level="27.1.2" data-path="application-12.html"><a href="application-12.html#qte-package"><i class="fa fa-check"></i><b>27.1.2</b> QTE package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="synthetic-control.html"><a href="synthetic-control.html"><i class="fa fa-check"></i><b>28</b> Synthetic Control</a>
<ul>
<li class="chapter" data-level="28.1" data-path="applications-1.html"><a href="applications-1.html"><i class="fa fa-check"></i><b>28.1</b> Applications</a>
<ul>
<li class="chapter" data-level="28.1.1" data-path="applications-1.html"><a href="applications-1.html#example-1-2"><i class="fa fa-check"></i><b>28.1.1</b> Example 1</a></li>
<li class="chapter" data-level="28.1.2" data-path="applications-1.html"><a href="applications-1.html#example-2-1"><i class="fa fa-check"></i><b>28.1.2</b> Example 2</a></li>
<li class="chapter" data-level="28.1.3" data-path="applications-1.html"><a href="applications-1.html#example-3-1"><i class="fa fa-check"></i><b>28.1.3</b> Example 3</a></li>
<li class="chapter" data-level="28.1.4" data-path="applications-1.html"><a href="applications-1.html#example-4-1"><i class="fa fa-check"></i><b>28.1.4</b> Example 4</a></li>
</ul></li>
<li class="chapter" data-level="28.2" data-path="augmented-synthetic-control-method.html"><a href="augmented-synthetic-control-method.html"><i class="fa fa-check"></i><b>28.2</b> Augmented Synthetic Control Method</a></li>
<li class="chapter" data-level="28.3" data-path="synthetic-control-with-staggered-adoption.html"><a href="synthetic-control-with-staggered-adoption.html"><i class="fa fa-check"></i><b>28.3</b> Synthetic Control with Staggered Adoption</a></li>
<li class="chapter" data-level="28.4" data-path="bayesian-synthetic-control.html"><a href="bayesian-synthetic-control.html"><i class="fa fa-check"></i><b>28.4</b> Bayesian Synthetic Control</a></li>
<li class="chapter" data-level="28.5" data-path="generalized-synthetic-control.html"><a href="generalized-synthetic-control.html"><i class="fa fa-check"></i><b>28.5</b> Generalized Synthetic Control</a></li>
<li class="chapter" data-level="28.6" data-path="other-advances.html"><a href="other-advances.html"><i class="fa fa-check"></i><b>28.6</b> Other Advances</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="event-studies.html"><a href="event-studies.html"><i class="fa fa-check"></i><b>29</b> Event Studies</a>
<ul>
<li class="chapter" data-level="29.1" data-path="other-issues.html"><a href="other-issues.html"><i class="fa fa-check"></i><b>29.1</b> Other Issues</a>
<ul>
<li class="chapter" data-level="29.1.1" data-path="other-issues.html"><a href="other-issues.html#event-studies-in-marketing"><i class="fa fa-check"></i><b>29.1.1</b> Event Studies in marketing</a></li>
<li class="chapter" data-level="29.1.2" data-path="other-issues.html"><a href="other-issues.html#economic-significance"><i class="fa fa-check"></i><b>29.1.2</b> Economic significance</a></li>
<li class="chapter" data-level="29.1.3" data-path="other-issues.html"><a href="other-issues.html#statistical-power"><i class="fa fa-check"></i><b>29.1.3</b> Statistical Power</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="testing.html"><a href="testing.html"><i class="fa fa-check"></i><b>29.2</b> Testing</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="testing.html"><a href="testing.html#parametric-test"><i class="fa fa-check"></i><b>29.2.1</b> Parametric Test</a></li>
<li class="chapter" data-level="29.2.2" data-path="testing.html"><a href="testing.html#non-parametric-test"><i class="fa fa-check"></i><b>29.2.2</b> Non-parametric Test</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="sample.html"><a href="sample.html"><i class="fa fa-check"></i><b>29.3</b> Sample</a>
<ul>
<li class="chapter" data-level="29.3.1" data-path="sample.html"><a href="sample.html#confounders"><i class="fa fa-check"></i><b>29.3.1</b> Confounders</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="biases.html"><a href="biases.html"><i class="fa fa-check"></i><b>29.4</b> Biases</a></li>
<li class="chapter" data-level="29.5" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html"><i class="fa fa-check"></i><b>29.5</b> Long-run event studies</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html#buy-and-hold-abnormal-returns-bhar"><i class="fa fa-check"></i><b>29.5.1</b> Buy and Hold Abnormal Returns (BHAR)</a></li>
<li class="chapter" data-level="29.5.2" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html#long-term-cumulative-abnormal-returns-lcars"><i class="fa fa-check"></i><b>29.5.2</b> Long-term Cumulative Abnormal Returns (LCARs)</a></li>
<li class="chapter" data-level="29.5.3" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html#calendar-time-portfolio-abnormal-returns-ctars"><i class="fa fa-check"></i><b>29.5.3</b> Calendar-time Portfolio Abnormal Returns (CTARs)</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="aggregation.html"><a href="aggregation.html"><i class="fa fa-check"></i><b>29.6</b> Aggregation</a>
<ul>
<li class="chapter" data-level="29.6.1" data-path="aggregation.html"><a href="aggregation.html#over-time"><i class="fa fa-check"></i><b>29.6.1</b> Over Time</a></li>
<li class="chapter" data-level="29.6.2" data-path="aggregation.html"><a href="aggregation.html#across-firms-over-time"><i class="fa fa-check"></i><b>29.6.2</b> Across Firms + Over Time</a></li>
</ul></li>
<li class="chapter" data-level="29.7" data-path="heterogeneity-in-the-event-effect.html"><a href="heterogeneity-in-the-event-effect.html"><i class="fa fa-check"></i><b>29.7</b> Heterogeneity in the event effect</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="heterogeneity-in-the-event-effect.html"><a href="heterogeneity-in-the-event-effect.html#common-variables-in-marketing"><i class="fa fa-check"></i><b>29.7.1</b> Common variables in marketing</a></li>
</ul></li>
<li class="chapter" data-level="29.8" data-path="expected-return-calculation.html"><a href="expected-return-calculation.html"><i class="fa fa-check"></i><b>29.8</b> Expected Return Calculation</a>
<ul>
<li class="chapter" data-level="29.8.1" data-path="expected-return-calculation.html"><a href="expected-return-calculation.html#statistical-models"><i class="fa fa-check"></i><b>29.8.1</b> Statistical Models</a></li>
<li class="chapter" data-level="29.8.2" data-path="expected-return-calculation.html"><a href="expected-return-calculation.html#economic-model"><i class="fa fa-check"></i><b>29.8.2</b> Economic Model</a></li>
</ul></li>
<li class="chapter" data-level="29.9" data-path="application-13.html"><a href="application-13.html"><i class="fa fa-check"></i><b>29.9</b> Application</a>
<ul>
<li class="chapter" data-level="29.9.1" data-path="application-13.html"><a href="application-13.html#eventus"><i class="fa fa-check"></i><b>29.9.1</b> Eventus</a></li>
<li class="chapter" data-level="29.9.2" data-path="application-13.html"><a href="application-13.html#evenstudies"><i class="fa fa-check"></i><b>29.9.2</b> Evenstudies</a></li>
<li class="chapter" data-level="29.9.3" data-path="application-13.html"><a href="application-13.html#eventstudy"><i class="fa fa-check"></i><b>29.9.3</b> EventStudy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="instrumental-variables.html"><a href="instrumental-variables.html"><i class="fa fa-check"></i><b>30</b> Instrumental Variables</a>
<ul>
<li class="chapter" data-level="30.1" data-path="framework.html"><a href="framework.html"><i class="fa fa-check"></i><b>30.1</b> Framework</a></li>
<li class="chapter" data-level="30.2" data-path="estimation-3.html"><a href="estimation-3.html"><i class="fa fa-check"></i><b>30.2</b> Estimation</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="estimation-3.html"><a href="estimation-3.html#sls-estimation"><i class="fa fa-check"></i><b>30.2.1</b> 2SLS Estimation</a></li>
<li class="chapter" data-level="30.2.2" data-path="estimation-3.html"><a href="estimation-3.html#iv-gmm"><i class="fa fa-check"></i><b>30.2.2</b> IV-GMM</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="inference-3.html"><a href="inference-3.html"><i class="fa fa-check"></i><b>30.3</b> Inference</a>
<ul>
<li class="chapter" data-level="30.3.1" data-path="inference-3.html"><a href="inference-3.html#ar-approach"><i class="fa fa-check"></i><b>30.3.1</b> AR approach</a></li>
<li class="chapter" data-level="30.3.2" data-path="inference-3.html"><a href="inference-3.html#tf-procedure"><i class="fa fa-check"></i><b>30.3.2</b> tF Procedure</a></li>
<li class="chapter" data-level="30.3.3" data-path="inference-3.html"><a href="inference-3.html#ak-approach"><i class="fa fa-check"></i><b>30.3.3</b> AK approach</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="testing-assumptions.html"><a href="testing-assumptions.html"><i class="fa fa-check"></i><b>30.4</b> Testing Assumptions</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="testing-assumptions.html"><a href="testing-assumptions.html#relevance-assumption"><i class="fa fa-check"></i><b>30.4.1</b> Relevance Assumption</a></li>
<li class="chapter" data-level="30.4.2" data-path="testing-assumptions.html"><a href="testing-assumptions.html#exogeneity-assumption"><i class="fa fa-check"></i><b>30.4.2</b> Exogeneity Assumption</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="negative-r2.html"><a href="negative-r2.html"><i class="fa fa-check"></i><b>30.5</b> Negative <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="30.6" data-path="treatment-intensity.html"><a href="treatment-intensity.html"><i class="fa fa-check"></i><b>30.6</b> Treatment Intensity</a></li>
<li class="chapter" data-level="30.7" data-path="control-function.html"><a href="control-function.html"><i class="fa fa-check"></i><b>30.7</b> Control Function</a>
<ul>
<li class="chapter" data-level="30.7.1" data-path="control-function.html"><a href="control-function.html#simulation"><i class="fa fa-check"></i><b>30.7.1</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="30.8" data-path="new-advances.html"><a href="new-advances.html"><i class="fa fa-check"></i><b>30.8</b> New Advances</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="matching-methods.html"><a href="matching-methods.html"><i class="fa fa-check"></i><b>31</b> Matching Methods</a>
<ul>
<li class="chapter" data-level="31.1" data-path="selection-on-observables.html"><a href="selection-on-observables.html"><i class="fa fa-check"></i><b>31.1</b> Selection on Observables</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matchit"><i class="fa fa-check"></i><b>31.1.1</b> MatchIt</a></li>
<li class="chapter" data-level="31.1.2" data-path="selection-on-observables.html"><a href="selection-on-observables.html#designmatch"><i class="fa fa-check"></i><b>31.1.2</b> designmatch</a></li>
<li class="chapter" data-level="31.1.3" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matchingfrontier"><i class="fa fa-check"></i><b>31.1.3</b> MatchingFrontier</a></li>
<li class="chapter" data-level="31.1.4" data-path="selection-on-observables.html"><a href="selection-on-observables.html#propensity-scores"><i class="fa fa-check"></i><b>31.1.4</b> Propensity Scores</a></li>
<li class="chapter" data-level="31.1.5" data-path="selection-on-observables.html"><a href="selection-on-observables.html#mahalanobis-distance"><i class="fa fa-check"></i><b>31.1.5</b> Mahalanobis Distance</a></li>
<li class="chapter" data-level="31.1.6" data-path="selection-on-observables.html"><a href="selection-on-observables.html#coarsened-exact-matching"><i class="fa fa-check"></i><b>31.1.6</b> Coarsened Exact Matching</a></li>
<li class="chapter" data-level="31.1.7" data-path="selection-on-observables.html"><a href="selection-on-observables.html#genetic-matching"><i class="fa fa-check"></i><b>31.1.7</b> Genetic Matching</a></li>
<li class="chapter" data-level="31.1.8" data-path="selection-on-observables.html"><a href="selection-on-observables.html#entropy-balancing"><i class="fa fa-check"></i><b>31.1.8</b> Entropy Balancing</a></li>
<li class="chapter" data-level="31.1.9" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matching-for-high-dimensional-data"><i class="fa fa-check"></i><b>31.1.9</b> Matching for high-dimensional data</a></li>
<li class="chapter" data-level="31.1.10" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matching-for-time-series-cross-section-data"><i class="fa fa-check"></i><b>31.1.10</b> Matching for time series-cross-section data</a></li>
<li class="chapter" data-level="31.1.11" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matching-for-multiple-treatments"><i class="fa fa-check"></i><b>31.1.11</b> Matching for multiple treatments</a></li>
<li class="chapter" data-level="31.1.12" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matching-for-multi-level-treatments"><i class="fa fa-check"></i><b>31.1.12</b> Matching for multi-level treatments</a></li>
<li class="chapter" data-level="31.1.13" data-path="selection-on-observables.html"><a href="selection-on-observables.html#matching-for-repeated-treatments"><i class="fa fa-check"></i><b>31.1.13</b> Matching for repeated treatments</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="selection-on-unobservables.html"><a href="selection-on-unobservables.html"><i class="fa fa-check"></i><b>31.2</b> Selection on Unobservables</a>
<ul>
<li class="chapter" data-level="31.2.1" data-path="selection-on-unobservables.html"><a href="selection-on-unobservables.html#rosenbaum-bounds"><i class="fa fa-check"></i><b>31.2.1</b> Rosenbaum Bounds</a></li>
<li class="chapter" data-level="31.2.2" data-path="selection-on-unobservables.html"><a href="selection-on-unobservables.html#relative-correlation-restrictions"><i class="fa fa-check"></i><b>31.2.2</b> Relative Correlation Restrictions</a></li>
<li class="chapter" data-level="31.2.3" data-path="selection-on-unobservables.html"><a href="selection-on-unobservables.html#coefficient-stability-bounds"><i class="fa fa-check"></i><b>31.2.3</b> Coefficient-stability Bounds</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="32" data-path="interrupted-time-series.html"><a href="interrupted-time-series.html"><i class="fa fa-check"></i><b>32</b> Interrupted Time Series</a>
<ul>
<li class="chapter" data-level="32.1" data-path="autocorrelation.html"><a href="autocorrelation.html"><i class="fa fa-check"></i><b>32.1</b> Autocorrelation</a></li>
<li class="chapter" data-level="32.2" data-path="multiple-groups.html"><a href="multiple-groups.html"><i class="fa fa-check"></i><b>32.2</b> Multiple Groups</a></li>
</ul></li>
<li class="part"><span><b>C. OTHER CONCERNS</b></span></li>
<li class="chapter" data-level="33" data-path="endogeneity.html"><a href="endogeneity.html"><i class="fa fa-check"></i><b>33</b> Endogeneity</a>
<ul>
<li class="chapter" data-level="33.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html"><i class="fa fa-check"></i><b>33.1</b> Endogenous Treatment</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#measurement-error"><i class="fa fa-check"></i><b>33.1.1</b> Measurement Error</a></li>
<li class="chapter" data-level="33.1.2" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#simultaneity"><i class="fa fa-check"></i><b>33.1.2</b> Simultaneity</a></li>
<li class="chapter" data-level="33.1.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#endogenous-treatment-solutions"><i class="fa fa-check"></i><b>33.1.3</b> Endogenous Treatment Solutions</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html"><i class="fa fa-check"></i><b>33.2</b> Endogenous Sample Selection</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-2"><i class="fa fa-check"></i><b>33.2.1</b> Tobit-2</a></li>
<li class="chapter" data-level="33.2.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-5"><i class="fa fa-check"></i><b>33.2.2</b> Tobit-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="other-biases.html"><a href="other-biases.html"><i class="fa fa-check"></i><b>34</b> Other Biases</a>
<ul>
<li class="chapter" data-level="34.1" data-path="aggregation-bias.html"><a href="aggregation-bias.html"><i class="fa fa-check"></i><b>34.1</b> Aggregation Bias</a>
<ul>
<li class="chapter" data-level="34.1.1" data-path="aggregation-bias.html"><a href="aggregation-bias.html#simpsons-paradox"><i class="fa fa-check"></i><b>34.1.1</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="34.2" data-path="contamination-bias.html"><a href="contamination-bias.html"><i class="fa fa-check"></i><b>34.2</b> Contamination Bias</a></li>
<li class="chapter" data-level="34.3" data-path="survivorship-bias.html"><a href="survivorship-bias.html"><i class="fa fa-check"></i><b>34.3</b> Survivorship Bias</a></li>
<li class="chapter" data-level="34.4" data-path="publication-bias.html"><a href="publication-bias.html"><i class="fa fa-check"></i><b>34.4</b> Publication Bias</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="controls.html"><a href="controls.html"><i class="fa fa-check"></i><b>35</b> Controls</a>
<ul>
<li class="chapter" data-level="35.1" data-path="bad-controls.html"><a href="bad-controls.html"><i class="fa fa-check"></i><b>35.1</b> Bad Controls</a>
<ul>
<li class="chapter" data-level="35.1.1" data-path="bad-controls.html"><a href="bad-controls.html#m-bias"><i class="fa fa-check"></i><b>35.1.1</b> M-bias</a></li>
<li class="chapter" data-level="35.1.2" data-path="bad-controls.html"><a href="bad-controls.html#bias-amplification-1"><i class="fa fa-check"></i><b>35.1.2</b> Bias Amplification</a></li>
<li class="chapter" data-level="35.1.3" data-path="bad-controls.html"><a href="bad-controls.html#overcontrol-bias"><i class="fa fa-check"></i><b>35.1.3</b> Overcontrol bias</a></li>
<li class="chapter" data-level="35.1.4" data-path="bad-controls.html"><a href="bad-controls.html#selection-bias"><i class="fa fa-check"></i><b>35.1.4</b> Selection Bias</a></li>
<li class="chapter" data-level="35.1.5" data-path="bad-controls.html"><a href="bad-controls.html#case-control-bias"><i class="fa fa-check"></i><b>35.1.5</b> Case-control Bias</a></li>
</ul></li>
<li class="chapter" data-level="35.2" data-path="good-controls.html"><a href="good-controls.html"><i class="fa fa-check"></i><b>35.2</b> Good Controls</a>
<ul>
<li class="chapter" data-level="35.2.1" data-path="good-controls.html"><a href="good-controls.html#omitted-variable-bias-correction"><i class="fa fa-check"></i><b>35.2.1</b> Omitted Variable Bias Correction</a></li>
<li class="chapter" data-level="35.2.2" data-path="good-controls.html"><a href="good-controls.html#omitted-variable-bias-in-mediation-correction"><i class="fa fa-check"></i><b>35.2.2</b> Omitted Variable Bias in Mediation Correction</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="neutral-controls.html"><a href="neutral-controls.html"><i class="fa fa-check"></i><b>35.3</b> Neutral Controls</a>
<ul>
<li class="chapter" data-level="35.3.1" data-path="neutral-controls.html"><a href="neutral-controls.html#good-predictive-controls"><i class="fa fa-check"></i><b>35.3.1</b> Good Predictive Controls</a></li>
<li class="chapter" data-level="35.3.2" data-path="neutral-controls.html"><a href="neutral-controls.html#good-selection-bias"><i class="fa fa-check"></i><b>35.3.2</b> Good Selection Bias</a></li>
<li class="chapter" data-level="35.3.3" data-path="neutral-controls.html"><a href="neutral-controls.html#bad-predictive-controls"><i class="fa fa-check"></i><b>35.3.3</b> Bad Predictive Controls</a></li>
<li class="chapter" data-level="35.3.4" data-path="neutral-controls.html"><a href="neutral-controls.html#bad-selection-bias"><i class="fa fa-check"></i><b>35.3.4</b> Bad Selection Bias</a></li>
</ul></li>
<li class="chapter" data-level="35.4" data-path="choosing-controls.html"><a href="choosing-controls.html"><i class="fa fa-check"></i><b>35.4</b> Choosing Controls</a></li>
</ul></li>
<li class="chapter" data-level="36" data-path="mediation.html"><a href="mediation.html"><i class="fa fa-check"></i><b>36</b> Mediation</a>
<ul>
<li class="chapter" data-level="36.1" data-path="traditional-approach.html"><a href="traditional-approach.html"><i class="fa fa-check"></i><b>36.1</b> Traditional Approach</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="traditional-approach.html"><a href="traditional-approach.html#assumptions-2"><i class="fa fa-check"></i><b>36.1.1</b> Assumptions</a></li>
<li class="chapter" data-level="36.1.2" data-path="traditional-approach.html"><a href="traditional-approach.html#indirect-effect-tests"><i class="fa fa-check"></i><b>36.1.2</b> Indirect Effect Tests</a></li>
<li class="chapter" data-level="36.1.3" data-path="traditional-approach.html"><a href="traditional-approach.html#multiple-mediation"><i class="fa fa-check"></i><b>36.1.3</b> Multiple Mediation</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="causal-inference-approach.html"><a href="causal-inference-approach.html"><i class="fa fa-check"></i><b>36.2</b> Causal Inference Approach</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="causal-inference-approach.html"><a href="causal-inference-approach.html#example-1-mediation-traditional"><i class="fa fa-check"></i><b>36.2.1</b> Example 1</a></li>
</ul></li>
<li class="chapter" data-level="36.3" data-path="model-based-causal-mediation-analysis.html"><a href="model-based-causal-mediation-analysis.html"><i class="fa fa-check"></i><b>36.3</b> Model-based causal mediation analysis</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="directed-acyclic-graph.html"><a href="directed-acyclic-graph.html"><i class="fa fa-check"></i><b>37</b> Directed Acyclic Graph</a>
<ul>
<li class="chapter" data-level="37.1" data-path="basic-notations.html"><a href="basic-notations.html"><i class="fa fa-check"></i><b>37.1</b> Basic Notations</a></li>
</ul></li>
<li class="part"><span><b>V. MISCELLANEOUS</b></span></li>
<li class="chapter" data-level="38" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>38</b> Report</a>
<ul>
<li class="chapter" data-level="38.1" data-path="one-summary-table.html"><a href="one-summary-table.html"><i class="fa fa-check"></i><b>38.1</b> One summary table</a></li>
<li class="chapter" data-level="38.2" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>38.2</b> Model Comparison</a></li>
<li class="chapter" data-level="38.3" data-path="changes-in-an-estimate.html"><a href="changes-in-an-estimate.html"><i class="fa fa-check"></i><b>38.3</b> Changes in an estimate</a></li>
<li class="chapter" data-level="38.4" data-path="standard-errors-3.html"><a href="standard-errors-3.html"><i class="fa fa-check"></i><b>38.4</b> Standard Errors</a></li>
<li class="chapter" data-level="38.5" data-path="coefficient-uncertainty-and-distribution.html"><a href="coefficient-uncertainty-and-distribution.html"><i class="fa fa-check"></i><b>38.5</b> Coefficient Uncertainty and Distribution</a></li>
<li class="chapter" data-level="38.6" data-path="descriptive-tables.html"><a href="descriptive-tables.html"><i class="fa fa-check"></i><b>38.6</b> Descriptive Tables</a></li>
<li class="chapter" data-level="38.7" data-path="visualizations-and-plots.html"><a href="visualizations-and-plots.html"><i class="fa fa-check"></i><b>38.7</b> Visualizations and Plots</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>39</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="40" data-path="sensitivity-analysis-robustness-check.html"><a href="sensitivity-analysis-robustness-check.html"><i class="fa fa-check"></i><b>40</b> Sensitivity Analysis/ Robustness Check</a>
<ul>
<li class="chapter" data-level="40.1" data-path="specification-curve.html"><a href="specification-curve.html"><i class="fa fa-check"></i><b>40.1</b> Specification curve</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="specification-curve.html"><a href="specification-curve.html#starbility"><i class="fa fa-check"></i><b>40.1.1</b> starbility</a></li>
<li class="chapter" data-level="40.1.2" data-path="specification-curve.html"><a href="specification-curve.html#rdfanalysis"><i class="fa fa-check"></i><b>40.1.2</b> rdfanalysis</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="coefficient-stability.html"><a href="coefficient-stability.html"><i class="fa fa-check"></i><b>40.2</b> Coefficient stability</a></li>
<li class="chapter" data-level="40.3" data-path="omitted-variable-bias-quantification.html"><a href="omitted-variable-bias-quantification.html"><i class="fa fa-check"></i><b>40.3</b> Omitted Variable Bias Quantification</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="replication-and-synthetic-data.html"><a href="replication-and-synthetic-data.html"><i class="fa fa-check"></i><b>41</b> Replication and Synthetic Data</a>
<ul>
<li class="chapter" data-level="41.1" data-path="the-replication-standard.html"><a href="the-replication-standard.html"><i class="fa fa-check"></i><b>41.1</b> The Replication Standard</a>
<ul>
<li class="chapter" data-level="41.1.1" data-path="the-replication-standard.html"><a href="the-replication-standard.html#solutions-for-empirical-replication"><i class="fa fa-check"></i><b>41.1.1</b> Solutions for Empirical Replication</a></li>
<li class="chapter" data-level="41.1.2" data-path="the-replication-standard.html"><a href="the-replication-standard.html#free-data-repositories"><i class="fa fa-check"></i><b>41.1.2</b> Free Data Repositories</a></li>
<li class="chapter" data-level="41.1.3" data-path="the-replication-standard.html"><a href="the-replication-standard.html#exceptions-to-replication"><i class="fa fa-check"></i><b>41.1.3</b> Exceptions to Replication</a></li>
</ul></li>
<li class="chapter" data-level="41.2" data-path="synthetic-data-an-overview.html"><a href="synthetic-data-an-overview.html"><i class="fa fa-check"></i><b>41.2</b> Synthetic Data: An Overview</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="synthetic-data-an-overview.html"><a href="synthetic-data-an-overview.html#benefits"><i class="fa fa-check"></i><b>41.2.1</b> Benefits</a></li>
<li class="chapter" data-level="41.2.2" data-path="synthetic-data-an-overview.html"><a href="synthetic-data-an-overview.html#concerns"><i class="fa fa-check"></i><b>41.2.2</b> Concerns</a></li>
<li class="chapter" data-level="41.2.3" data-path="synthetic-data-an-overview.html"><a href="synthetic-data-an-overview.html#further-insights-on-synthetic-data"><i class="fa fa-check"></i><b>41.2.3</b> Further Insights on Synthetic Data</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="application-14.html"><a href="application-14.html"><i class="fa fa-check"></i><b>41.3</b> Application</a></li>
</ul></li>
<li class="appendix"><span><b>APPENDIX</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a>
<ul>
<li class="chapter" data-level="A.1" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>A.1</b> Git</a></li>
<li class="chapter" data-level="A.2" data-path="short-cut.html"><a href="short-cut.html"><i class="fa fa-check"></i><b>A.2</b> Short-cut</a></li>
<li class="chapter" data-level="A.3" data-path="function-short-cut.html"><a href="function-short-cut.html"><i class="fa fa-check"></i><b>A.3</b> Function short-cut</a></li>
<li class="chapter" data-level="A.4" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>A.4</b> Citation</a></li>
<li class="chapter" data-level="A.5" data-path="install-all-necessary-packageslibaries-on-your-local-machine.html"><a href="install-all-necessary-packageslibaries-on-your-local-machine.html"><i class="fa fa-check"></i><b>A.5</b> Install all necessary packages/libaries on your local machine</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bookdown-cheat-sheet.html"><a href="bookdown-cheat-sheet.html"><i class="fa fa-check"></i><b>B</b> Bookdown cheat sheet</a>
<ul>
<li class="chapter" data-level="B.1" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>B.1</b> Operation</a></li>
<li class="chapter" data-level="B.2" data-path="math-expression-syntax.html"><a href="math-expression-syntax.html"><i class="fa fa-check"></i><b>B.2</b> Math Expression/ Syntax</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="math-expression-syntax.html"><a href="math-expression-syntax.html#statistics-notation"><i class="fa fa-check"></i><b>B.2.1</b> Statistics Notation</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="table.html"><a href="table.html"><i class="fa fa-check"></i><b>B.3</b> Table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods-for-handling-missing-data" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Methods for Handling Missing Data<a href="methods-for-handling-missing-data.html#methods-for-handling-missing-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="basic-methods" class="section level3 hasAnchor" number="11.4.1">
<h3><span class="header-section-number">11.4.1</span> Basic Methods<a href="methods-for-handling-missing-data.html#basic-methods" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="complete-case-analysis-listwise-deletion" class="section level4 hasAnchor" number="11.4.1.1">
<h4><span class="header-section-number">11.4.1.1</span> Complete Case Analysis (Listwise Deletion)<a href="methods-for-handling-missing-data.html#complete-case-analysis-listwise-deletion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Listwise deletion retains only cases with complete data for all features, discarding rows with any missing values.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Universally applicable to various statistical tests (e.g., SEM, multilevel regression).</li>
<li>When data are Missing Completely at Random (MCAR), parameter estimates and standard errors are unbiased.</li>
<li>Under specific Missing at Random (MAR) conditions, such as when the probability of missing data depends only on independent variables, listwise deletion can still yield unbiased estimates. For instance, in the model <span class="math inline">\(y = \beta_{0} + \beta_1X_1 + \beta_2X_2 + \epsilon\)</span>, if missingness in <span class="math inline">\(X_1\)</span> is independent of <span class="math inline">\(y\)</span> but depends on <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, the estimates remain unbiased <span class="citation">(<a href="#ref-Little_1992">Little 1992</a>)</span>.
<ul>
<li>This aligns with principles of stratified sampling, which does not bias estimates.</li>
<li>In logistic regression, if missing data depend only on the dependent variable but not on independent variables, listwise deletion produces consistent slope estimates, though the intercept may be biased <span class="citation">(<a href="#ref-Vach_1994">Vach and Vach 1994</a>)</span>.</li>
</ul></li>
<li>For regression analysis, listwise deletion is more robust than Maximum Likelihood (ML) or Multiple Imputation (MI) when the MAR assumption is violated.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Results in larger standard errors compared to advanced methods.</li>
<li>If data are MAR but not MCAR, biased estimates can occur.</li>
<li>In non-regression contexts, more sophisticated methods often outperform listwise deletion.</li>
</ul>
<hr />
</div>
<div id="available-case-analysis-pairwise-deletion" class="section level4 hasAnchor" number="11.4.1.2">
<h4><span class="header-section-number">11.4.1.2</span> Available Case Analysis (Pairwise Deletion)<a href="methods-for-handling-missing-data.html#available-case-analysis-pairwise-deletion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pairwise deletion calculates estimates using all available data for each pair of variables, without requiring complete cases. It is particularly suitable for methods like linear regression, factor analysis, and SEM, which rely on correlation or covariance matrices.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Under MCAR, pairwise deletion produces consistent and unbiased estimates in large samples.</li>
<li>Compared to listwise deletion <span class="citation">(<a href="#ref-Glasser_1964">Glasser 1964</a>)</span>:
<ul>
<li>When variable correlations are low, pairwise deletion provides more efficient estimates.</li>
<li>When correlations are high, listwise deletion becomes more efficient.</li>
</ul></li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Yields biased estimates under MAR conditions.</li>
<li>In small samples, covariance matrices might not be positive definite, rendering coefficient estimation infeasible.</li>
<li>Software implementation varies in how sample size is handled, potentially affecting standard errors.</li>
</ul>
<p><strong>Note</strong>: Carefully review software documentation to understand how sample size is treated, as this influences standard error calculations.</p>
<hr />
</div>
<div id="indicator-method-dummy-variable-adjustment" class="section level4 hasAnchor" number="11.4.1.3">
<h4><span class="header-section-number">11.4.1.3</span> Indicator Method (Dummy Variable Adjustment)<a href="methods-for-handling-missing-data.html#indicator-method-dummy-variable-adjustment" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Also known as the Missing Indicator Method, this approach introduces an additional variable to indicate missingness in the dataset.</p>
<p><strong>Implementation</strong>:</p>
<ol style="list-style-type: decimal">
<li>Create an indicator variable:</li>
</ol>
<p><span class="math display">\[
D =
\begin{cases}
1 &amp; \text{if data on } X \text{ are missing} \\
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Modify the original variable to accommodate missingness:</li>
</ol>
<p><span class="math display">\[
X^* =
\begin{cases}
X &amp; \text{if data are available} \\
c &amp; \text{if data are missing}
\end{cases}
\]</span></p>
<p><strong>Note</strong>: A common choice for <span class="math inline">\(c\)</span> is the mean of <span class="math inline">\(X\)</span>.</p>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>The coefficient of <span class="math inline">\(D\)</span> represents the difference in the expected value of <span class="math inline">\(Y\)</span> between cases with missing data and those without.</li>
<li>The coefficient of <span class="math inline">\(X^*\)</span> reflects the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> for cases with observed data.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Produces biased estimates of coefficients, even under MCAR conditions <span class="citation">(<a href="#ref-jones1996indicator">Jones 1996</a>)</span>.</li>
<li>May lead to overinterpretation of the “missingness effect,” complicating model interpretation.</li>
</ul>
<hr />
</div>
<div id="advantages-and-limitations-of-basic-methods" class="section level4 hasAnchor" number="11.4.1.4">
<h4><span class="header-section-number">11.4.1.4</span> Advantages and Limitations of Basic Methods<a href="methods-for-handling-missing-data.html#advantages-and-limitations-of-basic-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<table>
<colgroup>
<col width="25%" />
<col width="37%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Method</strong></th>
<th><strong>Advantages</strong></th>
<th><strong>Disadvantages</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Listwise Deletion</strong></td>
<td>Simple and universally applicable; unbiased under MCAR; robust in certain MAR scenarios.</td>
<td>Inefficient (larger standard errors); biased under MAR in many cases; discards potentially useful data.</td>
</tr>
<tr class="even">
<td><strong>Pairwise Deletion</strong></td>
<td>Utilizes all available data; efficient under MCAR with low correlations; avoids discarding all cases.</td>
<td>Biased under MAR; prone to non-positive-definite covariance matrices in small samples.</td>
</tr>
<tr class="odd">
<td><strong>Indicator Method</strong></td>
<td>Simple implementation; explicitly models missingness effect.</td>
<td>Biased even under MCAR; complicates interpretation; may not reflect true underlying relationships.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="single-imputation-techniques" class="section level3 hasAnchor" number="11.4.2">
<h3><span class="header-section-number">11.4.2</span> Single Imputation Techniques<a href="methods-for-handling-missing-data.html#single-imputation-techniques" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Single imputation methods replace missing data with a single value, generating a complete dataset that can be analyzed using standard techniques. While convenient, single imputation generally underestimates variability and risks biasing results.</p>
<hr />
<div id="deterministic-methods" class="section level4 hasAnchor" number="11.4.2.1">
<h4><span class="header-section-number">11.4.2.1</span> Deterministic Methods<a href="methods-for-handling-missing-data.html#deterministic-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="mean-median-mode-imputation" class="section level5 hasAnchor" number="11.4.2.1.1">
<h5><span class="header-section-number">11.4.2.1.1</span> Mean, Median, Mode Imputation<a href="methods-for-handling-missing-data.html#mean-median-mode-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>This method replaces missing values with the mean, median, or mode of the observed data.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Simplicity and ease of implementation.</li>
<li>Useful for quick exploratory data analysis.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li><strong>Bias in Variances and Relationships</strong>: Mean imputation reduces variance and disrupts relationships among variables, leading to biased estimates of variances and covariances <span class="citation">(<a href="#ref-haitovsky1968missing">Haitovsky 1968</a>)</span>.</li>
<li><strong>Underestimated Standard Errors</strong>: Results in overly optimistic conclusions and increased risk of Type I errors.</li>
<li><strong>Dependency Structure Ignored</strong>: Particularly problematic in high-dimensional data, as it fails to capture dependencies among features.</li>
</ul>
</div>
<div id="forward-and-backward-filling-time-series-contexts" class="section level5 hasAnchor" number="11.4.2.1.2">
<h5><span class="header-section-number">11.4.2.1.2</span> Forward and Backward Filling (Time Series Contexts)<a href="methods-for-handling-missing-data.html#forward-and-backward-filling-time-series-contexts" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Used in time series analysis, this method replaces missing values using the preceding (forward filling) or succeeding (backward filling) values.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Simple and preserves temporal ordering.</li>
<li>Suitable for datasets where adjacent values are strongly correlated.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Biased if missingness spans long gaps or occurs systematically.</li>
<li>Cannot capture trends or changes in the underlying process.</li>
</ul>
<hr />
</div>
</div>
<div id="statistical-prediction-models" class="section level4 hasAnchor" number="11.4.2.2">
<h4><span class="header-section-number">11.4.2.2</span> Statistical Prediction Models<a href="methods-for-handling-missing-data.html#statistical-prediction-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="linear-regression-imputation" class="section level5 hasAnchor" number="11.4.2.2.1">
<h5><span class="header-section-number">11.4.2.2.1</span> Linear Regression Imputation<a href="methods-for-handling-missing-data.html#linear-regression-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Missing values in a variable are imputed based on a linear regression model using observed values of other variables.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Preserves relationships between variables.</li>
<li>More sophisticated than mean or median imputation.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Assumes linear relationships, which may not hold in all datasets.</li>
<li>Fails to capture variability, leading to downwardly biased standard errors.</li>
</ul>
</div>
<div id="logistic-regression-for-categorical-variables" class="section level5 hasAnchor" number="11.4.2.2.2">
<h5><span class="header-section-number">11.4.2.2.2</span> Logistic Regression for Categorical Variables<a href="methods-for-handling-missing-data.html#logistic-regression-for-categorical-variables" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Similar to linear regression imputation but used for categorical variables. The missing category is predicted using a logistic regression model.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li>Useful for binary or multinomial categorical data.</li>
<li>Preserves relationships with other variables.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Assumes the underlying logistic model is appropriate.</li>
<li>Does not account for uncertainty in the imputed values.</li>
</ul>
<hr />
</div>
</div>
<div id="non-parametric-methods" class="section level4 hasAnchor" number="11.4.2.3">
<h4><span class="header-section-number">11.4.2.3</span> Non-Parametric Methods<a href="methods-for-handling-missing-data.html#non-parametric-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="hot-deck-imputation" class="section level5 hasAnchor" number="11.4.2.3.1">
<h5><span class="header-section-number">11.4.2.3.1</span> Hot Deck Imputation<a href="methods-for-handling-missing-data.html#hot-deck-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Hot Deck Imputation is a method of handling missing data where missing values are replaced with observed values from “donor” cases that are similar in other characteristics. This technique has been widely used in survey data, including by organizations like the U.S. Census Bureau, due to its flexibility and ability to maintain observed data distributions.</p>
<p><strong>Advantages of Hot Deck Imputation</strong></p>
<ul>
<li><strong>Retains observed data distributions</strong>: Since missing values are imputed using actual observed data, the overall distribution remains realistic.</li>
<li><strong>Flexible</strong>: This method is applicable to both categorical and continuous variables.</li>
<li><strong>Constrained imputations</strong>: Imputed values are always feasible, as they come from observed cases.</li>
<li><strong>Adds variability</strong>: By randomly selecting donors, this method introduces variability, which can aid in robust standard error estimation.</li>
</ul>
<p><strong>Disadvantages of Hot Deck Imputation</strong></p>
<ul>
<li><strong>Sensitivity to similarity definitions</strong>: The quality of imputed values depends on the criteria used to define similarity between cases.</li>
<li><strong>Computational intensity</strong>: Identifying similar cases and randomly selecting donors can be computationally expensive, especially for large datasets.</li>
<li><strong>Subjectivity</strong>: Deciding how to define “similar” can introduce subjectivity or bias.</li>
</ul>
<p><strong>Algorithm for Hot Deck Imputation</strong></p>
<p>Let <span class="math inline">\(n_1\)</span> represent the number of cases with complete data on the variable <span class="math inline">\(Y\)</span>, and <span class="math inline">\(n_0\)</span> represent the number of cases with missing data on <span class="math inline">\(Y\)</span>. The steps are as follows:</p>
<ol style="list-style-type: decimal">
<li>From the <span class="math inline">\(n_1\)</span> cases with complete data, take a random sample (with replacement) of <span class="math inline">\(n_1\)</span> cases.</li>
<li>From this sampled pool, take another random sample (with replacement) of size <span class="math inline">\(n_0\)</span>.</li>
<li>Assign the values from the sampled <span class="math inline">\(n_0\)</span> cases to the cases with missing data in <span class="math inline">\(Y\)</span>.</li>
<li>Repeat this process for every variable in the dataset.</li>
<li>For multiple imputation, repeat the above four steps multiple times to create multiple imputed datasets.</li>
</ol>
<p><strong>Variations and Considerations</strong></p>
<ul>
<li><strong>Skipping Step 1</strong>: If Step 1 is skipped, the variability of imputed values is reduced. This approach might not fully account for the uncertainty in missing data, which can underestimate standard errors.</li>
<li><strong>Defining similarity</strong>: A major challenge in this method is deciding what constitutes “similarity” between cases. Common approaches include matching based on distance metrics (e.g., Euclidean distance) or grouping cases by strata or clusters.</li>
</ul>
<p><strong>Practical Example</strong></p>
<p>The U.S. Census Bureau employs an approximate Bayesian bootstrap variation of Hot Deck Imputation. In this approach:</p>
<ul>
<li><p>Similar cases are identified based on shared characteristics or grouping variables.</p></li>
<li><p>A randomly chosen value from a similar individual in the sample is used to replace the missing value.</p></li>
</ul>
<p>This method ensures imputed values are plausible while incorporating variability.</p>
<p><strong>Key Notes</strong></p>
<ul>
<li><strong>Good aspects</strong>:
<ul>
<li>Imputed values are constrained to observed possibilities.</li>
<li>Random selection introduces variability, helpful for multiple imputation scenarios.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>Defining and operationalizing “similarity” remains a critical step in applying this method effectively.</li>
</ul></li>
</ul>
<p>Below is an example code snippet illustrating Hot Deck Imputation in R:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="methods-for-handling-missing-data.html#cb348-1" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb348-2"><a href="methods-for-handling-missing-data.html#cb348-2" tabindex="-1"></a></span>
<span id="cb348-3"><a href="methods-for-handling-missing-data.html#cb348-3" tabindex="-1"></a><span class="co"># Example dataset with missing values</span></span>
<span id="cb348-4"><a href="methods-for-handling-missing-data.html#cb348-4" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb348-5"><a href="methods-for-handling-missing-data.html#cb348-5" tabindex="-1"></a>  <span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb348-6"><a href="methods-for-handling-missing-data.html#cb348-6" tabindex="-1"></a>  <span class="at">Age =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">30</span>, <span class="cn">NA</span>, <span class="dv">40</span>, <span class="cn">NA</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="cn">NA</span>, <span class="dv">70</span>, <span class="dv">80</span>),</span>
<span id="cb348-7"><a href="methods-for-handling-missing-data.html#cb348-7" tabindex="-1"></a>  <span class="at">Gender =</span> <span class="fu">c</span>(<span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>)</span>
<span id="cb348-8"><a href="methods-for-handling-missing-data.html#cb348-8" tabindex="-1"></a>)</span>
<span id="cb348-9"><a href="methods-for-handling-missing-data.html#cb348-9" tabindex="-1"></a></span>
<span id="cb348-10"><a href="methods-for-handling-missing-data.html#cb348-10" tabindex="-1"></a><span class="co"># Perform Hot Deck Imputation using Hmisc::impute</span></span>
<span id="cb348-11"><a href="methods-for-handling-missing-data.html#cb348-11" tabindex="-1"></a>data<span class="sc">$</span>Age_imputed <span class="ot">&lt;-</span> <span class="fu">impute</span>(data<span class="sc">$</span>Age, <span class="st">&quot;random&quot;</span>)</span>
<span id="cb348-12"><a href="methods-for-handling-missing-data.html#cb348-12" tabindex="-1"></a></span>
<span id="cb348-13"><a href="methods-for-handling-missing-data.html#cb348-13" tabindex="-1"></a><span class="co"># Display the imputed dataset</span></span>
<span id="cb348-14"><a href="methods-for-handling-missing-data.html#cb348-14" tabindex="-1"></a><span class="fu">print</span>(data)</span>
<span id="cb348-15"><a href="methods-for-handling-missing-data.html#cb348-15" tabindex="-1"></a><span class="co">#&gt;    ID Age Gender Age_imputed</span></span>
<span id="cb348-16"><a href="methods-for-handling-missing-data.html#cb348-16" tabindex="-1"></a><span class="co">#&gt; 1   1  25      M          25</span></span>
<span id="cb348-17"><a href="methods-for-handling-missing-data.html#cb348-17" tabindex="-1"></a><span class="co">#&gt; 2   2  30      F          30</span></span>
<span id="cb348-18"><a href="methods-for-handling-missing-data.html#cb348-18" tabindex="-1"></a><span class="co">#&gt; 3   3  NA      F          25</span></span>
<span id="cb348-19"><a href="methods-for-handling-missing-data.html#cb348-19" tabindex="-1"></a><span class="co">#&gt; 4   4  40      M          40</span></span>
<span id="cb348-20"><a href="methods-for-handling-missing-data.html#cb348-20" tabindex="-1"></a><span class="co">#&gt; 5   5  NA      M          70</span></span>
<span id="cb348-21"><a href="methods-for-handling-missing-data.html#cb348-21" tabindex="-1"></a><span class="co">#&gt; 6   6  50      F          50</span></span>
<span id="cb348-22"><a href="methods-for-handling-missing-data.html#cb348-22" tabindex="-1"></a><span class="co">#&gt; 7   7  60      M          60</span></span>
<span id="cb348-23"><a href="methods-for-handling-missing-data.html#cb348-23" tabindex="-1"></a><span class="co">#&gt; 8   8  NA      F          25</span></span>
<span id="cb348-24"><a href="methods-for-handling-missing-data.html#cb348-24" tabindex="-1"></a><span class="co">#&gt; 9   9  70      M          70</span></span>
<span id="cb348-25"><a href="methods-for-handling-missing-data.html#cb348-25" tabindex="-1"></a><span class="co">#&gt; 10 10  80      F          80</span></span></code></pre></div>
<p>This code randomly imputes missing values in the <code>Age</code> column based on observed data using the <code>Hmisc</code> package’s <code>impute</code> function.</p>
</div>
<div id="cold-deck-imputation" class="section level5 hasAnchor" number="11.4.2.3.2">
<h5><span class="header-section-number">11.4.2.3.2</span> Cold Deck Imputation<a href="methods-for-handling-missing-data.html#cold-deck-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Cold Deck Imputation is a systematic variant of Hot Deck Imputation where the donor pool is predefined. Instead of selecting donors dynamically from within the same dataset, Cold Deck Imputation relies on an external reference dataset, such as historical data or other high-quality external sources.</p>
<p><strong>Advantages of Cold Deck Imputation</strong></p>
<ul>
<li><strong>Utilizes high-quality external data</strong>: This method is particularly useful when reliable external reference datasets are available, allowing for accurate and consistent imputations.</li>
<li><strong>Consistency</strong>: If the same donor pool is used across multiple datasets, imputations remain consistent, which can be advantageous in longitudinal studies or standardized processes.</li>
</ul>
<p><strong>Disadvantages of Cold Deck Imputation</strong></p>
<ul>
<li><strong>Lack of adaptability</strong>: External data may not adequately reflect the unique characteristics or variability of the current dataset.</li>
<li><strong>Potential for systematic bias</strong>: If the donor pool is significantly different from the target dataset, imputations may introduce bias.</li>
<li><strong>Reduces variability</strong>: Unlike Hot Deck Imputation, Cold Deck Imputation systematically selects values, which removes random variation. This can affect the estimation of standard errors and other inferential statistics.</li>
</ul>
<p><strong>Key Characteristics</strong></p>
<ul>
<li><strong>Systematic Selection</strong>: Cold Deck Imputation selects donor values systematically based on predefined rules or matching criteria, rather than using random sampling.</li>
<li><strong>External Donor Pool</strong>: Donors are typically drawn from a separate dataset or historical records.</li>
</ul>
<p><strong>Algorithm for Cold Deck Imputation</strong></p>
<ol style="list-style-type: decimal">
<li>Identify an external reference dataset or predefined donor pool.</li>
<li>Define the matching criteria to find “similar” cases between the donor pool and the current dataset (e.g., based on covariates or stratification).</li>
<li>Systematically assign values from the donor pool to missing values in the current dataset based on the matching criteria.</li>
<li>Repeat the process for each variable with missing data.</li>
</ol>
<p><strong>Practical Considerations</strong></p>
<ul>
<li>Cold Deck Imputation works well when external data closely resemble the target dataset. However, when there are significant differences in distributions or relationships between variables, imputations may be biased or unrealistic.<br />
</li>
<li>This method is less useful for datasets without access to reliable external reference data.</li>
</ul>
<p>Suppose we have a current dataset with missing values and a historical dataset with similar variables. The following example demonstrates how Cold Deck Imputation can be implemented:</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="methods-for-handling-missing-data.html#cb349-1" tabindex="-1"></a><span class="co"># Current dataset with missing values</span></span>
<span id="cb349-2"><a href="methods-for-handling-missing-data.html#cb349-2" tabindex="-1"></a>current_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb349-3"><a href="methods-for-handling-missing-data.html#cb349-3" tabindex="-1"></a>  <span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb349-4"><a href="methods-for-handling-missing-data.html#cb349-4" tabindex="-1"></a>  <span class="at">Age =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">30</span>, <span class="cn">NA</span>, <span class="dv">45</span>, <span class="cn">NA</span>),</span>
<span id="cb349-5"><a href="methods-for-handling-missing-data.html#cb349-5" tabindex="-1"></a>  <span class="at">Gender =</span> <span class="fu">c</span>(<span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;M&quot;</span>)</span>
<span id="cb349-6"><a href="methods-for-handling-missing-data.html#cb349-6" tabindex="-1"></a>)</span>
<span id="cb349-7"><a href="methods-for-handling-missing-data.html#cb349-7" tabindex="-1"></a></span>
<span id="cb349-8"><a href="methods-for-handling-missing-data.html#cb349-8" tabindex="-1"></a><span class="co"># External reference dataset (donor pool)</span></span>
<span id="cb349-9"><a href="methods-for-handling-missing-data.html#cb349-9" tabindex="-1"></a>reference_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb349-10"><a href="methods-for-handling-missing-data.html#cb349-10" tabindex="-1"></a>  <span class="at">Age =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">35</span>, <span class="dv">42</span>, <span class="dv">50</span>),</span>
<span id="cb349-11"><a href="methods-for-handling-missing-data.html#cb349-11" tabindex="-1"></a>  <span class="at">Gender =</span> <span class="fu">c</span>(<span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;M&quot;</span>)</span>
<span id="cb349-12"><a href="methods-for-handling-missing-data.html#cb349-12" tabindex="-1"></a>)</span>
<span id="cb349-13"><a href="methods-for-handling-missing-data.html#cb349-13" tabindex="-1"></a></span>
<span id="cb349-14"><a href="methods-for-handling-missing-data.html#cb349-14" tabindex="-1"></a><span class="co"># Perform Cold Deck Imputation</span></span>
<span id="cb349-15"><a href="methods-for-handling-missing-data.html#cb349-15" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb349-16"><a href="methods-for-handling-missing-data.html#cb349-16" tabindex="-1"></a></span>
<span id="cb349-17"><a href="methods-for-handling-missing-data.html#cb349-17" tabindex="-1"></a><span class="co"># Define a matching function to find closest donor</span></span>
<span id="cb349-18"><a href="methods-for-handling-missing-data.html#cb349-18" tabindex="-1"></a>impute_cold_deck <span class="ot">&lt;-</span> <span class="cf">function</span>(missing_row, reference_data) {</span>
<span id="cb349-19"><a href="methods-for-handling-missing-data.html#cb349-19" tabindex="-1"></a>  <span class="co"># Filter donors with the same gender</span></span>
<span id="cb349-20"><a href="methods-for-handling-missing-data.html#cb349-20" tabindex="-1"></a>  possible_donors <span class="ot">&lt;-</span> reference_data <span class="sc">%&gt;%</span></span>
<span id="cb349-21"><a href="methods-for-handling-missing-data.html#cb349-21" tabindex="-1"></a>    <span class="fu">filter</span>(Gender <span class="sc">==</span> missing_row<span class="sc">$</span>Gender)</span>
<span id="cb349-22"><a href="methods-for-handling-missing-data.html#cb349-22" tabindex="-1"></a>  </span>
<span id="cb349-23"><a href="methods-for-handling-missing-data.html#cb349-23" tabindex="-1"></a>  <span class="co"># Return the mean age of matching donors as an example of systematic imputation</span></span>
<span id="cb349-24"><a href="methods-for-handling-missing-data.html#cb349-24" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(possible_donors<span class="sc">$</span>Age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb349-25"><a href="methods-for-handling-missing-data.html#cb349-25" tabindex="-1"></a>}</span>
<span id="cb349-26"><a href="methods-for-handling-missing-data.html#cb349-26" tabindex="-1"></a></span>
<span id="cb349-27"><a href="methods-for-handling-missing-data.html#cb349-27" tabindex="-1"></a><span class="co"># Apply Cold Deck Imputation to the missing rows</span></span>
<span id="cb349-28"><a href="methods-for-handling-missing-data.html#cb349-28" tabindex="-1"></a>current_data <span class="ot">&lt;-</span> current_data <span class="sc">%&gt;%</span></span>
<span id="cb349-29"><a href="methods-for-handling-missing-data.html#cb349-29" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span></span>
<span id="cb349-30"><a href="methods-for-handling-missing-data.html#cb349-30" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb349-31"><a href="methods-for-handling-missing-data.html#cb349-31" tabindex="-1"></a>    <span class="at">Age_imputed =</span> <span class="fu">ifelse</span>(</span>
<span id="cb349-32"><a href="methods-for-handling-missing-data.html#cb349-32" tabindex="-1"></a>      <span class="fu">is.na</span>(Age),</span>
<span id="cb349-33"><a href="methods-for-handling-missing-data.html#cb349-33" tabindex="-1"></a>      <span class="fu">impute_cold_deck</span>(<span class="fu">cur_data</span>(), reference_data),</span>
<span id="cb349-34"><a href="methods-for-handling-missing-data.html#cb349-34" tabindex="-1"></a>      Age</span>
<span id="cb349-35"><a href="methods-for-handling-missing-data.html#cb349-35" tabindex="-1"></a>    )</span>
<span id="cb349-36"><a href="methods-for-handling-missing-data.html#cb349-36" tabindex="-1"></a>  )</span>
<span id="cb349-37"><a href="methods-for-handling-missing-data.html#cb349-37" tabindex="-1"></a></span>
<span id="cb349-38"><a href="methods-for-handling-missing-data.html#cb349-38" tabindex="-1"></a><span class="co"># Display the imputed dataset</span></span>
<span id="cb349-39"><a href="methods-for-handling-missing-data.html#cb349-39" tabindex="-1"></a><span class="fu">print</span>(current_data)</span>
<span id="cb349-40"><a href="methods-for-handling-missing-data.html#cb349-40" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 × 4</span></span>
<span id="cb349-41"><a href="methods-for-handling-missing-data.html#cb349-41" tabindex="-1"></a><span class="co">#&gt; # Rowwise: </span></span>
<span id="cb349-42"><a href="methods-for-handling-missing-data.html#cb349-42" tabindex="-1"></a><span class="co">#&gt;      ID   Age Gender Age_imputed</span></span>
<span id="cb349-43"><a href="methods-for-handling-missing-data.html#cb349-43" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;</span></span>
<span id="cb349-44"><a href="methods-for-handling-missing-data.html#cb349-44" tabindex="-1"></a><span class="co">#&gt; 1     1    25 M             25  </span></span>
<span id="cb349-45"><a href="methods-for-handling-missing-data.html#cb349-45" tabindex="-1"></a><span class="co">#&gt; 2     2    30 F             30  </span></span>
<span id="cb349-46"><a href="methods-for-handling-missing-data.html#cb349-46" tabindex="-1"></a><span class="co">#&gt; 3     3    NA F             38.8</span></span>
<span id="cb349-47"><a href="methods-for-handling-missing-data.html#cb349-47" tabindex="-1"></a><span class="co">#&gt; 4     4    45 M             45  </span></span>
<span id="cb349-48"><a href="methods-for-handling-missing-data.html#cb349-48" tabindex="-1"></a><span class="co">#&gt; 5     5    NA M             38.8</span></span></code></pre></div>
<p><strong>Comparison to Hot Deck Imputation</strong></p>
<table>
<colgroup>
<col width="25%" />
<col width="37%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Hot Deck Imputation</th>
<th>Cold Deck Imputation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Donor Pool</strong></td>
<td>Internal (within the dataset)</td>
<td>External (predefined dataset)</td>
</tr>
<tr class="even">
<td><strong>Selection</strong></td>
<td>Random</td>
<td>Systematic</td>
</tr>
<tr class="odd">
<td><strong>Variability</strong></td>
<td>Retained</td>
<td>Reduced</td>
</tr>
<tr class="even">
<td><strong>Bias Potential</strong></td>
<td>Lower</td>
<td>Higher (if donor pool differs)</td>
</tr>
</tbody>
</table>
<p>This method suits situations where external reference datasets are trusted and representative. However, careful consideration is required to ensure alignment between the donor pool and the target dataset to avoid systematic biases.</p>
</div>
<div id="random-draw-from-observed-distribution" class="section level5 hasAnchor" number="11.4.2.3.3">
<h5><span class="header-section-number">11.4.2.3.3</span> Random Draw from Observed Distribution<a href="methods-for-handling-missing-data.html#random-draw-from-observed-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>This imputation method replaces missing values by randomly sampling from the observed distribution of the variable with missing data. It is a simple, non-parametric approach that retains the variability of the original data.</p>
<p><strong>Advantages</strong></p>
<ul>
<li><strong>Preserves variability</strong>:
<ul>
<li>By randomly drawing values from the observed data, this method ensures that the imputed values reflect the inherent variability of the variable.</li>
</ul></li>
<li><strong>Computational simplicity</strong>:
<ul>
<li>The process is straightforward and does not require model fitting or complex calculations.</li>
</ul></li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
<li><strong>Ignores relationships among variables</strong>:
<ul>
<li>Since the imputation is based solely on the observed distribution of the variable, it does not consider relationships or dependencies with other variables.</li>
</ul></li>
<li><strong>May not align with trends</strong>:
<ul>
<li>Imputed values are random and may fail to align with patterns or trends present in the data, such as time series structures or interactions.</li>
</ul></li>
</ul>
<p><strong>Steps in Random Draw Imputation</strong></p>
<ol style="list-style-type: decimal">
<li>Identify the observed (non-missing) values of the variable.</li>
<li>For each missing value, randomly sample one value from the observed distribution with or without replacement.</li>
<li>Replace the missing value with the randomly sampled value.</li>
</ol>
<p>The following example demonstrates how to use random draw imputation to fill in missing values:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="methods-for-handling-missing-data.html#cb350-1" tabindex="-1"></a><span class="co"># Example dataset with missing values</span></span>
<span id="cb350-2"><a href="methods-for-handling-missing-data.html#cb350-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb350-3"><a href="methods-for-handling-missing-data.html#cb350-3" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb350-4"><a href="methods-for-handling-missing-data.html#cb350-4" tabindex="-1"></a>  <span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb350-5"><a href="methods-for-handling-missing-data.html#cb350-5" tabindex="-1"></a>  <span class="at">Value =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">20</span>, <span class="cn">NA</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="cn">NA</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="cn">NA</span>, <span class="dv">70</span>)</span>
<span id="cb350-6"><a href="methods-for-handling-missing-data.html#cb350-6" tabindex="-1"></a>)</span>
<span id="cb350-7"><a href="methods-for-handling-missing-data.html#cb350-7" tabindex="-1"></a></span>
<span id="cb350-8"><a href="methods-for-handling-missing-data.html#cb350-8" tabindex="-1"></a><span class="co"># Perform random draw imputation</span></span>
<span id="cb350-9"><a href="methods-for-handling-missing-data.html#cb350-9" tabindex="-1"></a>random_draw_impute <span class="ot">&lt;-</span> <span class="cf">function</span>(data, variable) {</span>
<span id="cb350-10"><a href="methods-for-handling-missing-data.html#cb350-10" tabindex="-1"></a>  observed_values <span class="ot">&lt;-</span> data[[variable]][<span class="sc">!</span><span class="fu">is.na</span>(data[[variable]])] <span class="co"># Observed values</span></span>
<span id="cb350-11"><a href="methods-for-handling-missing-data.html#cb350-11" tabindex="-1"></a>  data[[variable]][<span class="fu">is.na</span>(data[[variable]])] <span class="ot">&lt;-</span> <span class="fu">sample</span>(observed_values, </span>
<span id="cb350-12"><a href="methods-for-handling-missing-data.html#cb350-12" tabindex="-1"></a>                                                      <span class="fu">sum</span>(<span class="fu">is.na</span>(data[[variable]])), </span>
<span id="cb350-13"><a href="methods-for-handling-missing-data.html#cb350-13" tabindex="-1"></a>                                                      <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb350-14"><a href="methods-for-handling-missing-data.html#cb350-14" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb350-15"><a href="methods-for-handling-missing-data.html#cb350-15" tabindex="-1"></a>}</span>
<span id="cb350-16"><a href="methods-for-handling-missing-data.html#cb350-16" tabindex="-1"></a></span>
<span id="cb350-17"><a href="methods-for-handling-missing-data.html#cb350-17" tabindex="-1"></a><span class="co"># Apply the imputation</span></span>
<span id="cb350-18"><a href="methods-for-handling-missing-data.html#cb350-18" tabindex="-1"></a>imputed_data <span class="ot">&lt;-</span> <span class="fu">random_draw_impute</span>(data, <span class="at">variable =</span> <span class="st">&quot;Value&quot;</span>)</span>
<span id="cb350-19"><a href="methods-for-handling-missing-data.html#cb350-19" tabindex="-1"></a></span>
<span id="cb350-20"><a href="methods-for-handling-missing-data.html#cb350-20" tabindex="-1"></a><span class="co"># Display the imputed dataset</span></span>
<span id="cb350-21"><a href="methods-for-handling-missing-data.html#cb350-21" tabindex="-1"></a><span class="fu">print</span>(imputed_data)</span>
<span id="cb350-22"><a href="methods-for-handling-missing-data.html#cb350-22" tabindex="-1"></a><span class="co">#&gt;    ID Value</span></span>
<span id="cb350-23"><a href="methods-for-handling-missing-data.html#cb350-23" tabindex="-1"></a><span class="co">#&gt; 1   1    10</span></span>
<span id="cb350-24"><a href="methods-for-handling-missing-data.html#cb350-24" tabindex="-1"></a><span class="co">#&gt; 2   2    20</span></span>
<span id="cb350-25"><a href="methods-for-handling-missing-data.html#cb350-25" tabindex="-1"></a><span class="co">#&gt; 3   3    70</span></span>
<span id="cb350-26"><a href="methods-for-handling-missing-data.html#cb350-26" tabindex="-1"></a><span class="co">#&gt; 4   4    30</span></span>
<span id="cb350-27"><a href="methods-for-handling-missing-data.html#cb350-27" tabindex="-1"></a><span class="co">#&gt; 5   5    40</span></span>
<span id="cb350-28"><a href="methods-for-handling-missing-data.html#cb350-28" tabindex="-1"></a><span class="co">#&gt; 6   6    70</span></span>
<span id="cb350-29"><a href="methods-for-handling-missing-data.html#cb350-29" tabindex="-1"></a><span class="co">#&gt; 7   7    50</span></span>
<span id="cb350-30"><a href="methods-for-handling-missing-data.html#cb350-30" tabindex="-1"></a><span class="co">#&gt; 8   8    60</span></span>
<span id="cb350-31"><a href="methods-for-handling-missing-data.html#cb350-31" tabindex="-1"></a><span class="co">#&gt; 9   9    30</span></span>
<span id="cb350-32"><a href="methods-for-handling-missing-data.html#cb350-32" tabindex="-1"></a><span class="co">#&gt; 10 10    70</span></span></code></pre></div>
<p><strong>Considerations</strong></p>
<ul>
<li><p><strong>When to Use</strong>:</p>
<ul>
<li>This method is suitable for exploratory analysis or as a quick way to handle missing data in univariate contexts.</li>
</ul></li>
<li><p><strong>Limitations</strong>:</p>
<ul>
<li>Random draws may result in values that do not fit well in the broader context of the dataset, especially in cases where the variable has strong relationships with others.</li>
</ul></li>
</ul>
<table>
<colgroup>
<col width="30%" />
<col width="38%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Random Draw from Observed Distribution</th>
<th>Regression-Based Imputation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Complexity</strong></td>
<td>Simple</td>
<td>Moderate to High</td>
</tr>
<tr class="even">
<td><strong>Preserves Variability</strong></td>
<td>Yes</td>
<td>Limited in deterministic forms</td>
</tr>
<tr class="odd">
<td><strong>Considers Relationships</strong></td>
<td>No</td>
<td>Yes</td>
</tr>
<tr class="even">
<td><strong>Risk of Implausible Values</strong></td>
<td>Low (if observed values are plausible)</td>
<td>Moderate to High</td>
</tr>
</tbody>
</table>
<p>This method is a quick and computationally efficient way to address missing data but is best complemented by more sophisticated methods when relationships between variables are important.</p>
</div>
</div>
<div id="semi-parametric-methods" class="section level4 hasAnchor" number="11.4.2.4">
<h4><span class="header-section-number">11.4.2.4</span> Semi-Parametric Methods<a href="methods-for-handling-missing-data.html#semi-parametric-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="predictive-mean-matching-pmm" class="section level5 hasAnchor" number="11.4.2.4.1">
<h5><span class="header-section-number">11.4.2.4.1</span> Predictive Mean Matching (PMM)<a href="methods-for-handling-missing-data.html#predictive-mean-matching-pmm" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Predictive Mean Matching (PMM) imputes missing values by finding observed values closest in predicted value (based on a regression model) to the missing data. The donor values are then used to fill in the gaps.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li><p>Maintains observed variability in the data.</p></li>
<li><p>Ensures imputed values are realistic since they are drawn from observed data.</p></li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li><p>Requires a suitable predictive model.</p></li>
<li><p>Computationally intensive for large datasets.</p></li>
</ul>
<p><strong>Steps for PMM</strong>:</p>
<ol style="list-style-type: decimal">
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> (matrix of covariates) for the <span class="math inline">\(n_1\)</span> (non-missing cases) to estimate coefficients <span class="math inline">\(\hat{b}\)</span> and residual variance <span class="math inline">\(s^2\)</span>.</li>
<li>Draw from the posterior predictive distribution of residual variance: <span class="math display">\[s^2_{[1]} = \frac{(n_1-k)s^2}{\chi^2},\]</span> where <span class="math inline">\(\chi^2\)</span> is a random draw from <span class="math inline">\(\chi^2_{n_1-k}\)</span>.</li>
<li>Randomly sample from the posterior distribution of <span class="math inline">\(\hat{b}\)</span>: <span class="math display">\[b_{[1]} \sim MVN(\hat{b}, s^2_{[1]}(X&#39;X)^{-1}).\]</span></li>
<li>Standardize residuals for <span class="math inline">\(n_1\)</span> cases: <span class="math display">\[e_i = \frac{y_i - \hat{b}x_i}{\sqrt{s^2(1-k/n_1)}}.\]</span></li>
<li>Randomly draw a sample (with replacement) of <span class="math inline">\(n_0\)</span> residuals from Step 4.</li>
<li>Calculate imputed values for <span class="math inline">\(n_0\)</span> missing cases: <span class="math display">\[y_i = b_{[1]}x_i + s_{[1]}e_i.\]</span></li>
<li>Repeat Steps 2–6 (except Step 4) to create multiple imputations.</li>
</ol>
<p><strong>Notes</strong>:</p>
<ul>
<li><p>PMM can handle heteroskedasticity</p></li>
<li><p>works for multiple variables, imputing each using all others as predictors.</p></li>
</ul>
<p><strong>Example</strong>:</p>
<p>Example from <a href="https://statisticsglobe.com/predictive-mean-matching-imputation-method/">Statistics Globe</a></p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="methods-for-handling-missing-data.html#cb351-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>) <span class="co"># Seed</span></span>
<span id="cb351-2"><a href="methods-for-handling-missing-data.html#cb351-2" tabindex="-1"></a>N  <span class="ot">&lt;-</span> <span class="dv">100</span>                                    <span class="co"># Sample size</span></span>
<span id="cb351-3"><a href="methods-for-handling-missing-data.html#cb351-3" tabindex="-1"></a>y  <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">runif</span>(N,<span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>))                 <span class="co"># Target variable Y</span></span>
<span id="cb351-4"><a href="methods-for-handling-missing-data.html#cb351-4" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> y <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">runif</span>(N, <span class="dv">0</span>, <span class="dv">50</span>))              <span class="co"># Auxiliary variable 1</span></span>
<span id="cb351-5"><a href="methods-for-handling-missing-data.html#cb351-5" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">round</span>(y <span class="sc">+</span> <span class="fl">0.25</span> <span class="sc">*</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="sc">-</span><span class="dv">3</span>, <span class="dv">15</span>))  <span class="co"># Auxiliary variable 2</span></span>
<span id="cb351-6"><a href="methods-for-handling-missing-data.html#cb351-6" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fl">0.1</span> <span class="sc">*</span> x1 <span class="sc">+</span> <span class="fu">rpois</span>(N, <span class="dv">2</span>))           <span class="co"># Auxiliary variable 3</span></span>
<span id="cb351-7"><a href="methods-for-handling-missing-data.html#cb351-7" tabindex="-1"></a><span class="co"># (categorical variable)</span></span>
<span id="cb351-8"><a href="methods-for-handling-missing-data.html#cb351-8" tabindex="-1"></a>x4 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">round</span>(<span class="fl">0.02</span> <span class="sc">*</span> y <span class="sc">+</span> <span class="fu">runif</span>(N)))   <span class="co"># Auxiliary variable 4 </span></span>
<span id="cb351-9"><a href="methods-for-handling-missing-data.html#cb351-9" tabindex="-1"></a></span>
<span id="cb351-10"><a href="methods-for-handling-missing-data.html#cb351-10" tabindex="-1"></a><span class="co"># Insert 20% missing data in Y</span></span>
<span id="cb351-11"><a href="methods-for-handling-missing-data.html#cb351-11" tabindex="-1"></a>y[<span class="fu">rbinom</span>(N, <span class="dv">1</span>, <span class="fl">0.2</span>) <span class="sc">==</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span>               </span>
<span id="cb351-12"><a href="methods-for-handling-missing-data.html#cb351-12" tabindex="-1"></a></span>
<span id="cb351-13"><a href="methods-for-handling-missing-data.html#cb351-13" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x1, x2, x3, x4)         <span class="co"># Store data in dataset</span></span>
<span id="cb351-14"><a href="methods-for-handling-missing-data.html#cb351-14" tabindex="-1"></a><span class="fu">head</span>(data) <span class="co"># First 6 rows of our data</span></span>
<span id="cb351-15"><a href="methods-for-handling-missing-data.html#cb351-15" tabindex="-1"></a><span class="co">#&gt;    y x1  x2 x3 x4</span></span>
<span id="cb351-16"><a href="methods-for-handling-missing-data.html#cb351-16" tabindex="-1"></a><span class="co">#&gt; 1 NA 28 -10  5  0</span></span>
<span id="cb351-17"><a href="methods-for-handling-missing-data.html#cb351-17" tabindex="-1"></a><span class="co">#&gt; 2 NA 15  -2  2  1</span></span>
<span id="cb351-18"><a href="methods-for-handling-missing-data.html#cb351-18" tabindex="-1"></a><span class="co">#&gt; 3  1 15 -12  6  1</span></span>
<span id="cb351-19"><a href="methods-for-handling-missing-data.html#cb351-19" tabindex="-1"></a><span class="co">#&gt; 4  8 58  22 10  1</span></span>
<span id="cb351-20"><a href="methods-for-handling-missing-data.html#cb351-20" tabindex="-1"></a><span class="co">#&gt; 5 NA 26 -12  7  0</span></span>
<span id="cb351-21"><a href="methods-for-handling-missing-data.html#cb351-21" tabindex="-1"></a><span class="co">#&gt; 6 NA 19  36  5  1</span></span>
<span id="cb351-22"><a href="methods-for-handling-missing-data.html#cb351-22" tabindex="-1"></a></span>
<span id="cb351-23"><a href="methods-for-handling-missing-data.html#cb351-23" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mice&quot;</span>) <span class="co"># Load mice package</span></span>
<span id="cb351-24"><a href="methods-for-handling-missing-data.html#cb351-24" tabindex="-1"></a></span>
<span id="cb351-25"><a href="methods-for-handling-missing-data.html#cb351-25" tabindex="-1"></a><span class="do">##### Impute data via predictive mean matching (single imputation)#####</span></span>
<span id="cb351-26"><a href="methods-for-handling-missing-data.html#cb351-26" tabindex="-1"></a></span>
<span id="cb351-27"><a href="methods-for-handling-missing-data.html#cb351-27" tabindex="-1"></a>imp_single <span class="ot">&lt;-</span> <span class="fu">mice</span>(data, <span class="at">m =</span> <span class="dv">1</span>, <span class="at">method =</span> <span class="st">&quot;pmm&quot;</span>) <span class="co"># Impute missing values</span></span>
<span id="cb351-28"><a href="methods-for-handling-missing-data.html#cb351-28" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb351-29"><a href="methods-for-handling-missing-data.html#cb351-29" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb351-30"><a href="methods-for-handling-missing-data.html#cb351-30" tabindex="-1"></a><span class="co">#&gt;   1   1  y</span></span>
<span id="cb351-31"><a href="methods-for-handling-missing-data.html#cb351-31" tabindex="-1"></a><span class="co">#&gt;   2   1  y</span></span>
<span id="cb351-32"><a href="methods-for-handling-missing-data.html#cb351-32" tabindex="-1"></a><span class="co">#&gt;   3   1  y</span></span>
<span id="cb351-33"><a href="methods-for-handling-missing-data.html#cb351-33" tabindex="-1"></a><span class="co">#&gt;   4   1  y</span></span>
<span id="cb351-34"><a href="methods-for-handling-missing-data.html#cb351-34" tabindex="-1"></a><span class="co">#&gt;   5   1  y</span></span>
<span id="cb351-35"><a href="methods-for-handling-missing-data.html#cb351-35" tabindex="-1"></a>data_imp_single <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp_single)         <span class="co"># Store imputed data</span></span>
<span id="cb351-36"><a href="methods-for-handling-missing-data.html#cb351-36" tabindex="-1"></a><span class="co"># head(data_imp_single)</span></span>
<span id="cb351-37"><a href="methods-for-handling-missing-data.html#cb351-37" tabindex="-1"></a></span>
<span id="cb351-38"><a href="methods-for-handling-missing-data.html#cb351-38" tabindex="-1"></a><span class="co"># Since single imputation underestiamtes stnadard errors, </span></span>
<span id="cb351-39"><a href="methods-for-handling-missing-data.html#cb351-39" tabindex="-1"></a><span class="co"># we use multiple imputaiton</span></span>
<span id="cb351-40"><a href="methods-for-handling-missing-data.html#cb351-40" tabindex="-1"></a></span>
<span id="cb351-41"><a href="methods-for-handling-missing-data.html#cb351-41" tabindex="-1"></a><span class="do">##### Predictive mean matching (multiple imputation) #####</span></span>
<span id="cb351-42"><a href="methods-for-handling-missing-data.html#cb351-42" tabindex="-1"></a></span>
<span id="cb351-43"><a href="methods-for-handling-missing-data.html#cb351-43" tabindex="-1"></a><span class="co"># Impute missing values multiple times</span></span>
<span id="cb351-44"><a href="methods-for-handling-missing-data.html#cb351-44" tabindex="-1"></a>imp_multi <span class="ot">&lt;-</span> <span class="fu">mice</span>(data, <span class="at">m =</span> <span class="dv">5</span>, <span class="at">method =</span> <span class="st">&quot;pmm&quot;</span>)  </span>
<span id="cb351-45"><a href="methods-for-handling-missing-data.html#cb351-45" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb351-46"><a href="methods-for-handling-missing-data.html#cb351-46" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb351-47"><a href="methods-for-handling-missing-data.html#cb351-47" tabindex="-1"></a><span class="co">#&gt;   1   1  y</span></span>
<span id="cb351-48"><a href="methods-for-handling-missing-data.html#cb351-48" tabindex="-1"></a><span class="co">#&gt;   1   2  y</span></span>
<span id="cb351-49"><a href="methods-for-handling-missing-data.html#cb351-49" tabindex="-1"></a><span class="co">#&gt;   1   3  y</span></span>
<span id="cb351-50"><a href="methods-for-handling-missing-data.html#cb351-50" tabindex="-1"></a><span class="co">#&gt;   1   4  y</span></span>
<span id="cb351-51"><a href="methods-for-handling-missing-data.html#cb351-51" tabindex="-1"></a><span class="co">#&gt;   1   5  y</span></span>
<span id="cb351-52"><a href="methods-for-handling-missing-data.html#cb351-52" tabindex="-1"></a><span class="co">#&gt;   2   1  y</span></span>
<span id="cb351-53"><a href="methods-for-handling-missing-data.html#cb351-53" tabindex="-1"></a><span class="co">#&gt;   2   2  y</span></span>
<span id="cb351-54"><a href="methods-for-handling-missing-data.html#cb351-54" tabindex="-1"></a><span class="co">#&gt;   2   3  y</span></span>
<span id="cb351-55"><a href="methods-for-handling-missing-data.html#cb351-55" tabindex="-1"></a><span class="co">#&gt;   2   4  y</span></span>
<span id="cb351-56"><a href="methods-for-handling-missing-data.html#cb351-56" tabindex="-1"></a><span class="co">#&gt;   2   5  y</span></span>
<span id="cb351-57"><a href="methods-for-handling-missing-data.html#cb351-57" tabindex="-1"></a><span class="co">#&gt;   3   1  y</span></span>
<span id="cb351-58"><a href="methods-for-handling-missing-data.html#cb351-58" tabindex="-1"></a><span class="co">#&gt;   3   2  y</span></span>
<span id="cb351-59"><a href="methods-for-handling-missing-data.html#cb351-59" tabindex="-1"></a><span class="co">#&gt;   3   3  y</span></span>
<span id="cb351-60"><a href="methods-for-handling-missing-data.html#cb351-60" tabindex="-1"></a><span class="co">#&gt;   3   4  y</span></span>
<span id="cb351-61"><a href="methods-for-handling-missing-data.html#cb351-61" tabindex="-1"></a><span class="co">#&gt;   3   5  y</span></span>
<span id="cb351-62"><a href="methods-for-handling-missing-data.html#cb351-62" tabindex="-1"></a><span class="co">#&gt;   4   1  y</span></span>
<span id="cb351-63"><a href="methods-for-handling-missing-data.html#cb351-63" tabindex="-1"></a><span class="co">#&gt;   4   2  y</span></span>
<span id="cb351-64"><a href="methods-for-handling-missing-data.html#cb351-64" tabindex="-1"></a><span class="co">#&gt;   4   3  y</span></span>
<span id="cb351-65"><a href="methods-for-handling-missing-data.html#cb351-65" tabindex="-1"></a><span class="co">#&gt;   4   4  y</span></span>
<span id="cb351-66"><a href="methods-for-handling-missing-data.html#cb351-66" tabindex="-1"></a><span class="co">#&gt;   4   5  y</span></span>
<span id="cb351-67"><a href="methods-for-handling-missing-data.html#cb351-67" tabindex="-1"></a><span class="co">#&gt;   5   1  y</span></span>
<span id="cb351-68"><a href="methods-for-handling-missing-data.html#cb351-68" tabindex="-1"></a><span class="co">#&gt;   5   2  y</span></span>
<span id="cb351-69"><a href="methods-for-handling-missing-data.html#cb351-69" tabindex="-1"></a><span class="co">#&gt;   5   3  y</span></span>
<span id="cb351-70"><a href="methods-for-handling-missing-data.html#cb351-70" tabindex="-1"></a><span class="co">#&gt;   5   4  y</span></span>
<span id="cb351-71"><a href="methods-for-handling-missing-data.html#cb351-71" tabindex="-1"></a><span class="co">#&gt;   5   5  y</span></span>
<span id="cb351-72"><a href="methods-for-handling-missing-data.html#cb351-72" tabindex="-1"></a>data_imp_multi_all <span class="ot">&lt;-</span></span>
<span id="cb351-73"><a href="methods-for-handling-missing-data.html#cb351-73" tabindex="-1"></a>    <span class="co"># Store multiply imputed data</span></span>
<span id="cb351-74"><a href="methods-for-handling-missing-data.html#cb351-74" tabindex="-1"></a>    <span class="fu">complete</span>(imp_multi,       </span>
<span id="cb351-75"><a href="methods-for-handling-missing-data.html#cb351-75" tabindex="-1"></a>             <span class="st">&quot;repeated&quot;</span>,</span>
<span id="cb351-76"><a href="methods-for-handling-missing-data.html#cb351-76" tabindex="-1"></a>             <span class="at">include =</span> <span class="cn">TRUE</span>)</span>
<span id="cb351-77"><a href="methods-for-handling-missing-data.html#cb351-77" tabindex="-1"></a></span>
<span id="cb351-78"><a href="methods-for-handling-missing-data.html#cb351-78" tabindex="-1"></a>data_imp_multi <span class="ot">&lt;-</span></span>
<span id="cb351-79"><a href="methods-for-handling-missing-data.html#cb351-79" tabindex="-1"></a>    <span class="co"># Combine imputed Y and X1-X4 (for convenience)</span></span>
<span id="cb351-80"><a href="methods-for-handling-missing-data.html#cb351-80" tabindex="-1"></a>    <span class="fu">data.frame</span>(data_imp_multi_all[, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>], data[, <span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb351-81"><a href="methods-for-handling-missing-data.html#cb351-81" tabindex="-1"></a></span>
<span id="cb351-82"><a href="methods-for-handling-missing-data.html#cb351-82" tabindex="-1"></a><span class="fu">head</span>(data_imp_multi)</span>
<span id="cb351-83"><a href="methods-for-handling-missing-data.html#cb351-83" tabindex="-1"></a><span class="co">#&gt;   y.0 y.1 y.2 y.3 y.4 y.5 x1  x2 x3 x4</span></span>
<span id="cb351-84"><a href="methods-for-handling-missing-data.html#cb351-84" tabindex="-1"></a><span class="co">#&gt; 1  NA  -1   6  -1  -3   3 28 -10  5  0</span></span>
<span id="cb351-85"><a href="methods-for-handling-missing-data.html#cb351-85" tabindex="-1"></a><span class="co">#&gt; 2  NA -10  10   4   0   2 15  -2  2  1</span></span>
<span id="cb351-86"><a href="methods-for-handling-missing-data.html#cb351-86" tabindex="-1"></a><span class="co">#&gt; 3   1   1   1   1   1   1 15 -12  6  1</span></span>
<span id="cb351-87"><a href="methods-for-handling-missing-data.html#cb351-87" tabindex="-1"></a><span class="co">#&gt; 4   8   8   8   8   8   8 58  22 10  1</span></span>
<span id="cb351-88"><a href="methods-for-handling-missing-data.html#cb351-88" tabindex="-1"></a><span class="co">#&gt; 5  NA   0  -1  -6   2   0 26 -12  7  0</span></span>
<span id="cb351-89"><a href="methods-for-handling-missing-data.html#cb351-89" tabindex="-1"></a><span class="co">#&gt; 6  NA   4   0   3   3   3 19  36  5  1</span></span></code></pre></div>
<p>Example from <a href="https://stats.idre.ucla.edu/r/faq/how-do-i-perform-multiple-imputation-using-predictive-mean-matching-in-r/">UCLA Statistical Consulting</a></p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="methods-for-handling-missing-data.html#cb352-1" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb352-2"><a href="methods-for-handling-missing-data.html#cb352-2" tabindex="-1"></a><span class="fu">library</span>(VIM)</span>
<span id="cb352-3"><a href="methods-for-handling-missing-data.html#cb352-3" tabindex="-1"></a><span class="fu">library</span>(lattice)</span>
<span id="cb352-4"><a href="methods-for-handling-missing-data.html#cb352-4" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb352-5"><a href="methods-for-handling-missing-data.html#cb352-5" tabindex="-1"></a><span class="do">## set observations to NA</span></span>
<span id="cb352-6"><a href="methods-for-handling-missing-data.html#cb352-6" tabindex="-1"></a>anscombe <span class="ot">&lt;-</span> <span class="fu">within</span>(anscombe, {</span>
<span id="cb352-7"><a href="methods-for-handling-missing-data.html#cb352-7" tabindex="-1"></a>    y1[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb352-8"><a href="methods-for-handling-missing-data.html#cb352-8" tabindex="-1"></a>    y4[<span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb352-9"><a href="methods-for-handling-missing-data.html#cb352-9" tabindex="-1"></a>})</span>
<span id="cb352-10"><a href="methods-for-handling-missing-data.html#cb352-10" tabindex="-1"></a><span class="do">## view</span></span>
<span id="cb352-11"><a href="methods-for-handling-missing-data.html#cb352-11" tabindex="-1"></a><span class="fu">head</span>(anscombe)</span>
<span id="cb352-12"><a href="methods-for-handling-missing-data.html#cb352-12" tabindex="-1"></a><span class="co">#&gt;   x1 x2 x3 x4   y1   y2    y3   y4</span></span>
<span id="cb352-13"><a href="methods-for-handling-missing-data.html#cb352-13" tabindex="-1"></a><span class="co">#&gt; 1 10 10 10  8   NA 9.14  7.46 6.58</span></span>
<span id="cb352-14"><a href="methods-for-handling-missing-data.html#cb352-14" tabindex="-1"></a><span class="co">#&gt; 2  8  8  8  8   NA 8.14  6.77 5.76</span></span>
<span id="cb352-15"><a href="methods-for-handling-missing-data.html#cb352-15" tabindex="-1"></a><span class="co">#&gt; 3 13 13 13  8   NA 8.74 12.74   NA</span></span>
<span id="cb352-16"><a href="methods-for-handling-missing-data.html#cb352-16" tabindex="-1"></a><span class="co">#&gt; 4  9  9  9  8 8.81 8.77  7.11   NA</span></span>
<span id="cb352-17"><a href="methods-for-handling-missing-data.html#cb352-17" tabindex="-1"></a><span class="co">#&gt; 5 11 11 11  8 8.33 9.26  7.81   NA</span></span>
<span id="cb352-18"><a href="methods-for-handling-missing-data.html#cb352-18" tabindex="-1"></a><span class="co">#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04</span></span>
<span id="cb352-19"><a href="methods-for-handling-missing-data.html#cb352-19" tabindex="-1"></a></span>
<span id="cb352-20"><a href="methods-for-handling-missing-data.html#cb352-20" tabindex="-1"></a><span class="do">## check missing data patterns</span></span>
<span id="cb352-21"><a href="methods-for-handling-missing-data.html#cb352-21" tabindex="-1"></a><span class="fu">md.pattern</span>(anscombe)</span></code></pre></div>
<p><img src="11-imputation_files/figure-html/unnamed-chunk-10-1.png" width="90%" style="display: block; margin: auto;" /></p>
<pre><code>#&gt;   x1 x2 x3 x4 y2 y3 y1 y4  
#&gt; 6  1  1  1  1  1  1  1  1 0
#&gt; 2  1  1  1  1  1  1  1  0 1
#&gt; 2  1  1  1  1  1  1  0  1 1
#&gt; 1  1  1  1  1  1  1  0  0 2
#&gt;    0  0  0  0  0  0  3  3 6

## Number of observations per patterns for all pairs of variables
p &lt;- md.pairs(anscombe)
p 
#&gt; $rr
#&gt;    x1 x2 x3 x4 y1 y2 y3 y4
#&gt; x1 11 11 11 11  8 11 11  8
#&gt; x2 11 11 11 11  8 11 11  8
#&gt; x3 11 11 11 11  8 11 11  8
#&gt; x4 11 11 11 11  8 11 11  8
#&gt; y1  8  8  8  8  8  8  8  6
#&gt; y2 11 11 11 11  8 11 11  8
#&gt; y3 11 11 11 11  8 11 11  8
#&gt; y4  8  8  8  8  6  8  8  8
#&gt; 
#&gt; $rm
#&gt;    x1 x2 x3 x4 y1 y2 y3 y4
#&gt; x1  0  0  0  0  3  0  0  3
#&gt; x2  0  0  0  0  3  0  0  3
#&gt; x3  0  0  0  0  3  0  0  3
#&gt; x4  0  0  0  0  3  0  0  3
#&gt; y1  0  0  0  0  0  0  0  2
#&gt; y2  0  0  0  0  3  0  0  3
#&gt; y3  0  0  0  0  3  0  0  3
#&gt; y4  0  0  0  0  2  0  0  0
#&gt; 
#&gt; $mr
#&gt;    x1 x2 x3 x4 y1 y2 y3 y4
#&gt; x1  0  0  0  0  0  0  0  0
#&gt; x2  0  0  0  0  0  0  0  0
#&gt; x3  0  0  0  0  0  0  0  0
#&gt; x4  0  0  0  0  0  0  0  0
#&gt; y1  3  3  3  3  0  3  3  2
#&gt; y2  0  0  0  0  0  0  0  0
#&gt; y3  0  0  0  0  0  0  0  0
#&gt; y4  3  3  3  3  2  3  3  0
#&gt; 
#&gt; $mm
#&gt;    x1 x2 x3 x4 y1 y2 y3 y4
#&gt; x1  0  0  0  0  0  0  0  0
#&gt; x2  0  0  0  0  0  0  0  0
#&gt; x3  0  0  0  0  0  0  0  0
#&gt; x4  0  0  0  0  0  0  0  0
#&gt; y1  0  0  0  0  3  0  0  1
#&gt; y2  0  0  0  0  0  0  0  0
#&gt; y3  0  0  0  0  0  0  0  0
#&gt; y4  0  0  0  0  1  0  0  3</code></pre>
<ul>
<li><code>rr</code> = number of observations where both pairs of values are observed</li>
<li><code>rm</code> = the number of observations where both variables are missing values</li>
<li><code>mr</code> = the number of observations where the first variable’s value (e.g. the row variable) is observed and second (or column) variable is missing</li>
<li><code>mm</code> = the number of observations where the second variable’s value (e.g. the col variable) is observed and first (or row) variable is missing</li>
</ul>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="methods-for-handling-missing-data.html#cb354-1" tabindex="-1"></a><span class="do">## Margin plot of y1 and y4</span></span>
<span id="cb354-2"><a href="methods-for-handling-missing-data.html#cb354-2" tabindex="-1"></a><span class="fu">marginplot</span>(anscombe[<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">8</span>)], <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;orange&quot;</span>))</span></code></pre></div>
<p><img src="11-imputation_files/figure-html/unnamed-chunk-11-1.png" width="90%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="methods-for-handling-missing-data.html#cb355-1" tabindex="-1"></a></span>
<span id="cb355-2"><a href="methods-for-handling-missing-data.html#cb355-2" tabindex="-1"></a><span class="do">## 5 imputations for all missing values</span></span>
<span id="cb355-3"><a href="methods-for-handling-missing-data.html#cb355-3" tabindex="-1"></a>imp1 <span class="ot">&lt;-</span> <span class="fu">mice</span>(anscombe, <span class="at">m =</span> <span class="dv">5</span>)</span>
<span id="cb355-4"><a href="methods-for-handling-missing-data.html#cb355-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb355-5"><a href="methods-for-handling-missing-data.html#cb355-5" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb355-6"><a href="methods-for-handling-missing-data.html#cb355-6" tabindex="-1"></a><span class="co">#&gt;   1   1  y1  y4</span></span>
<span id="cb355-7"><a href="methods-for-handling-missing-data.html#cb355-7" tabindex="-1"></a><span class="co">#&gt;   1   2  y1  y4</span></span>
<span id="cb355-8"><a href="methods-for-handling-missing-data.html#cb355-8" tabindex="-1"></a><span class="co">#&gt;   1   3  y1  y4</span></span>
<span id="cb355-9"><a href="methods-for-handling-missing-data.html#cb355-9" tabindex="-1"></a><span class="co">#&gt;   1   4  y1  y4</span></span>
<span id="cb355-10"><a href="methods-for-handling-missing-data.html#cb355-10" tabindex="-1"></a><span class="co">#&gt;   1   5  y1  y4</span></span>
<span id="cb355-11"><a href="methods-for-handling-missing-data.html#cb355-11" tabindex="-1"></a><span class="co">#&gt;   2   1  y1  y4</span></span>
<span id="cb355-12"><a href="methods-for-handling-missing-data.html#cb355-12" tabindex="-1"></a><span class="co">#&gt;   2   2  y1  y4</span></span>
<span id="cb355-13"><a href="methods-for-handling-missing-data.html#cb355-13" tabindex="-1"></a><span class="co">#&gt;   2   3  y1  y4</span></span>
<span id="cb355-14"><a href="methods-for-handling-missing-data.html#cb355-14" tabindex="-1"></a><span class="co">#&gt;   2   4  y1  y4</span></span>
<span id="cb355-15"><a href="methods-for-handling-missing-data.html#cb355-15" tabindex="-1"></a><span class="co">#&gt;   2   5  y1  y4</span></span>
<span id="cb355-16"><a href="methods-for-handling-missing-data.html#cb355-16" tabindex="-1"></a><span class="co">#&gt;   3   1  y1  y4</span></span>
<span id="cb355-17"><a href="methods-for-handling-missing-data.html#cb355-17" tabindex="-1"></a><span class="co">#&gt;   3   2  y1  y4</span></span>
<span id="cb355-18"><a href="methods-for-handling-missing-data.html#cb355-18" tabindex="-1"></a><span class="co">#&gt;   3   3  y1  y4</span></span>
<span id="cb355-19"><a href="methods-for-handling-missing-data.html#cb355-19" tabindex="-1"></a><span class="co">#&gt;   3   4  y1  y4</span></span>
<span id="cb355-20"><a href="methods-for-handling-missing-data.html#cb355-20" tabindex="-1"></a><span class="co">#&gt;   3   5  y1  y4</span></span>
<span id="cb355-21"><a href="methods-for-handling-missing-data.html#cb355-21" tabindex="-1"></a><span class="co">#&gt;   4   1  y1  y4</span></span>
<span id="cb355-22"><a href="methods-for-handling-missing-data.html#cb355-22" tabindex="-1"></a><span class="co">#&gt;   4   2  y1  y4</span></span>
<span id="cb355-23"><a href="methods-for-handling-missing-data.html#cb355-23" tabindex="-1"></a><span class="co">#&gt;   4   3  y1  y4</span></span>
<span id="cb355-24"><a href="methods-for-handling-missing-data.html#cb355-24" tabindex="-1"></a><span class="co">#&gt;   4   4  y1  y4</span></span>
<span id="cb355-25"><a href="methods-for-handling-missing-data.html#cb355-25" tabindex="-1"></a><span class="co">#&gt;   4   5  y1  y4</span></span>
<span id="cb355-26"><a href="methods-for-handling-missing-data.html#cb355-26" tabindex="-1"></a><span class="co">#&gt;   5   1  y1  y4</span></span>
<span id="cb355-27"><a href="methods-for-handling-missing-data.html#cb355-27" tabindex="-1"></a><span class="co">#&gt;   5   2  y1  y4</span></span>
<span id="cb355-28"><a href="methods-for-handling-missing-data.html#cb355-28" tabindex="-1"></a><span class="co">#&gt;   5   3  y1  y4</span></span>
<span id="cb355-29"><a href="methods-for-handling-missing-data.html#cb355-29" tabindex="-1"></a><span class="co">#&gt;   5   4  y1  y4</span></span>
<span id="cb355-30"><a href="methods-for-handling-missing-data.html#cb355-30" tabindex="-1"></a><span class="co">#&gt;   5   5  y1  y4</span></span>
<span id="cb355-31"><a href="methods-for-handling-missing-data.html#cb355-31" tabindex="-1"></a></span>
<span id="cb355-32"><a href="methods-for-handling-missing-data.html#cb355-32" tabindex="-1"></a><span class="do">## linear regression for each imputed data set - 5 regression are run</span></span>
<span id="cb355-33"><a href="methods-for-handling-missing-data.html#cb355-33" tabindex="-1"></a>fitm <span class="ot">&lt;-</span> <span class="fu">with</span>(imp1, <span class="fu">lm</span>(y1 <span class="sc">~</span> y4 <span class="sc">+</span> x1))</span>
<span id="cb355-34"><a href="methods-for-handling-missing-data.html#cb355-34" tabindex="-1"></a><span class="fu">summary</span>(fitm)</span>
<span id="cb355-35"><a href="methods-for-handling-missing-data.html#cb355-35" tabindex="-1"></a><span class="co">#&gt; # A tibble: 15 × 6</span></span>
<span id="cb355-36"><a href="methods-for-handling-missing-data.html#cb355-36" tabindex="-1"></a><span class="co">#&gt;    term        estimate std.error statistic p.value  nobs</span></span>
<span id="cb355-37"><a href="methods-for-handling-missing-data.html#cb355-37" tabindex="-1"></a><span class="co">#&gt;    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;</span></span>
<span id="cb355-38"><a href="methods-for-handling-missing-data.html#cb355-38" tabindex="-1"></a><span class="co">#&gt;  1 (Intercept)    7.33      2.44       3.01  0.0169    11</span></span>
<span id="cb355-39"><a href="methods-for-handling-missing-data.html#cb355-39" tabindex="-1"></a><span class="co">#&gt;  2 y4            -0.416     0.223     -1.86  0.0996    11</span></span>
<span id="cb355-40"><a href="methods-for-handling-missing-data.html#cb355-40" tabindex="-1"></a><span class="co">#&gt;  3 x1             0.371     0.141      2.63  0.0302    11</span></span>
<span id="cb355-41"><a href="methods-for-handling-missing-data.html#cb355-41" tabindex="-1"></a><span class="co">#&gt;  4 (Intercept)    7.27      2.90       2.51  0.0365    11</span></span>
<span id="cb355-42"><a href="methods-for-handling-missing-data.html#cb355-42" tabindex="-1"></a><span class="co">#&gt;  5 y4            -0.435     0.273     -1.59  0.150     11</span></span>
<span id="cb355-43"><a href="methods-for-handling-missing-data.html#cb355-43" tabindex="-1"></a><span class="co">#&gt;  6 x1             0.387     0.160      2.41  0.0422    11</span></span>
<span id="cb355-44"><a href="methods-for-handling-missing-data.html#cb355-44" tabindex="-1"></a><span class="co">#&gt;  7 (Intercept)    6.54      2.80       2.33  0.0479    11</span></span>
<span id="cb355-45"><a href="methods-for-handling-missing-data.html#cb355-45" tabindex="-1"></a><span class="co">#&gt;  8 y4            -0.322     0.255     -1.26  0.243     11</span></span>
<span id="cb355-46"><a href="methods-for-handling-missing-data.html#cb355-46" tabindex="-1"></a><span class="co">#&gt;  9 x1             0.362     0.156      2.32  0.0491    11</span></span>
<span id="cb355-47"><a href="methods-for-handling-missing-data.html#cb355-47" tabindex="-1"></a><span class="co">#&gt; 10 (Intercept)    5.93      3.08       1.92  0.0907    11</span></span>
<span id="cb355-48"><a href="methods-for-handling-missing-data.html#cb355-48" tabindex="-1"></a><span class="co">#&gt; 11 y4            -0.286     0.282     -1.02  0.339     11</span></span>
<span id="cb355-49"><a href="methods-for-handling-missing-data.html#cb355-49" tabindex="-1"></a><span class="co">#&gt; 12 x1             0.418     0.176      2.37  0.0451    11</span></span>
<span id="cb355-50"><a href="methods-for-handling-missing-data.html#cb355-50" tabindex="-1"></a><span class="co">#&gt; 13 (Intercept)    8.16      2.67       3.05  0.0158    11</span></span>
<span id="cb355-51"><a href="methods-for-handling-missing-data.html#cb355-51" tabindex="-1"></a><span class="co">#&gt; 14 y4            -0.489     0.251     -1.95  0.0867    11</span></span>
<span id="cb355-52"><a href="methods-for-handling-missing-data.html#cb355-52" tabindex="-1"></a><span class="co">#&gt; 15 x1             0.326     0.151      2.17  0.0622    11</span></span>
<span id="cb355-53"><a href="methods-for-handling-missing-data.html#cb355-53" tabindex="-1"></a></span>
<span id="cb355-54"><a href="methods-for-handling-missing-data.html#cb355-54" tabindex="-1"></a><span class="do">## pool coefficients and standard errors across all 5 regression models</span></span>
<span id="cb355-55"><a href="methods-for-handling-missing-data.html#cb355-55" tabindex="-1"></a><span class="fu">pool</span>(fitm)</span>
<span id="cb355-56"><a href="methods-for-handling-missing-data.html#cb355-56" tabindex="-1"></a><span class="co">#&gt; Class: mipo    m = 5 </span></span>
<span id="cb355-57"><a href="methods-for-handling-missing-data.html#cb355-57" tabindex="-1"></a><span class="co">#&gt;          term m   estimate       ubar           b          t dfcom       df</span></span>
<span id="cb355-58"><a href="methods-for-handling-missing-data.html#cb355-58" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept) 5  7.0445966 7.76794670 0.719350800 8.63116766     8 5.805314</span></span>
<span id="cb355-59"><a href="methods-for-handling-missing-data.html#cb355-59" tabindex="-1"></a><span class="co">#&gt; 2          y4 5 -0.3896685 0.06634920 0.006991497 0.07473900     8 5.706243</span></span>
<span id="cb355-60"><a href="methods-for-handling-missing-data.html#cb355-60" tabindex="-1"></a><span class="co">#&gt; 3          x1 5  0.3727865 0.02473847 0.001134293 0.02609962     8 6.178032</span></span>
<span id="cb355-61"><a href="methods-for-handling-missing-data.html#cb355-61" tabindex="-1"></a><span class="co">#&gt;          riv     lambda       fmi</span></span>
<span id="cb355-62"><a href="methods-for-handling-missing-data.html#cb355-62" tabindex="-1"></a><span class="co">#&gt; 1 0.11112601 0.10001207 0.3044313</span></span>
<span id="cb355-63"><a href="methods-for-handling-missing-data.html#cb355-63" tabindex="-1"></a><span class="co">#&gt; 2 0.12644909 0.11225460 0.3161877</span></span>
<span id="cb355-64"><a href="methods-for-handling-missing-data.html#cb355-64" tabindex="-1"></a><span class="co">#&gt; 3 0.05502168 0.05215218 0.2586992</span></span>
<span id="cb355-65"><a href="methods-for-handling-missing-data.html#cb355-65" tabindex="-1"></a></span>
<span id="cb355-66"><a href="methods-for-handling-missing-data.html#cb355-66" tabindex="-1"></a><span class="do">## output parameter estimates</span></span>
<span id="cb355-67"><a href="methods-for-handling-missing-data.html#cb355-67" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">pool</span>(fitm))</span>
<span id="cb355-68"><a href="methods-for-handling-missing-data.html#cb355-68" tabindex="-1"></a><span class="co">#&gt;          term   estimate std.error statistic       df    p.value</span></span>
<span id="cb355-69"><a href="methods-for-handling-missing-data.html#cb355-69" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  7.0445966 2.9378849  2.397846 5.805314 0.05483678</span></span>
<span id="cb355-70"><a href="methods-for-handling-missing-data.html#cb355-70" tabindex="-1"></a><span class="co">#&gt; 2          y4 -0.3896685 0.2733843 -1.425350 5.706243 0.20638512</span></span>
<span id="cb355-71"><a href="methods-for-handling-missing-data.html#cb355-71" tabindex="-1"></a><span class="co">#&gt; 3          x1  0.3727865 0.1615538  2.307508 6.178032 0.05923999</span></span></code></pre></div>
</div>
<div id="stochastic-imputation" class="section level5 hasAnchor" number="11.4.2.4.2">
<h5><span class="header-section-number">11.4.2.4.2</span> Stochastic Imputation<a href="methods-for-handling-missing-data.html#stochastic-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Stochastic Imputation is an enhancement of regression imputation that introduces randomness into the imputation process by adding a random residual to the predicted values from a regression model. This approach aims to retain the variability of the original data while reducing the bias introduced by deterministic regression imputation.</p>
<p>Stochastic Imputation can be described as:</p>
<p><span class="math display">\[
\text{Imputed Value} = \text{Predicted Value (from regression)} + \text{Random Residual}
\]</span></p>
<p>This method is commonly used as a foundation for multiple imputation techniques.</p>
<p><strong>Advantages of Stochastic Imputation</strong></p>
<ul>
<li><strong>Retains all the benefits of regression imputation</strong>:
<ul>
<li>Preserves relationships between variables in the dataset.</li>
<li>Utilizes information from observed data to inform imputations.</li>
</ul></li>
<li><strong>Introduces randomness</strong>:
<ul>
<li>Adds variability by including a random residual term, making imputed values more realistic and better representing the uncertainty of missing data.</li>
</ul></li>
<li><strong>Supports multiple imputation</strong>:
<ul>
<li>By generating different random residuals for each iteration, it facilitates the creation of multiple plausible datasets for robust statistical analysis.</li>
</ul></li>
</ul>
<p><strong>Disadvantages of Stochastic Imputation</strong></p>
<ul>
<li><strong>Implausible values</strong>:
<ul>
<li>Depending on the random residuals, imputed values may fall outside the plausible range (e.g., negative values for variables like age or income).</li>
</ul></li>
<li><strong>Cannot handle heteroskedasticity</strong>:
<ul>
<li>If the data exhibit heteroskedasticity (i.e., non-constant variance of residuals), the randomness added by stochastic imputation may not accurately reflect the underlying variability.</li>
</ul></li>
</ul>
<p><strong>Steps in Stochastic Imputation</strong></p>
<ol style="list-style-type: decimal">
<li>Fit a regression model using cases with complete data for the variable with missing values.</li>
<li>Predict missing values using the fitted model.</li>
<li>Generate random residuals based on the distribution of residuals from the regression model.</li>
<li>Add the random residuals to the predicted values to impute missing values.</li>
</ol>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="methods-for-handling-missing-data.html#cb356-1" tabindex="-1"></a><span class="co"># Example dataset with missing values</span></span>
<span id="cb356-2"><a href="methods-for-handling-missing-data.html#cb356-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb356-3"><a href="methods-for-handling-missing-data.html#cb356-3" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb356-4"><a href="methods-for-handling-missing-data.html#cb356-4" tabindex="-1"></a>  <span class="at">X =</span> <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>),</span>
<span id="cb356-5"><a href="methods-for-handling-missing-data.html#cb356-5" tabindex="-1"></a>  <span class="at">Y =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">105</span>, <span class="dv">110</span>, <span class="cn">NA</span>, <span class="dv">120</span>, <span class="cn">NA</span>, <span class="dv">130</span>, <span class="dv">135</span>, <span class="dv">140</span>, <span class="cn">NA</span>)</span>
<span id="cb356-6"><a href="methods-for-handling-missing-data.html#cb356-6" tabindex="-1"></a>)</span>
<span id="cb356-7"><a href="methods-for-handling-missing-data.html#cb356-7" tabindex="-1"></a></span>
<span id="cb356-8"><a href="methods-for-handling-missing-data.html#cb356-8" tabindex="-1"></a><span class="co"># Perform stochastic imputation</span></span>
<span id="cb356-9"><a href="methods-for-handling-missing-data.html#cb356-9" tabindex="-1"></a>stochastic_impute <span class="ot">&lt;-</span> <span class="cf">function</span>(data, predictor, target) {</span>
<span id="cb356-10"><a href="methods-for-handling-missing-data.html#cb356-10" tabindex="-1"></a>  <span class="co"># Subset data with complete cases</span></span>
<span id="cb356-11"><a href="methods-for-handling-missing-data.html#cb356-11" tabindex="-1"></a>  complete_data <span class="ot">&lt;-</span> data[<span class="sc">!</span><span class="fu">is.na</span>(data[[target]]), ]</span>
<span id="cb356-12"><a href="methods-for-handling-missing-data.html#cb356-12" tabindex="-1"></a>  </span>
<span id="cb356-13"><a href="methods-for-handling-missing-data.html#cb356-13" tabindex="-1"></a>  <span class="co"># Fit a regression model</span></span>
<span id="cb356-14"><a href="methods-for-handling-missing-data.html#cb356-14" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">as.formula</span>(<span class="fu">paste</span>(target, <span class="st">&quot;~&quot;</span>, predictor)), <span class="at">data =</span> complete_data)</span>
<span id="cb356-15"><a href="methods-for-handling-missing-data.html#cb356-15" tabindex="-1"></a>  </span>
<span id="cb356-16"><a href="methods-for-handling-missing-data.html#cb356-16" tabindex="-1"></a>  <span class="co"># Predict missing values</span></span>
<span id="cb356-17"><a href="methods-for-handling-missing-data.html#cb356-17" tabindex="-1"></a>  missing_data <span class="ot">&lt;-</span> data[<span class="fu">is.na</span>(data[[target]]), ]</span>
<span id="cb356-18"><a href="methods-for-handling-missing-data.html#cb356-18" tabindex="-1"></a>  predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> missing_data)</span>
<span id="cb356-19"><a href="methods-for-handling-missing-data.html#cb356-19" tabindex="-1"></a>  </span>
<span id="cb356-20"><a href="methods-for-handling-missing-data.html#cb356-20" tabindex="-1"></a>  <span class="co"># Add random residuals</span></span>
<span id="cb356-21"><a href="methods-for-handling-missing-data.html#cb356-21" tabindex="-1"></a>  residual_sd <span class="ot">&lt;-</span> <span class="fu">sd</span>(model<span class="sc">$</span>residuals, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb356-22"><a href="methods-for-handling-missing-data.html#cb356-22" tabindex="-1"></a>  stochastic_values <span class="ot">&lt;-</span> predictions <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(predictions), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> residual_sd)</span>
<span id="cb356-23"><a href="methods-for-handling-missing-data.html#cb356-23" tabindex="-1"></a>  </span>
<span id="cb356-24"><a href="methods-for-handling-missing-data.html#cb356-24" tabindex="-1"></a>  <span class="co"># Impute missing values</span></span>
<span id="cb356-25"><a href="methods-for-handling-missing-data.html#cb356-25" tabindex="-1"></a>  data[<span class="fu">is.na</span>(data[[target]]), target] <span class="ot">&lt;-</span> stochastic_values</span>
<span id="cb356-26"><a href="methods-for-handling-missing-data.html#cb356-26" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb356-27"><a href="methods-for-handling-missing-data.html#cb356-27" tabindex="-1"></a>}</span>
<span id="cb356-28"><a href="methods-for-handling-missing-data.html#cb356-28" tabindex="-1"></a></span>
<span id="cb356-29"><a href="methods-for-handling-missing-data.html#cb356-29" tabindex="-1"></a><span class="co"># Apply stochastic imputation</span></span>
<span id="cb356-30"><a href="methods-for-handling-missing-data.html#cb356-30" tabindex="-1"></a>imputed_data <span class="ot">&lt;-</span> <span class="fu">stochastic_impute</span>(data, <span class="at">predictor =</span> <span class="st">&quot;X&quot;</span>, <span class="at">target =</span> <span class="st">&quot;Y&quot;</span>)</span>
<span id="cb356-31"><a href="methods-for-handling-missing-data.html#cb356-31" tabindex="-1"></a></span>
<span id="cb356-32"><a href="methods-for-handling-missing-data.html#cb356-32" tabindex="-1"></a><span class="co"># Display the imputed dataset</span></span>
<span id="cb356-33"><a href="methods-for-handling-missing-data.html#cb356-33" tabindex="-1"></a><span class="fu">print</span>(imputed_data)</span></code></pre></div>
<p>Notes</p>
<ul>
<li><p><strong>Multiple Imputation</strong>: Most multiple imputation methods are extensions of stochastic regression imputation. By repeating the imputation process with different random seeds, multiple datasets can be generated to account for uncertainty in the imputed values.</p></li>
<li><p><strong>Dealing with Implausible Values</strong>: Additional constraints or transformations (e.g., truncating imputed values to a plausible range) may be necessary to address the issue of implausible values.</p></li>
</ul>
<p><strong>Comparison to Deterministic Regression Imputation</strong></p>
<table>
<colgroup>
<col width="34%" />
<col width="40%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Deterministic Regression Imputation</th>
<th>Stochastic Imputation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Randomness</strong></td>
<td>None</td>
<td>Adds random residuals</td>
</tr>
<tr class="even">
<td><strong>Preserves Variability</strong></td>
<td>No</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td><strong>Use in Multiple Imputation</strong></td>
<td>Limited</td>
<td>Well-suited</td>
</tr>
<tr class="even">
<td><strong>Bias Potential</strong></td>
<td>Higher</td>
<td>Lower</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="methods-for-handling-missing-data.html#cb357-1" tabindex="-1"></a><span class="co"># Income data</span></span>
<span id="cb357-2"><a href="methods-for-handling-missing-data.html#cb357-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)                              <span class="co"># Set seed</span></span>
<span id="cb357-3"><a href="methods-for-handling-missing-data.html#cb357-3" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span>                                    <span class="co"># Sample size</span></span>
<span id="cb357-4"><a href="methods-for-handling-missing-data.html#cb357-4" tabindex="-1"></a></span>
<span id="cb357-5"><a href="methods-for-handling-missing-data.html#cb357-5" tabindex="-1"></a>income <span class="ot">&lt;-</span></span>
<span id="cb357-6"><a href="methods-for-handling-missing-data.html#cb357-6" tabindex="-1"></a>  <span class="fu">round</span>(<span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="dv">500</span>))            <span class="co"># Create some synthetic income data</span></span>
<span id="cb357-7"><a href="methods-for-handling-missing-data.html#cb357-7" tabindex="-1"></a>income[income <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> income[income <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="sc">*</span> (<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb357-8"><a href="methods-for-handling-missing-data.html#cb357-8" tabindex="-1"></a></span>
<span id="cb357-9"><a href="methods-for-handling-missing-data.html#cb357-9" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> income <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">1000</span>, <span class="dv">1500</span>)          <span class="co"># Auxiliary variables</span></span>
<span id="cb357-10"><a href="methods-for-handling-missing-data.html#cb357-10" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> income <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="sc">-</span><span class="dv">5000</span>, <span class="dv">2000</span>)</span>
<span id="cb357-11"><a href="methods-for-handling-missing-data.html#cb357-11" tabindex="-1"></a></span>
<span id="cb357-12"><a href="methods-for-handling-missing-data.html#cb357-12" tabindex="-1"></a></span>
<span id="cb357-13"><a href="methods-for-handling-missing-data.html#cb357-13" tabindex="-1"></a><span class="co"># Create 10% missingness in income</span></span>
<span id="cb357-14"><a href="methods-for-handling-missing-data.html#cb357-14" tabindex="-1"></a>income[<span class="fu">rbinom</span>(N, <span class="dv">1</span>, <span class="fl">0.1</span>) <span class="sc">==</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb357-15"><a href="methods-for-handling-missing-data.html#cb357-15" tabindex="-1"></a></span>
<span id="cb357-16"><a href="methods-for-handling-missing-data.html#cb357-16" tabindex="-1"></a>data_inc_miss <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(income, x1, x2)</span></code></pre></div>
<p>Single stochastic regression imputation</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="methods-for-handling-missing-data.html#cb358-1" tabindex="-1"></a>imp_inc_sri  <span class="ot">&lt;-</span> <span class="fu">mice</span>(data_inc_miss, <span class="at">method =</span> <span class="st">&quot;norm.nob&quot;</span>, <span class="at">m =</span> <span class="dv">1</span>)</span>
<span id="cb358-2"><a href="methods-for-handling-missing-data.html#cb358-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb358-3"><a href="methods-for-handling-missing-data.html#cb358-3" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb358-4"><a href="methods-for-handling-missing-data.html#cb358-4" tabindex="-1"></a><span class="co">#&gt;   1   1  income</span></span>
<span id="cb358-5"><a href="methods-for-handling-missing-data.html#cb358-5" tabindex="-1"></a><span class="co">#&gt;   2   1  income</span></span>
<span id="cb358-6"><a href="methods-for-handling-missing-data.html#cb358-6" tabindex="-1"></a><span class="co">#&gt;   3   1  income</span></span>
<span id="cb358-7"><a href="methods-for-handling-missing-data.html#cb358-7" tabindex="-1"></a><span class="co">#&gt;   4   1  income</span></span>
<span id="cb358-8"><a href="methods-for-handling-missing-data.html#cb358-8" tabindex="-1"></a><span class="co">#&gt;   5   1  income</span></span>
<span id="cb358-9"><a href="methods-for-handling-missing-data.html#cb358-9" tabindex="-1"></a>data_inc_sri <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp_inc_sri)</span></code></pre></div>
<p>Single predictive mean matching</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="methods-for-handling-missing-data.html#cb359-1" tabindex="-1"></a>imp_inc_pmm  <span class="ot">&lt;-</span> <span class="fu">mice</span>(data_inc_miss, <span class="at">method =</span> <span class="st">&quot;pmm&quot;</span>, <span class="at">m =</span> <span class="dv">1</span>)</span>
<span id="cb359-2"><a href="methods-for-handling-missing-data.html#cb359-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb359-3"><a href="methods-for-handling-missing-data.html#cb359-3" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb359-4"><a href="methods-for-handling-missing-data.html#cb359-4" tabindex="-1"></a><span class="co">#&gt;   1   1  income</span></span>
<span id="cb359-5"><a href="methods-for-handling-missing-data.html#cb359-5" tabindex="-1"></a><span class="co">#&gt;   2   1  income</span></span>
<span id="cb359-6"><a href="methods-for-handling-missing-data.html#cb359-6" tabindex="-1"></a><span class="co">#&gt;   3   1  income</span></span>
<span id="cb359-7"><a href="methods-for-handling-missing-data.html#cb359-7" tabindex="-1"></a><span class="co">#&gt;   4   1  income</span></span>
<span id="cb359-8"><a href="methods-for-handling-missing-data.html#cb359-8" tabindex="-1"></a><span class="co">#&gt;   5   1  income</span></span>
<span id="cb359-9"><a href="methods-for-handling-missing-data.html#cb359-9" tabindex="-1"></a>data_inc_pmm <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp_inc_pmm)</span></code></pre></div>
<p>Stochastic regression imputation contains negative values</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="methods-for-handling-missing-data.html#cb360-1" tabindex="-1"></a>data_inc_sri<span class="sc">$</span>income[data_inc_sri<span class="sc">$</span>income <span class="sc">&lt;</span> <span class="dv">0</span>]</span>
<span id="cb360-2"><a href="methods-for-handling-missing-data.html#cb360-2" tabindex="-1"></a><span class="co">#&gt;  [1]  -23.85404  -58.37790  -61.86396  -57.47909  -21.29221  -73.26549</span></span>
<span id="cb360-3"><a href="methods-for-handling-missing-data.html#cb360-3" tabindex="-1"></a><span class="co">#&gt;  [7]  -61.76194  -42.45942 -351.02991 -317.69090</span></span>
<span id="cb360-4"><a href="methods-for-handling-missing-data.html#cb360-4" tabindex="-1"></a><span class="co"># No values below 0</span></span>
<span id="cb360-5"><a href="methods-for-handling-missing-data.html#cb360-5" tabindex="-1"></a>data_inc_pmm<span class="sc">$</span>income[data_inc_pmm<span class="sc">$</span>income <span class="sc">&lt;</span> <span class="dv">0</span>] </span>
<span id="cb360-6"><a href="methods-for-handling-missing-data.html#cb360-6" tabindex="-1"></a><span class="co">#&gt; numeric(0)</span></span></code></pre></div>
<p>Evidence for heteroskadastic data</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="methods-for-handling-missing-data.html#cb361-1" tabindex="-1"></a><span class="co"># Heteroscedastic data</span></span>
<span id="cb361-2"><a href="methods-for-handling-missing-data.html#cb361-2" tabindex="-1"></a> </span>
<span id="cb361-3"><a href="methods-for-handling-missing-data.html#cb361-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)                             <span class="co"># Set seed</span></span>
<span id="cb361-4"><a href="methods-for-handling-missing-data.html#cb361-4" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>                                  <span class="co"># Sample size</span></span>
<span id="cb361-5"><a href="methods-for-handling-missing-data.html#cb361-5" tabindex="-1"></a> </span>
<span id="cb361-6"><a href="methods-for-handling-missing-data.html#cb361-6" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb361-7"><a href="methods-for-handling-missing-data.html#cb361-7" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb361-8"><a href="methods-for-handling-missing-data.html#cb361-8" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> N<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb361-9"><a href="methods-for-handling-missing-data.html#cb361-9" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(sigma2))</span>
<span id="cb361-10"><a href="methods-for-handling-missing-data.html#cb361-10" tabindex="-1"></a> </span>
<span id="cb361-11"><a href="methods-for-handling-missing-data.html#cb361-11" tabindex="-1"></a>y <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> N <span class="sc">+</span> eps                         <span class="co"># Heteroscedastic variable</span></span>
<span id="cb361-12"><a href="methods-for-handling-missing-data.html#cb361-12" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">30</span> <span class="sc">*</span> N <span class="sc">+</span> <span class="fu">rnorm</span>(N[<span class="fu">length</span>(N)], <span class="dv">1000</span>, <span class="dv">200</span>) <span class="co"># Correlated variable</span></span>
<span id="cb361-13"><a href="methods-for-handling-missing-data.html#cb361-13" tabindex="-1"></a> </span>
<span id="cb361-14"><a href="methods-for-handling-missing-data.html#cb361-14" tabindex="-1"></a>y[<span class="fu">rbinom</span>(N[<span class="fu">length</span>(N)], <span class="dv">1</span>, <span class="fl">0.3</span>) <span class="sc">==</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="cn">NA</span>   <span class="co"># 30% missing</span></span>
<span id="cb361-15"><a href="methods-for-handling-missing-data.html#cb361-15" tabindex="-1"></a> </span>
<span id="cb361-16"><a href="methods-for-handling-missing-data.html#cb361-16" tabindex="-1"></a>data_het_miss <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x)</span></code></pre></div>
<p>Single stochastic regression imputation</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="methods-for-handling-missing-data.html#cb362-1" tabindex="-1"></a>imp_het_sri  <span class="ot">&lt;-</span> <span class="fu">mice</span>(data_het_miss, <span class="at">method =</span> <span class="st">&quot;norm.nob&quot;</span>, <span class="at">m =</span> <span class="dv">1</span>)</span>
<span id="cb362-2"><a href="methods-for-handling-missing-data.html#cb362-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb362-3"><a href="methods-for-handling-missing-data.html#cb362-3" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb362-4"><a href="methods-for-handling-missing-data.html#cb362-4" tabindex="-1"></a><span class="co">#&gt;   1   1  y</span></span>
<span id="cb362-5"><a href="methods-for-handling-missing-data.html#cb362-5" tabindex="-1"></a><span class="co">#&gt;   2   1  y</span></span>
<span id="cb362-6"><a href="methods-for-handling-missing-data.html#cb362-6" tabindex="-1"></a><span class="co">#&gt;   3   1  y</span></span>
<span id="cb362-7"><a href="methods-for-handling-missing-data.html#cb362-7" tabindex="-1"></a><span class="co">#&gt;   4   1  y</span></span>
<span id="cb362-8"><a href="methods-for-handling-missing-data.html#cb362-8" tabindex="-1"></a><span class="co">#&gt;   5   1  y</span></span>
<span id="cb362-9"><a href="methods-for-handling-missing-data.html#cb362-9" tabindex="-1"></a>data_het_sri <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp_het_sri)</span></code></pre></div>
<p>Single predictive mean matching</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="methods-for-handling-missing-data.html#cb363-1" tabindex="-1"></a>imp_het_pmm  <span class="ot">&lt;-</span> <span class="fu">mice</span>(data_het_miss, <span class="at">method =</span> <span class="st">&quot;pmm&quot;</span>, <span class="at">m =</span> <span class="dv">1</span>)</span>
<span id="cb363-2"><a href="methods-for-handling-missing-data.html#cb363-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb363-3"><a href="methods-for-handling-missing-data.html#cb363-3" tabindex="-1"></a><span class="co">#&gt;  iter imp variable</span></span>
<span id="cb363-4"><a href="methods-for-handling-missing-data.html#cb363-4" tabindex="-1"></a><span class="co">#&gt;   1   1  y</span></span>
<span id="cb363-5"><a href="methods-for-handling-missing-data.html#cb363-5" tabindex="-1"></a><span class="co">#&gt;   2   1  y</span></span>
<span id="cb363-6"><a href="methods-for-handling-missing-data.html#cb363-6" tabindex="-1"></a><span class="co">#&gt;   3   1  y</span></span>
<span id="cb363-7"><a href="methods-for-handling-missing-data.html#cb363-7" tabindex="-1"></a><span class="co">#&gt;   4   1  y</span></span>
<span id="cb363-8"><a href="methods-for-handling-missing-data.html#cb363-8" tabindex="-1"></a><span class="co">#&gt;   5   1  y</span></span>
<span id="cb363-9"><a href="methods-for-handling-missing-data.html#cb363-9" tabindex="-1"></a>data_het_pmm <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp_het_pmm)</span></code></pre></div>
<p>Comparison between predictive mean matching and stochastic regression imputation</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="methods-for-handling-missing-data.html#cb364-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))                              <span class="co"># Both plots in one graphic</span></span>
<span id="cb364-2"><a href="methods-for-handling-missing-data.html#cb364-2" tabindex="-1"></a></span>
<span id="cb364-3"><a href="methods-for-handling-missing-data.html#cb364-3" tabindex="-1"></a><span class="co"># Plot of observed values</span></span>
<span id="cb364-4"><a href="methods-for-handling-missing-data.html#cb364-4" tabindex="-1"></a><span class="fu">plot</span>(x[<span class="sc">!</span><span class="fu">is.na</span>(data_het_sri<span class="sc">$</span>y)],</span>
<span id="cb364-5"><a href="methods-for-handling-missing-data.html#cb364-5" tabindex="-1"></a>     data_het_sri<span class="sc">$</span>y[<span class="sc">!</span><span class="fu">is.na</span>(data_het_sri<span class="sc">$</span>y)],</span>
<span id="cb364-6"><a href="methods-for-handling-missing-data.html#cb364-6" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb364-7"><a href="methods-for-handling-missing-data.html#cb364-7" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;X&quot;</span>,</span>
<span id="cb364-8"><a href="methods-for-handling-missing-data.html#cb364-8" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Y&quot;</span>)</span>
<span id="cb364-9"><a href="methods-for-handling-missing-data.html#cb364-9" tabindex="-1"></a><span class="co"># Plot of missing values</span></span>
<span id="cb364-10"><a href="methods-for-handling-missing-data.html#cb364-10" tabindex="-1"></a><span class="fu">points</span>(x[<span class="fu">is.na</span>(y)], data_het_sri<span class="sc">$</span>y[<span class="fu">is.na</span>(y)],</span>
<span id="cb364-11"><a href="methods-for-handling-missing-data.html#cb364-11" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb364-12"><a href="methods-for-handling-missing-data.html#cb364-12" tabindex="-1"></a></span>
<span id="cb364-13"><a href="methods-for-handling-missing-data.html#cb364-13" tabindex="-1"></a><span class="co"># Title of plot</span></span>
<span id="cb364-14"><a href="methods-for-handling-missing-data.html#cb364-14" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Stochastic Regression Imputation&quot;</span>,        </span>
<span id="cb364-15"><a href="methods-for-handling-missing-data.html#cb364-15" tabindex="-1"></a>      <span class="at">line =</span> <span class="fl">0.5</span>)</span>
<span id="cb364-16"><a href="methods-for-handling-missing-data.html#cb364-16" tabindex="-1"></a></span>
<span id="cb364-17"><a href="methods-for-handling-missing-data.html#cb364-17" tabindex="-1"></a><span class="co"># Regression line</span></span>
<span id="cb364-18"><a href="methods-for-handling-missing-data.html#cb364-18" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, data_het_sri),                   </span>
<span id="cb364-19"><a href="methods-for-handling-missing-data.html#cb364-19" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;#1b98e0&quot;</span>, <span class="at">lwd =</span> <span class="fl">2.5</span>)</span>
<span id="cb364-20"><a href="methods-for-handling-missing-data.html#cb364-20" tabindex="-1"></a></span>
<span id="cb364-21"><a href="methods-for-handling-missing-data.html#cb364-21" tabindex="-1"></a><span class="co"># Legend</span></span>
<span id="cb364-22"><a href="methods-for-handling-missing-data.html#cb364-22" tabindex="-1"></a><span class="fu">legend</span>(</span>
<span id="cb364-23"><a href="methods-for-handling-missing-data.html#cb364-23" tabindex="-1"></a>  <span class="st">&quot;topleft&quot;</span>,</span>
<span id="cb364-24"><a href="methods-for-handling-missing-data.html#cb364-24" tabindex="-1"></a>  <span class="fu">c</span>(<span class="st">&quot;Observed Values&quot;</span>, <span class="st">&quot;Imputed Values&quot;</span>, <span class="st">&quot;Regression Y ~ X&quot;</span>),</span>
<span id="cb364-25"><a href="methods-for-handling-missing-data.html#cb364-25" tabindex="-1"></a>  <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="cn">NA</span>),</span>
<span id="cb364-26"><a href="methods-for-handling-missing-data.html#cb364-26" tabindex="-1"></a>  <span class="at">lty =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="cn">NA</span>, <span class="dv">1</span>),</span>
<span id="cb364-27"><a href="methods-for-handling-missing-data.html#cb364-27" tabindex="-1"></a>  <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;#1b98e0&quot;</span>)</span>
<span id="cb364-28"><a href="methods-for-handling-missing-data.html#cb364-28" tabindex="-1"></a>)</span>
<span id="cb364-29"><a href="methods-for-handling-missing-data.html#cb364-29" tabindex="-1"></a></span>
<span id="cb364-30"><a href="methods-for-handling-missing-data.html#cb364-30" tabindex="-1"></a><span class="co"># Plot of observed values</span></span>
<span id="cb364-31"><a href="methods-for-handling-missing-data.html#cb364-31" tabindex="-1"></a><span class="fu">plot</span>(x[<span class="sc">!</span><span class="fu">is.na</span>(data_het_pmm<span class="sc">$</span>y)],</span>
<span id="cb364-32"><a href="methods-for-handling-missing-data.html#cb364-32" tabindex="-1"></a>     data_het_pmm<span class="sc">$</span>y[<span class="sc">!</span><span class="fu">is.na</span>(data_het_pmm<span class="sc">$</span>y)],</span>
<span id="cb364-33"><a href="methods-for-handling-missing-data.html#cb364-33" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb364-34"><a href="methods-for-handling-missing-data.html#cb364-34" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;X&quot;</span>,</span>
<span id="cb364-35"><a href="methods-for-handling-missing-data.html#cb364-35" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Y&quot;</span>)</span>
<span id="cb364-36"><a href="methods-for-handling-missing-data.html#cb364-36" tabindex="-1"></a></span>
<span id="cb364-37"><a href="methods-for-handling-missing-data.html#cb364-37" tabindex="-1"></a></span>
<span id="cb364-38"><a href="methods-for-handling-missing-data.html#cb364-38" tabindex="-1"></a><span class="co"># Plot of missing values</span></span>
<span id="cb364-39"><a href="methods-for-handling-missing-data.html#cb364-39" tabindex="-1"></a><span class="fu">points</span>(x[<span class="fu">is.na</span>(y)], data_het_pmm<span class="sc">$</span>y[<span class="fu">is.na</span>(y)],</span>
<span id="cb364-40"><a href="methods-for-handling-missing-data.html#cb364-40" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb364-41"><a href="methods-for-handling-missing-data.html#cb364-41" tabindex="-1"></a></span>
<span id="cb364-42"><a href="methods-for-handling-missing-data.html#cb364-42" tabindex="-1"></a><span class="co"># Title of plot</span></span>
<span id="cb364-43"><a href="methods-for-handling-missing-data.html#cb364-43" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Predictive Mean Matching&quot;</span>,</span>
<span id="cb364-44"><a href="methods-for-handling-missing-data.html#cb364-44" tabindex="-1"></a>      <span class="at">line =</span> <span class="fl">0.5</span>)</span>
<span id="cb364-45"><a href="methods-for-handling-missing-data.html#cb364-45" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, data_het_pmm),</span>
<span id="cb364-46"><a href="methods-for-handling-missing-data.html#cb364-46" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&quot;#1b98e0&quot;</span>, <span class="at">lwd =</span> <span class="fl">2.5</span>)</span>
<span id="cb364-47"><a href="methods-for-handling-missing-data.html#cb364-47" tabindex="-1"></a></span>
<span id="cb364-48"><a href="methods-for-handling-missing-data.html#cb364-48" tabindex="-1"></a><span class="co"># Legend</span></span>
<span id="cb364-49"><a href="methods-for-handling-missing-data.html#cb364-49" tabindex="-1"></a><span class="fu">legend</span>(</span>
<span id="cb364-50"><a href="methods-for-handling-missing-data.html#cb364-50" tabindex="-1"></a>  <span class="st">&quot;topleft&quot;</span>,</span>
<span id="cb364-51"><a href="methods-for-handling-missing-data.html#cb364-51" tabindex="-1"></a>  <span class="fu">c</span>(<span class="st">&quot;Observed Values&quot;</span>, <span class="st">&quot;Imputed Values&quot;</span>, <span class="st">&quot;Regression Y ~ X&quot;</span>),</span>
<span id="cb364-52"><a href="methods-for-handling-missing-data.html#cb364-52" tabindex="-1"></a>  <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="cn">NA</span>),</span>
<span id="cb364-53"><a href="methods-for-handling-missing-data.html#cb364-53" tabindex="-1"></a>  <span class="at">lty =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="cn">NA</span>, <span class="dv">1</span>),</span>
<span id="cb364-54"><a href="methods-for-handling-missing-data.html#cb364-54" tabindex="-1"></a>  <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;#1b98e0&quot;</span>)</span>
<span id="cb364-55"><a href="methods-for-handling-missing-data.html#cb364-55" tabindex="-1"></a>)</span>
<span id="cb364-56"><a href="methods-for-handling-missing-data.html#cb364-56" tabindex="-1"></a></span>
<span id="cb364-57"><a href="methods-for-handling-missing-data.html#cb364-57" tabindex="-1"></a><span class="fu">mtext</span>(</span>
<span id="cb364-58"><a href="methods-for-handling-missing-data.html#cb364-58" tabindex="-1"></a>  <span class="st">&quot;Imputation of Heteroscedastic Data&quot;</span>,</span>
<span id="cb364-59"><a href="methods-for-handling-missing-data.html#cb364-59" tabindex="-1"></a>  <span class="co"># Main title of plot</span></span>
<span id="cb364-60"><a href="methods-for-handling-missing-data.html#cb364-60" tabindex="-1"></a>  <span class="at">side =</span> <span class="dv">3</span>,</span>
<span id="cb364-61"><a href="methods-for-handling-missing-data.html#cb364-61" tabindex="-1"></a>  <span class="at">line =</span> <span class="sc">-</span><span class="fl">1.5</span>,</span>
<span id="cb364-62"><a href="methods-for-handling-missing-data.html#cb364-62" tabindex="-1"></a>  <span class="at">outer =</span> <span class="cn">TRUE</span>,</span>
<span id="cb364-63"><a href="methods-for-handling-missing-data.html#cb364-63" tabindex="-1"></a>  <span class="at">cex =</span> <span class="dv">2</span></span>
<span id="cb364-64"><a href="methods-for-handling-missing-data.html#cb364-64" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="11-imputation_files/figure-html/unnamed-chunk-19-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="matrix-completion" class="section level4 hasAnchor" number="11.4.2.5">
<h4><span class="header-section-number">11.4.2.5</span> Matrix Completion<a href="methods-for-handling-missing-data.html#matrix-completion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Matrix completion is a method used to impute missing data in a feature matrix while accounting for dependence between features. This approach leverages principal components to approximate the data matrix, a process referred to as <strong>matrix completion</strong> <span class="citation">(<a href="#ref-james2013">James et al. 2013</a>, Sec 12.3)</span>.</p>
<p><strong>Problem Setup</strong></p>
<p>Consider an <span class="math inline">\(n \times p\)</span> feature matrix <span class="math inline">\(\mathbf{X}\)</span>, where the element <span class="math inline">\(x_{ij}\)</span> represents the value for the <span class="math inline">\(i\)</span>th observation and <span class="math inline">\(j\)</span>th feature. Some elements of <span class="math inline">\(\mathbf{X}\)</span> are missing, and we aim to impute these missing values.</p>
<p>Similar to the process described in <a href="principal-components.html#principal-components">22.2</a>, the matrix <span class="math inline">\(\mathbf{X}\)</span> can be approximated using its leading principal components. Specifically, we consider <span class="math inline">\(M\)</span> principal components that minimize the following objective:</p>
<p><span class="math display">\[
\underset{\mathbf{A} \in \mathbb{R}^{n \times M}, \mathbf{B} \in \mathbb{R}^{p \times M}}{\operatorname{min}} \left\{ \sum_{(i,j) \in \mathcal{O}} (x_{ij} - \sum_{m=1}^M a_{im}b_{jm})^2 \right\}
\]</span></p>
<p>where <span class="math inline">\(\mathcal{O}\)</span> is the set of observed indices <span class="math inline">\((i,j)\)</span>, which is a subset of the total <span class="math inline">\(n \times p\)</span> pairs. Here: - <span class="math inline">\(\mathbf{A}\)</span> is an <span class="math inline">\(n \times M\)</span> matrix of principal component scores. - <span class="math inline">\(\mathbf{B}\)</span> is a <span class="math inline">\(p \times M\)</span> matrix of principal component loadings.</p>
<p><strong>Imputation of Missing Values</strong></p>
<p>After solving the minimization problem:</p>
<ol style="list-style-type: decimal">
<li>Missing observations <span class="math inline">\(x_{ij}\)</span> can be imputed using the formula: <span class="math display">\[
   \hat{x}_{ij} = \sum_{m=1}^M \hat{a}_{im}\hat{b}_{jm}
   \]</span> where <span class="math inline">\(\hat{a}_{im}\)</span> and <span class="math inline">\(\hat{b}_{jm}\)</span> are the estimated elements of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>, respectively.</li>
<li>The leading <span class="math inline">\(M\)</span> principal component scores and loadings can be approximately recovered, as is done in complete data scenarios.</li>
</ol>
<p><strong>Iterative Algorithm</strong></p>
<p>The eigen-decomposition used in standard principal component analysis is not applicable here because of missing values. Instead, an iterative algorithm, as described in <span class="citation">(<a href="#ref-james2013">James et al. 2013</a>, Alg 12.1)</span>, is employed:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Initialize the Complete Matrix</strong>: Construct an initial complete matrix <span class="math inline">\(\tilde{\mathbf{X}}\)</span> of dimension <span class="math inline">\(n \times p\)</span> where: <span class="math display">\[
\tilde{x}_{ij} =
\begin{cases}
x_{ij} &amp; \text{if } (i,j) \in \mathcal{O} \\
\bar{x}_j &amp; \text{if } (i,j) \notin \mathcal{O}
\end{cases}
\]</span> Here, <span class="math inline">\(\bar{x}_j\)</span> is the mean of the observed values for the <span class="math inline">\(j\)</span>th variable in the incomplete data matrix <span class="math inline">\(\mathbf{X}\)</span>. <span class="math inline">\(\mathcal{O}\)</span> indexes the observed elements of <span class="math inline">\(\mathbf{X}\)</span>.</p></li>
<li><p><strong>Iterative Steps</strong>: Repeat the following steps until convergence:</p>
<ul>
<li><p><strong>Minimize the Objective</strong>: Solve the problem: <span class="math display">\[
\underset{\mathbf{A} \in R^{n \times M}, \mathbf{B} \in R^{p \times M}}{\operatorname{min}} \left\{ \sum_{(i,j) \in \mathcal{O}} (x_{ij} - \sum_{m=1}^M a_{im}b_{jm})^2 \right\}
\]</span> by computing the principal components of the current <span class="math inline">\(\tilde{\mathbf{X}}\)</span>.</p></li>
<li><p><strong>Update Missing Values</strong>: For each missing element <span class="math inline">\((i,j) \notin \mathcal{O}\)</span>, set: <span class="math display">\[
\tilde{x}_{ij} \leftarrow \sum_{m=1}^M \hat{a}_{im}\hat{b}_{jm}
\]</span></p></li>
<li><p><strong>Recalculate the Objective</strong>: Compute the objective: <span class="math display">\[
\sum_{(i,j) \in \mathcal{O}} (x_{ij} - \sum_{m=1}^M \hat{a}_{im} \hat{b}_{jm})^2
\]</span></p></li>
</ul></li>
<li><p><strong>Return Imputed Values</strong>: Once the algorithm converges, return the estimated missing entries <span class="math inline">\(\tilde{x}_{ij}\)</span> for <span class="math inline">\((i,j) \notin \mathcal{O}\)</span>.</p></li>
</ol>
<p><strong>Key Considerations</strong></p>
<ul>
<li>This approach assumes that the missing data are missing at random (MAR).</li>
<li>Convergence criteria for the iterative algorithm often involve achieving a threshold for the change in the objective function or limiting the number of iterations.</li>
<li>The choice of <span class="math inline">\(M\)</span>, the number of principal components, can be guided by cross-validation or other model selection techniques.</li>
</ul>
</div>
<div id="comparison-of-single-imputation-techniques" class="section level4 hasAnchor" number="11.4.2.6">
<h4><span class="header-section-number">11.4.2.6</span> Comparison of Single Imputation Techniques<a href="methods-for-handling-missing-data.html#comparison-of-single-imputation-techniques" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<table>
<colgroup>
<col width="25%" />
<col width="30%" />
<col width="44%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Method</strong></th>
<th><strong>Advantages</strong></th>
<th><strong>Disadvantages</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Mean, Median, Mode Imputation</strong></td>
<td>Simple, quick implementation.</td>
<td>Biased variances and covariances; ignores relationships among variables.</td>
</tr>
<tr class="even">
<td><strong>Forward/Backward Filling</strong></td>
<td>Preserves temporal ordering.</td>
<td>Biased for systematic gaps or long missing sequences.</td>
</tr>
<tr class="odd">
<td><strong>Linear Regression Imputation</strong></td>
<td>Preserves relationships among variables.</td>
<td>Fails to capture variability; assumes linearity.</td>
</tr>
<tr class="even">
<td><strong>Logistic Regression Imputation</strong></td>
<td>Handles categorical variables well.</td>
<td>Requires appropriate model assumptions; ignores variability.</td>
</tr>
<tr class="odd">
<td><strong>PMM</strong></td>
<td>Maintains variability; imputes realistic values.</td>
<td>Computationally intensive; requires a good predictive model.</td>
</tr>
<tr class="even">
<td><strong>Hot Deck Imputation</strong></td>
<td>Flexible; maintains data distribution.</td>
<td>Sensitive to donor selection; computationally demanding.</td>
</tr>
<tr class="odd">
<td><strong>Cold Deck Imputation</strong></td>
<td>Consistent across datasets with predefined donor pools.</td>
<td>Risk of bias if donor data are not representative.</td>
</tr>
<tr class="even">
<td><strong>Random Draw from Observed</strong></td>
<td>Simple; retains variability in data.</td>
<td>Does not preserve relationships among variables; random imputation may distort trends.</td>
</tr>
<tr class="odd">
<td><strong>Matrix Completion</strong></td>
<td>Captures dependencies; imputes structurally consistent values.</td>
<td>Computationally intensive; assumes principal components capture data relationships.</td>
</tr>
</tbody>
</table>
<p>Single imputation techniques are straightforward and accessible, but they often underestimate uncertainty and fail to fully leverage relationships among variables. These limitations make them less ideal for rigorous analyses compared to multiple imputation or model-based approaches.</p>
</div>
</div>
<div id="machine-learning-and-modern-approaches" class="section level3 hasAnchor" number="11.4.3">
<h3><span class="header-section-number">11.4.3</span> Machine Learning and Modern Approaches<a href="methods-for-handling-missing-data.html#machine-learning-and-modern-approaches" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="tree-based-methods" class="section level4 hasAnchor" number="11.4.3.1">
<h4><span class="header-section-number">11.4.3.1</span> Tree-Based Methods<a href="methods-for-handling-missing-data.html#tree-based-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="random-forest-imputation-missforest" class="section level5 hasAnchor" number="11.4.3.1.1">
<h5><span class="header-section-number">11.4.3.1.1</span> Random Forest Imputation (missForest)<a href="methods-for-handling-missing-data.html#random-forest-imputation-missforest" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Random Forest Imputation uses an iterative process where a random forest model predicts missing values for one variable at a time, treating other variables as predictors. This process continues until convergence.</p>
<ul>
<li><strong>Mathematical Framework</strong>:
<ol style="list-style-type: decimal">
<li>For a variable <span class="math inline">\(X_j\)</span> with missing values, treat <span class="math inline">\(X_j\)</span> as the response variable.</li>
<li>Fit a random forest model <span class="math inline">\(f(X_{-j})\)</span> using the other variables <span class="math inline">\(X_{-j}\)</span> as predictors.</li>
<li>Predict missing values <span class="math inline">\(\hat{X}_j = f(X_{-j})\)</span>.</li>
<li>Repeat for all variables with missing data until imputed values stabilize.</li>
</ol></li>
<li><strong>Advantages</strong>:
<ul>
<li>Captures complex interactions and non-linearities.</li>
<li>Handles mixed data types seamlessly.</li>
</ul></li>
<li><strong>Limitations</strong>:
<ul>
<li>Computationally intensive for large datasets.</li>
<li>Sensitive to the quality of data relationships.</li>
</ul></li>
</ul>
<hr />
</div>
<div id="gradient-boosting-machines-gbm" class="section level5 hasAnchor" number="11.4.3.1.2">
<h5><span class="header-section-number">11.4.3.1.2</span> Gradient Boosting Machines (GBM)<a href="methods-for-handling-missing-data.html#gradient-boosting-machines-gbm" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Gradient Boosting Machines iteratively build models to minimize loss functions. For imputation, missing values are treated as a target variable to be predicted.</p>
<ul>
<li><p><strong>Mathematical Framework</strong>: The GBM algorithm minimizes the loss function: <span class="math display">\[
  L = \sum_{i=1}^n \ell(y_i, f(x_i)),
  \]</span> where <span class="math inline">\(\ell\)</span> is the loss function (e.g., mean squared error), <span class="math inline">\(y_i\)</span> are observed values, and <span class="math inline">\(f(x_i)\)</span> are predictions.</p></li>
<li><p>Missing values are treated as the <span class="math inline">\(y_i\)</span> and predicted iteratively.</p></li>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Highly accurate predictions.</li>
<li>Captures variable importance.</li>
</ul></li>
<li><p><strong>Limitations</strong>:</p>
<ul>
<li>Overfitting risks.</li>
<li>Requires careful parameter tuning.</li>
</ul></li>
</ul>
<hr />
</div>
</div>
<div id="neural-network-based-imputation" class="section level4 hasAnchor" number="11.4.3.2">
<h4><span class="header-section-number">11.4.3.2</span> Neural Network-Based Imputation<a href="methods-for-handling-missing-data.html#neural-network-based-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="autoencoders" class="section level5 hasAnchor" number="11.4.3.2.1">
<h5><span class="header-section-number">11.4.3.2.1</span> Autoencoders<a href="methods-for-handling-missing-data.html#autoencoders" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Autoencoders are unsupervised neural networks that compress and reconstruct data. Missing values are estimated during reconstruction.</p>
<ul>
<li><p><strong>Mathematical Framework</strong>: An autoencoder consists of:</p>
<ol style="list-style-type: decimal">
<li>An encoder function: <span class="math inline">\(h = g(Wx + b)\)</span>, which compresses the input <span class="math inline">\(x\)</span>.</li>
<li>A decoder function: <span class="math inline">\(\hat{x} = g&#39;(W&#39;h + b&#39;)\)</span>, which reconstructs the data.</li>
</ol></li>
<li><p>The network minimizes the reconstruction loss: <span class="math display">\[
  L = \sum_{i=1}^n (x_i - \hat{x}_i)^2.
  \]</span></p></li>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Handles high-dimensional and non-linear data.</li>
<li>Unsupervised learning.</li>
</ul></li>
<li><p><strong>Limitations</strong>:</p>
<ul>
<li>Computationally demanding.</li>
<li>Requires large datasets for effective training.</li>
</ul></li>
</ul>
<hr />
</div>
<div id="generative-adversarial-networks-gans-for-data-imputation" class="section level5 hasAnchor" number="11.4.3.2.2">
<h5><span class="header-section-number">11.4.3.2.2</span> Generative Adversarial Networks (GANs) for Data Imputation<a href="methods-for-handling-missing-data.html#generative-adversarial-networks-gans-for-data-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>GANs consist of a generator and a discriminator. For imputation, the generator fills in missing values, and the discriminator evaluates the quality of the imputations.</p>
<ul>
<li><strong>Mathematical Framework</strong>: GAN training involves optimizing: <span class="math display">\[
  \min_G \max_D \mathbb{E}[\log D(x)] + \mathbb{E}[\log(1 - D(G(z)))].
  \]</span>
<ul>
<li><span class="math inline">\(D(x)\)</span>: Discriminator’s probability that <span class="math inline">\(x\)</span> is real.</li>
<li><span class="math inline">\(G(z)\)</span>: Generator’s output for latent input <span class="math inline">\(z\)</span>.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>Realistic imputations that reflect underlying distributions.</li>
<li>Handles complex data types.</li>
</ul></li>
<li><strong>Limitations</strong>:
<ul>
<li>Difficult to train and tune.</li>
<li>Computationally intensive.</li>
</ul></li>
</ul>
<hr />
</div>
</div>
<div id="matrix-factorization-and-matrix-completion" class="section level4 hasAnchor" number="11.4.3.3">
<h4><span class="header-section-number">11.4.3.3</span> Matrix Factorization and Matrix Completion<a href="methods-for-handling-missing-data.html#matrix-factorization-and-matrix-completion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="singular-value-decomposition-svd" class="section level5 hasAnchor" number="11.4.3.3.1">
<h5><span class="header-section-number">11.4.3.3.1</span> Singular Value Decomposition (SVD)<a href="methods-for-handling-missing-data.html#singular-value-decomposition-svd" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>SVD decomposes a matrix <span class="math inline">\(A\)</span> into three matrices: <span class="math display">\[
A = U\Sigma V^T,
\]</span> where <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are orthogonal matrices, and <span class="math inline">\(\Sigma\)</span> contains singular values. Missing values are estimated by reconstructing <span class="math inline">\(A\)</span> using a low-rank approximation: <span class="math display">\[
\hat{A} = U_k \Sigma_k V_k^T.
\]</span></p>
<ul>
<li><strong>Advantages</strong>:
<ul>
<li>Captures global patterns.</li>
<li>Efficient for structured data.</li>
</ul></li>
<li><strong>Limitations</strong>:
<ul>
<li>Assumes linear relationships.</li>
<li>Sensitive to sparsity.</li>
</ul></li>
</ul>
<hr />
</div>
<div id="collaborative-filtering-approaches" class="section level5 hasAnchor" number="11.4.3.3.2">
<h5><span class="header-section-number">11.4.3.3.2</span> Collaborative Filtering Approaches<a href="methods-for-handling-missing-data.html#collaborative-filtering-approaches" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Collaborative filtering uses similarities between rows (users) or columns (items) to impute missing data. For instance, the value of <span class="math inline">\(X_{ij}\)</span> is predicted as: <span class="math display">\[
\hat{X}_{ij} = \frac{\sum_{k \in N(i)} w_{ik} X_{kj}}{\sum_{k \in N(i)} w_{ik}},
\]</span> where <span class="math inline">\(w_{ik}\)</span> represents similarity weights and <span class="math inline">\(N(i)\)</span> is the set of neighbors.</p>
<hr />
</div>
</div>
<div id="k-nearest-neighbor-knn-imputation" class="section level4 hasAnchor" number="11.4.3.4">
<h4><span class="header-section-number">11.4.3.4</span> K-Nearest Neighbor (KNN) Imputation<a href="methods-for-handling-missing-data.html#k-nearest-neighbor-knn-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>KNN identifies the <span class="math inline">\(k\)</span> nearest observations based on a distance metric and imputes missing values using a weighted average (continuous variables) or mode (categorical variables).</p>
<ul>
<li><p><strong>Mathematical Framework</strong>: For a missing value <span class="math inline">\(x\)</span>, its imputed value is: <span class="math display">\[
  \hat{x} = \frac{\sum_{i=1}^k w_i x_i}{\sum_{i=1}^k w_i},
  \]</span> where <span class="math inline">\(w_i = \frac{1}{d(x, x_i)}\)</span> and <span class="math inline">\(d(x, x_i)\)</span> is a distance metric (e.g., Euclidean or Manhattan).</p></li>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Simple and interpretable.</li>
<li>Non-parametric.</li>
</ul></li>
<li><p><strong>Limitations</strong>:</p>
<ul>
<li>Computationally expensive for large datasets.</li>
</ul></li>
</ul>
<hr />
</div>
<div id="hybrid-methods" class="section level4 hasAnchor" number="11.4.3.5">
<h4><span class="header-section-number">11.4.3.5</span> Hybrid Methods<a href="methods-for-handling-missing-data.html#hybrid-methods" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Hybrid methods combine statistical and machine learning approaches. For example, mean imputation followed by fine-tuning with machine learning models. These methods aim to leverage the strengths of multiple techniques.</p>
<hr />
</div>
<div id="summary-table" class="section level4 hasAnchor" number="11.4.3.6">
<h4><span class="header-section-number">11.4.3.6</span> Summary Table<a href="methods-for-handling-missing-data.html#summary-table" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<table>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Advantages</th>
<th>Limitations</th>
<th>Applications</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Random Forest (missForest)</td>
<td>Handles mixed data types, captures interactions</td>
<td>Computationally intensive</td>
<td>Mixed data types</td>
</tr>
<tr class="even">
<td>Gradient Boosting Machines</td>
<td>High accuracy, feature importance</td>
<td>Sensitive to parameters</td>
<td>Predictive tasks</td>
</tr>
<tr class="odd">
<td>Autoencoders</td>
<td>Handles high-dimensional, non-linear data</td>
<td>Computationally expensive</td>
<td>Complex datasets</td>
</tr>
<tr class="even">
<td>GANs</td>
<td>Realistic imputations, complex distributions</td>
<td>Difficult to train, resource-intensive</td>
<td>Healthcare, finance</td>
</tr>
<tr class="odd">
<td>SVD</td>
<td>Captures global patterns, efficient</td>
<td>Assumes linear relationships</td>
<td>Recommendation systems</td>
</tr>
<tr class="even">
<td>Collaborative Filtering</td>
<td>Intuitive for user-item data</td>
<td>Struggles with sparse or new data</td>
<td>Recommender systems</td>
</tr>
<tr class="odd">
<td>KNN Imputation</td>
<td>Simple, interpretable</td>
<td>Computationally intensive, sensitive to k</td>
<td>General-purpose</td>
</tr>
<tr class="even">
<td>Hybrid Methods</td>
<td>Combines multiple strengths</td>
<td>Complexity in design</td>
<td>Flexible</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="multiple-imputation" class="section level3 hasAnchor" number="11.4.4">
<h3><span class="header-section-number">11.4.4</span> Multiple Imputation<a href="methods-for-handling-missing-data.html#multiple-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Multiple Imputation (MI) is a statistical technique for handling missing data by creating several plausible datasets through imputation, analyzing each dataset separately, and then combining the results to account for uncertainty in the imputations. MI operates under the assumption that missing data is either <a href="theoretical-foundations-of-missing-data.html#missing-completely-at-random-mcar">Missing Completely at Random (MCAR)</a> or <a href="theoretical-foundations-of-missing-data.html#missing-at-random-mar">Missing at Random (MAR)</a>.</p>
<p>Unlike <a href="methods-for-handling-missing-data.html#single-imputation-techniques">Single Imputation Techniques</a>, MI reflects the uncertainty inherent in the missing data by introducing variability in the imputed values. It avoids biases introduced by ad hoc methods and produces more reliable statistical inferences.</p>
<p>The three fundamental steps in MI are:</p>
<ol style="list-style-type: decimal">
<li><strong>Imputation</strong>: Replace missing values with a set of plausible values to create multiple “completed” datasets.</li>
<li><strong>Analysis</strong>: Perform the desired statistical analysis on each imputed dataset.</li>
<li><strong>Combination</strong>: Combine the results using rules to account for within- and between-imputation variability.</li>
</ol>
<div id="why-multiple-imputation-is-important" class="section level4 hasAnchor" number="11.4.4.1">
<h4><span class="header-section-number">11.4.4.1</span> Why Multiple Imputation is Important<a href="methods-for-handling-missing-data.html#why-multiple-imputation-is-important" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Imputed values are estimates and inherently include random error. However, when these estimates are treated as exact values in subsequent analysis, the software may overlook this additional error. This oversight results in <strong>underestimated standard errors and overly small p-values</strong>, leading to misleading conclusions.</p>
<p><strong>Multiple imputation</strong> addresses this issue by generating multiple estimates for each missing value. These estimates differ slightly due to their random component, which reintroduces variation. This variation helps the software incorporate the uncertainty of imputed values, resulting in:</p>
<ul>
<li><p><strong>Unbiased parameter estimates</strong></p></li>
<li><p><strong>Accurate standard errors</strong></p></li>
<li><p><strong>Improved p-values</strong></p></li>
</ul>
<p>Multiple imputation was a significant breakthrough in statistics approximately 20 years ago. It provides solutions for many missing data issues (though not all) and, when applied correctly, leads to reliable parameter estimates.</p>
<p>If the proportion of missing data is very small (e.g., 2-3%), the choice of imputation method is less critical.</p>
</div>
<div id="goals-of-multiple-imputation" class="section level4 hasAnchor" number="11.4.4.2">
<h4><span class="header-section-number">11.4.4.2</span> Goals of Multiple Imputation<a href="methods-for-handling-missing-data.html#goals-of-multiple-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The primary goals of any missing data technique, including multiple imputation, are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Unbiased parameter estimates</strong>: Ensuring accurate regression coefficients, group means, odds ratios, etc.</p></li>
<li><p><strong>Accurate standard errors</strong>: This leads to reliable p-values and appropriate statistical inferences.</p></li>
<li><p><strong>Adequate power</strong>: To detect meaningful and significant parameter values.</p></li>
</ol>
</div>
<div id="overview-of-rubins-framework" class="section level4 hasAnchor" number="11.4.4.3">
<h4><span class="header-section-number">11.4.4.3</span> Overview of Rubin’s Framework<a href="methods-for-handling-missing-data.html#overview-of-rubins-framework" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Rubin’s Framework provides the theoretical foundation for MI. It uses a Bayesian model-based approach for generating imputations and a frequentist approach for evaluating the results. The central goals of Rubin’s framework are to ensure that imputations:</p>
<ul>
<li>Retain the statistical relationships present in the data.</li>
<li>Reflect the uncertainty about the true values of the missing data.</li>
</ul>
<p>Under Rubin’s framework, MI offers the following advantages:</p>
<ul>
<li><strong>Generalizability</strong>: Unlike Maximum Likelihood Estimation (MLE), MI can be applied to a wide range of models.</li>
<li><strong>Statistical Properties</strong>: When data is MAR or MCAR, MI estimates are consistent, asymptotically normal, and efficient.</li>
</ul>
<p>Rubin also emphasized the importance of using multiple imputations, as single imputations fail to account for variability in the imputed values, leading to underestimated standard errors and overly optimistic test statistics.</p>
</div>
<div id="multivariate-imputation-via-chained-equations-mice" class="section level4 hasAnchor" number="11.4.4.4">
<h4><span class="header-section-number">11.4.4.4</span> Multivariate Imputation via Chained Equations (MICE)<a href="methods-for-handling-missing-data.html#multivariate-imputation-via-chained-equations-mice" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Multivariate Imputation via Chained Equations (MICE) is a widely used algorithm for implementing MI, particularly in datasets with mixed variable types. The steps of MICE include:</p>
<ol style="list-style-type: decimal">
<li><strong>Initialization</strong>: Replace missing values with initial guesses, such as the mean or median of the observed data.</li>
<li><strong>Iterative Imputation</strong>:
<ul>
<li>For each variable with missing values, regress it on all other variables (or a subset of relevant predictors).</li>
<li>Use the regression model to predict missing values, adding a random error term drawn from the residual distribution.</li>
</ul></li>
<li><strong>Convergence</strong>: Repeat the imputation process until parameter estimates stabilize.</li>
</ol>
<p>MICE offers flexibility in specifying regression models for each variable, accommodating continuous, categorical, and binary data.</p>
</div>
<div id="bayesian-ridge-regression-for-imputation" class="section level4 hasAnchor" number="11.4.4.5">
<h4><span class="header-section-number">11.4.4.5</span> Bayesian Ridge Regression for Imputation<a href="methods-for-handling-missing-data.html#bayesian-ridge-regression-for-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Bayesian ridge regression is an advanced imputation method that incorporates prior distributions on the regression coefficients, making it particularly useful when:</p>
<ul>
<li>Predictors are highly correlated.</li>
<li>Sample sizes are small.</li>
<li>Missingness is substantial.</li>
</ul>
<p>This method treats the regression coefficients as random variables and samples from their posterior distribution, introducing variability into the imputation process. Bayesian ridge regression is more computationally intensive than simpler methods like MICE but offers greater robustness.</p>
</div>
<div id="combining-results-from-mi-rubins-rules" class="section level4 hasAnchor" number="11.4.4.6">
<h4><span class="header-section-number">11.4.4.6</span> Combining Results from MI (Rubin’s Rules)<a href="methods-for-handling-missing-data.html#combining-results-from-mi-rubins-rules" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Once multiple datasets are imputed and analyzed, Rubin’s Rules are used to combine the results. The goal is to properly account for the uncertainty introduced by missing data. For a parameter of interest <span class="math inline">\(\theta\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Estimate Combination</strong>: <span class="math display">\[
\bar{\theta} = \frac{1}{M} \sum_{m=1}^M \theta_m
\]</span> where <span class="math inline">\(\theta_m\)</span> is the estimate from the <span class="math inline">\(m\)</span>th imputed dataset, and <span class="math inline">\(M\)</span> is the number of imputations.</p></li>
<li><p><strong>Variance Combination</strong>: <span class="math display">\[
T = \bar{W} + \left(1 + \frac{1}{M}\right) B
\]</span> where:</p>
<ul>
<li><span class="math inline">\(\bar{W}\)</span> is the average within-imputation variance.</li>
<li><span class="math inline">\(B\)</span> is the between-imputation variance: <span class="math display">\[
B = \frac{1}{M-1} \sum_{m=1}^M (\theta_m - \bar{\theta})^2
\]</span></li>
</ul></li>
</ol>
<p>These formulas adjust the final variance to reflect uncertainty both within and across imputations.</p>
<div id="challenges" class="section level5 hasAnchor" number="11.4.4.6.1">
<h5><span class="header-section-number">11.4.4.6.1</span> Challenges<a href="methods-for-handling-missing-data.html#challenges" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li><strong>Stochastic Variability</strong>: MI results vary slightly between runs due to its reliance on random draws. To ensure reproducibility, always set a random seed.</li>
<li><strong>Convergence</strong>: Iterative algorithms like MICE may struggle to converge, especially with high proportions of missing data.</li>
<li><strong>Assumption of MAR</strong>: MI assumes that missing data is MAR. If data is Missing Not at Random (MNAR), MI can produce biased results.</li>
</ol>
</div>
<div id="best-practices" class="section level5 hasAnchor" number="11.4.4.6.2">
<h5><span class="header-section-number">11.4.4.6.2</span> Best Practices<a href="methods-for-handling-missing-data.html#best-practices" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li><strong>Algorithm Selection</strong>:
<ul>
<li>Use Multiple Imputation by Chained Equations (MICE) for datasets with mixed data types or when relationships between variables are complex.</li>
<li>Apply Bayesian Ridge Regression for small datasets or when predictors are highly correlated.</li>
</ul></li>
<li><strong>Diagnostic Checks</strong>:
<ul>
<li>Evaluate the quality of imputations and assess convergence using trace plots or diagnostic statistics to ensure reliable results.</li>
</ul></li>
<li><strong>Data Transformations</strong>:
<ul>
<li>For skewed or proportion data, consider applying log or logit transformations before imputation and inverse-transforming afterward to preserve the data’s original scale.</li>
</ul></li>
<li><strong>Handling Non-Linear Relationships</strong>:
<ul>
<li>For non-linear relationships or interactions, stratify imputations by the levels of the categorical variable involved to ensure accurate estimates.</li>
</ul></li>
<li><strong>Number of Imputations</strong>:
<ul>
<li>Use at least 20 imputations for small datasets or datasets with high missingness. This ensures robust and reliable results in downstream analyses.</li>
</ul></li>
<li><strong>Avoid Rounding Imputations for Dummy Variables</strong>:
<ul>
<li>Many imputation methods (e.g., Markov Chain Monte Carlo [MCMC]) assume normality, even for dummy variables. While it was historically recommended to round imputed values to 0 or 1 for binary variables, research shows that this introduces bias in parameter estimates. Instead, leave imputed values as fractional, even though this may seem counter-intuitive.</li>
</ul></li>
<li><strong>Do Not Transform Skewed Variables Before Imputation</strong>:
<ul>
<li>Transforming variables to meet normality assumptions before imputation can distort their relationships with other variables, leading to biased imputations and possibly introducing outliers. It is better to directly impute the skewed variable.</li>
</ul></li>
<li><strong>Use More Imputations</strong>:
<ul>
<li>Traditional advice suggests 5–10 imputations are sufficient for unbiased estimates, but inconsistencies may arise in repeated analyses. [@Bodner_2008] suggests using a number of imputations equal to the percentage of missing data. As additional imputations generally do not significantly increase the computational workload, using more imputations is a prudent choice.</li>
</ul></li>
<li><strong>Create Multiplicative Terms Before Imputation</strong>:
<ul>
<li>When your model includes interaction or quadratic terms, generate these terms before imputing missing values. Imputing first and then generating these terms can introduce bias in their regression parameters, as highlighted by [@von_Hippel_2009].</li>
</ul></li>
</ol>
</div>
</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Glasser_1964" class="csl-entry">
Glasser, MARC. 1964. <span>“Linear Regression Analysis with Missing Observations Among the Independent Variables.”</span> <em>Journal of the American Statistical Association</em> 59 (307): 834–44.
</div>
<div id="ref-haitovsky1968missing" class="csl-entry">
Haitovsky, Yoel. 1968. <span>“Missing Data in Regression Analysis.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 30 (1): 67–82.
</div>
<div id="ref-james2013" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.
</div>
<div id="ref-jones1996indicator" class="csl-entry">
Jones, Michael P. 1996. <span>“Indicator and Stratification Methods for Missing Explanatory Variables in Multiple Linear Regression.”</span> <em>Journal of the American Statistical Association</em> 91 (433): 222–30.
</div>
<div id="ref-Little_1992" class="csl-entry">
———. 1992. <span>“Regression with Missing x’s: A Review.”</span> <em>Journal of the American Statistical Association</em> 87 (420): 1227–37.
</div>
<div id="ref-Vach_1994" class="csl-entry">
Vach, Werner, and Werner Vach. 1994. <span>“Missing Values and Subsampling.”</span> <em>Logistic Regression with Missing Values in the Covariates</em>, 98–102.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="diagnosing-the-missing-data-mechanism.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="evaluation-of-imputation-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/11-imputation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/mikenguyen13/data_analysis/blob/main/11-imputation.Rmd",
"text": null
},
"download": ["data_analysis.pdf", "data_analysis.epub", "data_analysis.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": "https://github.com/mikenguyen13/data_analysis/edit/main/%s"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
