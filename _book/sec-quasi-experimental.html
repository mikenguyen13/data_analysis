<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 26 Quasi-Experimental Methods | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="Quasi-experimental methods are widely used in causal inference when randomized experiments are not feasible. Typically, these methods rely on pre- and post-intervention data and attempt to...">
<meta name="generator" content="bookdown 0.35 with bs4_book()">
<meta property="og:title" content="Chapter 26 Quasi-Experimental Methods | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/sec-quasi-experimental.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="Quasi-experimental methods are widely used in causal inference when randomized experiments are not feasible. Typically, these methods rely on pre- and post-intervention data and attempt to...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 26 Quasi-Experimental Methods | A Guide on Data Analysis">
<meta name="twitter:description" content="Quasi-experimental methods are widely used in causal inference when randomized experiments are not feasible. Typically, these methods rely on pre- and post-intervention data and attempt to...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="active" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="controls.html"><span class="header-section-number">38</span> Controls</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">39</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="sec-quasi-experimental" class="section level1" number="26">
<h1>
<span class="header-section-number">26</span> Quasi-Experimental Methods<a class="anchor" aria-label="anchor" href="#sec-quasi-experimental"><i class="fas fa-link"></i></a>
</h1>
<p>Quasi-experimental methods are widely used in causal inference when randomized experiments are not feasible. Typically, these methods rely on <strong>pre- and post-intervention data</strong> and attempt to identify <strong>exogenous variation</strong> that can be leveraged to estimate causal effects.</p>
<p>Great resources for causal inference include:</p>
<ul>
<li><a href="https://mixtape.scunning.com/introduction.html">Causal Inference Mixtape</a></li>
<li><a href="https://christinecai.github.io/PublicGoods/applied_micro_methods.pdf">Recent Advances in Micro</a></li>
</ul>
<p>The following R packages are useful for implementing quasi-experimental methods:</p>
<ul>
<li>
<a href="https://cran.r-project.org/web/views/Econometrics.html">Econometrics</a>: Covers a broad range of econometric techniques.</li>
<li>
<a href="https://cran.r-project.org/web/views/CausalInference.html">Causal Inference</a>: Provides tools for estimating causal effects under different identification assumptions.</li>
</ul>
<p>While internal validity ensures a credible causal effect, external validity assesses whether the findings <strong>generalize</strong> beyond the sample.</p>
<p>Key considerations:</p>
<ul>
<li>Representativeness of the Sample</li>
<li>Limitations of the Design</li>
<li>Using Quasi-Experimental Results with Structural Models
<ul>
<li>See <span class="citation">(<a href="references.html#ref-anderson2015growth">J. E. Anderson, Larch, and Yotov 2015</a>)</span>, <span class="citation">(<a href="references.html#ref-einav2010beyond">Einav, Finkelstein, and Levin 2010</a>)</span>, and <span class="citation">(<a href="references.html#ref-chung2014bonuses">Chung, Steenburgh, and Sudhir 2014</a>)</span> for applications.</li>
</ul>
</li>
</ul>
<hr>
<div id="identification-strategy-in-quasi-experiments" class="section level2" number="26.1">
<h2>
<span class="header-section-number">26.1</span> Identification Strategy in Quasi-Experiments<a class="anchor" aria-label="anchor" href="#identification-strategy-in-quasi-experiments"><i class="fas fa-link"></i></a>
</h2>
<p>Unlike randomized experiments, quasi-experiments lack <strong>formal statistical proof</strong> of causality. Instead, researchers must build a <strong>plausible argument</strong> supported by empirical evidence.</p>
<p>Key components of an identification strategy:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Source of Exogenous Variation</strong>
<ul>
<li>Justify where the exogenous variation originates.</li>
<li>Use institutional knowledge and theoretical arguments to support this claim.</li>
</ul>
</li>
<li>
<strong>Exclusion Restriction</strong>
<ul>
<li>Provide evidence that variation in the exogenous shock affects the outcome only through the proposed mechanism.</li>
<li>This requires ruling out confounding factors.</li>
</ul>
</li>
<li>
<strong>Stable Unit Treatment Value Assumption</strong>
<ul>
<li>The treatment of unit <span class="math inline">\(i\)</span> should only affect the outcome of unit <span class="math inline">\(i\)</span>.</li>
<li>No spillovers or interference between treatment and control groups.</li>
</ul>
</li>
</ol>
<p>Every quasi-experimental method involves a <strong>tradeoff between statistical power and support for the exogeneity assumption</strong>. This means that researchers often discard variation in the data that does not meet the exogeneity assumption.</p>
<p><strong>Important Notes:</strong></p>
<ul>
<li><p><span class="math inline">\(R^2\)</span> is not a reliable metric in causal inference and can be misleading for model comparison <span class="citation">(<a href="references.html#ref-ebbes2011sense">Ebbes, Papies, and Van Heerde 2011</a>)</span>.</p></li>
<li><p>Clustering should be determined based on the study design, not just expectations of correlation <span class="citation">(<a href="references.html#ref-abadie2023should">Abadie et al. 2023</a>)</span>.</p></li>
<li><p>For small samples, use the wild bootstrap procedure to correct for downward bias <span class="citation">(<a href="references.html#ref-cameron2008bootstrap">Cameron, Gelbach, and Miller 2008</a>)</span>. See also <span class="citation">(<a href="references.html#ref-cai2022implementation">Cai et al. 2022</a>)</span> for further assumptions.</p></li>
</ul>
<hr>
</div>
<div id="robustness-checks" class="section level2" number="26.2">
<h2>
<span class="header-section-number">26.2</span> Robustness Checks<a class="anchor" aria-label="anchor" href="#robustness-checks"><i class="fas fa-link"></i></a>
</h2>
<p>Robustness checks are essential to demonstrate that findings are not driven by model specification choices.</p>
<p>Recommended robustness checks <span class="citation">(<a href="references.html#ref-goldfarb2022conducting">Goldfarb, Tucker, and Wang 2022</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Alternative Control Sets</strong>
<ul>
<li>Show results with and without controls.</li>
<li>Examine how the estimate of interest changes.</li>
<li>Use <strong>Rosenbaum bounds</strong> for formal sensitivity analysis <span class="citation">(<a href="references.html#ref-altonji2005selection">Altonji, Elder, and Taber 2005</a>)</span>.</li>
<li>In marketing applications, see <span class="citation">(<a href="references.html#ref-manchanda2015social">Manchanda, Packard, and Pattabhiramaiah 2015</a>)</span> and <span class="citation">(<a href="references.html#ref-shin2012fire">Shin, Sudhir, and Yoon 2012</a>)</span>.</li>
</ul>
</li>
<li>
<strong>Different Functional Forms</strong>
<ul>
<li>Check whether the results hold under different model specifications (e.g., linear vs. non-linear models).</li>
</ul>
</li>
<li>
<strong>Varying Time Windows</strong>
<ul>
<li>In longitudinal settings, test different time frames to ensure robustness.</li>
</ul>
</li>
<li>
<strong>Alternative Dependent Variables</strong>
<ul>
<li>Use related outcomes or different measures of the dependent variable.</li>
</ul>
</li>
<li>
<strong>Varying Control Group Size</strong>
<ul>
<li>Compare results using <strong>matched vs. unmatched samples</strong> to assess sensitivity to sample selection.</li>
</ul>
</li>
<li>
<strong>Placebo Tests</strong>
<ul>
<li>Conduct placebo tests to ensure the effect is not spurious.</li>
<li>The appropriate placebo test depends on the specific quasi-experimental method used (examples provided in later sections).</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="establishing-mechanisms" class="section level2" number="26.3">
<h2>
<span class="header-section-number">26.3</span> Establishing Mechanisms<a class="anchor" aria-label="anchor" href="#establishing-mechanisms"><i class="fas fa-link"></i></a>
</h2>
<p>Once the causal effect is established, the next step is to investigate how the effect operates.</p>
<ol style="list-style-type: decimal">
<li>
<a href="mediation.html#mediation">Mediation</a> Analysis
<ul>
<li>Test whether an intermediate variable explains the effect of the treatment.</li>
</ul>
</li>
<li>
<a href="moderation.html#moderation">Moderation</a> Analysis
<ul>
<li>Estimate the model separately for different subgroups.</li>
<li>Test for three-way interactions (e.g., interaction between treatment, time, and group membership in <a href="sec-difference-in-differences.html#sec-difference-in-differences">Difference-in-Differences</a> settings).</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="limitations-of-quasi-experiments" class="section level2" number="26.4">
<h2>
<span class="header-section-number">26.4</span> Limitations of Quasi-Experiments<a class="anchor" aria-label="anchor" href="#limitations-of-quasi-experiments"><i class="fas fa-link"></i></a>
</h2>
<p>Researchers should explicitly discuss the limitations of their quasi-experimental approach.</p>
<p>Key Questions to Address:</p>
<ol style="list-style-type: decimal">
<li>
<strong>What are the identification assumptions?</strong>
<ul>
<li>Clearly state the assumptions required for causal inference.</li>
</ul>
</li>
<li>
<strong>What are the threats to validity?</strong>
<ul>
<li>Consider potential confounders, measurement errors, and violations of SUTVA.</li>
</ul>
</li>
<li>
<strong>How do you address these threats?</strong>
<ul>
<li>Describe robustness checks and alternative specifications.</li>
<li>Suggest directions for future research to improve causal identification.</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="assumptions-for-identifying-treatment-effects" class="section level2" number="26.5">
<h2>
<span class="header-section-number">26.5</span> Assumptions for Identifying Treatment Effects<a class="anchor" aria-label="anchor" href="#assumptions-for-identifying-treatment-effects"><i class="fas fa-link"></i></a>
</h2>
<p>To identify causal effects in <strong>non-randomized studies</strong>, we rely on three key assumptions:</p>
<ol style="list-style-type: decimal">
<li>
<a href="sec-quasi-experimental.html#sec-sutva">Stable Unit Treatment Value Assumption</a> (SUTVA)</li>
<li><a href="sec-quasi-experimental.html#sec-conditional-ignorability-assumption">Conditional Ignorability (Unconfoundedness) Assumption</a></li>
<li><a href="sec-quasi-experimental.html#sec-overlap-positivity-assumption">Overlap (Positivity) Assumption</a></li>
</ol>
<p>These assumptions ensure that we can properly define and estimate causal effects, mitigating biases from confounders or selection effects.</p>
<hr>
<div id="sec-sutva" class="section level3" number="26.5.1">
<h3>
<span class="header-section-number">26.5.1</span> Stable Unit Treatment Value Assumption<a class="anchor" aria-label="anchor" href="#sec-sutva"><i class="fas fa-link"></i></a>
</h3>
<p>SUTVA consists of two key components:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Consistency Assumption:</strong> The treatment indicator <span class="math inline">\(Z \in \{0,1\}\)</span> adequately represents all versions of the treatment.</li>
<li>
<strong>No Interference Assumption:</strong> A subject’s outcome depends <strong>only</strong> on its own treatment status and is <strong>not affected</strong> by the treatment assignments of other subjects.</li>
</ol>
<p>This assumption ensures that potential outcomes are well-defined and independent of external influences, forming the foundation of Rubin’s Causal Model (RCM). Violations of SUTVA can lead to biased estimators and incorrect standard errors.</p>
<hr>
<p>Let <span class="math inline">\(Y_i(Z)\)</span> denote the <strong>potential outcome</strong> for unit <span class="math inline">\(i\)</span> under treatment assignment <span class="math inline">\(Z\)</span>, where <span class="math inline">\(Z \in \{0,1\}\)</span> represents a binary treatment.</p>
<p>SUTVA states that:</p>
<p><span class="math display">\[
Y_i(Z) = Y_i(Z, \mathbf{Z}_{-i})
\]</span></p>
<p>where <span class="math inline">\(\mathbf{Z}_{-i}\)</span> denotes the treatment assignments of all other units <strong>except</strong> <span class="math inline">\(i\)</span>. If SUTVA holds, then:</p>
<p><span class="math display">\[
Y_i(Z) = Y_i(Z, \mathbf{Z}_{-i}) \quad \forall \mathbf{Z}_{-i}.
\]</span></p>
<p>This implies that unit <span class="math inline">\(i\)</span>’s outcome depends <strong>only</strong> on its own treatment status and is unaffected by the treatment of others.</p>
<hr>
<div id="implications-of-sutva" class="section level4" number="26.5.1.1">
<h4>
<span class="header-section-number">26.5.1.1</span> Implications of SUTVA<a class="anchor" aria-label="anchor" href="#implications-of-sutva"><i class="fas fa-link"></i></a>
</h4>
<p>If SUTVA holds, the <a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a> is well-defined as:</p>
<p><span class="math display">\[
\text{ATE} = \mathbb{E}[Y_i(1)] - \mathbb{E}[Y_i(0)].
\]</span></p>
<p>However, if SUTVA is violated, standard causal inference methods may fail. Common violations include:</p>
<ul>
<li>
<a href="sec-quasi-experimental.html#sec-no-interference">Interference</a> <strong>(Spillover Effects):</strong> The treatment of one unit influences another’s outcome.
<ul>
<li>Example: A marketing campaign for a product influences both treated and untreated customers through word-of-mouth effects.</li>
<li>
<strong>Solution:</strong> Use <strong>spatial econometrics</strong> or <strong>network-based causal inference models</strong> to account for spillovers.</li>
</ul>
</li>
<li>
<a href="sec-quasi-experimental.html#sec-no-hidden-variations-in-treatment">Treatment Inconsistency</a>: Multiple versions of a treatment exist but are not explicitly modeled.
<ul>
<li>Example: Different incentive levels in a sales promotion may have different effects.</li>
<li>
<strong>Solution:</strong> Explicitly define and distinguish different treatment versions using <strong>principal stratification</strong>.</li>
</ul>
</li>
</ul>
<p>Violating SUTVA introduces significant challenges in causal inference, leading to:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="19%">
<col width="80%">
</colgroup>
<tbody>
<tr class="odd">
<td>Issue</td>
<td>Consequence</td>
</tr>
<tr class="even">
<td><strong>Bias in Estimators</strong></td>
<td>If interference is ignored, treatment effects may be over- or underestimated.</td>
</tr>
<tr class="odd">
<td><strong>Incorrect Standard Errors</strong></td>
<td>Standard errors may be <strong>underestimated</strong> (if spillovers are ignored) or <strong>overestimated</strong> (if hidden treatment variations exist).</td>
</tr>
<tr class="even">
<td><strong>Ill-Defined Causal Effects</strong></td>
<td>If multiple treatment versions exist, it becomes unclear which causal effect is being estimated.</td>
</tr>
</tbody>
</table></div>
<p>Thus, when SUTVA is unlikely to hold, researchers must adopt more flexible methodologies to ensure valid inferences.</p>
<hr>
</div>
<div id="sec-no-interference" class="section level4" number="26.5.1.2">
<h4>
<span class="header-section-number">26.5.1.2</span> No Interference<a class="anchor" aria-label="anchor" href="#sec-no-interference"><i class="fas fa-link"></i></a>
</h4>
<p>The <a href="sec-quasi-experimental.html#sec-no-interference">no interference</a> component of the Stable Unit Treatment Value Assumption states that one unit’s treatment assignment does not influence another unit’s outcome. However, in many real-world scenarios, this assumption is violated due to <strong>spillover effects</strong>, such as:</p>
<ul>
<li>
<strong>Epidemiology</strong>: In vaccine studies, an individual’s health status may depend on the vaccination status of their social network.</li>
<li>
<strong>Marketing Experiments</strong>: In online advertising, one consumer’s exposure to an ad campaign may influence their peers’ purchasing behavior.</li>
</ul>
<p>Mathematically, interference occurs when unit <span class="math inline">\(i\)</span>’s outcome depends on the treatment assignments of other units within a neighborhood function <span class="math inline">\(\mathcal{N}(i)\)</span>:</p>
<p><span class="math display">\[
Y_i(Z, \mathbf{Z}_{\mathcal{N}(i)}),
\]</span></p>
<p>where <span class="math inline">\(\mathbf{Z}_{\mathcal{N}(i)}\)</span> represents the treatment assignments of neighboring units. If <span class="math inline">\(\mathcal{N}(i) \neq \emptyset\)</span>, then SUTVA is violated, necessitating alternative modeling approaches such as <strong>spatial econometrics</strong>, <strong>network-based causal inference</strong>, or <strong>graph-based treatment effect estimation</strong>.</p>
<hr>
<p><strong>Special Cases of Interference</strong></p>
<p>Several forms of interference can arise in applied settings:</p>
<ul>
<li>
<strong>Complete Interference</strong>: Each unit’s outcome depends on the treatment assignments of all other units (e.g., in a fully connected social network).</li>
<li>
<strong>Partial Interference</strong>: Interference occurs <strong>within</strong> subgroups but not <strong>between</strong> them (e.g., students within classrooms but not across schools).</li>
<li>
<strong>Network Interference</strong>: Treatment effects propagate through a social or spatial network, requiring models such as <strong>graph-based causal inference</strong> or <strong>spatial econometrics</strong>.</li>
</ul>
<p>Each of these cases necessitates adjustments to standard causal inference techniques.</p>
<hr>
</div>
<div id="sec-no-hidden-variations-in-treatment" class="section level4" number="26.5.1.3">
<h4>
<span class="header-section-number">26.5.1.3</span> No Hidden Variations in Treatment<a class="anchor" aria-label="anchor" href="#sec-no-hidden-variations-in-treatment"><i class="fas fa-link"></i></a>
</h4>
<p>The second component of SUTVA ensures that the treatment is <strong>uniquely defined</strong>, meaning there are no unaccounted variations in treatment administration. If multiple versions of the treatment exist (e.g., different dosages of a drug), the causal effect may not be well-defined.</p>
<p>Mathematically, if different treatment versions <span class="math inline">\(v\)</span> exist for a given treatment <span class="math inline">\(Z\)</span>, the potential outcome should be indexed accordingly:</p>
<p><span class="math display">\[
Y_i(Z, v).
\]</span></p>
<p>If treatment variations lead to different responses:</p>
<p><span class="math display">\[
Y_i(Z, v_1) \neq Y_i(Z, v_2),
\]</span></p>
<p>then SUTVA is violated. In such cases, methods such as <a href="sec-instrumental-variables.html#sec-instrumental-variables">instrumental variables</a> or <strong>latent variable models</strong> can help adjust for treatment heterogeneity.</p>
<hr>
</div>
<div id="strategies-to-address-sutva-violations" class="section level4" number="26.5.1.4">
<h4>
<span class="header-section-number">26.5.1.4</span> Strategies to Address SUTVA Violations<a class="anchor" aria-label="anchor" href="#strategies-to-address-sutva-violations"><i class="fas fa-link"></i></a>
</h4>
<p>Several approaches help mitigate the effects of SUTVA violations:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Randomized Saturation Designs</strong>: Assign treatment at varying intensities across clusters to estimate spillover effects.</li>
<li>
<strong>Network-Based Causal Models</strong>: Utilize graph theory or adjacency matrices to account for interference.</li>
<li>
<a href="sec-instrumental-variables.html#sec-instrumental-variables">Instrumental Variables</a>: If multiple versions of a treatment exist, use an IV to isolate a single version.</li>
<li>
<strong>Stratified Analysis</strong>: When treatment variations are known, analyze subgroups separately.</li>
<li>
<a href="sec-difference-in-differences.html#sec-difference-in-differences">Difference-in-Differences</a> with Spatial Controls: Incorporate spatial lag terms to model geographic spillovers.</li>
</ol>
<hr>
</div>
</div>
<div id="sec-conditional-ignorability-assumption" class="section level3" number="26.5.2">
<h3>
<span class="header-section-number">26.5.2</span> Conditional Ignorability Assumption<a class="anchor" aria-label="anchor" href="#sec-conditional-ignorability-assumption"><i class="fas fa-link"></i></a>
</h3>
<p>Next, we must assume that <strong>treatment assignment is independent of the potential outcomes conditional on the observed covariates</strong>. This assumption has several equivalent names in the causal inference literature, including</p>
<ul>
<li><p>Conditional Ignorability</p></li>
<li><p>Conditional Exchangeability</p></li>
<li><p>No Unobserved Confounding</p></li>
<li><p>No Omitted Variables</p></li>
</ul>
<p>In the language of causal diagrams, this assumption ensures that all backdoor paths between treatment and outcome are blocked by observed covariates.</p>
<p>Formally, we assume that treatment assignment <span class="math inline">\(Z\)</span> is independent of the potential outcomes <span class="math inline">\(Y(Z)\)</span> given a set of observed covariates <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
Y(1), Y(0) \perp\!\!\!\perp Z \mid X.
\]</span></p>
<p>This means that after conditioning on <span class="math inline">\(X\)</span>, the probability of receiving treatment is unrelated to the potential outcomes, ensuring that comparisons between treated and untreated units are unbiased.</p>
<hr>
<p>In causal inference, <strong>treatment assignment is said to be ignorable</strong> if, conditional on observed covariates <span class="math inline">\(X\)</span>, the treatment indicator <span class="math inline">\(Z\)</span> is independent of the potential outcomes:</p>
<p><span class="math display">\[
P(Y(1), Y(0) \mid Z, X) = P(Y(1), Y(0) \mid X).
\]</span></p>
<p>Equivalently, in terms of conditional probability:</p>
<p><span class="math display">\[
P(Z = 1 \mid Y(1), Y(0), X) = P(Z = 1 \mid X).
\]</span></p>
<p>This ensures that treatment assignment is <strong>as good as random</strong> once we control for <span class="math inline">\(X\)</span>, meaning that the probability of receiving treatment does not depend on unmeasured confounders.</p>
<p>A direct consequence is that we can estimate the <a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a> using observational data:</p>
<p><span class="math display">\[
\mathbb{E}[Y(1) - Y(0)] = \mathbb{E}[\mathbb{E}[Y \mid Z=1, X] - \mathbb{E}[Y \mid Z=0, X]].
\]</span></p>
<p>If ignorability holds, standard regression models, matching, or weighting techniques (e.g., propensity score weighting) can provide unbiased causal estimates.</p>
<hr>
<div id="the-role-of-causal-diagrams-and-backdoor-paths" class="section level4" number="26.5.2.1">
<h4>
<span class="header-section-number">26.5.2.1</span> The Role of Causal Diagrams and Backdoor Paths<a class="anchor" aria-label="anchor" href="#the-role-of-causal-diagrams-and-backdoor-paths"><i class="fas fa-link"></i></a>
</h4>
<p>In causal diagrams (DAGs), confounding arises when a backdoor path exists between treatment <span class="math inline">\(Z\)</span> and outcome <span class="math inline">\(Y\)</span>. A backdoor path is any non-causal path that creates spurious associations between <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span>. The conditional ignorability assumption requires that all such paths be blocked by conditioning on a sufficient set of covariates <span class="math inline">\(X\)</span>.</p>
<p>Consider a simple causal diagram:</p>
<div class="inline-figure"><img src="26-quasi-experimental_files/figure-html/unnamed-chunk-1-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Here, <span class="math inline">\(X\)</span> is a common cause of both <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span>, creating a backdoor path <span class="math inline">\(Z \leftarrow X \rightarrow Y\)</span>. If we fail to control for <span class="math inline">\(X\)</span>, the estimated effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span> will be biased. However, if we condition on <span class="math inline">\(X\)</span>, we block the backdoor path and obtain an unbiased estimate of the treatment effect.</p>
<p>To satisfy the conditional ignorability assumption, researchers must identify a <strong>sufficient set of confounders</strong> to block all backdoor paths. This is often done using <strong>domain knowledge</strong> and <strong>causal structure learning algorithms</strong>.</p>
<ul>
<li>
<strong>Minimal Sufficient Adjustment Set</strong>: The smallest set of covariates <span class="math inline">\(X\)</span> that, when conditioned upon, satisfies ignorability.</li>
<li>
<strong>Propensity Score Methods</strong>: Instead of adjusting directly for <span class="math inline">\(X\)</span>, one can estimate the probability of treatment <span class="math inline">\(P(Z=1 \mid X)\)</span> and use inverse probability weighting or <a href="sec-matching-methods.html#sec-matching-methods">matching</a>.</li>
</ul>
<hr>
</div>
<div id="violations-of-the-ignorability-assumption" class="section level4" number="26.5.2.2">
<h4>
<span class="header-section-number">26.5.2.2</span> Violations of the Ignorability Assumption<a class="anchor" aria-label="anchor" href="#violations-of-the-ignorability-assumption"><i class="fas fa-link"></i></a>
</h4>
<p>If ignorability does not hold, treatment assignment depends on unobserved confounders, introducing omitted variable bias. Mathematically, if there exists an unmeasured variable <span class="math inline">\(U\)</span> such that:</p>
<p><span class="math display">\[
Y(1), Y(0) \not\perp\!\!\!\perp Z \mid X,
\]</span></p>
<p>then estimates of the treatment effect will be biased.</p>
<p><strong>Consequences of Violations</strong></p>
<ul>
<li>
<strong>Confounded Estimates</strong>: The estimated treatment effect captures both the causal effect and the bias from unobserved confounders.</li>
<li>
<strong>Selection Bias</strong>: If treatment assignment is related to factors that also influence the outcome, the sample may not be representative.</li>
<li>
<strong>Overestimation or Underestimation</strong>: Ignoring important confounders can lead to inflated or deflated estimates of treatment effects.</li>
</ul>
<p><strong>Example of Confounding</strong></p>
<p>Consider an observational study on smoking and lung cancer:</p>
<div class="inline-figure"><img src="26-quasi-experimental_files/figure-html/unnamed-chunk-2-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Here, genetics is an unmeasured confounder affecting both smoking and lung cancer. If we do not control for genetics, the estimated effect of smoking on lung cancer will be biased.</p>
<hr>
</div>
<div id="strategies-to-address-violations" class="section level4" number="26.5.2.3">
<h4>
<span class="header-section-number">26.5.2.3</span> Strategies to Address Violations<a class="anchor" aria-label="anchor" href="#strategies-to-address-violations"><i class="fas fa-link"></i></a>
</h4>
<p>If ignorability is violated due to <strong>unobserved confounding</strong>, several techniques can be used to mitigate bias:</p>
<ol style="list-style-type: decimal">
<li>
<a href="sec-instrumental-variables.html#sec-instrumental-variables">Instrumental Variables</a>:
<ul>
<li>Use a variable <span class="math inline">\(W\)</span> that affects treatment <span class="math inline">\(Z\)</span> but has no direct effect on <span class="math inline">\(Y\)</span>, ensuring exogeneity.</li>
<li>Example: Randomized incentives to encourage treatment uptake.</li>
</ul>
</li>
<li>
<a href="sec-difference-in-differences.html#sec-difference-in-differences">Difference-in-Differences</a>:
<ul>
<li>Compare changes in outcomes before and after treatment in a treated vs. control group.</li>
<li>Requires a parallel trends assumption.</li>
</ul>
</li>
<li>
<a href="sec-regression-discontinuity.html#sec-regression-discontinuity">Regression Discontinuity</a>:
<ul>
<li>Exploit cutoff-based treatment assignment.</li>
<li>Example: Scholarship eligibility at a certain GPA threshold.</li>
</ul>
</li>
<li>
<a href="sec-matching-methods.html#sec-propensity-scores">Propensity Score Methods</a>:
<ul>
<li>Estimate the probability of treatment given <span class="math inline">\(X\)</span>.</li>
<li>Use <strong>matching, inverse probability weighting (IPW), or stratification</strong> to balance treatment groups.</li>
</ul>
</li>
<li>
<strong>Sensitivity Analysis</strong>:
<ul>
<li>Quantify how much unobserved confounding would be needed to alter conclusions.</li>
<li>Example: <a href="sec-matching-methods.html#sec-rosenbaum-bounds">Rosenbaum’s sensitivity bounds</a>.</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="practical-considerations-5" class="section level4" number="26.5.2.4">
<h4>
<span class="header-section-number">26.5.2.4</span> Practical Considerations<a class="anchor" aria-label="anchor" href="#practical-considerations-5"><i class="fas fa-link"></i></a>
</h4>
<p>How to Select Covariates <span class="math inline">\(X\)</span>?</p>
<ul>
<li>Domain Knowledge: Consult experts to identify potential confounders.</li>
<li>Causal Discovery Methods: Use Bayesian networks or structure learning to infer relationships.</li>
<li>Statistical Tests: Examine balance in pre-treatment characteristics.</li>
</ul>
<p>Trade-Offs in Covariate Selection</p>
<ul>
<li>Too Few Covariates → Risk of omitted variable bias.</li>
<li>Too Many Covariates → Overfitting, loss of efficiency in estimation.</li>
</ul>
<hr>
</div>
</div>
<div id="sec-overlap-positivity-assumption" class="section level3" number="26.5.3">
<h3>
<span class="header-section-number">26.5.3</span> Overlap (Positivity) Assumption<a class="anchor" aria-label="anchor" href="#sec-overlap-positivity-assumption"><i class="fas fa-link"></i></a>
</h3>
<p>The <strong>overlap assumption</strong>, also known as <strong>common support</strong> or <strong>positivity</strong>, ensures that the probability of receiving treatment is strictly between 0 and 1 for all values of the observed covariates <span class="math inline">\(X_i\)</span>. Mathematically, this is expressed as:</p>
<p><span class="math display">\[
0 &lt; P(Z_i = 1 \mid X_i) &lt; 1, \quad \forall X_i.
\]</span></p>
<p>This condition ensures that for every possible value of <span class="math inline">\(X_i\)</span>, there is a <strong>nonzero probability</strong> of receiving both treatment (<span class="math inline">\(Z_i = 1\)</span>) and control (<span class="math inline">\(Z_i = 0\)</span>). That is, the <strong>covariate distributions of treated and control units must overlap</strong>.</p>
<p>When overlap is limited, the <a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a> may not be identifiable. In some cases, the <a href="sec-causal-inference.html#sec-average-treatment-effect-on-the-treated">Average Treatment Effect on the Treated</a> remains identifiable, but extreme violations of overlap can make even ATT estimation problematic. An alternative estimand, the Average Treatment Effect for the Overlap Population (ATO), may be used instead, focusing on a subpopulation where treatment assignment is not deterministic <span class="citation">(<a href="references.html#ref-li2018balancing">F. Li, Morgan, and Zaslavsky 2018</a>)</span>.</p>
<hr>
<p>The overlap assumption prevents cases where treatment assignment is deterministic, ensuring that:</p>
<p><span class="math display">\[
0 &lt; P(Z_i = 1 \mid X_i) &lt; 1, \quad \forall X_i.
\]</span></p>
<p>This implies two key properties:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Positivity Condition</strong>: Every unit has a nonzero probability of receiving treatment.</li>
<li>
<strong>No Deterministic Treatment Assignment</strong>: If <span class="math inline">\(P(Z_i = 1 \mid X_i) = 0\)</span> or <span class="math inline">\(P(Z_i = 1 \mid X_i) = 1\)</span> for some <span class="math inline">\(X_i\)</span>, then the causal effect is not identifiable for those values.</li>
</ol>
<p>If some subpopulations always receive treatment (<span class="math inline">\(P(Z_i = 1 \mid X_i) = 1\)</span>) or never receive treatment (<span class="math inline">\(P(Z_i = 1 \mid X_i) = 0\)</span>), then there is no counterfactual available, making causal inference impossible for those groups.</p>
<hr>
<div id="implications-of-violating-the-overlap-assumption" class="section level4" number="26.5.3.1">
<h4>
<span class="header-section-number">26.5.3.1</span> Implications of Violating the Overlap Assumption<a class="anchor" aria-label="anchor" href="#implications-of-violating-the-overlap-assumption"><i class="fas fa-link"></i></a>
</h4>
<p>When the overlap assumption is violated, identifying causal effects becomes challenging. Key implications include:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="35%">
<col width="64%">
</colgroup>
<thead><tr class="header">
<th><strong>Issue</strong></th>
<th><strong>Consequence</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Limited Generalizability of ATE</strong></td>
<td>ATE cannot be estimated if there is poor overlap in covariate distributions.</td>
</tr>
<tr class="even">
<td><strong>ATT May Still Be Identifiable</strong></td>
<td>ATT can be estimated if some overlap exists, but it is restricted to the treated group.</td>
</tr>
<tr class="odd">
<td><strong>Severe Violations Can Prevent ATT Estimation</strong></td>
<td>If there is no overlap, even ATT is not identifiable.</td>
</tr>
<tr class="even">
<td><strong>Extrapolation Bias</strong></td>
<td>Weak overlap forces models to extrapolate, leading to unstable and biased estimates.</td>
</tr>
</tbody>
</table></div>
<p><strong>Example: Education Intervention and Socioeconomic Status</strong></p>
<p>Suppose we study an education intervention aimed at improving student performance. If only high-income students received the intervention (<span class="math inline">\(P(Z = 1 \mid X) = 1\)</span> for high income) and no low-income students received it (<span class="math inline">\(P(Z = 1 \mid X) = 0\)</span> for low income), then there is no common support. As a result, we cannot estimate a valid treatment effect for low-income students.</p>
<hr>
</div>
<div id="diagnosing-overlap-violations" class="section level4" number="26.5.3.2">
<h4>
<span class="header-section-number">26.5.3.2</span> Diagnosing Overlap Violations<a class="anchor" aria-label="anchor" href="#diagnosing-overlap-violations"><i class="fas fa-link"></i></a>
</h4>
<p>Before estimating causal effects, it is crucial to assess overlap using diagnostic tools such as:</p>
<ol style="list-style-type: decimal">
<li><strong>Propensity Score Distribution</strong></li>
</ol>
<p>Estimate the <strong>propensity score</strong> <span class="math inline">\(e(X) = P(Z = 1 \mid X)\)</span> and visualize its distribution:</p>
<ul>
<li>
<strong>Good Overlap (Well-Mixed Propensity Score Distributions)</strong> → Treated and control groups have similar propensity score distributions.</li>
<li>
<strong>Poor Overlap</strong> (<strong>Separated Propensity Score Distributions)</strong> → Clear separation in propensity score distributions suggests limited common support.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Standardized Mean Differences</strong></li>
</ol>
<p>Compare covariate distributions between treated and control groups. Large imbalances suggest weak overlap.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Kernel Density Plots</strong></li>
</ol>
<p>Visualize the density of propensity scores in each treatment group. Non-overlapping regions indicate poor support.</p>
<hr>
</div>
<div id="strategies-to-address-overlap-violations" class="section level4" number="26.5.3.3">
<h4>
<span class="header-section-number">26.5.3.3</span> Strategies to Address Overlap Violations<a class="anchor" aria-label="anchor" href="#strategies-to-address-overlap-violations"><i class="fas fa-link"></i></a>
</h4>
<p>If overlap is weak, several strategies can help:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Trimming Non-Overlapping Units</strong>
<ul>
<li>Exclude units with extreme propensity scores (e.g., <span class="math inline">\(P(Z = 1 \mid X) \approx 0\)</span> or <span class="math inline">\(P(Z = 1 \mid X) \approx 1\)</span>).</li>
<li>Improves internal validity but reduces sample size.</li>
</ul>
</li>
<li>
<strong>Reweighting Approaches</strong>
<ul>
<li>Use overlap weights to focus on a population where treatment was plausibly assignable.</li>
<li>The Average Treatment Effect for the Overlap Population (ATO) estimates effects for units where <span class="math inline">\(P(Z = 1 \mid X)\)</span> is moderate (e.g., close to 0.5).</li>
</ul>
</li>
<li>
<strong>Matching on the Propensity Score</strong>
<ul>
<li>Remove units that lack suitable matches in the opposite treatment group.</li>
<li>Improves balance at the cost of excluding observations.</li>
</ul>
</li>
<li>
<strong>Covariate Balancing Techniques</strong>
<ul>
<li>Use entropy balancing or inverse probability weighting to adjust for limited overlap.</li>
</ul>
</li>
<li>
<strong>Sensitivity Analysis</strong>
<ul>
<li>Assess how overlap violations affect causal conclusions.</li>
<li>Example: <a href="sec-matching-methods.html#sec-rosenbaum-bounds">Rosenbaum’s sensitivity bounds</a> quantify the impact of unmeasured confounding.</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="average-treatment-effect-for-the-overlap-population" class="section level4" number="26.5.3.4">
<h4>
<span class="header-section-number">26.5.3.4</span> Average Treatment Effect for the Overlap Population<a class="anchor" aria-label="anchor" href="#average-treatment-effect-for-the-overlap-population"><i class="fas fa-link"></i></a>
</h4>
<p>When overlap is weak, ATO offers an alternative estimand that focuses on the subpopulation where treatment is not deterministic.</p>
<p>Instead of estimating the <strong>ATE</strong> (which applies to the entire population) or the <strong>ATT</strong> (which applies to the treated population), ATO focuses on units where <strong>both treatment and control were plausible options</strong>.</p>
<p>ATO is estimated using <strong>overlap weights</strong>:</p>
<p><span class="math display">\[
W_i = P(Z_i = 1 \mid X_i) (1 - P(Z_i = 1 \mid X_i)).
\]</span></p>
<p>These weights:</p>
<ul>
<li>Downweight extreme propensity scores (where <span class="math inline">\(P(Z = 1 \mid X)\)</span> is close to 0 or 1).</li>
<li>Focus inference on the subpopulation with the most overlap.</li>
<li>Improve robustness in cases with limited common support.</li>
</ul>
<div class="inline-table"><table class="table table-sm">
<caption><strong>Comparison of Estimands</strong></caption>
<thead><tr class="header">
<th><strong>Estimand</strong></th>
<th><strong>Target Population</strong></th>
<th><strong>Overlap Requirement</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>ATE</strong></td>
<td>Entire population</td>
<td>Strong</td>
</tr>
<tr class="even">
<td><strong>ATT</strong></td>
<td>Treated population</td>
<td>Moderate</td>
</tr>
<tr class="odd">
<td><strong>ATO</strong></td>
<td>Overlap population</td>
<td>Weak</td>
</tr>
</tbody>
</table></div>
<p><strong>Practical Applications of ATO</strong></p>
<ul>
<li>
<strong>Policy Evaluation</strong>: When treatment assignment is highly structured, ATO ensures conclusions are relevant to a feasible intervention group.</li>
<li>
<strong>Observational Studies</strong>: Avoids extrapolation bias when estimating treatment effects in subpopulations with common support.</li>
</ul>
<hr>
</div>
</div>
</div>
<div id="sec-natural-experiments" class="section level2" number="26.6">
<h2>
<span class="header-section-number">26.6</span> Natural Experiments<a class="anchor" aria-label="anchor" href="#sec-natural-experiments"><i class="fas fa-link"></i></a>
</h2>
<p>A natural experiment is an observational study in which an exogenous event, policy change, or external factor creates as-if random variation in treatment assignment across units. Unlike <a href="sec-experimental-design.html#sec-experimental-design">randomized controlled trials</a> (RCTs)—where researchers actively manipulate treatment assignment—natural experiments leverage naturally occurring circumstances that approximate randomization.</p>
<p>In many fields, including economics, marketing, political science, and epidemiology, natural experiments provide an indispensable tool for causal inference, particularly when RCTs are impractical, unethical, or prohibitively expensive.</p>
<p><strong>Key Characteristics of Natural Experiments</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Exogenous Shock</strong>: Treatment assignment is determined by an external event, policy, or regulation rather than by researchers.</li>
<li>
<strong>As-If Randomization</strong>: The event must create variation that is plausibly <strong>unrelated</strong> to unobserved confounders, mimicking an RCT.</li>
<li>
<strong>Comparability of Treatment and Control Groups</strong>: The study design should ensure that treated and untreated units are comparable <strong>except for their exposure</strong> to the intervention.</li>
</ol>
<hr>
<p><strong>Examples of Natural Experiments in Economics and Marketing</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Minimum Wage Policy and Employment</strong></li>
</ol>
<p>A classic example comes from <span class="citation">Card and Krueger (<a href="references.html#ref-card1993minimum">1993</a>)</span> study on the minimum wage. When New Jersey increased its minimum wage while neighboring Pennsylvania did not, this created a natural experiment. By comparing fast-food employment trends in both states, the study estimated the causal effect of the minimum wage increase on employment.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Advertising Bans and Consumer Behavior</strong></li>
</ol>
<p>Suppose a country bans advertising for a particular product, such as tobacco or alcohol, while a similar neighboring country does not. This policy creates a natural experiment: researchers can compare sales trends before and after the ban in both countries to estimate the causal impact of advertising restrictions on consumer demand.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>The Facebook Outage as a Natural Experiment</strong></li>
</ol>
<p>In October 2021, Facebook experienced a global outage, making its advertising platform temporarily unavailable. For businesses that relied on Facebook ads, this outage created an exogenous shock in digital marketing strategies. Researchers could compare advertisers’ sales and website traffic before, during, and after the outage to assess the impact of social media advertising.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Lottery-Based Admission to Schools</strong></li>
</ol>
<p>In many cities, students apply to competitive schools via lottery-based admissions. Since admission is randomly assigned, this creates a natural experiment for studying the causal effect of elite schooling on future earnings, college attendance, or academic performance.</p>
<p>These examples illustrate how natural experiments are leveraged to estimate causal effects when randomization is infeasible.</p>
<hr>
<p><strong>Why Are Natural Experiments Important?</strong></p>
<p>Natural experiments are powerful tools for identifying causal relationships because they often eliminate selection bias—a major issue in observational studies. However, they also present challenges:</p>
<ul>
<li>
<strong>Treatment Assignment is Not Always Perfectly Random</strong>: Unlike RCTs, natural experiments rely on assumptions about the <strong>as-if randomness</strong> of treatment.</li>
<li>
<strong>Potential for Confounding</strong>: Even if treatment appears random, hidden factors might still bias results.</li>
<li>
<strong>Repeated Use of the Same Natural Experiment</strong>: When researchers analyze the same natural experiment multiple times, it increases the risk of <strong>false discoveries</strong> due to multiple hypothesis testing.</li>
</ul>
<p>These statistical challenges, especially the risks of <strong>false positives</strong>, are crucial to understand and address.</p>
<hr>
<div id="the-problem-of-reusing-natural-experiments" class="section level3" number="26.6.1">
<h3>
<span class="header-section-number">26.6.1</span> The Problem of Reusing Natural Experiments<a class="anchor" aria-label="anchor" href="#the-problem-of-reusing-natural-experiments"><i class="fas fa-link"></i></a>
</h3>
<p>Recent simulations demonstrate that when the number of estimated outcomes <strong>far exceeds</strong> the number of true effects (<span class="math inline">\(N_{\text{Outcome}} \gg N_{\text{True effect}}\)</span>), the proportion of <strong>false positive</strong> findings can exceed 50% <span class="citation">(<a href="references.html#ref-heath2023reusing">Heath et al. 2023, 2331</a>)</span>. This problem arises due to:</p>
<ul>
<li>
<strong>Data Snooping</strong>: If multiple hypotheses are tested on the same dataset, the probability of finding at least one statistically significant result purely by chance increases.</li>
<li>
<strong>Researcher Degrees of Freedom</strong>: The flexibility in defining outcomes, selecting models, and specifying robustness checks can lead to p-hacking and publication bias.</li>
<li>
<strong>Dependence Across Tests</strong>: Many estimated outcomes are correlated, meaning traditional multiple testing corrections may not adequately control for Type I errors.</li>
</ul>
<p>This problem is exacerbated when:</p>
<ul>
<li><p>Studies use the same policy change, regulatory event, or shock across different settings.</p></li>
<li><p>Multiple subgroups and model specifications are tested without proper corrections.</p></li>
<li><p>P-values are interpreted without adjusting for multiple testing bias.</p></li>
</ul>
</div>
<div id="statistical-challenges-in-reusing-natural-experiments" class="section level3" number="26.6.2">
<h3>
<span class="header-section-number">26.6.2</span> Statistical Challenges in Reusing Natural Experiments<a class="anchor" aria-label="anchor" href="#statistical-challenges-in-reusing-natural-experiments"><i class="fas fa-link"></i></a>
</h3>
<p>When the same <a href="sec-quasi-experimental.html#sec-natural-experiments">natural experiment</a> is analyzed in multiple studies, or even within a single study across many different outcomes, the probability of obtaining <strong>spurious significant results</strong> increases. Key statistical challenges include:</p>
<ol style="list-style-type: decimal">
<li><strong>Family-Wise Error Rate (FWER) Inflation</strong></li>
</ol>
<p>Each additional hypothesis tested increases the probability of at least one false rejection of the null hypothesis (Type I error). If we test <span class="math inline">\(m\)</span> independent hypotheses at the nominal significance level <span class="math inline">\(\alpha\)</span>, the probability of making at least one Type I error is:</p>
<p><span class="math display">\[
P(\text{At least one false positive}) = 1 - (1 - \alpha)^m.
\]</span></p>
<p>For example, with <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(m = 20\)</span> tests:</p>
<p><span class="math display">\[
P(\text{At least one false positive}) = 1 - (0.95)^{20} \approx 0.64.
\]</span></p>
<p>This means that even if all null hypotheses are true, we expect a 64% chance of falsely rejecting at least one.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>False Discovery Rate (FDR) and Dependent Tests</strong></li>
</ol>
<p>FWER corrections such as Bonferroni are conservative and may be too stringent when outcomes are correlated. In cases where researchers test multiple related hypotheses, False Discovery Rate (FDR) control provides an alternative by limiting the expected proportion of false discoveries among rejected hypotheses.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Multiple Testing in Sequential Experiments</strong></li>
</ol>
<p>In many longitudinal or rolling studies, results are reported over time as more data becomes available. Chronological testing introduces additional biases:</p>
<ul>
<li>Repeated interim analyses increase the probability of stopping early on false positives.</li>
<li>Outcomes tested at different times require corrections that adjust for sequential dependence.</li>
</ul>
<p>To address these issues, researchers must apply multiple testing corrections.</p>
<hr>
</div>
<div id="solutions-multiple-testing-corrections" class="section level3" number="26.6.3">
<h3>
<span class="header-section-number">26.6.3</span> Solutions: Multiple Testing Corrections<a class="anchor" aria-label="anchor" href="#solutions-multiple-testing-corrections"><i class="fas fa-link"></i></a>
</h3>
<p>To mitigate the risks of <strong>false positives</strong> in natural experiment research, various statistical corrections can be applied.</p>
<ol style="list-style-type: decimal">
<li><strong>Family-Wise Error Rate (FWER) Control</strong></li>
</ol>
<p>The most conservative approach controls the <strong>probability of at least one false positive</strong>:</p>
<ul>
<li>
<p><strong>Bonferroni Correction</strong>:</p>
<p><span class="math display">\[
p^*_i = m \cdot p_i,
\]</span></p>
<p>where <span class="math inline">\(p^*_i\)</span> is the adjusted p-value and <span class="math inline">\(m\)</span> is the total number of hypotheses tested.</p>
</li>
<li><p><strong>Holm-Bonferroni Method</strong> <span class="citation">(<a href="references.html#ref-holm1979simple">Holm 1979</a>)</span>: Less conservative than Bonferroni, adjusting significance thresholds in a stepwise fashion.</p></li>
<li><p><strong>Sidak Correction</strong> <span class="citation">(<a href="references.html#ref-vsidak1967rectangular">Šidák 1967</a>)</span>: Accounts for multiple comparisons assuming independent tests.</p></li>
<li><p><strong>Romano-Wolf Stepwise Correction</strong> <span class="citation">(<a href="references.html#ref-romano2005stepwise">Romano and Wolf 2005</a>, <a href="references.html#ref-romano2016efficient">2016</a>)</span>: Recommended for natural experiments as it controls for dependence across tests.</p></li>
<li><p><strong>Hochberg’s Sharper FWER Control</strong> <span class="citation">(<a href="references.html#ref-hochberg1988sharper">Hochberg 1988</a>)</span>: A step-up procedure, more powerful than Holm’s method.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>False Discovery Rate (FDR) Control</strong></li>
</ol>
<p>FDR-controlling methods are less conservative than FWER-based approaches, allowing for <strong>some false positives</strong> while controlling their expected proportion.</p>
<ul>
<li>
<strong>Benjamini-Hochberg (BH) Procedure</strong> <span class="citation">(<a href="references.html#ref-benjamini1995controlling">Benjamini and Hochberg 1995</a>)</span>: Limits the expected proportion of false discoveries among rejected hypotheses.</li>
<li>
<strong>Adaptive Benjamini-Hochberg</strong> <span class="citation">(<a href="references.html#ref-benjamini2000adaptive">Benjamini and Hochberg 2000</a>)</span>: Adjusts for situations where the true proportion of null hypotheses is unknown.</li>
<li>
<strong>Benjamini-Yekutieli (BY) Correction</strong> <span class="citation">(<a href="references.html#ref-benjamini2001control">Benjamini and Yekutieli 2001</a>)</span>: Accounts for arbitrary dependence between tests.</li>
<li>
<strong>Two-Stage Benjamini-Hochberg</strong> <span class="citation">(<a href="references.html#ref-benjamini2006adaptive">Benjamini, Krieger, and Yekutieli 2006</a>)</span>: A more powerful version of BH, particularly useful in large-scale studies.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Sequential Approaches to Multiple Testing</strong></li>
</ol>
<p>Two major frameworks exist for applying multiple testing corrections over time:</p>
<ol style="list-style-type: decimal">
<li><strong>Chronological Sequencing</strong></li>
</ol>
<ul>
<li><p>Outcomes are ordered by the date they were first reported.</p></li>
<li><p>Multiple testing corrections are applied sequentially, progressively increasing the statistical significance threshold over time.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Best Foot Forward Policy</strong></li>
</ol>
<ul>
<li><p>Outcomes are ranked from most to least likely to be rejected based on experimental data.</p></li>
<li><p>Frequently used in clinical trials where primary outcomes are given priority.</p></li>
<li><p>New outcomes are added only if linked to primary treatment effects.</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Alternatively, refer to the rules of thumb from Table AI <span class="citation">(<a href="references.html#ref-heath2023reusing">Heath et al. 2023, 2356</a>)</span>.</li>
</ol>
<p>These approaches ensure that the p-value correction is consistent with the temporal structure of natural experiments.</p>
<hr>
<ol style="list-style-type: decimal">
<li><strong>Romano-Wolf Correction</strong></li>
</ol>
<p>The Romano-Wolf correction is highly recommended for handling multiple testing in natural experiments:</p>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="sec-quasi-experimental.html#cb719-1" tabindex="-1"></a><span class="co"># Install required packages</span></span>
<span id="cb719-2"><a href="sec-quasi-experimental.html#cb719-2" tabindex="-1"></a><span class="co"># install.packages("fixest")</span></span>
<span id="cb719-3"><a href="sec-quasi-experimental.html#cb719-3" tabindex="-1"></a><span class="co"># install.packages("wildrwolf")</span></span>
<span id="cb719-4"><a href="sec-quasi-experimental.html#cb719-4" tabindex="-1"></a></span>
<span id="cb719-5"><a href="sec-quasi-experimental.html#cb719-5" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb719-6"><a href="sec-quasi-experimental.html#cb719-6" tabindex="-1"></a><span class="fu">library</span>(wildrwolf)</span>
<span id="cb719-7"><a href="sec-quasi-experimental.html#cb719-7" tabindex="-1"></a></span>
<span id="cb719-8"><a href="sec-quasi-experimental.html#cb719-8" tabindex="-1"></a><span class="co"># Load example data</span></span>
<span id="cb719-9"><a href="sec-quasi-experimental.html#cb719-9" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb719-10"><a href="sec-quasi-experimental.html#cb719-10" tabindex="-1"></a></span>
<span id="cb719-11"><a href="sec-quasi-experimental.html#cb719-11" tabindex="-1"></a><span class="co"># Fit multiple regression models</span></span>
<span id="cb719-12"><a href="sec-quasi-experimental.html#cb719-12" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">feols</span>(Sepal.Width <span class="sc">~</span> Sepal.Length, <span class="at">data =</span> iris)</span>
<span id="cb719-13"><a href="sec-quasi-experimental.html#cb719-13" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">feols</span>(Petal.Length <span class="sc">~</span> Sepal.Length, <span class="at">data =</span> iris)</span>
<span id="cb719-14"><a href="sec-quasi-experimental.html#cb719-14" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> <span class="fu">feols</span>(Petal.Width <span class="sc">~</span> Sepal.Length, <span class="at">data =</span> iris)</span>
<span id="cb719-15"><a href="sec-quasi-experimental.html#cb719-15" tabindex="-1"></a></span>
<span id="cb719-16"><a href="sec-quasi-experimental.html#cb719-16" tabindex="-1"></a><span class="co"># Apply Romano-Wolf stepwise correction</span></span>
<span id="cb719-17"><a href="sec-quasi-experimental.html#cb719-17" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">rwolf</span>(</span>
<span id="cb719-18"><a href="sec-quasi-experimental.html#cb719-18" tabindex="-1"></a>  <span class="at">models =</span> <span class="fu">list</span>(fit1, fit2, fit3), </span>
<span id="cb719-19"><a href="sec-quasi-experimental.html#cb719-19" tabindex="-1"></a>  <span class="at">param =</span> <span class="st">"Sepal.Length"</span>,  </span>
<span id="cb719-20"><a href="sec-quasi-experimental.html#cb719-20" tabindex="-1"></a>  <span class="at">B =</span> <span class="dv">500</span></span>
<span id="cb719-21"><a href="sec-quasi-experimental.html#cb719-21" tabindex="-1"></a>)</span>
<span id="cb719-22"><a href="sec-quasi-experimental.html#cb719-22" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb719-23"><a href="sec-quasi-experimental.html#cb719-23" tabindex="-1"></a>  <span class="sc">|</span>                                                                            </span>
<span id="cb719-24"><a href="sec-quasi-experimental.html#cb719-24" tabindex="-1"></a>  <span class="er">|</span>                                                                      <span class="er">|</span>   <span class="dv">0</span>%</span>
<span id="cb719-25"><a href="sec-quasi-experimental.html#cb719-25" tabindex="-1"></a>  <span class="sc">|</span>                                                                            </span>
<span id="cb719-26"><a href="sec-quasi-experimental.html#cb719-26" tabindex="-1"></a>  <span class="er">|=======================</span>                                               <span class="er">|</span>  <span class="dv">33</span>%</span>
<span id="cb719-27"><a href="sec-quasi-experimental.html#cb719-27" tabindex="-1"></a>  <span class="sc">|</span>                                                                            </span>
<span id="cb719-28"><a href="sec-quasi-experimental.html#cb719-28" tabindex="-1"></a>  <span class="er">|===============================================</span>                       <span class="er">|</span>  <span class="dv">67</span>%</span>
<span id="cb719-29"><a href="sec-quasi-experimental.html#cb719-29" tabindex="-1"></a>  <span class="sc">|</span>                                                                            </span>
<span id="cb719-30"><a href="sec-quasi-experimental.html#cb719-30" tabindex="-1"></a>  <span class="er">|======================================================================|</span> <span class="dv">100</span>%</span>
<span id="cb719-31"><a href="sec-quasi-experimental.html#cb719-31" tabindex="-1"></a></span>
<span id="cb719-32"><a href="sec-quasi-experimental.html#cb719-32" tabindex="-1"></a>res</span>
<span id="cb719-33"><a href="sec-quasi-experimental.html#cb719-33" tabindex="-1"></a><span class="co">#&gt;   model   Estimate Std. Error   t value     Pr(&gt;|t|) RW Pr(&gt;|t|)</span></span>
<span id="cb719-34"><a href="sec-quasi-experimental.html#cb719-34" tabindex="-1"></a><span class="co">#&gt; 1     1 -0.0618848 0.04296699 -1.440287    0.1518983 0.141716567</span></span>
<span id="cb719-35"><a href="sec-quasi-experimental.html#cb719-35" tabindex="-1"></a><span class="co">#&gt; 2     2   1.858433 0.08585565  21.64602 1.038667e-47 0.001996008</span></span>
<span id="cb719-36"><a href="sec-quasi-experimental.html#cb719-36" tabindex="-1"></a><span class="co">#&gt; 3     3  0.7529176 0.04353017  17.29645 2.325498e-37 0.001996008</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><strong>General Multiple Testing Adjustments</strong></li>
</ol>
<p>For other multiple testing adjustments, use the <code>multtest</code> package:</p>
<div class="sourceCode" id="cb720"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Install package if necessary</span></span>
<span><span class="co"># BiocManager::install("multtest")</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">multtest</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define multiple correction procedures</span></span>
<span><span class="va">procs</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Bonferroni"</span>,</span>
<span>      <span class="st">"Holm"</span>,</span>
<span>      <span class="st">"Hochberg"</span>,</span>
<span>      <span class="st">"SidakSS"</span>,</span>
<span>      <span class="st">"SidakSD"</span>,</span>
<span>      <span class="st">"BH"</span>,</span>
<span>      <span class="st">"BY"</span>,</span>
<span>      <span class="st">"ABH"</span>,</span>
<span>      <span class="st">"TSBH"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate random p-values for demonstration</span></span>
<span><span class="va">p_values</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Apply multiple testing corrections</span></span>
<span><span class="va">adj_pvals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/multtest/man/mt.rawp2adjp.html">mt.rawp2adjp</a></span><span class="op">(</span><span class="va">p_values</span>, <span class="va">procs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Print results in a readable format</span></span>
<span><span class="va">adj_pvals</span> <span class="op">|&gt;</span> <span class="fu">causalverse</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/causalverse/man/nice_tab.html">nice_tab</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt;    adjp.rawp adjp.Bonferroni adjp.Holm adjp.Hochberg adjp.SidakSS adjp.SidakSD</span></span>
<span><span class="co">#&gt; 1       0.12               1         1          0.75         0.72         0.72</span></span>
<span><span class="co">#&gt; 2       0.22               1         1          0.75         0.92         0.89</span></span>
<span><span class="co">#&gt; 3       0.24               1         1          0.75         0.94         0.89</span></span>
<span><span class="co">#&gt; 4       0.29               1         1          0.75         0.97         0.91</span></span>
<span><span class="co">#&gt; 5       0.36               1         1          0.75         0.99         0.93</span></span>
<span><span class="co">#&gt; 6       0.38               1         1          0.75         0.99         0.93</span></span>
<span><span class="co">#&gt; 7       0.44               1         1          0.75         1.00         0.93</span></span>
<span><span class="co">#&gt; 8       0.59               1         1          0.75         1.00         0.93</span></span>
<span><span class="co">#&gt; 9       0.65               1         1          0.75         1.00         0.93</span></span>
<span><span class="co">#&gt; 10      0.75               1         1          0.75         1.00         0.93</span></span>
<span><span class="co">#&gt;    adjp.BH adjp.BY adjp.ABH adjp.TSBH_0.05 index h0.ABH h0.TSBH</span></span>
<span><span class="co">#&gt; 1     0.63       1     0.63           0.63     2     10      10</span></span>
<span><span class="co">#&gt; 2     0.63       1     0.63           0.63     6     10      10</span></span>
<span><span class="co">#&gt; 3     0.63       1     0.63           0.63     8     10      10</span></span>
<span><span class="co">#&gt; 4     0.63       1     0.63           0.63     3     10      10</span></span>
<span><span class="co">#&gt; 5     0.63       1     0.63           0.63    10     10      10</span></span>
<span><span class="co">#&gt; 6     0.63       1     0.63           0.63     1     10      10</span></span>
<span><span class="co">#&gt; 7     0.63       1     0.63           0.63     7     10      10</span></span>
<span><span class="co">#&gt; 8     0.72       1     0.72           0.72     9     10      10</span></span>
<span><span class="co">#&gt; 9     0.72       1     0.72           0.72     5     10      10</span></span>
<span><span class="co">#&gt; 10    0.75       1     0.75           0.75     4     10      10</span></span>
<span></span>
<span><span class="co"># adj_pvals$adjp</span></span></code></pre></div>
</div>
</div>
<div id="design-vs.-model-based-approaches" class="section level2" number="26.7">
<h2>
<span class="header-section-number">26.7</span> Design vs. Model-Based Approaches<a class="anchor" aria-label="anchor" href="#design-vs.-model-based-approaches"><i class="fas fa-link"></i></a>
</h2>
<p>Quasi-experimental methods exist along a spectrum between <strong>design-based</strong> and <strong>model-based</strong> approaches, rather than fitting neatly into one category or the other. At one end, the <strong>design-based perspective</strong> emphasizes study structure, aiming to approximate randomization through external sources of variation, such as policy changes or natural experiments. At the other end, the <strong>model-based perspective</strong> relies more heavily on statistical assumptions and functional forms to estimate causal relationships.</p>
<p>Most quasi-experimental methods blend elements of both perspectives, differing in the degree to which they prioritize design validity over statistical modeling. This section explores the continuum of these approaches, highlighting their fundamental differences and implications for empirical research.</p>
<p>To illustrate this, I will generate a visual spectrum positioning common quasi-experimental methods along the continuum from design-based to model-based.</p>
<div class="inline-figure"><img src="26-quasi-experimental_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;"></div>
<ol style="list-style-type: decimal">
<li>
<strong>Design-Based Causal Inference</strong>:</li>
</ol>
<ul>
<li><p>Focuses on using the design of the study or experiment to establish causal relationships.</p></li>
<li><p>Relies heavily on randomization, natural experiments, and quasi-experimental designs (e.g., Difference-in-Differences, Regression Discontinuity, Instrumental Variables).</p></li>
<li><p>Assumes that well-designed studies or natural experiments produce plausibly exogenous variation in the treatment, minimizing reliance on strong modeling assumptions.</p></li>
<li><p>Emphasizes transparency in how the treatment assignment mechanism isolates causal effects.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Model-Based Causal Inference</strong>:</li>
</ol>
<ul>
<li><p>Relies on explicit statistical models to infer causality, typically grounded in theory and assumptions about the data-generating process.</p></li>
<li><p>Commonly uses structural equation models, propensity score models, and frameworks like Bayesian inference.</p></li>
<li><p>Assumptions are crucial (e.g., no omitted variable bias, correct model specification, ignorability).</p></li>
<li><p>May be employed when experimental or quasi-experimental designs are not feasible.</p></li>
</ul>
<div class="inline-table"><table class="table table-sm">
<caption>Comparison of Two Perspectives</caption>
<colgroup>
<col width="17%">
<col width="45%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th><strong>Aspect</strong></th>
<th><strong>Design-Based</strong></th>
<th><strong>Model-Based</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Approach</strong></td>
<td>Relies on study design</td>
<td>Relies on statistical models</td>
</tr>
<tr class="even">
<td><strong>Assumptions</strong></td>
<td>Fewer, often intuitive (e.g., cutoff)</td>
<td>Stronger, often less testable</td>
</tr>
<tr class="odd">
<td><strong>Examples</strong></td>
<td>RCTs, natural experiments, RD, DiD</td>
<td>Structural models, PSM</td>
</tr>
<tr class="even">
<td><strong>Strengths</strong></td>
<td>Transparent, robust to misspecification</td>
<td>Useful when design is not possible</td>
</tr>
<tr class="odd">
<td><strong>Weaknesses</strong></td>
<td>Limited generalizability, context-specific</td>
<td>Sensitive to assumptions</td>
</tr>
</tbody>
</table></div>
<p>Both streams are complementary, and often, researchers combine elements of both to robustly estimate causal effects (i.e., multi-method studies). For example, a design-based approach might be supplemented with a model-based framework to address specific limitations like imperfect randomization.</p>
<div id="sec-design-based" class="section level3" number="26.7.1">
<h3>
<span class="header-section-number">26.7.1</span> Design-Based Perspective<a class="anchor" aria-label="anchor" href="#sec-design-based"><i class="fas fa-link"></i></a>
</h3>
<p>The design-based perspective in causal inference emphasizes exploiting natural sources of variation that approximate <strong>randomization</strong>. Unlike structural models, which rely on extensive theoretical assumptions, design-based methods leverage <strong>exogenous events, policy changes, or assignment rules</strong> to infer causal effects with <strong>minimal modeling assumptions</strong>.</p>
<p>These methods are particularly useful when:</p>
<ul>
<li><p>Randomized controlled trials are infeasible, unethical, or impractical.</p></li>
<li><p>Treatment assignment is plausibly exogenous due to a policy, threshold, or external shock.</p></li>
<li><p>Quasi-random variation exists (e.g., firms, consumers, or individuals are assigned treatment based on factors outside their control).</p></li>
</ul>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="13%">
<col width="22%">
<col width="31%">
<col width="32%">
</colgroup>
<thead><tr class="header">
<th><strong>Method</strong></th>
<th><strong>Key Concept</strong></th>
<th><strong>Assumptions</strong></th>
<th><strong>Example (Marketing &amp; Economics)</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Regression Discontinuity</strong></td>
<td>Units near a threshold are <strong>as good as random</strong>.</td>
<td>No precise control over cutoff; outcomes continuous.</td>
<td>Loyalty program tiers, minimum wage effects.</td>
</tr>
<tr class="even">
<td><strong>Synthetic Control</strong></td>
<td>Constructs a weighted synthetic counterfactual.</td>
<td>Pre-treatment trends must match; no confounding post-treatment shocks.</td>
<td>National ad campaign impact, tax cut effects.</td>
</tr>
<tr class="odd">
<td><strong>Event Studies</strong></td>
<td>Measures how an event changes outcomes over time.</td>
<td>Parallel pre-trends; no anticipatory effects.</td>
<td>Black Friday sales, stock price reactions.</td>
</tr>
<tr class="even">
<td><strong>Matching Methods</strong></td>
<td>Matches similar treated &amp; untreated units.</td>
<td>Selection on observables; common support.</td>
<td>Ad exposure vs. non-exposure, education &amp; earnings.</td>
</tr>
<tr class="odd">
<td><strong>Instrumental Variables</strong></td>
<td>Uses an exogenous variable to mimic randomization.</td>
<td>Instrument must be relevant; must not affect outcomes directly.</td>
<td>Ad regulations as IV for ad exposure, lottery-based college admissions.</td>
</tr>
</tbody>
</table></div>
</div>
<div id="sec-model-based-perspective" class="section level3" number="26.7.2">
<h3>
<span class="header-section-number">26.7.2</span> Model-Based Perspective<a class="anchor" aria-label="anchor" href="#sec-model-based-perspective"><i class="fas fa-link"></i></a>
</h3>
<p>The <a href="sec-quasi-experimental.html#sec-model-based-perspective">model-based perspective</a> in causal inference relies on statistical modeling techniques to estimate treatment effects, rather than exploiting exogenous sources of variation as in <a href="sec-quasi-experimental.html#sec-design-based">design-based approaches</a>. In this framework, researchers <strong>explicitly specify relationships between variables</strong>, using mathematical models to control for confounding and estimate counterfactual outcomes.</p>
<p>Unlike other quasi-experimental designs that leverage external assignment mechanisms (e.g., a cutoff, policy change, or natural experiment), model-based methods assume that confounding can be adequately adjusted for using statistical techniques alone. This makes them highly flexible but also more vulnerable to model misspecification and omitted variable bias.</p>
<p><strong>Key Characteristics of Model-Based Approaches</strong></p>
<ol style="list-style-type: decimal">
<li>
<p><strong>Dependence on Correct Model Specification</strong></p>
<ul>
<li><p>The validity of causal estimates hinges on the correct functional form of the model.</p></li>
<li><p>If the model is misspecified (e.g., incorrect interactions, omitted variables), bias can arise.</p></li>
</ul>
</li>
<li>
<p><strong>No Need for Exogenous Variation</strong></p>
<ul>
<li><p>Unlike design-based methods, model-based approaches do not rely on policy shocks, thresholds, or instrumental variables.</p></li>
<li><p>Instead, they estimate causal effects entirely through statistical modeling.</p></li>
</ul>
</li>
<li>
<p><strong>Assumption of Ignorability</strong></p>
<ul>
<li><p>These methods assume that all relevant confounders are observed and properly included in the model.</p></li>
<li><p>This assumption is untestable and may be violated in practice, leading to biased estimates.</p></li>
</ul>
</li>
<li>
<p><strong>Flexibility and Generalizability</strong></p>
<ul>
<li><p>Model-based methods allow researchers to estimate treatment effects even when exogenous variation is unavailable.</p></li>
<li><p>They can be applied in a wide range of settings where policy-driven variation does not exist.</p></li>
</ul>
</li>
</ol>
<p><strong>Key Model-Based Methods in Causal Inference</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="18%">
<col width="26%">
<col width="23%">
<col width="30%">
</colgroup>
<thead><tr class="header">
<th><strong>Method</strong></th>
<th><strong>Key Concept</strong></th>
<th><strong>Assumptions</strong></th>
<th><strong>Example (Marketing &amp; Economics)</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Propensity Score Matching (PSM) / Weighting</strong></td>
<td>Uses estimated probabilities of treatment to create comparable groups.</td>
<td>Treatment assignment is modeled correctly; no unmeasured confounding.</td>
<td>Job training programs (matching participants to non-participants); Ad campaign exposure.</td>
</tr>
<tr class="even">
<td><strong>Structural Causal Models (SCMs) / DAGs</strong></td>
<td>Specifies causal relationships using directed acyclic graphs (DAGs).</td>
<td>Correct causal structure; no omitted paths.</td>
<td>Customer churn prediction; Impact of pricing on sales.</td>
</tr>
<tr class="odd">
<td><strong>Covariate Adjustment (Regression-Based Approaches)</strong></td>
<td>Uses regression to control for confounding variables.</td>
<td>Linear or nonlinear functional forms are correctly specified.</td>
<td>Estimating the impact of online ads on revenue.</td>
</tr>
<tr class="even">
<td><strong>Machine Learning for Causal Inference</strong></td>
<td>Uses ML algorithms (e.g., causal forests, BART) to estimate treatment effects.</td>
<td>Assumes data-driven methods can capture complex relationships.</td>
<td>Personalized marketing campaigns; Predicting loan default rates.</td>
</tr>
</tbody>
</table></div>
<div id="propensity-score-matching-and-weighting" class="section level4" number="26.7.2.1">
<h4>
<span class="header-section-number">26.7.2.1</span> Propensity Score Matching and Weighting<a class="anchor" aria-label="anchor" href="#propensity-score-matching-and-weighting"><i class="fas fa-link"></i></a>
</h4>
<p>Propensity Score Matching estimates the probability of treatment assignment based on observed characteristics, then matches treated and control units with similar probabilities to mimic randomization.</p>
<p><strong>Key Assumptions</strong></p>
<ul>
<li><p>Correct Model Specification: The propensity score model (typically a logistic regression) must correctly capture all relevant covariates affecting treatment assignment.</p></li>
<li><p>Ignorability: There are no unmeasured confounders—all relevant differences between treated and control groups are accounted for.</p></li>
</ul>
<p><strong>Why It’s Model-Based</strong></p>
<ul>
<li><p>Unlike design-based methods, which exploit external sources of variation, PSM depends entirely on the statistical model to balance covariates.</p></li>
<li><p>Any mis-specification in the propensity score model can introduce bias.</p></li>
</ul>
<p><strong>Examples</strong></p>
<ul>
<li><p><strong>Marketing</strong>: Evaluating the impact of targeted advertising on purchase behavior by matching customers exposed to an ad with unexposed customers who have similar browsing histories.</p></li>
<li><p><strong>Economics</strong>: Estimating the effect of job training programs on income by matching participants with non-participants based on demographic and employment history.</p></li>
</ul>
</div>
<div id="structural-causal-models-and-directed-acyclic-graphs" class="section level4" number="26.7.2.2">
<h4>
<span class="header-section-number">26.7.2.2</span> Structural Causal Models and Directed Acyclic Graphs<a class="anchor" aria-label="anchor" href="#structural-causal-models-and-directed-acyclic-graphs"><i class="fas fa-link"></i></a>
</h4>
<p>SCMs provide a mathematical framework to represent causal relationships using structural equations and directed acyclic graphs (DAGs). These models explicitly encode assumptions about how variables influence each other.</p>
<p><strong>Key Assumptions</strong></p>
<ul>
<li><p>Correct DAG Specification: The researcher must correctly specify the causal graph structure.</p></li>
<li><p>Exclusion Restrictions: Some variables must only affect outcomes through specified causal pathways.</p></li>
</ul>
<p><strong>Why It’s Model-Based</strong></p>
<ul>
<li><p>SCMs require explicit causal assumptions, unlike design-based approaches that rely on external assignments.</p></li>
<li><p>Identification depends on structural equations, which can be misspecified.</p></li>
</ul>
<p><strong>Examples</strong></p>
<ul>
<li><p><strong>Marketing</strong>: Modeling the causal impact of pricing strategies on sales while accounting for advertising, competitor actions, and seasonal effects.</p></li>
<li><p><strong>Economics</strong>: Estimating the effect of education on wages, considering the impact of family background, school quality, and job market conditions.</p></li>
</ul>
<p><strong>Covariate Adjustment (Regression-Based Approaches)</strong></p>
<p>Regression models estimate causal effects by controlling for observed confounders. This includes linear regression, logistic regression, and more flexible models like generalized additive models (GAMs).</p>
<p><strong>Key Assumptions</strong></p>
<ul>
<li><p>Linear or Nonlinear Functional Form Must Be Correct.</p></li>
<li><p>No Omitted Variable Bias: All relevant confounders must be measured and included.</p></li>
</ul>
<p><strong>Why It’s Model-Based</strong></p>
<ul>
<li><p>Estimates depend entirely on the correctness of the model form and covariates included.</p></li>
<li><p>Unlike design-based methods, there is no exogenous source of variation.</p></li>
</ul>
<p><strong>Examples</strong></p>
<ul>
<li><p><strong>Marketing</strong>: Estimating the effect of social media ads on conversions while controlling for past purchase behavior and customer demographics.</p></li>
<li><p><strong>Economics</strong>: Evaluating the impact of financial aid on student performance, adjusting for prior academic records.</p></li>
</ul>
</div>
<div id="machine-learning-for-causal-inference" class="section level4" number="26.7.2.3">
<h4>
<span class="header-section-number">26.7.2.3</span> Machine Learning for Causal Inference<a class="anchor" aria-label="anchor" href="#machine-learning-for-causal-inference"><i class="fas fa-link"></i></a>
</h4>
<p>Machine learning (ML) techniques, such as causal forests, Bayesian Additive Regression Trees (BART), and double machine learning (DML), provide flexible methods for estimating treatment effects without strict functional form assumptions.</p>
<p><strong>Key Assumptions</strong></p>
<ul>
<li><p>Sufficient Training Data: ML models require large datasets to capture treatment heterogeneity.</p></li>
<li><p>Algorithm Interpretability: Unlike standard regression, ML-based causal inference can be harder to interpret.</p></li>
</ul>
<p><strong>Why It’s Model-Based</strong></p>
<ul>
<li><p>Relies on statistical learning algorithms rather than external assignment mechanisms.</p></li>
<li><p>Identification depends on data-driven feature selection, not a policy design.</p></li>
</ul>
<p><strong>Examples</strong></p>
<ul>
<li><p><strong>Marketing</strong>: Predicting individualized treatment effects of ad targeting using causal forests.</p></li>
<li><p><strong>Economics</strong>: Estimating heterogeneous effects of tax incentives on business investment.</p></li>
</ul>
</div>
</div>
<div id="placing-methods-along-a-spectrum" class="section level3" number="26.7.3">
<h3>
<span class="header-section-number">26.7.3</span> Placing Methods Along a Spectrum<a class="anchor" aria-label="anchor" href="#placing-methods-along-a-spectrum"><i class="fas fa-link"></i></a>
</h3>
<p>In reality, each method balances these two philosophies differently:</p>
<ul>
<li><p><strong>Strongly Design-Based</strong>: Randomized Controlled Trials, clear natural experiments (e.g., lotteries), or near-random assignment rules (RD near the threshold).</p></li>
<li><p><strong>Hybrid / Semi-Design Approaches</strong>: Difference-in-Differences, Synthetic Control, many matching approaches (they rely on credible assumptions or designs but often still need modeling choices, e.g., functional form for trends).</p></li>
<li><p><strong>Strongly Model-Based</strong>: Structural equation models (SCMs), certain propensity score approaches, Bayesian causal inference with a fully specified likelihood, etc.</p></li>
</ul>
<p>Hence, <em>the key question for each method is:</em></p>
<blockquote>
<p><strong>“How much is identification relying on the ‘as-good-as-random’ design versus how much on structural or statistical modeling assumptions?”</strong></p>
</blockquote>
<ul>
<li><p>If you can argue the variation in treatment is practically random (or near-random) from a design standpoint, you’re leaning toward the design-based camp.</p></li>
<li><p>If your identification crucially depends on specifying a correct model or having strong assumptions about the data-generating process, you’re more in the model-based camp.</p></li>
</ul>
<p>Most real-world applications lie somewhere in the middle, combining aspects of both approaches.</p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<caption><strong>Model-Based vs. Design-Based Causal Inference: Key Differences</strong></caption>
<colgroup>
<col width="24%">
<col width="40%">
<col width="34%">
</colgroup>
<thead><tr class="header">
<th><strong>Feature</strong></th>
<th><strong>Design-Based Perspective</strong></th>
<th><strong>Model-Based Perspective</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Causal Identification</strong></td>
<td>Based on external design (e.g., policy, cutoff, exogenous event).</td>
<td>Based on statistical modeling of treatment assignment.</td>
</tr>
<tr class="even">
<td><strong>Reliance on Exogeneity</strong></td>
<td>Yes, due to natural variation in treatment assignment.</td>
<td>No, relies on observed data adjustments.</td>
</tr>
<tr class="odd">
<td><strong>Control for Confounders</strong></td>
<td>Partially through design (e.g., RD exploits cutoffs).</td>
<td>Entirely through covariate control.</td>
</tr>
<tr class="even">
<td><strong>Handling of Unobserved Confounders</strong></td>
<td>Often addressed through <strong>design assumptions</strong>.</td>
<td>Assumes <strong>ignorability</strong> (no unobserved confounders).</td>
</tr>
<tr class="odd">
<td><strong>Examples</strong></td>
<td>RD, DiD, IV, Synthetic Control.</td>
<td>PSM, DAGs, Regression-Based, ML-Based Causal Inference.</td>
</tr>
</tbody>
</table></div>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></div>
<div class="next"><a href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-quasi-experimental"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="nav-link" href="#identification-strategy-in-quasi-experiments"><span class="header-section-number">26.1</span> Identification Strategy in Quasi-Experiments</a></li>
<li><a class="nav-link" href="#robustness-checks"><span class="header-section-number">26.2</span> Robustness Checks</a></li>
<li><a class="nav-link" href="#establishing-mechanisms"><span class="header-section-number">26.3</span> Establishing Mechanisms</a></li>
<li><a class="nav-link" href="#limitations-of-quasi-experiments"><span class="header-section-number">26.4</span> Limitations of Quasi-Experiments</a></li>
<li>
<a class="nav-link" href="#assumptions-for-identifying-treatment-effects"><span class="header-section-number">26.5</span> Assumptions for Identifying Treatment Effects</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-sutva"><span class="header-section-number">26.5.1</span> Stable Unit Treatment Value Assumption</a></li>
<li><a class="nav-link" href="#sec-conditional-ignorability-assumption"><span class="header-section-number">26.5.2</span> Conditional Ignorability Assumption</a></li>
<li><a class="nav-link" href="#sec-overlap-positivity-assumption"><span class="header-section-number">26.5.3</span> Overlap (Positivity) Assumption</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-natural-experiments"><span class="header-section-number">26.6</span> Natural Experiments</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-problem-of-reusing-natural-experiments"><span class="header-section-number">26.6.1</span> The Problem of Reusing Natural Experiments</a></li>
<li><a class="nav-link" href="#statistical-challenges-in-reusing-natural-experiments"><span class="header-section-number">26.6.2</span> Statistical Challenges in Reusing Natural Experiments</a></li>
<li><a class="nav-link" href="#solutions-multiple-testing-corrections"><span class="header-section-number">26.6.3</span> Solutions: Multiple Testing Corrections</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#design-vs.-model-based-approaches"><span class="header-section-number">26.7</span> Design vs. Model-Based Approaches</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-design-based"><span class="header-section-number">26.7.1</span> Design-Based Perspective</a></li>
<li><a class="nav-link" href="#sec-model-based-perspective"><span class="header-section-number">26.7.2</span> Model-Based Perspective</a></li>
<li><a class="nav-link" href="#placing-methods-along-a-spectrum"><span class="header-section-number">26.7.3</span> Placing Methods Along a Spectrum</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/26-quasi-experimental.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/26-quasi-experimental.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-03-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
