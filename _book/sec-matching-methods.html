<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 35 Matching Methods | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="Matching is a strategy that aims to eliminate—or at least minimize—potential sources of bias by constructing treatment and comparison groups with similar observed characteristics. By doing so, any...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 35 Matching Methods | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/sec-matching-methods.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="Matching is a strategy that aims to eliminate—or at least minimize—potential sources of bias by constructing treatment and comparison groups with similar observed characteristics. By doing so, any...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 35 Matching Methods | A Guide on Data Analysis">
<meta name="twitter:description" content="Matching is a strategy that aims to eliminate—or at least minimize—potential sources of bias by constructing treatment and comparison groups with similar observed characteristics. By doing so, any...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="active" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="sec-endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="sec-directed-acyclic-graphs.html"><span class="header-section-number">38</span> Directed Acyclic Graphs</a></li>
<li><a class="" href="sec-controls.html"><span class="header-section-number">39</span> Controls</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li><a class="" href="high-performance-computing.html"><span class="header-section-number">44</span> High-Performance Computing</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="chapter-cluster-randomization-and-interference-bias.html"><span class="header-section-number">C</span> Chapter: Cluster Randomization and Interference Bias</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="sec-matching-methods" class="section level1" number="35">
<h1>
<span class="header-section-number">35</span> Matching Methods<a class="anchor" aria-label="anchor" href="#sec-matching-methods"><i class="fas fa-link"></i></a>
</h1>
<p>Matching is a strategy that aims to eliminate—or at least minimize—potential sources of bias by constructing treatment and comparison groups with similar observed characteristics. By doing so, any observed differences in outcomes between these groups can be attributed more confidently to the treatment itself rather than to other factors. In observational research, matching is frequently combined with <a href="sec-difference-in-differences.html#sec-difference-in-differences">Difference-in-Differences</a> (DiD) techniques to address issues of selection bias, particularly when multiple pre-treatment outcomes are available.</p>
<blockquote>
<p>Matching is defined as “any method that aims to equate (or”balance”) the distribution of covariates in the treated and control groups.” <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-stuart2010matching">Stuart 2010, 1</a>)</span></p>
</blockquote>
<p>Matching is particularly useful when:</p>
<ul>
<li>Outcomes are <strong>not yet observed</strong>, such as in follow-up studies, and you want to construct balanced treatment/control groups.</li>
<li>Outcomes <strong>are available</strong>, but you wish to <strong>reduce model dependence</strong> and <strong>improve robustness</strong>.</li>
</ul>
<blockquote>
<p>Conceptually, matching can also be viewed through the lens of <strong>missing data</strong>, since we never observe both potential outcomes <span class="math inline">\((Y_i^T, Y_i^C)\)</span> for any unit. Hence, this topic closely relates to <a href="imputation-missing-data.html#imputation-missing-data">Imputation (Missing Data)</a>.</p>
</blockquote>
<div id="introduction-and-motivation" class="section level2" number="35.1">
<h2>
<span class="header-section-number">35.1</span> Introduction and Motivation<a class="anchor" aria-label="anchor" href="#introduction-and-motivation"><i class="fas fa-link"></i></a>
</h2>
<div id="why-match" class="section level3" number="35.1.1">
<h3>
<span class="header-section-number">35.1.1</span> Why Match?<a class="anchor" aria-label="anchor" href="#why-match"><i class="fas fa-link"></i></a>
</h3>
<p>In many observational studies, researchers do not have the luxury of randomization. Subjects (people, firms, schools, etc.) typically select or are selected into treatment based on certain observed and/or unobserved characteristics. This can introduce systematic differences (selection bias) that confound causal inference. Matching attempts to approximate a randomized experiment by “balancing” these observed characteristics between treated and non-treated (control) units.</p>
<ul>
<li>
<strong>Goal:</strong> Reduce model dependence and clarify causal effects by ensuring that treated and control subjects have sufficiently comparable covariates.</li>
<li>
<strong>Challenge:</strong> Even if matching achieves balance in observed covariates, any <strong>unobserved</strong> confounders remain a threat to identification (i.e., Matching is only a selection observables identification strategy). Matching does not magically fix bias from unobserved variables.</li>
</ul>
<p>To understand why causal inference is difficult in observational studies, consider:</p>
<p><span class="math display">\[
\begin{aligned} E(Y_i^T | T) - E(Y_i^C | C) &amp;= E(Y_i^T - Y_i^C | T) + \underbrace{[E(Y_i^C | T) - E(Y_i^C | C)]}_{\text{Selection Bias}} \\ \end{aligned} \]</span></p>
<ul>
<li>The term <span class="math inline">\(E(Y_i^T - Y_i^C | T)\)</span> is the <strong>causal effect</strong> (specifically the ATT).</li>
<li>The term <span class="math inline">\(E(Y_i^C | T) - E(Y_i^C | C)\)</span> reflects <strong>selection bias</strong> due to systematic differences in the untreated potential outcome across treated and control groups.</li>
</ul>
<p>Random assignment ensures:</p>
<p><span class="math display">\[ E(Y_i^C | T) = E(Y_i^C | C) \]</span></p>
<p>which eliminates selection bias. In observational data, however, this equality rarely holds.</p>
<p>Matching aims to mimic randomization by <strong>conditioning on covariates</strong> <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[ E(Y_i^C | X, T) = E(Y_i^C | X, C) \]</span></p>
<p>For example, propensity score matching achieves this balance by conditioning on the <strong>propensity score</strong> <span class="math inline">\(P(X)\)</span>:</p>
<p><span class="math display">\[ E(Y_i^C | P(X), T) = E(Y_i^C | P(X), C) \]</span></p>
<p>(See <a href="sec-matching-methods.html#sec-propensity-scores">Propensity Scores</a> for further discussion.)</p>
<p>The <a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a> (ATE) under matching is typically estimated as:</p>
<p><span class="math display">\[ \frac{1}{N_T} \sum_{i=1}^{N_T} \left(Y_i^T - \frac{1}{N_{C_i}} \sum_{j \in \mathcal{C}_i} Y_j^C\right) \]</span></p>
<p>where <span class="math inline">\(\mathcal{C}_i\)</span> denotes the matched controls for treated unit <span class="math inline">\(i\)</span>.</p>
<p>Standard Errors in Matching</p>
<ul>
<li>Matching does not have a closed-form standard error for the ATE or ATT.</li>
<li>Therefore, we rely on bootstrapping to estimate uncertainty.</li>
</ul>
<blockquote>
<p><strong>Note</strong>: Matching tends to yield larger standard errors than <a href="linear-regression.html#ordinary-least-squares">OLS</a> because it reduces the effective sample size by discarding unmatched observations.</p>
</blockquote>
<hr>
</div>
<div id="matching-as-pruning" class="section level3" number="35.1.2">
<h3>
<span class="header-section-number">35.1.2</span> Matching as “Pruning”<a class="anchor" aria-label="anchor" href="#matching-as-pruning"><i class="fas fa-link"></i></a>
</h3>
<p>Matching can be thought of as “<strong>pruning</strong>” (a <strong>preprocessing</strong> step) <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-king2017balance">G. King, Lucas, and Nielsen 2017</a>)</span>. The goal is to <strong>prune</strong> unmatched or poorly matched units before conducting analysis, reducing model dependence.</p>
<p>Without Matching:</p>
<ul>
<li>Imbalanced data → Model dependence → Researcher discretion → Biased estimates</li>
</ul>
<p>With Matching:</p>
<ul>
<li>Balanced data → Reduces discretion → More credible causal inference</li>
</ul>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<caption>Degree of Balance Across Designs</caption>
<colgroup>
<col width="33%">
<col width="34%">
<col width="31%">
</colgroup>
<thead><tr class="header">
<th>Balance of Covariates</th>
<th>Complete Randomization</th>
<th>Fully Exact Matching</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Observed</strong></td>
<td>On average</td>
<td>Exact</td>
</tr>
<tr class="even">
<td><strong>Unobserved</strong></td>
<td>On average</td>
<td>On average</td>
</tr>
</tbody>
</table></div>
<p>Fully blocked or exactly matched designs outperform randomized ones on:</p>
<ul>
<li><strong>Imbalance</strong></li>
<li><strong>Model dependence</strong></li>
<li><strong>Efficiency and power</strong></li>
<li><strong>Bias</strong></li>
<li><strong>Robustness</strong></li>
<li><strong>Research costs</strong></li>
</ul>
<hr>
</div>
<div id="matching-with-did" class="section level3" number="35.1.3">
<h3>
<span class="header-section-number">35.1.3</span> Matching with DiD<a class="anchor" aria-label="anchor" href="#matching-with-did"><i class="fas fa-link"></i></a>
</h3>
<p>Matching can be fruitfully combined with DiD when multiple pre-treatment periods are available. Such designs can help correct for selection bias under certain assumptions:</p>
<ul>
<li>When selection bias is symmetric around the treatment date, standard DID (implemented symmetrically around the treatment date) remains consistent <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-chabe2015analysis">Chabé-Ferret 2015</a> )</span>.</li>
<li>If selection bias is asymmetric, simulations by <span class="citation">Chabé-Ferret (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-chabe2015analysis">2015</a>)</span> show that symmetric DID still outperforms matching alone, although having more pre-treatment observations can improve matching performance.</li>
</ul>
<p>In short, matching is not a universal solution but often provides a helpful preprocessing step before conducting DiD or other causal estimation methods <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-smith2005does">J. A. Smith and Todd 2005</a>)</span>.</p>
<hr>
</div>
</div>
<div id="key-assumptions-4" class="section level2" number="35.2">
<h2>
<span class="header-section-number">35.2</span> Key Assumptions<a class="anchor" aria-label="anchor" href="#key-assumptions-4"><i class="fas fa-link"></i></a>
</h2>
<p>Matching relies on the standard set of assumptions underpinning <a href="sec-matching-methods.html#sec-selection-on-observables">selection on observables</a>—also known as the <strong>back-door criterion</strong> (see <a href="sec-quasi-experimental.html#assumptions-for-identifying-treatment-effects">Assumptions for Identifying Treatment Effects</a>). When these assumptions hold, matching can yield valid estimates of causal effects by constructing treated and control groups that are comparable on observed covariates.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Strong</strong> <a href="sec-quasi-experimental.html#sec-conditional-ignorability-assumption">Conditional Ignorability Assumption</a> (Unconfoundedness)</li>
</ol>
<p>Also known as the <strong>no hidden bias</strong> or <strong>ignorability</strong> assumption:</p>
<p><span class="math display">\[
(Y(0),\, Y(1)) \,\perp\, T \,\big|\, X
\]</span></p>
<p>This implies that, conditional on covariates <span class="math inline">\(X\)</span>, treatment assignment is independent of the potential outcomes. In other words, there are no unobserved confounders once we adjust for <span class="math inline">\(X\)</span>.</p>
<ul>
<li>This assumption is not testable, but it is more plausible when all relevant confounders are observed and included in <span class="math inline">\(X\)</span>.</li>
<li>It is often satisfied approximately when unobserved covariates are highly correlated with the observed ones.</li>
<li>If unobserved variables are unrelated to <span class="math inline">\(X\)</span>, you can:
<ul>
<li>Conduct sensitivity analysis to test the robustness of your estimates.</li>
<li>Apply design sensitivity techniques: If unobserved confounding is suspected, methods such as <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-heller2009split">Heller, Rosenbaum, and Small 2009</a>)</span>’s design sensitivity approaches or bounding approaches (e.g., the <code>rbounds</code> R package) can be used to test how robust findings are to hidden bias.</li>
</ul>
</li>
</ul>
<blockquote>
<p>This is the cornerstone assumption of matching: without it, causal inference from observational data is generally invalid.</p>
</blockquote>
<hr>
<ol start="2" style="list-style-type: decimal">
<li>
<a href="sec-quasi-experimental.html#sec-overlap-positivity-assumption">Overlap (Positivity) Assumption</a> <strong>(Common Support)</strong>
</li>
</ol>
<p><span class="math display">\[
0 &lt; P(T=1 \mid X) &lt; 1 \quad \forall X
\]</span></p>
<p>This condition ensures that, for every value of the covariates <span class="math inline">\(X\)</span>, there is a positive probability of receiving both treatment and control.</p>
<ul>
<li>If this assumption fails, there are regions of covariate space where either treatment or control units are absent, making comparison impossible.</li>
<li>Matching enforces this assumption by discarding units outside of the region of common support.</li>
</ul>
<blockquote>
<p>This pruning step is both a strength and limitation of matching—it improves internal validity at the cost of generalizability.</p>
</blockquote>
<hr>
<ol start="3" style="list-style-type: decimal">
<li>
<a href="sec-quasi-experimental.html#sec-sutva">Stable Unit Treatment Value Assumption</a> (SUTVA)</li>
</ol>
<p>SUTVA requires that:</p>
<ul>
<li>The potential outcomes for any individual unit do not depend on the treatment assignment of other units.</li>
</ul>
<p>That is, there are <strong>no interference or spillover effects</strong> between units.</p>
<ul>
<li>Mathematically, <span class="math inline">\(Y_i(T_i)\)</span> depends only on <span class="math inline">\(T_i\)</span>, not on <span class="math inline">\(T_j\)</span> for any <span class="math inline">\(j \neq i\)</span>.</li>
<li>Violations can occur in settings like:
<ul>
<li>Education (peer effects)</li>
<li>Epidemiology (disease transmission)</li>
<li>Marketing (network influence)</li>
</ul>
</li>
</ul>
<blockquote>
<p>In cases with known spillover, efforts should be made to reduce interactions or explicitly model interference.</p>
</blockquote>
<hr>
<p>Summary of Assumptions for Matching</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="18%">
<col width="52%">
<col width="28%">
</colgroup>
<thead><tr class="header">
<th>Assumption</th>
<th>Description</th>
<th>Notation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Conditional Ignorability</strong></td>
<td>No hidden confounding after conditioning on covariates</td>
<td><span class="math inline">\((Y(0), Y(1)) \perp T \mid X\)</span></td>
</tr>
<tr class="even">
<td><strong>Overlap (Positivity)</strong></td>
<td>Each unit has a non-zero probability of treatment and control assignment</td>
<td><span class="math inline">\(0 &lt; P(T=1 \mid X) &lt; 1\)</span></td>
</tr>
<tr class="odd">
<td><strong>SUTVA</strong></td>
<td>No interference between units; one unit’s outcome unaffected by another’s treatment</td>
<td>
<span class="math inline">\(Y_i(T_i)\)</span> unaffected by <span class="math inline">\(T_j\)</span> for <span class="math inline">\(j \ne i\)</span>
</td>
</tr>
</tbody>
</table></div>
<p>These three assumptions form the foundation for valid causal inference using matching methods.</p>
<hr>
</div>
<div id="framework-for-generalization" class="section level2" number="35.3">
<h2>
<span class="header-section-number">35.3</span> Framework for Generalization<a class="anchor" aria-label="anchor" href="#framework-for-generalization"><i class="fas fa-link"></i></a>
</h2>
<p>Let:</p>
<ul>
<li>
<span class="math inline">\(P_t\)</span>, <span class="math inline">\(P_c\)</span>: treated and control populations</li>
<li>
<span class="math inline">\(N_t\)</span>, <span class="math inline">\(N_c\)</span>: random samples drawn from <span class="math inline">\(P_t\)</span>, <span class="math inline">\(P_c\)</span>
</li>
<li>
<span class="math inline">\(\mu_i\)</span>, <span class="math inline">\(\Sigma_i\)</span>: means and covariance matrices of the <span class="math inline">\(p\)</span> covariates in group <span class="math inline">\(i \in \{t, c\}\)</span>
</li>
<li>
<span class="math inline">\(X_j\)</span>: vector of covariates for individual <span class="math inline">\(j\)</span>
</li>
<li>
<span class="math inline">\(T_j \in \{0, 1\}\)</span>: treatment indicator (1 = treated, 0 = control)</li>
<li>
<span class="math inline">\(Y_j\)</span>: observed outcome</li>
<li>Assume <span class="math inline">\(N_t &lt; N_c\)</span> (i.e., more controls than treated)</li>
</ul>
<p>The conditional treatment effect is:</p>
<p><span class="math display">\[
\tau(x) = R_1(x) - R_0(x), \quad \text{where } R_1(x) = E[Y(1) \mid X = x], \quad R_0(x) = E[Y(0) \mid X = x]
\]</span></p>
<p>If we assume <strong>constant treatment effects (parallel trends)</strong>, then <span class="math inline">\(\tau(x) = \tau\)</span> for all <span class="math inline">\(x\)</span>. If this assumption is relaxed, we can still estimate an <strong>average</strong> effect over the distribution of <span class="math inline">\(X\)</span>.</p>
<p><strong>Common Estimands</strong></p>
<ul>
<li>
<a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a> (ATE): Average causal effect across all units.</li>
<li>
<a href="sec-causal-inference.html#sec-average-treatment-effect-on-the-treated">Average Treatment Effect on the Treated</a> (ATT): Causal effect for treated units only.</li>
</ul>
<hr>
</div>
<div id="steps-for-matching" class="section level2" number="35.4">
<h2>
<span class="header-section-number">35.4</span> Steps for Matching<a class="anchor" aria-label="anchor" href="#steps-for-matching"><i class="fas fa-link"></i></a>
</h2>
<p>Most matching methods rely on:</p>
<ul>
<li>
<strong>Propensity score</strong>: summarizes <span class="math inline">\(P(T=1|X)\)</span>
</li>
<li>
<strong>Distance metric</strong>: measures similarity</li>
<li>
<strong>Covariates</strong>: assumed to satisfy ignorability</li>
</ul>
<div id="step-1-define-closeness-distance-metrics" class="section level3" number="35.4.1">
<h3>
<span class="header-section-number">35.4.1</span> Step 1: Define “Closeness” (Distance Metrics)<a class="anchor" aria-label="anchor" href="#step-1-define-closeness-distance-metrics"><i class="fas fa-link"></i></a>
</h3>
<p>Matching requires a <strong>distance metric</strong> to define similarity between treated and control units.</p>
<p><strong>Variable Selection Guidelines</strong></p>
<ul>
<li>Include as many pre-treatment covariates as possible to support conditional ignorability.</li>
<li>Avoid post-treatment variables, which introduce bias.</li>
<li>Be cautious with variables (e.g., heavy drug users) highly correlated with the outcome (e.g., heavy drinkers) but not treatment (e.g., mediators).</li>
<li>If variables are uncorrelated with both treatment and outcome, the cost of inclusion is small.</li>
</ul>
<p><strong>Distance Measures</strong></p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="13%">
<col width="23%">
<col width="62%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Formula</th>
<th>Notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Exact Matching</strong></td>
<td>
<span class="math inline">\(D_{ij} = 0\)</span> if <span class="math inline">\(X_i = X_j\)</span>, else <span class="math inline">\(\infty\)</span>
</td>
<td>Only feasible in low dimensions; can be relaxed via [Coarsened Exact Matching]</td>
</tr>
<tr class="even">
<td><strong>Mahalanobis Distance</strong></td>
<td><span class="math inline">\(D_{ij} = (X_i - X_j)' \Sigma^{-1}(X_i - X_j)\)</span></td>
<td>
<span class="math inline">\(\Sigma\)</span> (var-covar matrix of <span class="math inline">\(X\)</span>) from control group if ATT is of interest or pooled if ATE is of interest; sensitive to dimensionality</td>
</tr>
<tr class="odd">
<td><strong>Propensity Score</strong></td>
<td><span class="math inline">\(D_{ij} = |e_i - e_j|\)</span></td>
<td>
<p>Where <span class="math inline">\(e_k\)</span> is the estimated propensity score <span class="math inline">\(P(T=1 \mid X_k)\)</span> for unit <span class="math inline">\(k\)</span>.</p>
<p>Advanced: <strong>Prognostic scores</strong> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-hansen2008prognostic">B. B. Hansen 2008</a>)</span> require modeling <span class="math inline">\(E[Y(0)|X]\)</span>, so they depend on the outcome model.</p>
</td>
</tr>
<tr class="even">
<td><strong>Logit Propensity Score</strong></td>
<td><span class="math inline">\(D_{ij} = |\text{logit}(e_i) - \text{logit}(e_j)|\)</span></td>
<td>More stable in tails of distribution</td>
</tr>
</tbody>
</table></div>
<blockquote>
<p><strong>Tip</strong>: In high dimensions, exact and Mahalanobis matching perform poorly. Combining Mahalanobis with <strong>propensity score calipers</strong> can improve robustness <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rubin2000combining">Rubin and Thomas 2000</a>)</span>.</p>
</blockquote>
<p>Advanced methods for longitudinal setting:</p>
<ul>
<li>
<strong>Marginal Structural Models</strong>: for time-varying treatments <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-robins2000marginal">Robins, Hernan, and Brumback 2000</a>)</span>
</li>
<li>
<strong>Balanced Risk Set Matching</strong>: for survival analysis <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-li2001balanced">Y. P. Li, Propert, and Rosenbaum 2001</a>)</span>
</li>
</ul>
<hr>
</div>
<div id="step-2-matching-algorithms" class="section level3" number="35.4.2">
<h3>
<span class="header-section-number">35.4.2</span> Step 2: Matching Algorithms<a class="anchor" aria-label="anchor" href="#step-2-matching-algorithms"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>Nearest Neighbor Matching</li>
</ol>
<ul>
<li>
<strong>Greedy matching</strong>: Fast, but suboptimal under competition for controls.</li>
<li>
<strong>Optimal matching</strong>: Minimizes global distance across all pairs.</li>
<li>
<strong>Ratio matching (k:1)</strong>: Useful when controls outnumber treated; choose <span class="math inline">\(k\)</span> using trade-off between bias and variance <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rubin1996matching">Rubin and Thomas 1996</a>)</span>.</li>
<li>
<strong>With vs. without replacement</strong>:
<ul>
<li>
<strong>With replacement</strong>: Improves matching quality, but requires <strong>frequency weights</strong> for analysis.</li>
<li>
<strong>Without replacement</strong>: Simpler, but less flexible.</li>
</ul>
</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Subclassification, Full Matching, and Weighting</li>
</ol>
<p>These methods generalize nearest-neighbor approaches by assigning <strong>fractional weights</strong>.</p>
<ul>
<li>
<strong>Subclassification</strong>: Partition into strata based on propensity score (e.g., quintiles).</li>
<li>
<strong>Full Matching</strong>: Each treated unit is matched to a weighted group of controls (and vice versa) to minimize average within-set distance.</li>
<li>
<strong>Weighting</strong>: Weighting techniques use propensity scores to estimate the ATE. However, if the weights are extreme, the resulting variance may be inflated—not due to the underlying probabilities, but due to the estimation procedure itself. To address this issue, researchers can employ (1) weight trimming or (2) doubly robust methods when using propensity scores for weighting or matching.
<ul>
<li>
<strong>Inverse Probability of Treatment Weighting (IPTW)</strong>: <span class="math display">\[
w_i = \frac{T_i}{\hat{e}_i} + \frac{1 - T_i}{1 - \hat{e}_i}
\]</span>
</li>
<li>
<strong>Odds weighting</strong>: <span class="math display">\[
w_i = T_i + (1 - T_i)\frac{\hat{e}_i}{1 - \hat{e}_i}
\]</span>
</li>
<li>
<strong>Kernel weighting</strong>: Smooth average over control group (popular in economics).</li>
<li>
<strong>Trimming and Doubly-Robust Methods</strong>: Reduce variance due to extreme weights.</li>
</ul>
</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Assessing Common Support</li>
</ol>
<ul>
<li>Use propensity score histograms to visualize overlap.</li>
<li>Units outside the convex hull of <span class="math inline">\(X\)</span> (i.e., unmatched regions) can be discarded.</li>
<li>Lack of overlap indicates that some comparisons are extrapolations, not empirical matches.</li>
</ul>
<hr>
</div>
<div id="step-3-diagnosing-match-quality" class="section level3" number="35.4.3">
<h3>
<span class="header-section-number">35.4.3</span> Step 3: Diagnosing Match Quality<a class="anchor" aria-label="anchor" href="#step-3-diagnosing-match-quality"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Balance Diagnostics</strong></p>
<p>Matching aims to balance the covariate distributions between treated and control units. A well-matched sample satisfies:</p>
<p><span class="math display">\[
\tilde{p}(X \mid T=1) \approx \tilde{p}(X \mid T=0)
\]</span></p>
<p>where <span class="math inline">\(\tilde{p}\)</span> is the empirical distribution.</p>
<ol style="list-style-type: decimal">
<li>Numerical Checks</li>
</ol>
<ul>
<li>
<strong>Standardized differences in means</strong> (most common): Should be <span class="math inline">\(&lt; 0.1\)</span>
</li>
<li>
<strong>Standardized difference of propensity scores</strong>: Should be <span class="math inline">\(&lt; 0.25\)</span> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rubin2001using">Rubin 2001</a>)</span>
</li>
<li>
<strong>Variance ratio of propensity scores</strong>: Between 0.5 and 2.0 <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rubin2001using">Rubin 2001</a>)</span>
</li>
<li>
<strong>Variance of residuals</strong> after regression on propensity score (treated vs. control) for each covariate</li>
</ul>
<blockquote>
<p>Avoid using p-values as diagnostics—they conflate balance with statistical power and are sensitive to sample size.</p>
</blockquote>
<ol start="2" style="list-style-type: decimal">
<li>Graphical Diagnostics</li>
</ol>
<ul>
<li><strong>Empirical Distribution Plots</strong></li>
<li><strong>Quantile-Quantile (QQ) Plots</strong></li>
<li>
<strong>Love Plots</strong>: Summarize standardized differences before/after matching</li>
</ul>
<hr>
</div>
<div id="step-4-estimating-treatment-effects" class="section level3" number="35.4.4">
<h3>
<span class="header-section-number">35.4.4</span> Step 4: Estimating Treatment Effects<a class="anchor" aria-label="anchor" href="#step-4-estimating-treatment-effects"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>After Matching</li>
</ol>
<ul>
<li>With k:1 matching with replacement, use weights to adjust for reuse of controls.</li>
<li>Use regression adjustment on matched samples to improve precision and adjust for residual imbalance.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>After Subclassification or Full Matching</li>
</ol>
<ul>
<li>
<strong>ATT</strong>: Weight subclass-specific estimates by number of treated units.</li>
<li>
<strong>ATE</strong>: Weight by total units per subclass.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Variance Estimation</li>
</ol>
<p>Must reflect uncertainty in both:</p>
<ol style="list-style-type: decimal">
<li>The <strong>matching procedure</strong> (sampling and distance calculation) (Step 3)</li>
<li>The <strong>outcome model</strong> (regression, difference-in-means, etc.) (Step 4)</li>
</ol>
<p>Often estimated via <strong>bootstrapping</strong>.</p>
<hr>
</div>
</div>
<div id="special-considerations" class="section level2" number="35.5">
<h2>
<span class="header-section-number">35.5</span> Special Considerations<a class="anchor" aria-label="anchor" href="#special-considerations"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><strong>Handling Missing Data</strong></li>
</ol>
<ul>
<li>Use generalized boosted models or multiple imputation <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-qu2009propensity">Qu and Lipkovich 2009</a>)</span>.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Violation of Ignorability</strong></li>
</ol>
<p>Strategies when unobservables bias treatment:</p>
<ul>
<li>Use pre-treatment measures of outcome</li>
<li>Compare multiple control groups</li>
<li>Conduct sensitivity analysis:
<ul>
<li>Quantify correlation between unobserved confounders and both treatment and outcome to nullify the observed effect</li>
</ul>
</li>
</ul>
<hr>
</div>
<div id="choosing-a-matching-strategy" class="section level2" number="35.6">
<h2>
<span class="header-section-number">35.6</span> Choosing a Matching Strategy<a class="anchor" aria-label="anchor" href="#choosing-a-matching-strategy"><i class="fas fa-link"></i></a>
</h2>
<div id="based-on-estimand" class="section level3" number="35.6.1">
<h3>
<span class="header-section-number">35.6.1</span> Based on Estimand<a class="anchor" aria-label="anchor" href="#based-on-estimand"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<strong>ATE</strong>: Use IPTW or full matching</li>
<li>
<strong>ATT</strong>:
<ul>
<li>If many controls (<span class="math inline">\(N_c &gt; 3N_t\)</span>): k:1 nearest neighbor without replacement</li>
<li>If few controls: subclassification, full matching, or odds weighting</li>
</ul>
</li>
</ul>
</div>
<div id="based-on-diagnostics" class="section level3" number="35.6.2">
<h3>
<span class="header-section-number">35.6.2</span> Based on Diagnostics<a class="anchor" aria-label="anchor" href="#based-on-diagnostics"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>If balanced: proceed with regression on matched samples</li>
<li>If imbalance on few covariates: Mahalanobis matching on those</li>
<li>If imbalance on many covariates: Try k:1 matching with replacement</li>
</ul>
</div>
<div id="selection-criteria" class="section level3" number="35.6.3">
<h3>
<span class="header-section-number">35.6.3</span> Selection Criteria<a class="anchor" aria-label="anchor" href="#selection-criteria"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Minimize standardized differences across many covariates</li>
<li>Especially prioritize prognostic covariates</li>
<li>Minimize number of covariates with large (<span class="math inline">\(&gt;0.25\)</span>) imbalance <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-diamond2013genetic">Diamond and Sekhon 2013</a>)</span>
</li>
</ul>
<p>Matching is not one-size-fits-all. Choose methods based on the target estimand, data structure, and diagnostic results.</p>
<hr>
</div>
</div>
<div id="matching-vs.-regression" class="section level2" number="35.7">
<h2>
<span class="header-section-number">35.7</span> Matching vs. Regression<a class="anchor" aria-label="anchor" href="#matching-vs.-regression"><i class="fas fa-link"></i></a>
</h2>
<p>Matching and regression are two core strategies used in observational studies to adjust for differences in covariates <span class="math inline">\(X\)</span> and estimate causal effects. While both aim to remove bias due to confounding, they approach the problem differently, particularly in how they <strong>weight observations</strong>, handle <strong>functional form assumptions</strong>, and address <strong>covariate balance</strong>.</p>
<p>Neither method can resolve the issue of <strong>unobserved confounding</strong>, but each can be a powerful tool when used with care and supported by appropriate diagnostics.</p>
<ul>
<li>
<strong>Matching</strong> emphasizes covariate balance by pruning the dataset to retain only comparable units. It is nonparametric, focusing on ATT.</li>
<li>
<strong>Regression</strong> (typically <a href="linear-regression.html#ordinary-least-squares">OLS</a>) emphasizes functional form and allows for model-based adjustment, enabling the estimation of ATE and continuous or interactive effects of treatment.</li>
</ul>
<p>Both matching and regression assign implicit or explicit weights to observations during estimation:</p>
<ul>
<li>
<strong>Matching</strong>: Weights observations more heavily in strata with more treated units, aligning with the ATT estimand.</li>
<li>
<a href="linear-regression.html#ordinary-least-squares">OLS</a> <strong>Regression</strong>: Places more weight on strata where the variance of treatment assignment is highest—i.e., when groups are approximately balanced between treated and control (near 50/50).</li>
</ul>
<p>This results in differing estimands and sensitivities:</p>
<blockquote>
<p><strong>Important Caveat</strong>: If your <a href="linear-regression.html#ordinary-least-squares">OLS</a> estimate is biased due to unobserved confounding, your matching estimate is likely biased too. Both depend on the <a href="sec-matching-methods.html#sec-selection-on-observables">selection on observables</a> assumption.</p>
</blockquote>
<p>We explore the difference in estimands between matching and regression, especially for estimating the ATT.</p>
<div id="matching-estimand" class="section level3" number="35.7.1">
<h3>
<span class="header-section-number">35.7.1</span> Matching Estimand<a class="anchor" aria-label="anchor" href="#matching-estimand"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose we want the treatment effect on the treated:</p>
<p><span class="math display">\[
\delta_{\text{TOT}} = E[Y_{1i} - Y_{0i} \mid D_i = 1]
\]</span></p>
<p>Using the <a href="prerequisites.html#law-of-iterated-expectation">Law of Iterated Expectation</a>:</p>
<p><span class="math display">\[
\delta_{\text{TOT}} = E\left[ E[Y_{1i} \mid X_i, D_i = 1] - E[Y_{0i} \mid X_i, D_i = 1] \mid D_i = 1 \right]
\]</span></p>
<p>Assuming conditional independence:</p>
<p><span class="math display">\[
E[Y_{0i} \mid X_i, D_i = 0] = E[Y_{0i} \mid X_i, D_i = 1]
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\begin{aligned}
\delta_{TOT} &amp;= E [ E[ Y_{1i} | X_i, D_i = 1] - E[ Y_{0i}|X_i, D_i = 0 ]|D_i = 1 ] \\
&amp;= E\left[ E[Y_i \mid X_i, D_i = 1] - E[Y_i \mid X_i, D_i = 0] \mid D_i = 1 \right] \\
&amp;= E[\delta_X |D_i = 1]
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\delta_X\)</span> is an <span class="math inline">\(X\)</span>-specific difference in means at covariate value <span class="math inline">\(X_i\)</span></p>
<p>If <span class="math inline">\(X_i\)</span> is discrete, the matching estimand becomes:</p>
<p><span class="math display">\[
\delta_M = \sum_x \delta_x P(X_i = x \mid D_i = 1)
\]</span></p>
<p>where <span class="math inline">\(P(X_i = x |D_i = 1)\)</span> is the probability mass function for <span class="math inline">\(X_i\)</span> given <span class="math inline">\(D_i = 1\)</span></p>
<p>By Bayes’ rule:</p>
<p><span class="math display">\[
P(X_i = x \mid D_i = 1) = \frac{P(D_i = 1 \mid X_i = x) P(X_i = x)}{P(D_i = 1)}
\]</span></p>
<p>So,</p>
<p><span class="math display">\[
\begin{aligned}
\delta_M &amp;= \frac{\sum_x \delta_x P (D_i = 1 | X_i = x) P (X_i = x)}{\sum_x P(D_i = 1 |X_i = x)P(X_i = x)} \\
&amp;= \sum_x \delta_x \frac{ P (D_i = 1 | X_i = x) P (X_i = x)}{\sum_x P(D_i = 1 |X_i = x)P(X_i = x)}
\end{aligned}
\]</span></p>
<hr>
</div>
<div id="regression-estimand" class="section level3" number="35.7.2">
<h3>
<span class="header-section-number">35.7.2</span> Regression Estimand<a class="anchor" aria-label="anchor" href="#regression-estimand"><i class="fas fa-link"></i></a>
</h3>
<p>In regression:</p>
<p><span class="math display">\[
Y_i = \sum_x d_{ix} \beta_x + \delta_R D_i + \varepsilon_i
\]</span></p>
<ul>
<li>
<span class="math inline">\(d_{ix}\)</span> = indicator that <span class="math inline">\(X_i = x\)</span>
</li>
<li>
<span class="math inline">\(\beta_x\)</span> = baseline outcome at <span class="math inline">\(X = x\)</span>
</li>
<li>
<span class="math inline">\(\delta_R\)</span> = regression estimand</li>
</ul>
<p>Then,</p>
<p><span class="math display">\[
\begin{aligned}
\delta_R &amp;= \frac{\sum_x \delta_x [P(D_i = 1 | X_i = x) (1 - P(D_i = 1 | X_i = x))]P(X_i = x)}{\sum_x [P(D_i = 1| X_i = x)(1 - P(D_i = 1 | X_i = x))]P(X_i = x)} \\
&amp;= \sum_x \delta_x \frac{[P(D_i = 1 | X_i = x) (1 - P(D_i = 1 | X_i = x))]P(X_i = x)}{\sum_x [P(D_i = 1| X_i = x)(1 - P(D_i = 1 | X_i = x))]P(X_i = x)}
\end{aligned}
\]</span></p>
<hr>
</div>
<div id="interpretation-weighting-differences" class="section level3" number="35.7.3">
<h3>
<span class="header-section-number">35.7.3</span> Interpretation: Weighting Differences<a class="anchor" aria-label="anchor" href="#interpretation-weighting-differences"><i class="fas fa-link"></i></a>
</h3>
<p>The distinction between matching and regression comes down to how covariate-specific treatment effects <span class="math inline">\(\delta_x\)</span> are weighted:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="3%">
<col width="27%">
<col width="30%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th>Type</th>
<th>Weighting Function</th>
<th>Interpretation</th>
<th>Makes Sense Because…</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Matching</td>
<td><span class="math inline">\(P(D_i = 1 \mid X_i = x)\)</span></td>
<td>Weights more heavily where more treated units exist (ATT-focused)</td>
<td>We’re interested in the effect on the treated, so more weight is placed where treated units are observed</td>
</tr>
<tr class="even">
<td>Regression</td>
<td><span class="math inline">\(\begin{aligned}P(D_i = 1 \mid X_i = x)\\(1 - P(D_i = 1 \mid X_i = x))\end{aligned}\)</span></td>
<td>Weights more where treatment assignment has high variance (i.e., near 50/50 treated/control)</td>
<td>These cells provide lowest-variance estimates of <span class="math inline">\(\delta_x\)</span>, assuming the treatment effect is homogenous across <span class="math inline">\(X\)</span>
</td>
</tr>
</tbody>
</table></div>
<p><strong>Summary Table: Matching vs. Regression</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="41%">
<col width="38%">
</colgroup>
<thead><tr class="header">
<th>Feature</th>
<th>Matching</th>
<th>Regression (OLS)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Functional Form</strong></td>
<td>Less parametric; no assumption of linearity</td>
<td>Parametric; usually assumes linearity</td>
</tr>
<tr class="even">
<td><strong>Primary Estimand</strong></td>
<td>ATT (effect on the treated)</td>
<td>ATE or effects of continuous/interacted treatments</td>
</tr>
<tr class="odd">
<td><strong>Balance</strong></td>
<td>Enforces balance via matched samples</td>
<td>Does not guarantee balance</td>
</tr>
<tr class="even">
<td><strong>Diagnostics</strong></td>
<td>Covariate SMDs, QQ plots, empirical distributions</td>
<td>Residual plots, R-squared, heteroskedasticity tests</td>
</tr>
<tr class="odd">
<td><strong>Unobserved Confounding</strong></td>
<td>Cannot be resolved; assumes ignorability</td>
<td>Same limitation</td>
</tr>
<tr class="even">
<td><strong>Standard Errors</strong></td>
<td>Larger; require bootstrapping</td>
<td>Smaller; closed-form under assumptions</td>
</tr>
<tr class="odd">
<td><strong>Best Used When</strong></td>
<td>High control-to-treated ratio; misspecification concerns</td>
<td>Model is correctly specified; sufficient overlap</td>
</tr>
</tbody>
</table></div>
<hr>
<p><strong>Qualitative Comparisons</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="49%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>Matching</th>
<th>Regression</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Not sensitive to the form of covariate-outcome relationship</td>
<td>Can estimate continuous or interacted treatment effects</td>
</tr>
<tr class="even">
<td>Easier to assess balance and interpret diagnostics</td>
<td>Easier to estimate the effects of all covariates, not just treatment</td>
</tr>
<tr class="odd">
<td>Facilitates clear visual evaluation of overlap and balance</td>
<td>Less intuitive diagnostics; model diagnostics used</td>
</tr>
<tr class="even">
<td>Helps when treatment is rare (prunes clearly incomparable controls)</td>
<td>Performs better with balanced treatment assignment</td>
</tr>
<tr class="odd">
<td>Forces explicit enforcement of common support</td>
<td>May extrapolate outside the support of covariate distributions</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
</div>
<div id="software-and-practical-implementation" class="section level2" number="35.8">
<h2>
<span class="header-section-number">35.8</span> Software and Practical Implementation<a class="anchor" aria-label="anchor" href="#software-and-practical-implementation"><i class="fas fa-link"></i></a>
</h2>
<p>Many R packages provide functionality for implementing the various matching methods discussed above. Below is an overview of some popular options:</p>
<ul>
<li><p><strong>MatchIt</strong>:<br>
Implements a wide range of matching methods (nearest neighbor, optimal, full, subclassification, exact, etc.). It focuses on “preprocessing” data before a final outcome analysis.</p></li>
<li><p><strong>Matching</strong>:<br>
Provides multivariate and propensity score matching, including options for <em>exact</em> and <em>nearest neighbor</em> matching. The package also offers functions to evaluate balance and to conduct sensitivity analyses.</p></li>
<li><p><strong>cem</strong> (<a href="sec-matching-methods.html#sec-cem">Coarsened Exact Matching</a>):<br>
Uses a coarsening approach to create strata within which exact matching can be performed. This can reduce imbalance by discarding units that do not overlap in coarsened covariate space.</p></li>
<li><p><strong>optmatch</strong>:<br>
Enables <em>optimal matching</em> with variable matching ratios and full matching, allowing for flexible group constructions that minimize overall distance.</p></li>
<li><p><strong>MatchingFrontier</strong> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-king2017balance">G. King, Lucas, and Nielsen 2017</a>)</span>:<br>
Finds the “frontier” of matching solutions by balancing sample size (or other constraints) against covariate balance. Allows analysts to see trade-offs in real time.</p></li>
<li><p><strong>CBPS</strong> (Covariate Balancing Propensity Score):<br>
Estimates propensity scores such that covariate balance is directly optimized. This can help avoid iterative re-specification of the propensity score model.</p></li>
<li><p><strong>PanelMatch</strong> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rauh2025panelmatch">Rauh, Kim, and Imai 2025</a>)</span>:<br>
Tailored to panel (longitudinal) data settings, providing matching methods that exploit repeated observations over time (e.g., for DID-type analyses in a time-series cross-sectional environment).</p></li>
<li><p><strong>PSAgraphics</strong>:<br>
Specializes in visual diagnostics for propensity score analyses, offering graphical tools to inspect balance and common support.</p></li>
<li><p><strong>rbounds</strong>:<br>
Conducts <strong>Rosenbaum bounds</strong> sensitivity analysis on matched data. Researchers can examine how a hypothetical unmeasured confounder could undermine their estimated treatment effects.</p></li>
<li><p><strong>twang</strong>:<br>
Implements <em>generalized boosted models (GBM)</em> to estimate propensity scores. Often used for weighting approaches such as inverse probability weighting (IPW).</p></li>
</ul>
<p>In practice, the choice of software and methods hinges on the study design, the nature of the data, and the researcher’s theoretical expectations regarding treatment assignment.</p>
<hr>
</div>
<div id="sec-selection-on-observables" class="section level2" number="35.9">
<h2>
<span class="header-section-number">35.9</span> Selection on Observables<a class="anchor" aria-label="anchor" href="#sec-selection-on-observables"><i class="fas fa-link"></i></a>
</h2>
<p>In observational studies, treatment assignment is typically not randomized. This poses a challenge when estimating causal effects, as treated and control groups may differ systematically. A central assumption that allows us to estimate causal effects from such data is <strong>selection on observables</strong>, also known as <strong>unconfoundedness</strong> or <strong>conditional independence</strong>.</p>
<p>Suppose we observe a binary treatment indicator <span class="math inline">\(T_i \in \{0, 1\}\)</span> and an outcome <span class="math inline">\(Y_i\)</span>. Each unit <span class="math inline">\(i\)</span> has two potential outcomes:</p>
<ul>
<li>
<span class="math inline">\(Y_i(1)\)</span>: outcome if treated</li>
<li>
<span class="math inline">\(Y_i(0)\)</span>: outcome if untreated</li>
</ul>
<p>However, only one of these outcomes is observed for each unit. The average treatment effect on the treated (ATT) is:</p>
<p><span class="math display">\[
\text{ATT} = \mathbb{E}[Y(1) - Y(0) \mid T = 1]
\]</span></p>
<p>To identify this from data, we invoke the <strong>conditional independence assumption</strong>:</p>
<p><span class="math display">\[
(Y(0), Y(1)) \perp T \mid X
\]</span></p>
<p>This assumption means that after controlling for covariates <span class="math inline">\(X\)</span>, treatment is as good as randomly assigned. A secondary assumption is <strong>overlap</strong>:</p>
<p><span class="math display">\[
0 &lt; \mathbb{P}(T = 1 \mid X = x) &lt; 1 \quad \text{for all } x
\]</span></p>
<p>This ensures that for every covariate profile, there is a positive probability of being both treated and untreated.</p>
<p>Matching attempts to approximate the conditions of a randomized experiment by creating a comparison group that is similar to the treated group in terms of observed covariates. Instead of relying solely on model-based adjustment (e.g., regression), matching balances the covariate distribution across treatment groups before estimation.</p>
<hr>
<div id="matching-with-matchit" class="section level3" number="35.9.1">
<h3>
<span class="header-section-number">35.9.1</span> Matching with <code>MatchIt</code><a class="anchor" aria-label="anchor" href="#matching-with-matchit"><i class="fas fa-link"></i></a>
</h3>
<p>We demonstrate the matching procedure using the <code>lalonde</code> dataset, a classic example in the causal inference literature, which investigates the effect of job training on subsequent earnings.</p>
<div class="sourceCode" id="cb927"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/">MatchIt</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"lalonde"</span><span class="op">)</span></span></code></pre></div>
<p>We focus on estimating the effect of the treatment (<code>treat</code>) on earnings in 1978 (<code>re78</code>), conditional on covariates.</p>
<hr>
<p><strong>Step 1: Planning the Analysis</strong></p>
<p>Before conducting matching, several strategic decisions must be made:</p>
<ul>
<li><p><strong>Estimand</strong>: Do you want ATT (effect on treated), ATE (effect in population), or ATC (effect on controls)? Matching typically targets the ATT.</p></li>
<li><p><strong>Covariate Selection</strong>: Only include <strong>pre-treatment variables</strong> that are potential confounders—i.e., affect both the treatment assignment and the outcome <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-austin2011optimal">Austin 2011</a>; <a href="chapter-cluster-randomization-and-interference-bias.html#ref-vanderweele2019principles">T. J. VanderWeele 2019</a>)</span>.</p></li>
<li><p><strong>Distance Measure</strong>: Choose how to quantify similarity between units (e.g., propensity score, Mahalanobis distance).</p></li>
<li><p><strong>Matching Method</strong>: Determine the method (e.g., nearest neighbor, full matching, genetic matching).</p></li>
</ul>
<p>For our demonstration, we focus on ATT using <strong>propensity score matching</strong>.</p>
<hr>
<p><strong>Step 2: Assessing Initial Imbalance</strong></p>
<p>We first assess imbalance between treatment and control groups before matching.</p>
<div class="sourceCode" id="cb928"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Estimate propensity scores with logistic regression</span></span>
<span><span class="va">m.out0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">race</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">nodegree</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>  method <span class="op">=</span> <span class="cn">NULL</span>,     <span class="co"># no matching, only estimates propensity scores</span></span>
<span>  distance <span class="op">=</span> <span class="st">"glm"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summary of balance statistics before matching</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m.out0</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; matchit(formula = treat ~ age + educ + race + married + nodegree + </span></span>
<span><span class="co">#&gt;     re74 + re75, data = MatchIt::lalonde, method = NULL, distance = "glm")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Summary of Balance for All Data:</span></span>
<span><span class="co">#&gt;            Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span><span class="co">#&gt; distance          0.5774        0.1822          1.7941     0.9211    0.3774</span></span>
<span><span class="co">#&gt; age              25.8162       28.0303         -0.3094     0.4400    0.0813</span></span>
<span><span class="co">#&gt; educ             10.3459       10.2354          0.0550     0.4959    0.0347</span></span>
<span><span class="co">#&gt; raceblack         0.8432        0.2028          1.7615          .    0.6404</span></span>
<span><span class="co">#&gt; racehispan        0.0595        0.1422         -0.3498          .    0.0827</span></span>
<span><span class="co">#&gt; racewhite         0.0973        0.6550         -1.8819          .    0.5577</span></span>
<span><span class="co">#&gt; married           0.1892        0.5128         -0.8263          .    0.3236</span></span>
<span><span class="co">#&gt; nodegree          0.7081        0.5967          0.2450          .    0.1114</span></span>
<span><span class="co">#&gt; re74           2095.5737     5619.2365         -0.7211     0.5181    0.2248</span></span>
<span><span class="co">#&gt; re75           1532.0553     2466.4844         -0.2903     0.9563    0.1342</span></span>
<span><span class="co">#&gt;            eCDF Max</span></span>
<span><span class="co">#&gt; distance     0.6444</span></span>
<span><span class="co">#&gt; age          0.1577</span></span>
<span><span class="co">#&gt; educ         0.1114</span></span>
<span><span class="co">#&gt; raceblack    0.6404</span></span>
<span><span class="co">#&gt; racehispan   0.0827</span></span>
<span><span class="co">#&gt; racewhite    0.5577</span></span>
<span><span class="co">#&gt; married      0.3236</span></span>
<span><span class="co">#&gt; nodegree     0.1114</span></span>
<span><span class="co">#&gt; re74         0.4470</span></span>
<span><span class="co">#&gt; re75         0.2876</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample Sizes:</span></span>
<span><span class="co">#&gt;           Control Treated</span></span>
<span><span class="co">#&gt; All           429     185</span></span>
<span><span class="co">#&gt; Matched       429     185</span></span>
<span><span class="co">#&gt; Unmatched       0       0</span></span>
<span><span class="co">#&gt; Discarded       0       0</span></span></code></pre></div>
<p>This summary provides:</p>
<ul>
<li><p>Standardized mean differences</p></li>
<li><p>Variance ratios</p></li>
<li><p>Propensity score distributions</p></li>
</ul>
<p>These diagnostics help us understand the extent of covariate imbalance.</p>
<hr>
<p><strong>Step 3: Implementing Matching</strong></p>
<ol style="list-style-type: decimal">
<li>Nearest Neighbor Matching (1:1 without Replacement)</li>
</ol>
<div class="sourceCode" id="cb929"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.out1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">race</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">nodegree</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>  method <span class="op">=</span> <span class="st">"nearest"</span>,</span>
<span>  distance <span class="op">=</span> <span class="st">"glm"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Matching is based on estimated propensity scores. Each treated unit is matched to the closest control unit.</p>
<p>Assess Balance After Matching</p>
<div class="sourceCode" id="cb930"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m.out1</span>, un <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>  <span class="co"># only show post-matching stats</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; matchit(formula = treat ~ age + educ + race + married + nodegree + </span></span>
<span><span class="co">#&gt;     re74 + re75, data = MatchIt::lalonde, method = "nearest", </span></span>
<span><span class="co">#&gt;     distance = "glm")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Summary of Balance for Matched Data:</span></span>
<span><span class="co">#&gt;            Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span><span class="co">#&gt; distance          0.5774        0.3629          0.9739     0.7566    0.1321</span></span>
<span><span class="co">#&gt; age              25.8162       25.3027          0.0718     0.4568    0.0847</span></span>
<span><span class="co">#&gt; educ             10.3459       10.6054         -0.1290     0.5721    0.0239</span></span>
<span><span class="co">#&gt; raceblack         0.8432        0.4703          1.0259          .    0.3730</span></span>
<span><span class="co">#&gt; racehispan        0.0595        0.2162         -0.6629          .    0.1568</span></span>
<span><span class="co">#&gt; racewhite         0.0973        0.3135         -0.7296          .    0.2162</span></span>
<span><span class="co">#&gt; married           0.1892        0.2108         -0.0552          .    0.0216</span></span>
<span><span class="co">#&gt; nodegree          0.7081        0.6378          0.1546          .    0.0703</span></span>
<span><span class="co">#&gt; re74           2095.5737     2342.1076         -0.0505     1.3289    0.0469</span></span>
<span><span class="co">#&gt; re75           1532.0553     1614.7451         -0.0257     1.4956    0.0452</span></span>
<span><span class="co">#&gt;            eCDF Max Std. Pair Dist.</span></span>
<span><span class="co">#&gt; distance     0.4216          0.9740</span></span>
<span><span class="co">#&gt; age          0.2541          1.3938</span></span>
<span><span class="co">#&gt; educ         0.0757          1.2474</span></span>
<span><span class="co">#&gt; raceblack    0.3730          1.0259</span></span>
<span><span class="co">#&gt; racehispan   0.1568          1.0743</span></span>
<span><span class="co">#&gt; racewhite    0.2162          0.8390</span></span>
<span><span class="co">#&gt; married      0.0216          0.8281</span></span>
<span><span class="co">#&gt; nodegree     0.0703          1.0106</span></span>
<span><span class="co">#&gt; re74         0.2757          0.7965</span></span>
<span><span class="co">#&gt; re75         0.2054          0.7381</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample Sizes:</span></span>
<span><span class="co">#&gt;           Control Treated</span></span>
<span><span class="co">#&gt; All           429     185</span></span>
<span><span class="co">#&gt; Matched       185     185</span></span>
<span><span class="co">#&gt; Unmatched     244       0</span></span>
<span><span class="co">#&gt; Discarded       0       0</span></span>
<span></span>
<span><span class="co"># Visual diagnostic: jitter plot of propensity scores</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">m.out1</span>, type <span class="op">=</span> <span class="st">"jitter"</span>, interactive <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="35-matching-methods_files/figure-html/unnamed-chunk-4-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb931"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># QQ plot for individual covariates</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">m.out1</span>, type <span class="op">=</span> <span class="st">"qq"</span>, which.xs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"age"</span>, <span class="st">"re74"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="35-matching-methods_files/figure-html/unnamed-chunk-4-2.png" width="90%" style="display: block; margin: auto;"></div>
<p><strong>Interpretation</strong>: Good matches will show overlapping distributions of covariates across groups, and standardized differences should be below 0.1 in absolute value.</p>
<ol start="2" style="list-style-type: decimal">
<li>Full Matching</li>
</ol>
<p>Allows many-to-one or one-to-many matches, minimizing overall distance.</p>
<div class="sourceCode" id="cb932"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.out2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">race</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">nodegree</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>  method <span class="op">=</span> <span class="st">"full"</span>,</span>
<span>  distance <span class="op">=</span> <span class="st">"glm"</span>,</span>
<span>  link <span class="op">=</span> <span class="st">"probit"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m.out2</span>, un <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; matchit(formula = treat ~ age + educ + race + married + nodegree + </span></span>
<span><span class="co">#&gt;     re74 + re75, data = MatchIt::lalonde, method = "full", distance = "glm", </span></span>
<span><span class="co">#&gt;     link = "probit")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Summary of Balance for Matched Data:</span></span>
<span><span class="co">#&gt;            Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span><span class="co">#&gt; distance          0.5773        0.5764          0.0045     0.9949    0.0043</span></span>
<span><span class="co">#&gt; age              25.8162       25.5347          0.0393     0.4790    0.0787</span></span>
<span><span class="co">#&gt; educ             10.3459       10.5381         -0.0956     0.6192    0.0253</span></span>
<span><span class="co">#&gt; raceblack         0.8432        0.8389          0.0119          .    0.0043</span></span>
<span><span class="co">#&gt; racehispan        0.0595        0.0492          0.0435          .    0.0103</span></span>
<span><span class="co">#&gt; racewhite         0.0973        0.1119         -0.0493          .    0.0146</span></span>
<span><span class="co">#&gt; married           0.1892        0.1633          0.0660          .    0.0259</span></span>
<span><span class="co">#&gt; nodegree          0.7081        0.6577          0.1110          .    0.0504</span></span>
<span><span class="co">#&gt; re74           2095.5737     2100.2150         -0.0009     1.3467    0.0314</span></span>
<span><span class="co">#&gt; re75           1532.0553     1561.4420         -0.0091     1.5906    0.0536</span></span>
<span><span class="co">#&gt;            eCDF Max Std. Pair Dist.</span></span>
<span><span class="co">#&gt; distance     0.0486          0.0198</span></span>
<span><span class="co">#&gt; age          0.2742          1.2843</span></span>
<span><span class="co">#&gt; educ         0.0730          1.2179</span></span>
<span><span class="co">#&gt; raceblack    0.0043          0.0162</span></span>
<span><span class="co">#&gt; racehispan   0.0103          0.4412</span></span>
<span><span class="co">#&gt; racewhite    0.0146          0.3454</span></span>
<span><span class="co">#&gt; married      0.0259          0.4473</span></span>
<span><span class="co">#&gt; nodegree     0.0504          0.9872</span></span>
<span><span class="co">#&gt; re74         0.1881          0.8387</span></span>
<span><span class="co">#&gt; re75         0.1984          0.8240</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample Sizes:</span></span>
<span><span class="co">#&gt;               Control Treated</span></span>
<span><span class="co">#&gt; All            429.       185</span></span>
<span><span class="co">#&gt; Matched (ESS)   50.76     185</span></span>
<span><span class="co">#&gt; Matched        429.       185</span></span>
<span><span class="co">#&gt; Unmatched        0.         0</span></span>
<span><span class="co">#&gt; Discarded        0.         0</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Exact Matching</li>
</ol>
<p>Only matches units with exactly the same covariate values (usually categorical):</p>
<div class="sourceCode" id="cb933"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.out3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">race</span> <span class="op">+</span> <span class="va">nodegree</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>  method <span class="op">=</span> <span class="st">"exact"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Optimal Matching</li>
</ol>
<p>Minimizes the total distance between matched units across the sample.</p>
<div class="sourceCode" id="cb934"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.out4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>  method <span class="op">=</span> <span class="st">"optimal"</span>,</span>
<span>  ratio <span class="op">=</span> <span class="fl">2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li>Genetic Matching</li>
</ol>
<p>Searches over weights assigned to covariates to optimize balance.</p>
<div class="sourceCode" id="cb935"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.out5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>  method <span class="op">=</span> <span class="st">"genetic"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<hr>
<p><strong>Step 4: Estimating Treatment Effects</strong></p>
<p>Once matching is complete, we use the matched data to estimate treatment effects.</p>
<div class="sourceCode" id="cb936"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">lmtest</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://sandwich.R-Forge.R-project.org/">sandwich</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract matched data</span></span>
<span><span class="va">matched_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/match_data.html">match.data</a></span><span class="op">(</span><span class="va">m.out1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Estimate ATT with robust standard errors</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">re78</span> <span class="op">~</span> <span class="va">treat</span> <span class="op">+</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">race</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>            data <span class="op">=</span> <span class="va">matched_data</span>,</span>
<span>            weights <span class="op">=</span> <span class="va">weights</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">model</span>, vcov. <span class="op">=</span> <span class="va">vcovCL</span>, cluster <span class="op">=</span> <span class="op">~</span><span class="va">subclass</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                Estimate  Std. Error t value Pr(&gt;|t|)   </span></span>
<span><span class="co">#&gt; (Intercept) -437.664937 1912.759171 -0.2288 0.819143   </span></span>
<span><span class="co">#&gt; treat       1398.134870  723.745751  1.9318 0.054164 . </span></span>
<span><span class="co">#&gt; age           -0.343085   39.256789 -0.0087 0.993032   </span></span>
<span><span class="co">#&gt; educ         470.767350  147.892765  3.1832 0.001583 **</span></span>
<span><span class="co">#&gt; racehispan  1518.303924 1035.083141  1.4668 0.143287   </span></span>
<span><span class="co">#&gt; racewhite    557.295853  897.121013  0.6212 0.534856   </span></span>
<span><span class="co">#&gt; re74           0.017244    0.166298  0.1037 0.917470   </span></span>
<span><span class="co">#&gt; re75           0.226076    0.165722  1.3642 0.173357   </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>The coefficient on <code>treat</code> is our estimate of the ATT. The weights and subclass clustering account for the matched design.</p>
</div>
<div id="reporting-standards" class="section level3" number="35.9.2">
<h3>
<span class="header-section-number">35.9.2</span> Reporting Standards<a class="anchor" aria-label="anchor" href="#reporting-standards"><i class="fas fa-link"></i></a>
</h3>
<p>To ensure transparency and reproducibility, always report the following:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Matching method</strong> (e.g., nearest neighbor, genetic)</p></li>
<li><p><strong>Distance metric</strong> (e.g., propensity score via logistic regression)</p></li>
<li><p><strong>Covariates matched on</strong> and justification for their inclusion</p></li>
<li><p><strong>Balance statistics</strong> (e.g., standardized mean differences before/after)</p></li>
<li><p><strong>Sample sizes</strong>: total, matched, unmatched, discarded</p></li>
<li><p><strong>Estimation model</strong>: whether treatment effects are estimated using regression adjustment, with or without weights</p></li>
<li><p><strong>Assumptions</strong>: especially unconfoundedness and overlap</p></li>
</ol>
<hr>
</div>
<div id="optimization-based-matching-via-designmatch" class="section level3" number="35.9.3">
<h3>
<span class="header-section-number">35.9.3</span> Optimization-Based Matching via <code>designmatch</code><a class="anchor" aria-label="anchor" href="#optimization-based-matching-via-designmatch"><i class="fas fa-link"></i></a>
</h3>
<p>For more advanced applications, the <code>designmatch</code> package provides matching methods based on combinatorial optimization.</p>
<div class="sourceCode" id="cb937"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">designmatch</span><span class="op">)</span></span></code></pre></div>
<p>Notable methods:</p>
<ul>
<li><p><code><a href="https://rdrr.io/pkg/designmatch/man/distmatch.html">distmatch()</a></code>: Distance-based matching with custom constraints</p></li>
<li><p><code><a href="https://rdrr.io/pkg/designmatch/man/bmatch.html">bmatch()</a></code>: Bipartite matching using linear programming</p></li>
<li><p><code><a href="https://rdrr.io/pkg/designmatch/man/cardmatch.html">cardmatch()</a></code>: Cardinality matching for maximum matched sample size with balance constraints</p></li>
<li><p><code><a href="https://rdrr.io/pkg/designmatch/man/profmatch.html">profmatch()</a></code>: Profile matching for stratified treatment allocation</p></li>
<li><p><code><a href="https://rdrr.io/pkg/designmatch/man/nmatch.html">nmatch()</a></code>: Non-bipartite matching (e.g., in interference settings)</p></li>
</ul>
<hr>
</div>
<div id="matchingfrontier" class="section level3" number="35.9.4">
<h3>
<span class="header-section-number">35.9.4</span> MatchingFrontier<a class="anchor" aria-label="anchor" href="#matchingfrontier"><i class="fas fa-link"></i></a>
</h3>
<p>As mentioned in <code>MatchIt</code>, you have to make trade-off (also known as bias-variance trade-off) between balance and sample size. An automated procedure to optimize this trade-off is implemented in <code>MatchingFrontier</code> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-king2017balance">G. King, Lucas, and Nielsen 2017</a>)</span>, which solves this joint optimization problem.</p>
<p>Following <code>MatchingFrontier</code> <a href="https://projects.iq.harvard.edu/files/frontier/files/using_matchingfrontier.pdf">guide</a></p>
<div class="sourceCode" id="cb938"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># library(devtools)</span></span>
<span><span class="co"># install_github('ChristopherLucas/MatchingFrontier')</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MatchingFrontier</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"lalonde"</span>, package <span class="op">=</span> <span class="st">"MatchIt"</span><span class="op">)</span></span>
<span><span class="co"># choose var to match on</span></span>
<span><span class="va">match.on</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">lalonde</span><span class="op">)</span><span class="op">[</span><span class="op">!</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">lalonde</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'re78'</span>, <span class="st">'treat'</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">match.on</span></span>
<span></span>
<span><span class="co"># Mahanlanobis frontier (default)</span></span>
<span><span class="va">mahal.frontier</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">makeFrontier</span><span class="op">(</span></span>
<span>        dataset <span class="op">=</span> <span class="va">lalonde</span>,</span>
<span>        treatment <span class="op">=</span> <span class="st">"treat"</span>,</span>
<span>        match.on <span class="op">=</span> <span class="va">match.on</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">mahal.frontier</span></span>
<span></span>
<span><span class="co"># L1 frontier</span></span>
<span><span class="va">L1.frontier</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">makeFrontier</span><span class="op">(</span></span>
<span>        dataset <span class="op">=</span> <span class="va">lalonde</span>,</span>
<span>        treatment <span class="op">=</span> <span class="st">'treat'</span>,</span>
<span>        match.on <span class="op">=</span> <span class="va">match.on</span>,</span>
<span>        QOI <span class="op">=</span> <span class="st">'SATT'</span>,</span>
<span>        metric <span class="op">=</span> <span class="st">'L1'</span>,</span>
<span>        ratio <span class="op">=</span> <span class="st">'fixed'</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">L1.frontier</span></span>
<span></span>
<span><span class="co"># estimate effects along the frontier</span></span>
<span></span>
<span><span class="co"># Set base form</span></span>
<span><span class="va">my.form</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">re78</span> <span class="op">~</span> <span class="va">treat</span> <span class="op">+</span> <span class="va">age</span> <span class="op">+</span> <span class="va">black</span> <span class="op">+</span> <span class="va">education</span> </span>
<span>               <span class="op">+</span> <span class="va">hispanic</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">nodegree</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Estimate effects for the mahalanobis frontier</span></span>
<span><span class="va">mahal.estimates</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">estimateEffects</span><span class="op">(</span></span>
<span>        <span class="va">mahal.frontier</span>,</span>
<span>        <span class="st">'re78 ~ treat'</span>,</span>
<span>        mod.dependence.formula <span class="op">=</span> <span class="va">my.form</span>,</span>
<span>        continuous.vars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'age'</span>, <span class="st">'education'</span>, <span class="st">'re74'</span>, <span class="st">'re75'</span><span class="op">)</span>,</span>
<span>        prop.estimated <span class="op">=</span> <span class="fl">.1</span>,</span>
<span>        means.as.cutpoints <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Estimate effects for the L1 frontier</span></span>
<span><span class="va">L1.estimates</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">estimateEffects</span><span class="op">(</span></span>
<span>        <span class="va">L1.frontier</span>,</span>
<span>        <span class="st">'re78 ~ treat'</span>,</span>
<span>        mod.dependence.formula <span class="op">=</span> <span class="va">my.form</span>,</span>
<span>        continuous.vars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'age'</span>, <span class="st">'education'</span>, <span class="st">'re74'</span>, <span class="st">'re75'</span><span class="op">)</span>,</span>
<span>        prop.estimated <span class="op">=</span> <span class="fl">.1</span>,</span>
<span>        means.as.cutpoints <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot covariates means </span></span>
<span><span class="co"># plotPrunedMeans()</span></span>
<span></span>
<span></span>
<span><span class="co"># Plot estimates (deprecated)</span></span>
<span><span class="co"># plotEstimates(</span></span>
<span><span class="co">#     L1.estimates,</span></span>
<span><span class="co">#     ylim = c(-10000, 3000),</span></span>
<span><span class="co">#     cex.lab = 1.4,</span></span>
<span><span class="co">#     cex.axis = 1.4,</span></span>
<span><span class="co">#     panel.first = grid(NULL, NULL, lwd = 2,)</span></span>
<span><span class="co"># )</span></span>
<span></span>
<span><span class="co"># Plot estimates</span></span>
<span><span class="fu">plotMeans</span><span class="op">(</span><span class="va">L1.frontier</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># parallel plot</span></span>
<span><span class="fu">parallelPlot</span><span class="op">(</span></span>
<span>    <span class="va">L1.frontier</span>,</span>
<span>    N <span class="op">=</span> <span class="fl">400</span>,</span>
<span>    variables <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'age'</span>, <span class="st">'re74'</span>, <span class="st">'re75'</span>, <span class="st">'black'</span><span class="op">)</span>,</span>
<span>    treated.col <span class="op">=</span> <span class="st">'blue'</span>,</span>
<span>    control.col <span class="op">=</span> <span class="st">'gray'</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># export matched dataset</span></span>
<span><span class="co"># take 400 units</span></span>
<span><span class="va">matched.data</span> <span class="op">&lt;-</span> <span class="fu">generateDataset</span><span class="op">(</span><span class="va">L1.frontier</span>, N <span class="op">=</span> <span class="fl">400</span><span class="op">)</span> </span></code></pre></div>
<hr>
</div>
<div id="sec-propensity-scores" class="section level3" number="35.9.5">
<h3>
<span class="header-section-number">35.9.5</span> Propensity Scores<a class="anchor" aria-label="anchor" href="#sec-propensity-scores"><i class="fas fa-link"></i></a>
</h3>
<p>Propensity score methods are widely used for estimating causal effects in observational studies, where random assignment to treatment and control groups is not feasible. The core idea is to mimic a randomized experiment by adjusting for confounding variables that predict treatment assignment. Formally, the <strong>propensity score</strong> is defined as the probability of assignment to treatment conditional on observed covariates <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rosenbaum1983central">Rosenbaum and Rubin 1983</a>, <a href="chapter-cluster-randomization-and-interference-bias.html#ref-rosenbaum1985bias">1985</a>)</span>:</p>
<p><span class="math display">\[
e_i(X_i) = P(T_i = 1 \mid X_i)
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(T_i \in \{0, 1\}\)</span> is the binary treatment indicator for unit <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(X_i\)</span> is a vector of observed pre-treatment covariates for unit <span class="math inline">\(i\)</span>.</li>
</ul>
<p>The key insight from <span class="citation">Rosenbaum and Rubin (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rosenbaum1983central">1983</a>)</span> is that conditioning on the propensity score is sufficient to remove bias due to confounding from observed covariates, under certain assumptions.</p>
<hr>
<div id="assumptions-for-identification-1" class="section level4" number="35.9.5.1">
<h4>
<span class="header-section-number">35.9.5.1</span> Assumptions for Identification<a class="anchor" aria-label="anchor" href="#assumptions-for-identification-1"><i class="fas fa-link"></i></a>
</h4>
<p>To identify causal effects using propensity scores, the following assumptions must hold:</p>
<ul>
<li><strong>Unconfoundedness / Conditional Independence Assumption (CIA):</strong></li>
</ul>
<p><span class="math display">\[
(Y_i(0), Y_i(1)) \perp T_i \mid X_i
\]</span></p>
<ul>
<li><strong>Positivity (Overlap):</strong></li>
</ul>
<p><span class="math display">\[
0 &lt; P(T_i = 1 \mid X_i) &lt; 1 \quad \text{for all } i
\]</span></p>
<p>These assumptions ensure that for each unit, we can observe comparable treated and untreated units in the sample. Violations of positivity, especially in high-dimensional covariate spaces, are a critical weakness of propensity score matching.</p>
<hr>
</div>
<div id="why-psm-is-not-recommended-anymore" class="section level4" number="35.9.5.2">
<h4>
<span class="header-section-number">35.9.5.2</span> Why PSM Is Not Recommended Anymore<a class="anchor" aria-label="anchor" href="#why-psm-is-not-recommended-anymore"><i class="fas fa-link"></i></a>
</h4>
<p>Despite its intuitive appeal, recent literature has strongly cautioned against using propensity score matching for causal inference <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-king2019propensity">G. King and Nielsen 2019</a>)</span>. The main criticisms are as follows:</p>
<ul>
<li>
<strong>Imbalance</strong>: PSM often fails to achieve covariate balance better than simpler techniques like covariate adjustment via regression or exact matching. Matching on the propensity score is a <em>scalar reduction</em> of a multivariate distribution, and this reduction can distort multivariate relationships.</li>
<li>
<strong>Inefficiency</strong>: Discarding unmatched units reduces statistical efficiency, especially when better estimators (e.g., inverse probability weighting or doubly robust estimators) can use all data.</li>
<li>
<strong>Model dependence</strong>: Small changes in the specification of the propensity score model can lead to large changes in matches and estimated treatment effects.</li>
<li>
<strong>Bias</strong>: Poor matches and irrelevant covariates can introduce additional bias rather than reduce it.</li>
</ul>
<p><span class="citation">Abadie and Imbens (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-abadie2016matching">2016</a>)</span> show that the asymptotic distribution of treatment effect estimators is sensitive to the estimation of the propensity score itself:</p>
<ul>
<li>The estimated propensity score can improve efficiency over using the true propensity score when estimating the <a href="sec-causal-inference.html#sec-average-treatment-effect">ATE</a>. Formally, the adjustment to the asymptotic variance is non-positive.</li>
<li>However, for the <a href="sec-causal-inference.html#sec-average-treatment-effect-on-the-treated">ATT</a>, the sign of the adjustment is data-dependent. Estimation error in the propensity score can lead to misestimated confidence intervals: they may be too wide or too narrow.</li>
</ul>
<p>This result suggests that even in large samples, failure to account for the estimation uncertainty in the propensity score can produce misleading inference.</p>
<p>A fundamental flaw in PSM is the <strong>asymmetry of match quality</strong>:</p>
<ul>
<li>If <span class="math inline">\(X_c = X_t\)</span>, then it must be that <span class="math inline">\(e(X_c) = e(X_t)\)</span>.</li>
<li>However, the converse <strong>does not hold</strong>:<br><span class="math inline">\(e(X_c) = e(X_t) \nRightarrow X_c = X_t\)</span>
</li>
</ul>
<p>Therefore, two units with identical propensity scores may still differ substantially in covariate space. This undermines the matching goal of achieving similarity across all covariates.</p>
<hr>
</div>
<div id="estimating-the-propensity-score" class="section level4" number="35.9.5.3">
<h4>
<span class="header-section-number">35.9.5.3</span> Estimating the Propensity Score<a class="anchor" aria-label="anchor" href="#estimating-the-propensity-score"><i class="fas fa-link"></i></a>
</h4>
<p>Estimation of the propensity score is typically carried out using:</p>
<ul>
<li>
<strong>Parametric models</strong>:
<ul>
<li>Logistic regression:<br><span class="math display">\[
\hat{e}_i = \frac{1}{1 + \exp(-X_i^\top \hat{\beta})}
\]</span>
</li>
</ul>
</li>
<li>
<strong>Nonparametric / machine learning methods</strong>:
<ul>
<li>Generalized Boosted Models (GBM)</li>
<li>Boosted Classification and Regression Trees (CART)</li>
<li>Random forests or Bayesian Additive Regression Trees (BART)</li>
</ul>
</li>
</ul>
<p>These machine learning approaches often yield better balance due to flexible functional forms, but they also complicate interpretation and inference.</p>
<hr>
</div>
<div id="matching-algorithms" class="section level4" number="35.9.5.4">
<h4>
<span class="header-section-number">35.9.5.4</span> Matching Algorithms<a class="anchor" aria-label="anchor" href="#matching-algorithms"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<strong>Reduce</strong> the high-dimensional vector <span class="math inline">\(X_i\)</span> to the scalar <span class="math inline">\(\hat{e}_i\)</span>.</li>
<li>
<strong>Calculate distances</strong> between treated and control units based on <span class="math inline">\(\hat{e}_i\)</span>: <span class="math display">\[
d(i, j) = |\hat{e}_i - \hat{e}_j|
\]</span>
</li>
<li>
<strong>Match</strong> each treated unit <span class="math inline">\(i\)</span> to the control unit <span class="math inline">\(j\)</span> with the closest propensity score.</li>
<li>
<strong>Prune</strong>:
<ul>
<li>Control units not used in any match are discarded.</li>
<li>Matches exceeding a caliper (maximum distance threshold) are also discarded.</li>
</ul>
</li>
<li>
<strong>No replacement</strong> is typically assumed — each control unit is matched at most once.</li>
</ol>
<p>Let <span class="math inline">\(c &gt; 0\)</span> be a caliper. Then a treated unit <span class="math inline">\(i\)</span> is matched to control unit <span class="math inline">\(j\)</span> only if:</p>
<p><span class="math display">\[
|\hat{e}_i - \hat{e}_j| &lt; c
\]</span></p>
<p>Caliper matching helps reduce poor matches, but may result in <em>random pruning</em>, further reducing balance and efficiency.</p>
<hr>
</div>
<div id="practical-recommendations" class="section level4" number="35.9.5.5">
<h4>
<span class="header-section-number">35.9.5.5</span> Practical Recommendations<a class="anchor" aria-label="anchor" href="#practical-recommendations"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<strong>Do not include irrelevant covariates</strong>: Including variables that are unrelated to the outcome can increase the variability of the estimated propensity score and reduce matching quality.</li>
<li>
<strong>Avoid instrumental variables</strong> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-bhattacharya2007instrumental">Bhattacharya and Vogt 2007</a>)</span>: Including IVs in the propensity score model can <strong>inflate bias</strong> by introducing variation in treatment assignment unrelated to potential outcomes.</li>
<li>Focus on <strong>covariates that are confounders</strong>, i.e., those that affect both treatment and outcome.</li>
</ul>
<p>What remains <strong>after pruning</strong> is more consequential than the initial covariate set. Matching can discard a large portion of the sample, which distorts representativeness and increases variance.</p>
<hr>
</div>
<div id="diagnostics-and-evaluation" class="section level4" number="35.9.5.6">
<h4>
<span class="header-section-number">35.9.5.6</span> Diagnostics and Evaluation<a class="anchor" aria-label="anchor" href="#diagnostics-and-evaluation"><i class="fas fa-link"></i></a>
</h4>
<p>After matching, the primary diagnostic tool is covariate balance. Key diagnostics include:</p>
<ul>
<li>
<strong>Standardized mean differences (SMD)</strong> between treatment groups before and after matching</li>
<li><strong>Variance ratios</strong></li>
<li>
<strong>Visual inspection</strong> via Love plots or density plots</li>
</ul>
<p>Statistical model fit criteria (e.g., AIC, BIC, c-statistics) are <strong>not valid</strong> for evaluating propensity score models, since the goal is <em>not prediction</em>, but achieving balance.</p>
<p>There is <strong>no need to worry about collinearity</strong> in the covariates when estimating propensity scores — unlike in outcome regression models, where multicollinearity can inflate standard errors.</p>
<hr>
</div>
<div id="applications-in-business-and-finance" class="section level4" number="35.9.5.7">
<h4>
<span class="header-section-number">35.9.5.7</span> Applications in Business and Finance<a class="anchor" aria-label="anchor" href="#applications-in-business-and-finance"><i class="fas fa-link"></i></a>
</h4>
<p>Propensity score methods have been used in empirical finance and marketing, though increasingly replaced by more robust approaches. One illustrative application is found in <span class="citation">Hirtle, Kovner, and Plosser (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-hirtle2020impact">2020</a>)</span>, which investigates the causal effect of regulatory bank supervision on firm-level outcomes:</p>
<ul>
<li>
<strong>Treatment</strong>: Degree of supervisory attention.</li>
<li>
<strong>Outcomes</strong>: Loan risk, profitability, volatility, and firm growth.</li>
<li>
<strong>Method</strong>: Propensity score matching to construct treated and control groups of banks with comparable observed characteristics.</li>
</ul>
<p>Their matched sample analysis reveals that <strong>intensified supervision</strong> leads to:</p>
<ul>
<li>Lower risk (more conservative loan portfolios)</li>
<li>Reduced volatility</li>
<li>No significant loss in profitability or growth</li>
</ul>
<hr>
</div>
<div id="conclusion-1" class="section level4" number="35.9.5.8">
<h4>
<span class="header-section-number">35.9.5.8</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion-1"><i class="fas fa-link"></i></a>
</h4>
<p>While the theoretical motivation behind propensity scores remains sound, their application via naive matching methods is no longer considered best practice. The statistical community increasingly favors alternatives such as:</p>
<ul>
<li><strong>Covariate adjustment via regression</strong></li>
<li><strong>Inverse probability weighting (IPW)</strong></li>
<li><strong>Doubly robust estimators</strong></li>
<li><strong>Targeted Maximum Likelihood Estimation (TMLE)</strong></li>
</ul>
<p>These approaches better utilize the full dataset, yield more efficient estimators, and offer more transparent diagnostics. Matching on estimated propensity scores may still be useful for illustration or sensitivity analysis, but should not be the primary method for causal inference in applied research.</p>
<hr>
</div>
<div id="look-ahead-propensity-score-matching" class="section level4" number="35.9.5.9">
<h4>
<span class="header-section-number">35.9.5.9</span> Look-Ahead Propensity Score Matching<a class="anchor" aria-label="anchor" href="#look-ahead-propensity-score-matching"><i class="fas fa-link"></i></a>
</h4>
<p>In observational data, estimating <strong>causal effects</strong> is complicated by <strong>self-selection bias</strong>: individuals who receive a treatment may differ systematically from those who do not. Standard <strong>PSM</strong> methods attempt to control for such biases by matching treated and untreated units on observable characteristics.</p>
<p>However, when <strong>unobservable</strong> or <strong>latent traits</strong> influence both treatment assignment and outcomes, traditional PSM may produce biased estimates. <span class="citation">Bapna, Ramaprasad, and Umyarov (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-bapna2018monetizing">2018</a>)</span> introduce <strong>Look-Ahead Propensity Score Matching (LA-PSM)</strong>, a novel technique that leverages <strong>future behavior</strong> to correct for <strong>time-invariant unobserved confounding</strong>, particularly useful in rare-event economic decisions.</p>
<p>In the study of <span class="citation">Bapna, Ramaprasad, and Umyarov (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-bapna2018monetizing">2018</a>)</span>:</p>
<ul>
<li>Treatment: user pays for a premium subscription.</li>
<li>Outcome: social engagement (songs listened, playlists created, friends made).</li>
<li>Problem: users choosing to subscribe are systematically different (e.g., more engaged).</li>
</ul>
<p><strong>LA-PSM Implementation:</strong></p>
<ul>
<li><p>Treated group: users subscribing between Sept 2011 - June 2012.</p></li>
<li><p>Control group: users who will subscribe later (June 2012 - Jan 2015).</p></li>
<li><p>Matching on: observed demographics, past behavior.</p></li>
<li><p>Analysis: <a href="sec-difference-in-differences.html#sec-difference-in-differences">Difference-in-Differences</a> estimation.</p></li>
</ul>
<p><strong>Results:</strong> Premium adoption increases:</p>
<ul>
<li>Songs listened: +287.2%</li>
<li>Playlists created: +1.92%</li>
<li>Forum posts: +2.01%</li>
<li>Friends added: +15.77%</li>
</ul>
<hr>
<p>In standard PSM:</p>
<ul>
<li>Match individuals who received treatment with individuals who did not, based on observed covariates.</li>
<li>Assume selection into treatment is <strong>strongly ignorable</strong>, conditional on covariates.</li>
</ul>
<p>Problem:</p>
<ul>
<li><p>Unobserved factors (e.g., ambition, risk tolerance) may bias both treatment and outcome.</p></li>
<li><p>Standard PSM cannot correct for this.</p></li>
</ul>
<p><strong>Solution: Look-Ahead PSM</strong></p>
<ul>
<li><p>Match treated units with <strong>future-treated</strong> units: those who haven’t yet received treatment but will in the future.</p></li>
<li><p>Future-treated units share unobservable traits with current-treated units.</p></li>
</ul>
<p>Thus, LA-PSM controls for <strong>time-invariant unobserved confounders</strong>.</p>
<hr>
<p>Let:</p>
<ul>
<li><p><span class="math inline">\(i \in \{1, \ldots, N\}\)</span> index individuals.</p></li>
<li><p><span class="math inline">\(D_i(t)\)</span> = 1 if individual <span class="math inline">\(i\)</span> is treated at time <span class="math inline">\(t\)</span>, 0 otherwise.</p></li>
<li><p><span class="math inline">\(X_i\)</span> = observed covariates.</p></li>
<li><p><span class="math inline">\(U_i\)</span> = unobserved time-invariant confounders.</p></li>
<li><p><span class="math inline">\(Y_i(t)\)</span> = outcome at time <span class="math inline">\(t\)</span>.</p></li>
</ul>
<p>In standard PSM:</p>
<ul>
<li>Match on <span class="math inline">\(\mathbb{P}(D_i(t) = 1 \mid X_i)\)</span>.</li>
</ul>
<p>In LA-PSM:</p>
<ul>
<li><p>Match <strong>current treated</strong> individuals with <strong>future treated</strong> individuals based on: <span class="math display">\[ \mathbb{P}(D_i(t) = 1 \mid X_i) \]</span></p></li>
<li><p>and require: <span class="math display">\[ \exists \, s &gt; t \quad \text{such that} \quad D_i(s) = 1 \]</span></p></li>
</ul>
<p>Formally, define:</p>
<ul>
<li><p>Treatment group: <span class="math display">\[ T = \{ i \mid D_i(t) = 1 \} \]</span></p></li>
<li><p>Control group: <span class="math display">\[ C = \{ j \mid D_j(t) = 0 \quad \text{and} \quad \exists \, s&gt;t : D_j(s) = 1 \} \]</span></p></li>
</ul>
<p>Thus, both treatment and control groups are “eventual adopters,” just at different times.</p>
<hr>
<p><strong>Proposition:</strong><br>
If <span class="math inline">\(U_i\)</span> is <strong>time-invariant</strong> and <strong>affects both treatment assignment and outcomes</strong>, then LA-PSM produces unbiased causal estimates under weaker assumptions than standard PSM.</p>
<ol style="list-style-type: decimal">
<li>In regular PSM, matching on <span class="math inline">\(X_i\)</span> cannot adjust for <span class="math inline">\(U_i\)</span>.</li>
<li>In LA-PSM, by restricting controls to <strong>future adopters</strong>, we select units that share latent traits <span class="math inline">\(U_i\)</span> driving adoption.</li>
<li>Thus, <span class="math inline">\(U_i\)</span> is balanced across treatment and control, eliminating bias from <span class="math inline">\(U_i\)</span>.</li>
<li>Remaining bias is due only to differences in <span class="math inline">\(X_i\)</span>, which are adjusted for via matching.</li>
</ol>
<hr>
<p><strong>Practical Implementation Steps</strong></p>
<ol style="list-style-type: decimal">
<li>In <strong>Static Look-Ahead PSM</strong>, we:</li>
</ol>
<ul>
<li>Fix a single matching window at a given time <span class="math inline">\(t\)</span>.</li>
<li>Define:
<ul>
<li>
<strong>Treatment Group</strong>: Individuals who receive treatment at time <span class="math inline">\(t\)</span>.</li>
<li>
<strong>Control Group</strong>: Individuals who are not yet treated at <span class="math inline">\(t\)</span> but will receive treatment at a later time <span class="math inline">\(t'&gt;t\)</span>.</li>
</ul>
</li>
<li>Estimate propensity scores based only on observed covariates <span class="math inline">\(X\)</span>.</li>
<li>Match treated and (future-treated) control units based on their propensity scores.</li>
</ul>
<p>This ensures treated and control individuals have similar observed <span class="math inline">\(X\)</span> and similar unobserved <span class="math inline">\(U\)</span>, assuming <span class="math inline">\(U\)</span> is time-invariant.</p>
<p>How to implement Static LA-PSM:</p>
<ol style="list-style-type: decimal">
<li>Identify individuals <strong>treated now</strong> (treatment group) and <strong>future adopters</strong> (control group).</li>
<li>Estimate propensity scores <span class="math inline">\(\mathbb{P}(D=1 \mid X)\)</span>.</li>
<li>Match treated and control units using nearest-neighbor matching.</li>
<li>Estimate treatment effects via a regression on the matched sample.</li>
</ol>
<p><strong>Important:</strong></p>
<ul>
<li><p>Drop individuals who are never treated from the analysis.</p></li>
<li><p>Only compare current-treated and future-treated!</p></li>
</ul>
<hr>
<ol start="2" style="list-style-type: decimal">
<li>In <strong>Dynamic Look-Ahead PSM</strong>, we:</li>
</ol>
<ul>
<li>Allow time to move forward (<span class="math inline">\(t=1,2,3,\dots\)</span>).</li>
<li>At each time <span class="math inline">\(t\)</span>:
<ul>
<li>Define treated individuals (those who receive treatment at <span class="math inline">\(t\)</span>).</li>
<li>Define control individuals (those untreated at <span class="math inline">\(t\)</span> but who will adopt later).</li>
</ul>
</li>
<li>Repeat matching separately for each <span class="math inline">\(t\)</span>.</li>
<li>Aggregate results across different <span class="math inline">\(t\)</span> periods to estimate the overall effect.</li>
</ul>
<p>Dynamic LA-PSM is more flexible:</p>
<ul>
<li><p>It updates control groups over time.</p></li>
<li><p>Better handles situations where treatment adoption spreads gradually over time.</p></li>
</ul>
<p>How to implement Dynamic LA-PSM:</p>
<ol style="list-style-type: decimal">
<li>For each time period <span class="math inline">\(t\)</span>:
<ul>
<li>Define treated-now = individuals treated at <span class="math inline">\(t\)</span>.</li>
<li>Define control = individuals untreated at <span class="math inline">\(t\)</span> but who adopt later.</li>
</ul>
</li>
<li>Estimate propensity scores <span class="math inline">\(\mathbb{P}(D=1 \mid X)\)</span> within that time window.</li>
<li>Match treated and controls at each <span class="math inline">\(t\)</span> separately.</li>
<li>Pool matched samples from all <span class="math inline">\(t\)</span> together.</li>
<li>Estimate treatment effects using the pooled sample.</li>
</ol>
<p><strong>Important:</strong></p>
<ul>
<li><p>Keep track of time — matching is done separately each period.</p></li>
<li><p>Aggregate the treatment effect estimates carefully (either by averaging or pooling matched data).</p></li>
</ul>
<hr>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="36%">
<col width="44%">
</colgroup>
<thead><tr class="header">
<th align="left">Feature</th>
<th align="left">Static Look-Ahead PSM</th>
<th align="left">Dynamic Look-Ahead PSM</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Matching Window</td>
<td align="left">Single, fixed window (e.g., <span class="math inline">\(t=5\)</span>)</td>
<td align="left">Rolling window at each time <span class="math inline">\(t\)</span>
</td>
</tr>
<tr class="even">
<td align="left">Treated Group</td>
<td align="left">Treated at <span class="math inline">\(t\)</span>
</td>
<td align="left">Treated at <span class="math inline">\(t\)</span>
</td>
</tr>
<tr class="odd">
<td align="left">Control Group</td>
<td align="left">Future treated (after <span class="math inline">\(t\)</span>)</td>
<td align="left">Future treated relative to each <span class="math inline">\(t\)</span>
</td>
</tr>
<tr class="even">
<td align="left">Updates over time?</td>
<td align="left">No</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">Suitable for</td>
<td align="left">Simple adoption settings</td>
<td align="left">Gradual adoption / time-sensitive settings</td>
</tr>
</tbody>
</table></div>
<blockquote>
<p><strong>Challenge:</strong><br>
Simulate your own dataset with hidden confounding and implement both Static and Dynamic Look-Ahead PSM.<br>
Compare bias against Standard PSM and Randomized Assignment.</p>
</blockquote>
<hr>
</div>
</div>
<div id="sec-mahalanobis" class="section level3" number="35.9.6">
<h3>
<span class="header-section-number">35.9.6</span> Mahalanobis Distance Matching<a class="anchor" aria-label="anchor" href="#sec-mahalanobis"><i class="fas fa-link"></i></a>
</h3>
<p>Mahalanobis Distance Matching is a method for matching units in observational studies based on the <strong>multivariate similarity</strong> of covariates. Unlike propensity score matching, which reduces the covariate space to a single scalar, Mahalanobis distance operates in the full multivariate space. As a result, Mahalanobis matching can be interpreted as approximating a <strong>fully blocked design</strong>, where each treated unit is paired with a control unit that has nearly identical covariate values.</p>
<ul>
<li>In the ideal case: <span class="math inline">\(X_t = X_c\)</span>, implying a perfect match.</li>
<li>In practice, Mahalanobis distance allows for “near-exact” matches in high-dimensional space.</li>
</ul>
<p>Because it preserves the multivariate structure of the covariates, Mahalanobis matching more faithfully emulates randomization within <strong>covariate strata</strong>, making it more robust to specification error than propensity score matching.</p>
<p>This method is particularly appealing when the number of covariates is relatively small and when these covariates are continuous and well-measured.</p>
<hr>
<p>Given a set of <span class="math inline">\(p\)</span> covariates <span class="math inline">\(X_i \in \mathbb{R}^p\)</span> for unit <span class="math inline">\(i\)</span>, the <strong>Mahalanobis distance</strong> between a treated unit <span class="math inline">\(t\)</span> and a control unit <span class="math inline">\(c\)</span> is defined as:</p>
<p><span class="math display">\[
D_M(X_t, X_c) = \sqrt{(X_t - X_c)^\top S^{-1}(X_t - X_c)}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_c\)</span> are the <span class="math inline">\(p\)</span>-dimensional vectors of covariates for treated and control units, respectively,</li>
<li>
<span class="math inline">\(S\)</span> is the sample covariance matrix of the covariates across all units (treated and control),</li>
<li>
<span class="math inline">\(S^{-1}\)</span> serves to standardize and decorrelate the covariate space, accounting for both scale and correlation among covariates.</li>
</ul>
<hr>
<p><strong>Why Not Use Euclidean Distance?</strong></p>
<p>The Euclidean distance:</p>
<p><span class="math display">\[
D_E(X_t, X_c) = \sqrt{(X_t - X_c)^\top (X_t - X_c)}
\]</span></p>
<p>does <strong>not adjust for different variances</strong> among covariates or for <strong>correlation</strong> between them. Mahalanobis distance corrects for this by incorporating the inverse covariance matrix <span class="math inline">\(S^{-1}\)</span>, effectively transforming the data to a space where the covariates are <strong>standardized and orthogonal</strong>.</p>
<p>This makes the Mahalanobis distance <strong>scale-invariant</strong>, i.e., invariant under affine transformations of the data, which is essential when matching on variables of different units (e.g., income in dollars and age in years).</p>
<hr>
<div id="mahalanobis-matching-algorithm" class="section level4" number="35.9.6.1">
<h4>
<span class="header-section-number">35.9.6.1</span> Mahalanobis Matching Algorithm<a class="anchor" aria-label="anchor" href="#mahalanobis-matching-algorithm"><i class="fas fa-link"></i></a>
</h4>
<p>Let <span class="math inline">\(\mathcal{T}\)</span> be the set of treated units and <span class="math inline">\(\mathcal{C}\)</span> the set of control units. The procedure for Mahalanobis matching can be described as follows:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Compute the covariance matrix</strong> <span class="math inline">\(S\)</span> of the covariates <span class="math inline">\(X\)</span> across all units.</li>
<li>
<strong>For each treated unit</strong> <span class="math inline">\(i \in \mathcal{T}\)</span>, compute <span class="math inline">\(D_M(X_i, X_j)\)</span> for all <span class="math inline">\(j \in \mathcal{C}\)</span>.</li>
<li>
<strong>Match</strong> treated unit <span class="math inline">\(i\)</span> to the control unit <span class="math inline">\(j\)</span> with the smallest Mahalanobis distance.</li>
<li>
<strong>Prune</strong>:
<ul>
<li>Control units not used in any match are discarded.</li>
<li>Matches where <span class="math inline">\(D_M &gt; \delta\)</span> (a caliper threshold) are also discarded.</li>
</ul>
</li>
</ol>
<p>A caliper <span class="math inline">\(\delta\)</span> is used to enforce a maximum allowable distance. That is, a match is made between <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> only if:</p>
<p><span class="math display">\[
D_M(X_i, X_j) &lt; \delta
\]</span></p>
<p>This prevents poor-quality matches and helps ensure that treated and control units are meaningfully similar. If no match falls within the caliper for a given treated unit, that unit is left unmatched, and potentially discarded from the analysis.</p>
<hr>
</div>
<div id="properties" class="section level4" number="35.9.6.2">
<h4>
<span class="header-section-number">35.9.6.2</span> Properties<a class="anchor" aria-label="anchor" href="#properties"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<strong>Scale-invariant</strong>: Standardizes variables using <span class="math inline">\(S^{-1}\)</span>, ensuring that variables with large scales do not dominate the distance metric.</li>
<li>
<strong>Correlation-adjusted</strong>: Accounts for linear relationships among covariates, which is critical in multivariate contexts.</li>
<li>
<strong>Non-parametric</strong>: No model for treatment assignment is estimated; purely based on observed covariates.</li>
</ul>
<hr>
</div>
<div id="limitations" class="section level4" number="35.9.6.3">
<h4>
<span class="header-section-number">35.9.6.3</span> Limitations<a class="anchor" aria-label="anchor" href="#limitations"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<strong>Sensitive to multicollinearity</strong>: If the covariates are highly collinear, the covariance matrix <span class="math inline">\(S\)</span> may be nearly singular, making <span class="math inline">\(S^{-1}\)</span> unstable or non-invertible. Regularization techniques may be required.</li>
<li>
<strong>Not suitable for high-dimensional covariate spaces</strong>: As <span class="math inline">\(p\)</span> increases, exact or even near-exact matches become harder to find. Dimensionality reduction techniques (e.g., PCA) may help.</li>
<li>
<strong>Inefficient with categorical variables</strong>: Since Mahalanobis distance is based on continuous covariates and assumes multivariate normality (implicitly), it’s less effective when most covariates are categorical or binary.</li>
</ul>
<hr>
</div>
<div id="hybrid-approaches" class="section level4" number="35.9.6.4">
<h4>
<span class="header-section-number">35.9.6.4</span> Hybrid Approaches<a class="anchor" aria-label="anchor" href="#hybrid-approaches"><i class="fas fa-link"></i></a>
</h4>
<p>Mahalanobis matching can be <strong>combined with propensity scores</strong> for improved performance:</p>
<ul>
<li>
<strong>Within propensity score calipers</strong>: Match using Mahalanobis distance only within groups of units that fall within a specified caliper of each other in propensity score space.</li>
<li>
<strong>Stratified matching</strong>: Divide the sample into strata based on propensity scores and apply Mahalanobis matching within each stratum.</li>
</ul>
<p>These hybrid methods aim to preserve the robustness of Mahalanobis matching while mitigating its weaknesses in high dimensions.</p>
<hr>
</div>
<div id="practical-considerations-7" class="section level4" number="35.9.6.5">
<h4>
<span class="header-section-number">35.9.6.5</span> Practical Considerations<a class="anchor" aria-label="anchor" href="#practical-considerations-7"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>Estimate <span class="math inline">\(S\)</span> from the pooled sample (treated + control) to ensure consistency.</li>
<li>Standardize all covariates before applying Mahalanobis distance to ensure comparability and numerical stability.</li>
<li>Use diagnostic plots (e.g., QQ plots or multivariate distance histograms) to assess match quality.</li>
</ul>
<hr>
</div>
</div>
<div id="sec-cem" class="section level3" number="35.9.7">
<h3>
<span class="header-section-number">35.9.7</span> Coarsened Exact Matching (CEM)<a class="anchor" aria-label="anchor" href="#sec-cem"><i class="fas fa-link"></i></a>
</h3>
<p>Coarsened Exact Matching (CEM) is a <strong>monotonic imbalance bounding</strong> matching method designed to improve covariate balance between treated and control units in observational studies. CEM operates by <strong>coarsening</strong> continuous or high-cardinality covariates into discrete bins and then applying <strong>exact matching</strong> on this coarsened space. The result is a non-parametric method that prioritizes covariate balance and robustness over modeling assumptions.</p>
<p>Introduced and formalized in <span class="citation">Iacus, King, and Porro (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-iacus2012causal">2012</a>)</span>, CEM is well-suited for causal inference when covariates are noisy or when traditional modeling-based approaches (e.g., propensity scores) are unstable or hard to interpret.</p>
<hr>
<p>The central idea is to <strong>discretize covariates</strong> into meaningful bins (either automatically or manually), then sort observations into <strong>strata</strong> or subclasses based on the <strong>unique combinations</strong> of these binned covariate values. Exact matching is applied within each stratum.</p>
<p>Let <span class="math inline">\(X_i \in \mathbb{R}^p\)</span> be the <span class="math inline">\(p\)</span>-dimensional covariate vector for unit <span class="math inline">\(i\)</span>. Define <span class="math inline">\(C(X_i)\)</span> to be a coarsened version of <span class="math inline">\(X_i\)</span>, where:</p>
<ul>
<li>Continuous variables are binned into intervals (e.g., age 20–29, 30–39, etc.)</li>
<li>Categorical variables may be grouped (e.g., Likert scales aggregated into fewer categories)</li>
</ul>
<p>Then, matching proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>Temporarily coarsen the covariate space <span class="math inline">\(X \to C(X)\)</span>.</li>
<li>Sort observations into strata defined by unique values of <span class="math inline">\(C(X)\)</span>.</li>
<li>Prune any stratum that contains only treated or only control units.</li>
<li>Retain all original (uncoarsened) units in matched strata for analysis.</li>
</ol>
<p>This process produces a matched sample in which each stratum includes at least one treated and one control unit, improving internal validity by design.</p>
<p>As with other matching methods, CEM requires the <strong>ignorability assumption</strong> (also known as unconfoundedness or selection on observables):</p>
<p><span class="math display">\[ (Y_i(0), Y_i(1)) \perp T_i \mid X_i \]</span></p>
<p>Under this assumption and sufficient overlap in the coarsened strata, CEM yields unbiased estimates of causal effects within the matched sample.</p>
<hr>
<div id="mathematical-properties" class="section level4" number="35.9.7.1">
<h4>
<span class="header-section-number">35.9.7.1</span> Mathematical Properties<a class="anchor" aria-label="anchor" href="#mathematical-properties"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li><strong>Monotonic Imbalance Bounding</strong></li>
</ol>
<p>CEM is a Monotonic Imbalance Bounding method, meaning that the user can pre-specify the maximum level of imbalance allowed on each covariate. The imbalance measure is guaranteed to be weakly decreasing as coarsening becomes finer. This provides:</p>
<ul>
<li>
<strong>Transparency</strong>: The imbalance tradeoff is determined <em>ex ante</em> by the user.</li>
<li>
<strong>Control</strong>: Users can make a direct decision about how much imbalance is tolerable.</li>
</ul>
<p>Formally, let <span class="math inline">\(\mathcal{L}(C(X))\)</span> denote a measure of imbalance under coarsened covariates. Then, for any refinements of <span class="math inline">\(C(X)\)</span>:</p>
<p><span class="math display">\[
\text{if } C_1(X) \preceq C_2(X), \text{ then } \mathcal{L}(C_1(X)) \leq \mathcal{L}(C_2(X))
\]</span></p>
<p>That is, finer coarsenings (more bins) cannot increase imbalance.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Congruence Principle</strong></li>
</ol>
<p>CEM respects the congruence principle, which asserts that analysis should not be more precise than the data allow. By coarsening, CEM protects against overfitting and artificial precision, especially when measurement error is present.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Robustness</strong></li>
</ol>
<ul>
<li>
<strong>Robust to measurement error</strong>: Discretization makes matching less sensitive to noise in covariates.</li>
<li>
<strong>Works with missing data</strong>: The <code>cem</code> R package supports partial handling of missingness.</li>
<li>
<strong>Multiple imputation</strong>: CEM can be applied within imputation routines to preserve matching structure across imputed datasets.</li>
<li>
<strong>Supports multi-valued treatments</strong>: Matching can be extended to treatments beyond binary <span class="math inline">\(T \in \{0, 1\}\)</span>.</li>
</ul>
<hr>
<ol style="list-style-type: decimal">
<li>Load and Prepare Data</li>
</ol>
<div class="sourceCode" id="cb939"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://gking.harvard.edu/cem">cem</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">LeLonde</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Remove missing values</span></span>
<span><span class="va">Le</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="va">LeLonde</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Treatment and control indices</span></span>
<span><span class="va">tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/which.html">which</a></span><span class="op">(</span><span class="va">Le</span><span class="op">$</span><span class="va">treated</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">ct</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/which.html">which</a></span><span class="op">(</span><span class="va">Le</span><span class="op">$</span><span class="va">treated</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">ntr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">tr</span><span class="op">)</span></span>
<span><span class="va">nct</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">ct</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Unadjusted bias (naïve difference in means)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/mean.html">mean</a></span><span class="op">(</span><span class="va">Le</span><span class="op">$</span><span class="va">re78</span><span class="op">[</span><span class="va">tr</span><span class="op">]</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/mean.html">mean</a></span><span class="op">(</span><span class="va">Le</span><span class="op">$</span><span class="va">re78</span><span class="op">[</span><span class="va">ct</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 759.0479</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Define Pre-Treatment Covariates</li>
</ol>
<div class="sourceCode" id="cb940"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"age"</span>, <span class="st">"education"</span>, <span class="st">"black"</span>, <span class="st">"married"</span>, <span class="st">"nodegree"</span>,</span>
<span>    <span class="st">"re74"</span>, <span class="st">"re75"</span>, <span class="st">"hispanic"</span>, <span class="st">"u74"</span>, <span class="st">"u75"</span>, <span class="st">"q1"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Pre-treatment imbalance</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/cem/man/imbalance.html">imbalance</a></span><span class="op">(</span>group <span class="op">=</span> <span class="va">Le</span><span class="op">$</span><span class="va">treated</span>, data <span class="op">=</span> <span class="va">Le</span><span class="op">[</span><span class="va">vars</span><span class="op">]</span><span class="op">)</span> <span class="co"># L1 imbalance = 0.902</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Imbalance Measure: L1=0.902</span></span>
<span><span class="co">#&gt; Percentage of local common support: LCS=5.8%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Univariate Imbalance Measures:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;               statistic   type           L1 min 25%      50%       75%</span></span>
<span><span class="co">#&gt; age        -0.252373042 (diff) 5.102041e-03   0   0   0.0000   -1.0000</span></span>
<span><span class="co">#&gt; education   0.153634710 (diff) 8.463851e-02   1   0   1.0000    1.0000</span></span>
<span><span class="co">#&gt; black      -0.010322734 (diff) 1.032273e-02   0   0   0.0000    0.0000</span></span>
<span><span class="co">#&gt; married    -0.009551495 (diff) 9.551495e-03   0   0   0.0000    0.0000</span></span>
<span><span class="co">#&gt; nodegree   -0.081217371 (diff) 8.121737e-02   0  -1   0.0000    0.0000</span></span>
<span><span class="co">#&gt; re74      -18.160446880 (diff) 5.551115e-17   0   0 284.0715  806.3452</span></span>
<span><span class="co">#&gt; re75      101.501761679 (diff) 5.551115e-17   0   0 485.6310 1238.4114</span></span>
<span><span class="co">#&gt; hispanic   -0.010144756 (diff) 1.014476e-02   0   0   0.0000    0.0000</span></span>
<span><span class="co">#&gt; u74        -0.045582186 (diff) 4.558219e-02   0   0   0.0000    0.0000</span></span>
<span><span class="co">#&gt; u75        -0.065555292 (diff) 6.555529e-02   0   0   0.0000    0.0000</span></span>
<span><span class="co">#&gt; q1          7.494021189 (Chi2) 1.067078e-01  NA  NA       NA        NA</span></span>
<span><span class="co">#&gt;                  max</span></span>
<span><span class="co">#&gt; age          -6.0000</span></span>
<span><span class="co">#&gt; education     1.0000</span></span>
<span><span class="co">#&gt; black         0.0000</span></span>
<span><span class="co">#&gt; married       0.0000</span></span>
<span><span class="co">#&gt; nodegree      0.0000</span></span>
<span><span class="co">#&gt; re74      -2139.0195</span></span>
<span><span class="co">#&gt; re75        490.3945</span></span>
<span><span class="co">#&gt; hispanic      0.0000</span></span>
<span><span class="co">#&gt; u74           0.0000</span></span>
<span><span class="co">#&gt; u75           0.0000</span></span>
<span><span class="co">#&gt; q1                NA</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Automatically Coarsen and Match</li>
</ol>
<div class="sourceCode" id="cb941"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/cem/man/cem.html">cem</a></span><span class="op">(</span></span>
<span>    treatment <span class="op">=</span> <span class="st">"treated"</span>,</span>
<span>    data <span class="op">=</span> <span class="va">Le</span>,</span>
<span>    drop <span class="op">=</span> <span class="st">"re78"</span>,     <span class="co"># outcome variable</span></span>
<span>    keep.all <span class="op">=</span> <span class="cn">TRUE</span>    <span class="co"># retain unmatched units in output</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Using 'treated'='1' as baseline group</span></span>
<span><span class="va">mat</span></span>
<span><span class="co">#&gt;            G0  G1</span></span>
<span><span class="co">#&gt; All       392 258</span></span>
<span><span class="co">#&gt; Matched    95  84</span></span>
<span><span class="co">#&gt; Unmatched 297 174</span></span></code></pre></div>
<ul>
<li><p><code>mat$w</code> contains <strong>weights</strong> for matched units.</p></li>
<li><p>Summary of matched strata and units retained.</p></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Manual Coarsening (User-Controlled)</li>
</ol>
<p>Users may coarsen variables explicitly based on theoretical knowledge or data distribution.</p>
<p>Example: Grouped Categorical and Binned Continuous Covariates</p>
<div class="sourceCode" id="cb942"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Inspect levels for grouping</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">Le</span><span class="op">$</span><span class="va">q1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "agree"             "disagree"          "neutral"          </span></span>
<span><span class="co">#&gt; [4] "no opinion"        "strongly agree"    "strongly disagree"</span></span>
<span></span>
<span><span class="co"># Group Likert responses</span></span>
<span><span class="va">q1.grp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"strongly agree"</span>, <span class="st">"agree"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"neutral"</span>, <span class="st">"no opinion"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"strongly disagree"</span>, <span class="st">"disagree"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Custom cutpoints for education</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/table.html">table</a></span><span class="op">(</span><span class="va">Le</span><span class="op">$</span><span class="va">education</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   3   4   5   6   7   8   9  10  11  12  13  14  15 </span></span>
<span><span class="co">#&gt;   1   5   4   6  12  55 106 146 173 113  19   9   1</span></span>
<span><span class="va">educut</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">6.5</span>, <span class="fl">8.5</span>, <span class="fl">12.5</span>, <span class="fl">17</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Run CEM with manual coarsening</span></span>
<span><span class="va">mat1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/cem/man/cem.html">cem</a></span><span class="op">(</span></span>
<span>    treatment <span class="op">=</span> <span class="st">"treated"</span>,</span>
<span>    data <span class="op">=</span> <span class="va">Le</span>,</span>
<span>    drop <span class="op">=</span> <span class="st">"re78"</span>,</span>
<span>    cutpoints <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>education <span class="op">=</span> <span class="va">educut</span><span class="op">)</span>,</span>
<span>    grouping <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>q1 <span class="op">=</span> <span class="va">q1.grp</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Using 'treated'='1' as baseline group</span></span>
<span><span class="va">mat1</span></span>
<span><span class="co">#&gt;            G0  G1</span></span>
<span><span class="co">#&gt; All       392 258</span></span>
<span><span class="co">#&gt; Matched   158 115</span></span>
<span><span class="co">#&gt; Unmatched 234 143</span></span></code></pre></div>
<p>This allows for <strong>domain-specific discretion</strong> and enhances interpretability.</p>
</div>
<div id="progressive-coarsening" class="section level4" number="35.9.7.2">
<h4>
<span class="header-section-number">35.9.7.2</span> Progressive Coarsening<a class="anchor" aria-label="anchor" href="#progressive-coarsening"><i class="fas fa-link"></i></a>
</h4>
<p>CEM supports <strong>progressive coarsening</strong>, where matching is attempted with fine coarsening first. If insufficient matches are found, coarsening is gradually relaxed until a suitable number of matched units is retained.</p>
<p>This strategy balances:</p>
<ul>
<li><p><strong>Precision</strong> (finer bins)</p></li>
<li><p><strong>Sample size retention</strong> (coarser bins)</p></li>
</ul>
</div>
<div id="summary-2" class="section level4" number="35.9.7.3">
<h4>
<span class="header-section-number">35.9.7.3</span> Summary<a class="anchor" aria-label="anchor" href="#summary-2"><i class="fas fa-link"></i></a>
</h4>
<p>Strengths</p>
<ul>
<li><p>Transparent and tunable matching procedure</p></li>
<li><p>Non-parametric: Does not require estimation of a treatment assignment model</p></li>
<li><p>Robust to measurement error and model misspecification</p></li>
<li><p>Supports multi-valued treatments and partial missingness</p></li>
<li><p>Theoretically grounded via monotonic imbalance bounding</p></li>
</ul>
<p>Limitations</p>
<ul>
<li><p>Loss of information due to coarsening</p></li>
<li><p>Arbitrary binning may influence results if not theoretically motivated</p></li>
<li><p>Not designed for high-dimensional settings without careful variable selection</p></li>
<li><p>Cannot account for unobserved confounding</p></li>
</ul>
<p>Coarsened Exact Matching offers a powerful, transparent, and theoretically principled method for preprocessing observational data before estimating causal effects. It overcomes several limitations of traditional matching approaches, particularly propensity score matching, by giving researchers direct control over the quality of matches and by anchoring inference in empirical balance rather than model-dependent estimates.</p>
<hr>
</div>
</div>
<div id="sec-genetic-matching" class="section level3" number="35.9.8">
<h3>
<span class="header-section-number">35.9.8</span> Genetic Matching<a class="anchor" aria-label="anchor" href="#sec-genetic-matching"><i class="fas fa-link"></i></a>
</h3>
<p>Genetic Matching (GM) is a generalization of <a href="sec-matching-methods.html#sec-propensity-scores">propensity score</a> and <a href="sec-matching-methods.html#sec-mahalanobis">Mahalanobis distance matching</a>, leveraging a search algorithm inspired by evolutionary biology to optimize covariate balance. Unlike classical matching techniques, which rely on pre-specified distance metrics, Genetic Matching <em>learns</em> an optimal distance metric through an iterative process aimed at minimizing imbalance between treated and control groups.</p>
<p>Genetic Matching was introduced by <span class="citation">Diamond and Sekhon (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-diamond2013genetic">2013</a>)</span> and is designed to improve balance on observed covariates by selecting optimal weights for each covariate. The core idea is to define a generalized Mahalanobis distance metric, where the weights used in the distance calculation are chosen by a <strong>genetic search algorithm</strong>. This process adaptively explores the space of possible weighting matrices and evolves toward a set of weights that result in optimal covariate balance across treatment groups.</p>
<p>The method combines two components:</p>
<ul>
<li>
<a href="sec-matching-methods.html#sec-propensity-scores"><strong>Propensity Score Matching</strong></a>: Balances on the estimated probability of treatment assignment given covariates.</li>
<li>
<a href="sec-matching-methods.html#sec-mahalanobis"><strong>Mahalanobis Distance Matching</strong></a>: Accounts for correlations among covariates and ensures geometric proximity in multivariate space.</li>
</ul>
<p>The Genetic Matching approach treats the selection of covariate weights as an optimization problem, solved using techniques inspired by natural selection—mutation, crossover, and survival of the fittest.</p>
<p>Compared to traditional matching methods such as:</p>
<ul>
<li>
<strong>Nearest Neighbor Matching</strong>: May result in poor balance in high-dimensional or imbalanced datasets.</li>
<li>
<strong>Full Matching</strong>: More efficient but not always feasible with severe imbalance.</li>
</ul>
<p>Genetic Matching is particularly powerful in situations where traditional distance metrics are insufficient to achieve balance. It adaptively searches the weight space to ensure better covariate overlap, which is crucial for unbiased causal inference.</p>
<p>In empirical settings, this often results in superior balance on observed covariates and more credible estimates of treatment effects.</p>
<hr>
<p>Let:</p>
<ul>
<li><p><span class="math inline">\(T_i \in \{0, 1\}\)</span> be the binary treatment indicator for unit <span class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^p\)</span> be the covariate vector for unit <span class="math inline">\(i\)</span>, where <span class="math inline">\(p\)</span> is the number of observed covariates.</p></li>
<li><p><span class="math inline">\(\mathbf{W}\)</span> be a <span class="math inline">\(p \times p\)</span> positive definite weight matrix optimized by the algorithm.</p></li>
</ul>
<p>The <strong>generalized Mahalanobis distance</strong> between unit <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is defined as:</p>
<p><span class="math display">\[
D_{ij} = \sqrt{(\mathbf{X}_i - \mathbf{X}_j)^\top \mathbf{W} (\mathbf{X}_i - \mathbf{X}_j)}
\]</span></p>
<p>Here, <span class="math inline">\(\mathbf{W}\)</span> is not necessarily the inverse of the covariance matrix (as in standard Mahalanobis distance), but a data-driven weighting matrix found by Genetic Matching to optimize covariate balance.</p>
<p>The genetic algorithm optimizes the weights in <span class="math inline">\(\mathbf{W}\)</span> to minimize a global imbalance metric <span class="math inline">\(\mathcal{B}\)</span> across all covariates. This can involve different balance criteria:</p>
<ul>
<li>Paired <span class="math inline">\(t\)</span>-tests for continuous or dichotomous variables</li>
<li>Kolmogorov–Smirnov (K–S) test statistics for distributional similarity</li>
<li>Standardized mean differences</li>
</ul>
<p>Let <span class="math inline">\(b_k\)</span> denote the balance metric for the <span class="math inline">\(k\)</span>th covariate. Then the total imbalance could be:</p>
<p><span class="math display">\[
\mathcal{B} = \sum_{k=1}^{p} w_k b_k^2
\]</span></p>
<p>The optimization objective becomes finding <span class="math inline">\(\mathbf{W}\)</span> that minimizes <span class="math inline">\(\mathcal{B}\)</span>.</p>
<hr>
<p>Genetic Matching is implemented in the <code>Matching</code> package in R via the <code><a href="https://rdrr.io/pkg/Matching/man/GenMatch.html">GenMatch()</a></code> function. This function:</p>
<ul>
<li>Accepts a treatment indicator (<code>Tr</code>) and a matrix of covariates (<code>X</code>).</li>
<li>Optionally takes a <strong>Balance Matrix</strong> (<code>BalanceMatrix</code>) that specifies which variables should be balanced.</li>
<li>Uses a genetic search to find the weight matrix that best achieves balance on the specified variables.</li>
</ul>
<p>Balance is assessed via:</p>
<ul>
<li>Paired <span class="math inline">\(t\)</span>-tests for dichotomous or continuous variables</li>
<li>Kolmogorov-Smirnov (K–S) tests for distributional differences</li>
</ul>
<p>Matching can be performed:</p>
<ul>
<li>
<strong>With or without replacement</strong> (with replacement often improves match quality at the cost of increased variance).</li>
<li>For different estimands: <a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a>, <a href="sec-causal-inference.html#sec-average-treatment-effect-on-the-treated">Average Treatment Effect on the Treated</a>, or <a href="sec-causal-inference.html#sec-average-treatment-effect-on-the-control">Average Treatment Effect on the Control</a>.</li>
</ul>
<hr>
<div class="sourceCode" id="cb943"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/JasjeetSekhon/Matching">Matching</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">lalonde</span>, package <span class="op">=</span> <span class="st">"MatchIt"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/attach.html">attach</a></span><span class="op">(</span><span class="va">lalonde</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define the covariates to match on</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">age</span>, <span class="va">educ</span>, <span class="va">black</span>, <span class="va">hisp</span>, <span class="va">married</span>, <span class="va">nodegr</span>, <span class="va">u74</span>, <span class="va">u75</span>, <span class="va">re75</span>, <span class="va">re74</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define the covariates to balance on</span></span>
<span><span class="va">BalanceMat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">age</span>, <span class="va">educ</span>, <span class="va">black</span>, <span class="va">hisp</span>, <span class="va">married</span>, <span class="va">nodegr</span>,</span>
<span>  <span class="va">u74</span>, <span class="va">u75</span>, <span class="va">re75</span>, <span class="va">re74</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">re74</span> <span class="op">*</span> <span class="va">re75</span><span class="op">)</span> <span class="co"># Include interaction term</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Genetic Matching to optimize covariate balance</span></span>
<span><span class="co"># Note: pop.size = 16 is too small for real applications</span></span>
<span><span class="va">genout</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matching/man/GenMatch.html">GenMatch</a></span><span class="op">(</span></span>
<span>  Tr <span class="op">=</span> <span class="va">treat</span>,</span>
<span>  X <span class="op">=</span> <span class="va">X</span>,</span>
<span>  BalanceMatrix <span class="op">=</span> <span class="va">BalanceMat</span>,</span>
<span>  estimand <span class="op">=</span> <span class="st">"ATE"</span>,</span>
<span>  M <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  pop.size <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  max.generations <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  wait.generations <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define the outcome variable</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">re78</span> <span class="op">/</span> <span class="fl">1000</span></span>
<span></span>
<span><span class="co"># Perform matching with the optimized weights</span></span>
<span><span class="va">mout</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matching/man/Match.html">Match</a></span><span class="op">(</span></span>
<span>  Y <span class="op">=</span> <span class="va">Y</span>,</span>
<span>  Tr <span class="op">=</span> <span class="va">treat</span>,</span>
<span>  X <span class="op">=</span> <span class="va">X</span>,</span>
<span>  estimand <span class="op">=</span> <span class="st">"ATE"</span>,</span>
<span>  Weight.matrix <span class="op">=</span> <span class="va">genout</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summarize the treatment effect estimates</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mout</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Assess post-matching balance</span></span>
<span><span class="va">mb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matching/man/MatchBalance.html">MatchBalance</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">black</span> <span class="op">+</span> <span class="va">hisp</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">nodegr</span> <span class="op">+</span></span>
<span>    <span class="va">u74</span> <span class="op">+</span> <span class="va">u75</span> <span class="op">+</span> <span class="va">re75</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">re74</span> <span class="op">*</span> <span class="va">re75</span><span class="op">)</span>,</span>
<span>  match.out <span class="op">=</span> <span class="va">mout</span>,</span>
<span>  nboots <span class="op">=</span> <span class="fl">500</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><strong>Extensions and Considerations</strong></p>
<ul>
<li><p>The method can be extended to multinomial treatments (via generalized entropy balancing).</p></li>
<li><p>For longitudinal or panel data, entropy balancing can be adapted to match across time points.</p></li>
<li><p>One should avoid balancing on post-treatment variables, which would bias estimates.</p></li>
</ul>
<p>Entropy balancing fits naturally into modern workflows for causal inference, and is especially valuable when researchers want to prioritize design over modeling.</p>
<hr>
</div>
<div id="entropy-balancing" class="section level3" number="35.9.9">
<h3>
<span class="header-section-number">35.9.9</span> Entropy Balancing<a class="anchor" aria-label="anchor" href="#entropy-balancing"><i class="fas fa-link"></i></a>
</h3>
<p>Entropy balancing is a data preprocessing technique for causal inference in observational studies. Introduced by <span class="citation">Hainmueller (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-hainmueller2012entropy">2012</a>)</span>, it is particularly useful in settings with binary treatments where covariate imbalance between treated and control groups threatens the validity of causal estimates.</p>
<p>The method applies a <strong>maximum entropy reweighting</strong> scheme to assign <strong>unit weights</strong> to control group observations such that the <strong>reweighted covariate distribution</strong> in the control group matches the <strong>sample moments</strong> (e.g., means, variances) of the treated group.</p>
<p>Entropy balancing directly targets covariate balance and avoids the trial-and-error of iterative propensity score or matching methods. It also reduces reliance on outcome models by ensuring pre-treatment covariates are aligned between groups.</p>
<ul>
<li>
<strong>Goal</strong>: Create a set of weights for the control group such that its covariate distribution matches that of the treated group.</li>
<li>
<strong>Approach</strong>: Solve a constrained optimization problem that minimizes information loss (measured via Shannon entropy) subject to <strong>balance constraints</strong> on covariates.</li>
</ul>
<p>Entropy balancing:</p>
<ul>
<li><p>Achieves exact balance on the specified covariate moments (e.g., means, variances).</p></li>
<li><p>Produces unique, data-driven weights without the need for iterative matching.</p></li>
<li><p>Is compatible with any outcome model in the second stage (e.g., weighted regression, IPW, DID, etc.).</p></li>
</ul>
<p><strong>Advantages of Entropy Balancing</strong></p>
<ul>
<li>
<strong>Exact balance</strong>: Guarantees moment balance without iterative diagnostics.</li>
<li>
<strong>Flexibility</strong>: Can balance on higher moments, interactions, or non-linear transformations.</li>
<li>
<strong>Model independence</strong>: Reduces reliance on correct specification of the outcome model.</li>
<li>
<strong>Stability</strong>: The optimization procedure is smooth and produces stable, interpretable weights.</li>
</ul>
<p>Entropy balancing is especially useful in high-dimensional settings or when working with small treated groups, where matching can perform poorly or fail entirely.</p>
<hr>
<p>Suppose we have <span class="math inline">\(n_1\)</span> treated units and <span class="math inline">\(n_0\)</span> control units, with covariates <span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^p\)</span> for each unit <span class="math inline">\(i\)</span>. Let <span class="math inline">\(T_i \in \{0,1\}\)</span> be the treatment indicator.</p>
<p>Let the treatment group’s sample moment vector be:</p>
<p><span class="math display">\[
\bar{\mathbf{X}}_T = \frac{1}{n_1} \sum_{i: T_i=1} \mathbf{X}_i
\]</span></p>
<p>We seek a set of weights <span class="math inline">\(\{w_i\}_{i: T_i=0}\)</span> for control units such that:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Covariate balancing constraints</strong> (e.g., mean balance):</li>
</ol>
<p><span class="math display">\[
\sum_{i: T_i=0} w_i \mathbf{X}_i = \bar{\mathbf{X}}_T
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Minimum entropy divergence</strong> from uniform weights:</li>
</ol>
<p>We minimize the Kullback-Leibler divergence between the new weights <span class="math inline">\(w_i\)</span> and uniform base weights <span class="math inline">\(w_i^{(0)} = \frac{1}{n_0}\)</span>:</p>
<p><span class="math display">\[
\min_{\{w_i\}} \sum_{i: T_i=0} w_i \log \left( \frac{w_i}{w_i^{(0)}} \right)
\]</span></p>
<p>subject to:</p>
<ul>
<li>
<span class="math inline">\(\sum w_i = 1\)</span> (weights must sum to 1)</li>
<li><span class="math inline">\(\sum w_i \mathbf{X}_i = \bar{\mathbf{X}}_T\)</span></li>
<li>(Optionally) higher-order moments, e.g., variances, skewness, etc.</li>
</ul>
<p>This is a <strong>convex optimization problem</strong>, ensuring a unique global solution.</p>
<hr>
<div class="sourceCode" id="cb944"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://web.stanford.edu/~jhain/">ebal</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n_treat</span> <span class="op">&lt;-</span> <span class="fl">50</span></span>
<span><span class="va">n_control</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span></span>
<span><span class="co"># Covariates</span></span>
<span><span class="va">X_treat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_treat</span> <span class="op">*</span> <span class="fl">3</span>, mean <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">X_control</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_control</span> <span class="op">*</span> <span class="fl">3</span>, mean <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">rbind</a></span><span class="op">(</span><span class="va">X_control</span>, <span class="va">X_treat</span><span class="op">)</span>  <span class="co"># Order: control first, then treated</span></span>
<span></span>
<span><span class="co"># Treatment vector: 0 = control, 1 = treated</span></span>
<span><span class="va">treatment</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n_control</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n_treat</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Apply entropy balancing</span></span>
<span><span class="va">eb_out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ebal/man/ebalance.html">ebalance</a></span><span class="op">(</span>Treatment <span class="op">=</span> <span class="va">treatment</span>, X <span class="op">=</span> <span class="va">X</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate outcome variable</span></span>
<span><span class="va">Y_control</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_control</span>, mean <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">Y_treat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_treat</span>, mean <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">Y_control</span>, <span class="va">Y_treat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Construct weights: treated get weight 1, control get weights from ebalance</span></span>
<span><span class="va">weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">eb_out</span><span class="op">$</span><span class="va">w</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n_treat</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Estimate ATE using weighted linear regression</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>Y <span class="op">=</span> <span class="va">Y</span>, treat <span class="op">=</span> <span class="va">treatment</span>, weights <span class="op">=</span> <span class="va">weights</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">treat</span>, data <span class="op">=</span> <span class="va">df</span>, weights <span class="op">=</span> <span class="va">weights</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<hr>
</div>
<div id="matching-for-high-dimensional-data" class="section level3" number="35.9.10">
<h3>
<span class="header-section-number">35.9.10</span> Matching for High-Dimensional Data<a class="anchor" aria-label="anchor" href="#matching-for-high-dimensional-data"><i class="fas fa-link"></i></a>
</h3>
<p>As the dimensionality of covariates increases, traditional matching methods (such as nearest neighbor matching using propensity scores or Mahalanobis distance) become increasingly unreliable. This issue, often referred to as the <strong>curse of dimensionality</strong>, undermines the ability to find good matches because distances between points become less informative in high-dimensional space.</p>
<p>In high-dimensional settings, where the number of covariates is large (potentially exceeding the number of observations), careful preprocessing is necessary to reduce dimensionality before matching can be effectively applied. The following approaches are commonly used to mitigate these challenges by reducing the feature space while preserving meaningful structure relevant to treatment assignment and outcomes.</p>
<div id="dimensionality-reduction-techniques" class="section level4" number="35.9.10.1">
<h4>
<span class="header-section-number">35.9.10.1</span> Dimensionality Reduction Techniques<a class="anchor" aria-label="anchor" href="#dimensionality-reduction-techniques"><i class="fas fa-link"></i></a>
</h4>
<p>A variety of dimensionality reduction techniques can be employed prior to matching. Each method has distinct assumptions and use cases:</p>
<ul>
<li><p><strong>Lasso Regression (Least Absolute Shrinkage and Selection Operator)</strong><br>
Lasso imposes an <span class="math inline">\(L_1\)</span> penalty on the regression coefficients, effectively shrinking some coefficients to zero. This property is particularly useful in high-dimensional settings, as it performs both regularization and variable selection.<br>
Lasso can be used to identify a smaller set of covariates that are most predictive of treatment assignment or outcome, which can then be used in matching procedures <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-gordon2019comparison">Gordon et al. 2019</a>)</span>.</p></li>
<li><p><strong>Penalized Logistic Regression</strong><br>
When the treatment is binary, penalized logistic regression (e.g., using an <span class="math inline">\(L_1\)</span> or <span class="math inline">\(L_2\)</span> penalty) can be employed to estimate propensity scores while avoiding overfitting in high-dimensional spaces. These penalized models provide more stable estimates of the propensity score, which is essential for reliable matching <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-eckles2021bias">Eckles and Bakshy 2021</a>)</span>.</p></li>
<li><p><strong>Principal Component Analysis (PCA)</strong><br>
PCA is an unsupervised linear transformation that projects the original features into a lower-dimensional space by retaining the directions of maximum variance. While PCA does not consider treatment assignment directly, it is effective for denoising and compressing data, particularly when covariates are highly correlated.<br>
The principal components can then be used as inputs to standard matching methods.</p></li>
<li><p><strong>Locality Preserving Projections (LPP)</strong><br>
LPP is a linear dimensionality reduction technique that, unlike PCA, preserves local neighborhood structures. It constructs a similarity graph and projects data into a lower-dimensional space such that nearby points remain close. This locality-preserving property is beneficial for matching, as it helps maintain the integrity of local relationships within the data <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-li2016matching">S. Li et al. 2016</a>)</span>.</p></li>
<li><p><strong>Random Projection</strong><br>
Random projection reduces dimensionality by projecting data onto a lower-dimensional subspace using a random matrix. It is computationally efficient and has theoretical guarantees (e.g., Johnson–Lindenstrauss lemma) that distances between points are approximately preserved. This makes it a viable option for extremely high-dimensional data where exact structure preservation is less critical.</p></li>
<li><p><strong>Autoencoders</strong><br>
Autoencoders are neural network architectures designed to learn efficient, nonlinear representations (encodings) of data. An autoencoder consists of an encoder that compresses the input and a decoder that attempts to reconstruct the original input from this compressed representation.<br>
Autoencoders are particularly effective in capturing complex, nonlinear relationships among features, which may be missed by linear methods like PCA. The latent representation obtained from the encoder can then be used for matching <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-ramachandra2018deep">Ramachandra 2018</a>)</span>.</p></li>
</ul>
</div>
<div id="joint-dimensionality-reduction-and-distribution-balancing" class="section level4" number="35.9.10.2">
<h4>
<span class="header-section-number">35.9.10.2</span> Joint Dimensionality Reduction and Distribution Balancing<a class="anchor" aria-label="anchor" href="#joint-dimensionality-reduction-and-distribution-balancing"><i class="fas fa-link"></i></a>
</h4>
<p>Rather than performing dimensionality reduction and matching as separate steps, an emerging strategy is to jointly learn representations that simultaneously:</p>
<ol style="list-style-type: decimal">
<li>Reduce dimensionality, and</li>
<li>Balance the covariate distributions between treated and control groups.</li>
</ol>
<p>This is exemplified by <em>representation learning for causal inference</em> approaches. One such method, proposed by <span class="citation">Yao et al. (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-yao2018representation">2018</a>)</span>, integrates neural networks with matching objectives to learn latent representations of covariates that are both low-dimensional and balanced. These representations are optimized such that the distributions of treated and control units in the latent space are similar (e.g., using maximum mean discrepancy or other balancing metrics), thereby improving the quality of matches and robustness of treatment effect estimates.</p>
</div>
<div id="summary-of-approaches" class="section level4" number="35.9.10.3">
<h4>
<span class="header-section-number">35.9.10.3</span> Summary of Approaches<a class="anchor" aria-label="anchor" href="#summary-of-approaches"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="22%">
<col width="12%">
<col width="9%">
<col width="36%">
<col width="19%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Type</th>
<th>Supervised?</th>
<th>Key Feature</th>
<th>Reference</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Lasso</td>
<td>Linear, sparse</td>
<td>Yes</td>
<td>Variable selection via <span class="math inline">\(L_1\)</span> penalty</td>
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-gordon2019comparison">Gordon et al. 2019</a>)</span></td>
</tr>
<tr class="even">
<td>Penalized logistic regression</td>
<td>Linear</td>
<td>Yes</td>
<td>Regularized propensity score estimation</td>
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-eckles2021bias">Eckles and Bakshy 2021</a>)</span></td>
</tr>
<tr class="odd">
<td>PCA</td>
<td>Linear</td>
<td>No</td>
<td>Projects onto directions of maximal variance</td>
<td>–</td>
</tr>
<tr class="even">
<td>LPP</td>
<td>Linear</td>
<td>No</td>
<td>Preserves local neighborhood structure</td>
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-li2016matching">S. Li et al. 2016</a>)</span></td>
</tr>
<tr class="odd">
<td>Random projection</td>
<td>Linear (random)</td>
<td>No</td>
<td>Fast and preserves pairwise distances</td>
<td>–</td>
</tr>
<tr class="even">
<td>Autoencoders</td>
<td>Nonlinear</td>
<td>Yes</td>
<td>Learns nonlinear representations</td>
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-ramachandra2018deep">Ramachandra 2018</a>)</span></td>
</tr>
<tr class="odd">
<td>Joint representation learning</td>
<td>Nonlinear</td>
<td>Yes</td>
<td>Learns balanced low-dimensional representations</td>
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-yao2018representation">Yao et al. 2018</a>)</span></td>
</tr>
</tbody>
</table></div>
</div>
<div id="practical-considerations-8" class="section level4" number="35.9.10.4">
<h4>
<span class="header-section-number">35.9.10.4</span> Practical Considerations<a class="anchor" aria-label="anchor" href="#practical-considerations-8"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Model selection and validation</strong>: When applying dimensionality reduction prior to matching, one must ensure that the reduced representation still contains sufficient information for confounding adjustment. Cross-validation and balance metrics (e.g., standardized mean differences) should be used to assess the adequacy of the transformation.</p></li>
<li><p><strong>Interpretability</strong>: While methods like PCA or autoencoders can be effective, they may obscure the interpretability of matches since the transformed features may not correspond to original covariates. Sparse methods like Lasso retain interpretability by selecting original covariates.</p></li>
<li><p><strong>Computational efficiency</strong>: Techniques such as random projection or penalized regression are computationally efficient and scalable to large datasets, while autoencoders and joint learning approaches may require more extensive training and hyperparameter tuning.</p></li>
</ul>
<hr>
</div>
</div>
<div id="matching-for-multiple-treatments" class="section level3" number="35.9.11">
<h3>
<span class="header-section-number">35.9.11</span> Matching for Multiple Treatments<a class="anchor" aria-label="anchor" href="#matching-for-multiple-treatments"><i class="fas fa-link"></i></a>
</h3>
<p>In many applied settings, researchers face the challenge of estimating causal effects for <strong>more than two treatment levels</strong>. For example, a marketing campaign may have three variants (e.g., control, light exposure, heavy exposure), or a policy evaluation may involve multiple interventions. Standard binary treatment matching methods fall short in these cases, necessitating methodological extensions.</p>
<p>Suppose a dataset includes <span class="math inline">\(T\)</span> distinct treatment groups: <span class="math inline">\(\mathcal{T} = \{0, 1, ..., T-1\}\)</span>. Here, <span class="math inline">\(T = 0\)</span> typically denotes the control group, and <span class="math inline">\(T \in \{1, ..., T-1\}\)</span> are active treatments. The goal is to estimate the <a href="sec-causal-inference.html#sec-average-treatment-effect">Average Treatment Effect</a> or <strong>Pairwise Treatment Effects</strong>, such as <span class="math inline">\(\text{ATE}_{j,k} = \mathbb{E}[Y(j) - Y(k)]\)</span> for any <span class="math inline">\(j, k \in \mathcal{T}\)</span>.</p>
<p>Key challenges in this setting include:</p>
<ul>
<li>Ensuring common support across multiple groups</li>
<li>Adjusting for confounders in a balanced way across all treatment pairs</li>
<li>Managing covariate imbalance and dimensionality as the number of treatments increases</li>
</ul>
<hr>
<div id="matching-approaches-for-multiple-treatments" class="section level4" number="35.9.11.1">
<h4>
<span class="header-section-number">35.9.11.1</span> Matching Approaches for Multiple Treatments<a class="anchor" aria-label="anchor" href="#matching-approaches-for-multiple-treatments"><i class="fas fa-link"></i></a>
</h4>
<p>Several strategies exist for matching in the presence of multiple treatments:</p>
<ol style="list-style-type: decimal">
<li><strong>Generalized Propensity Scores (GPS)</strong></li>
</ol>
<p>The generalized propensity score is defined as the conditional probability of receiving each treatment level given covariates:</p>
<p><span class="math display">\[
e_t(X) = \mathbb{P}(T = t \mid X), \quad \text{for } t = 0, 1, ..., T-1
\]</span></p>
<p>Estimation is typically done using <strong>multinomial logistic regression</strong>. Once GPS scores are estimated, matching can proceed via:</p>
<ul>
<li>
<strong>One-vs-all</strong>: For each treatment level, match treated units to all others combined.</li>
<li>
<strong>Pairwise matching</strong>: Conduct separate pairwise comparisons between all treatment levels.</li>
<li>
<strong>Full matching</strong>: Attempt to construct a global matched sample covering all treatments, using the GPS vector.</li>
</ul>
<p><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-mccaffrey2013tutorial">McCaffrey et al. 2013</a>)</span> provides a comprehensive overview of GPS-based methods, including their implementation in the <code>twang</code> package.</p>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Covariate Balancing Propensity Scores (CBPS)</strong> for Multiple Treatments</li>
</ol>
<p><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-lopez2017estimation">Lopez and Gutman 2017</a>)</span> extend CBPS to the multinomial case. Rather than merely estimating GPS, CBPS directly optimizes covariate balance across treatment groups while estimating GPS parameters. This dual-objective estimation leads to more robust causal estimates in finite samples.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Kernel or Distance-Based Matching on Multinomial Scores</strong></li>
</ol>
<p>Instead of reducing GPS to scalar scores, matching can be performed using the full vector of propensity scores, using distance metrics such as Euclidean or Mahalanobis distance in the GPS space. This approach aligns with <span class="citation">Q.-Y. Zhao et al. (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-zhao2021propensity">2021</a>)</span>, who also consider <strong>continuous treatments</strong> using <strong>Generalized Propensity Score Density Estimation</strong>.</p>
<hr>
</div>
<div id="matching-with-multiple-treatments-using-matchit-and-alternatives" class="section level4" number="35.9.11.2">
<h4>
<span class="header-section-number">35.9.11.2</span> Matching with Multiple Treatments Using MatchIt and Alternatives<a class="anchor" aria-label="anchor" href="#matching-with-multiple-treatments-using-matchit-and-alternatives"><i class="fas fa-link"></i></a>
</h4>
<p>While the <code>MatchIt</code> package in R was originally developed with binary treatment settings in mind, it can be adapted to handle multiple treatment groups through <strong>pairwise matching</strong> and careful design. However, this approach requires manual data preparation and a clear understanding of the causal estimands of interest—such as the ATT, ATC, or ATE.</p>
<ol style="list-style-type: decimal">
<li>Pairwise Matching with a Shared Control Group</li>
</ol>
<p>To estimate the effect of multiple treatments compared to a shared control group, one straightforward method is to perform separate pairwise matchings between the control group and each treatment group:</p>
<div class="sourceCode" id="cb945"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/">MatchIt</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ngreifer.github.io/cobalt/">cobalt</a></span><span class="op">)</span>  <span class="co"># For balance checking</span></span>
<span></span>
<span><span class="co"># Example dataset: Simulated</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">400</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  treat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"control"</span>, <span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span><span class="op">)</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  cov1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  cov2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  cov3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>  outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define treatment levels</span></span>
<span><span class="va">treatment_levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span><span class="op">)</span></span>
<span><span class="va">control_level</span> <span class="op">&lt;-</span> <span class="st">"control"</span></span>
<span></span>
<span><span class="co"># Initialize weight column</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">match.weights</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span></span>
<span><span class="co"># Perform pairwise matching of each treatment group vs control</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">treat</span> <span class="kw">in</span> <span class="va">treatment_levels</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Subset to control and current treatment</span></span>
<span>  <span class="va">subset_df</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">treat</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">treat</span>, <span class="va">control_level</span><span class="op">)</span>, <span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Create a binary treatment variable: 1 for current treatment, 0 for control</span></span>
<span>  <span class="va">subset_df</span><span class="op">$</span><span class="va">treat_binary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">subset_df</span><span class="op">$</span><span class="va">treat</span> <span class="op">==</span> <span class="va">treat</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Run matching</span></span>
<span>  <span class="va">m.out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span><span class="va">treat_binary</span> <span class="op">~</span> <span class="va">cov1</span> <span class="op">+</span> <span class="va">cov2</span> <span class="op">+</span> <span class="va">cov3</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">subset_df</span>, method <span class="op">=</span> <span class="st">"nearest"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Assign weights back to the original dataset</span></span>
<span>  <span class="va">matched_units</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">m.out</span><span class="op">$</span><span class="va">weights</span><span class="op">[</span><span class="va">m.out</span><span class="op">$</span><span class="va">weights</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">df</span><span class="op">[</span><span class="va">matched_units</span>, <span class="st">"match.weights"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">m.out</span><span class="op">$</span><span class="va">weights</span><span class="op">[</span><span class="va">matched_units</span><span class="op">]</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Check covariate balance</span></span>
<span><span class="fu"><a href="https://ngreifer.github.io/cobalt/reference/bal.tab.html">bal.tab</a></span><span class="op">(</span><span class="va">treat</span> <span class="op">~</span> <span class="va">cov1</span> <span class="op">+</span> <span class="va">cov2</span> <span class="op">+</span> <span class="va">cov3</span>, data <span class="op">=</span> <span class="va">df</span>,</span>
<span>        weights <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">match.weights</span>, method <span class="op">=</span> <span class="st">"matching"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Balance summary across all treatment pairs</span></span>
<span><span class="co">#&gt;         Type Max.Diff.Adj</span></span>
<span><span class="co">#&gt; cov1 Contin.       0.2200</span></span>
<span><span class="co">#&gt; cov2 Contin.       0.1416</span></span>
<span><span class="co">#&gt; cov3  Binary       0.0412</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample sizes</span></span>
<span><span class="co">#&gt;           A  B  C control</span></span>
<span><span class="co">#&gt; All     104 97 85     114</span></span>
<span><span class="co">#&gt; Matched 104 97 85     114</span></span>
<span></span>
<span><span class="co"># Estimate treatment effects using weighted regression</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">outcome</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/relevel.html">relevel</a></span><span class="op">(</span><span class="va">treat</span>, ref <span class="op">=</span> <span class="st">"control"</span><span class="op">)</span>,</span>
<span>             data <span class="op">=</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">match.weights</span> <span class="op">&gt;</span> <span class="fl">0</span>, <span class="op">]</span>,</span>
<span>             weights <span class="op">=</span> <span class="va">match.weights</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = outcome ~ relevel(treat, ref = "control"), data = df[df$match.weights &gt; </span></span>
<span><span class="co">#&gt;     0, ], weights = match.weights)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                                  Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)                      -0.03758    0.09349  -0.402    0.688</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")A  0.08584    0.13536   0.634    0.526</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")B  0.06877    0.13789   0.499    0.618</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")C  0.03806    0.14305   0.266    0.790</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.9964463)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 395.05  on 399  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 394.59  on 396  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 1139.7</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
<p>This approach estimates the <strong>ATT for each treatment group</strong> relative to the control. That is, for each treated group (e.g., A, B, or C), we ask: <em>what would the outcome have been if those who received treatment had instead received the control?</em></p>
<ol start="2" style="list-style-type: decimal">
<li>Estimating the ATC Using <code>MatchIt</code>
</li>
</ol>
<p>In some cases, we may wish to estimate the ATC—i.e., what would have happened to the control group if they had received each of the treatments. To do this, we match <strong>control units to each treated group</strong>, reversing the focal population. Practically, this means keeping the control group intact and separately matching each treatment group to it.</p>
<div class="sourceCode" id="cb946"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/">MatchIt</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ngreifer.github.io/cobalt/">cobalt</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate example data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">456</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">400</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  treat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"control"</span>, <span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span><span class="op">)</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  cov1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  cov2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  cov3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>  outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define treatment levels</span></span>
<span><span class="va">treatment_levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span><span class="op">)</span></span>
<span><span class="va">control_level</span> <span class="op">&lt;-</span> <span class="st">"control"</span></span>
<span></span>
<span><span class="co"># Initialize weight column</span></span>
<span><span class="va">df</span><span class="op">$</span><span class="va">match.weights</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span></span>
<span><span class="co"># Estimate ATC by matching treated units to the control group</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">treat</span> <span class="kw">in</span> <span class="va">treatment_levels</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Subset to current treatment and control</span></span>
<span>  <span class="va">subset_df</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">treat</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">treat</span>, <span class="va">control_level</span><span class="op">)</span>, <span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Binary treatment variable: 0 for treatment group, 1 for control</span></span>
<span>  <span class="co"># This reverses the focus, targeting the control as the treated group</span></span>
<span>  <span class="va">subset_df</span><span class="op">$</span><span class="va">treat_binary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">subset_df</span><span class="op">$</span><span class="va">treat</span> <span class="op">==</span> <span class="va">control_level</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Perform matching</span></span>
<span>  <span class="va">m.out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span><span class="va">treat_binary</span> <span class="op">~</span> <span class="va">cov1</span> <span class="op">+</span> <span class="va">cov2</span> <span class="op">+</span> <span class="va">cov3</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">subset_df</span>, method <span class="op">=</span> <span class="st">"nearest"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Extract matched unit IDs</span></span>
<span>  <span class="va">matched_ids</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">m.out</span><span class="op">$</span><span class="va">weights</span><span class="op">[</span><span class="va">m.out</span><span class="op">$</span><span class="va">weights</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Assign weights back to original dataset</span></span>
<span>  <span class="va">df</span><span class="op">[</span><span class="va">matched_ids</span>, <span class="st">"match.weights"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">m.out</span><span class="op">$</span><span class="va">weights</span><span class="op">[</span><span class="va">matched_ids</span><span class="op">]</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Check balance (optional)</span></span>
<span><span class="fu"><a href="https://ngreifer.github.io/cobalt/reference/bal.tab.html">bal.tab</a></span><span class="op">(</span><span class="va">treat</span> <span class="op">~</span> <span class="va">cov1</span> <span class="op">+</span> <span class="va">cov2</span> <span class="op">+</span> <span class="va">cov3</span>, data <span class="op">=</span> <span class="va">df</span>,</span>
<span>        weights <span class="op">=</span> <span class="va">df</span><span class="op">$</span><span class="va">match.weights</span>, method <span class="op">=</span> <span class="st">"matching"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Balance summary across all treatment pairs</span></span>
<span><span class="co">#&gt;         Type Max.Diff.Adj</span></span>
<span><span class="co">#&gt; cov1 Contin.       0.1229</span></span>
<span><span class="co">#&gt; cov2 Contin.       0.2695</span></span>
<span><span class="co">#&gt; cov3  Binary       0.1985</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample sizes</span></span>
<span><span class="co">#&gt;            A  B  C control</span></span>
<span><span class="co">#&gt; All       99 90 98     113</span></span>
<span><span class="co">#&gt; Matched   99 90 98     111</span></span>
<span><span class="co">#&gt; Unmatched  0  0  0       2</span></span>
<span></span>
<span><span class="co"># Estimate ATC via weighted regression</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">outcome</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/relevel.html">relevel</a></span><span class="op">(</span><span class="va">treat</span>, ref <span class="op">=</span> <span class="st">"control"</span><span class="op">)</span>,</span>
<span>             data <span class="op">=</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">match.weights</span> <span class="op">&gt;</span> <span class="fl">0</span>, <span class="op">]</span>,</span>
<span>             weights <span class="op">=</span> <span class="va">match.weights</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = outcome ~ relevel(treat, ref = "control"), data = df[df$match.weights &gt; </span></span>
<span><span class="co">#&gt;     0, ], weights = match.weights)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                                  Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)                       0.06826    0.09176   0.744    0.457</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")A -0.05103    0.13364  -0.382    0.703</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")B  0.08667    0.13713   0.632    0.528</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")C  0.09488    0.13400   0.708    0.479</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.9346181)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 369.69  on 397  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 368.24  on 394  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 1108.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Regression and Effect Estimation</li>
</ol>
<p>After constructing the matched dataset, one can use regression on the matched sample to estimate the treatment effects:</p>
<div class="sourceCode" id="cb947"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Subset the data first</span></span>
<span><span class="va">matched_data</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">match.weights</span> <span class="op">&gt;</span> <span class="fl">0</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Then fit the weighted regression using the weights from the subset</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">outcome</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/relevel.html">relevel</a></span><span class="op">(</span><span class="va">treat</span>, ref <span class="op">=</span> <span class="st">"control"</span><span class="op">)</span>,</span>
<span>             data <span class="op">=</span> <span class="va">matched_data</span>,</span>
<span>             weights <span class="op">=</span> <span class="va">matched_data</span><span class="op">$</span><span class="va">match.weights</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = outcome ~ relevel(treat, ref = "control"), data = matched_data, </span></span>
<span><span class="co">#&gt;     weights = matched_data$match.weights)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                                  Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)                       0.06826    0.09176   0.744    0.457</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")A -0.05103    0.13364  -0.382    0.703</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")B  0.08667    0.13713   0.632    0.528</span></span>
<span><span class="co">#&gt; relevel(treat, ref = "control")C  0.09488    0.13400   0.708    0.479</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.9346181)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 369.69  on 397  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 368.24  on 394  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 1108.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
<p>Caveats and Limitations</p>
<ul>
<li><p>Matching one treatment group at a time does not preserve global covariate balance across all treatment groups, only pairwise balance with the control.</p></li>
<li><p>Overlap (common support) assumptions should be verified individually for each pairwise comparison.</p></li>
<li><p>Matched samples may vary for each comparison, complicating aggregate inference or joint hypothesis testing.</p></li>
</ul>
<hr>
</div>
<div id="alternative-weighting-for-multiple-treatments-with-weightit" class="section level4" number="35.9.11.3">
<h4>
<span class="header-section-number">35.9.11.3</span> Alternative: Weighting for Multiple Treatments with <code>WeightIt</code><a class="anchor" aria-label="anchor" href="#alternative-weighting-for-multiple-treatments-with-weightit"><i class="fas fa-link"></i></a>
</h4>
<p>Matching can be cumbersome in multiple-treatment settings. Weighting approaches offer a more seamless framework, especially when estimating ATE or ATC across all treatment levels simultaneously. The <code>WeightIt</code> package extends propensity score weighting to multi-treatment scenarios with strong support for diagnostics and flexible estimation.</p>
<div class="sourceCode" id="cb948"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ngreifer.github.io/WeightIt/">WeightIt</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ngreifer.github.io/cobalt/">cobalt</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate example data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">789</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">400</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  treat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"control"</span>, <span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span><span class="op">)</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  cov1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  cov2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  cov3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>  outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Estimate weights for ATE across all treatment levels using multinomial logistic regression</span></span>
<span><span class="va">w.out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ngreifer.github.io/WeightIt/reference/weightit.html">weightit</a></span><span class="op">(</span></span>
<span>  <span class="va">treat</span> <span class="op">~</span> <span class="va">cov1</span> <span class="op">+</span> <span class="va">cov2</span> <span class="op">+</span> <span class="va">cov3</span>,</span>
<span>  data <span class="op">=</span> <span class="va">df</span>,</span>
<span>  estimand <span class="op">=</span> <span class="st">"ATE"</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"glm"</span>  <span class="co"># multinomial model when treat is a factor with &gt;2 levels</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check covariate balance</span></span>
<span><span class="fu"><a href="https://ngreifer.github.io/cobalt/reference/bal.tab.html">bal.tab</a></span><span class="op">(</span><span class="va">w.out</span><span class="op">)</span></span>
<span><span class="co">#&gt; Balance summary across all treatment pairs</span></span>
<span><span class="co">#&gt;         Type Max.Diff.Adj</span></span>
<span><span class="co">#&gt; cov1 Contin.       0.0309</span></span>
<span><span class="co">#&gt; cov2 Contin.       0.0341</span></span>
<span><span class="co">#&gt; cov3  Binary       0.0109</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Effective sample sizes</span></span>
<span><span class="co">#&gt;                 A     B      C control</span></span>
<span><span class="co">#&gt; Unadjusted 112.   99.   107.     82.  </span></span>
<span><span class="co">#&gt; Adjusted   109.59 92.71 100.11   80.73</span></span>
<span></span>
<span><span class="fu"><a href="https://ngreifer.github.io/cobalt/reference/bal.tab.html">bal.tab</a></span><span class="op">(</span><span class="va">w.out</span>, which.treat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Balance by treatment pair</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  - - - A (0) vs. B (1) - - - </span></span>
<span><span class="co">#&gt; Balance Measures</span></span>
<span><span class="co">#&gt;         Type Diff.Adj</span></span>
<span><span class="co">#&gt; cov1 Contin.  -0.0211</span></span>
<span><span class="co">#&gt; cov2 Contin.  -0.0018</span></span>
<span><span class="co">#&gt; cov3  Binary   0.0013</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Effective sample sizes</span></span>
<span><span class="co">#&gt;                 A     B</span></span>
<span><span class="co">#&gt; Unadjusted 112.   99.  </span></span>
<span><span class="co">#&gt; Adjusted   109.59 92.71</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  - - - A (0) vs. C (1) - - - </span></span>
<span><span class="co">#&gt; Balance Measures</span></span>
<span><span class="co">#&gt;         Type Diff.Adj</span></span>
<span><span class="co">#&gt; cov1 Contin.  -0.0034</span></span>
<span><span class="co">#&gt; cov2 Contin.   0.0322</span></span>
<span><span class="co">#&gt; cov3  Binary   0.0109</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Effective sample sizes</span></span>
<span><span class="co">#&gt;                 A      C</span></span>
<span><span class="co">#&gt; Unadjusted 112.   107.  </span></span>
<span><span class="co">#&gt; Adjusted   109.59 100.11</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  - - - B (0) vs. C (1) - - - </span></span>
<span><span class="co">#&gt; Balance Measures</span></span>
<span><span class="co">#&gt;         Type Diff.Adj</span></span>
<span><span class="co">#&gt; cov1 Contin.   0.0176</span></span>
<span><span class="co">#&gt; cov2 Contin.   0.0341</span></span>
<span><span class="co">#&gt; cov3  Binary   0.0097</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Effective sample sizes</span></span>
<span><span class="co">#&gt;                B      C</span></span>
<span><span class="co">#&gt; Unadjusted 99.   107.  </span></span>
<span><span class="co">#&gt; Adjusted   92.71 100.11</span></span>
<span><span class="co">#&gt;  - - - - - - - - - - - - - - - -</span></span>
<span></span>
<span></span>
<span><span class="co"># Estimate treatment effects with robust SEs</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://jtools.jacob-long.com">jtools</a></span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">outcome</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/relevel.html">relevel</a></span><span class="op">(</span><span class="va">treat</span>, ref <span class="op">=</span> <span class="st">"control"</span><span class="op">)</span>,</span>
<span>             data <span class="op">=</span> <span class="va">df</span>,</span>
<span>             weights <span class="op">=</span> <span class="va">w.out</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://jtools.jacob-long.com/reference/summ.html">summ</a></span><span class="op">(</span><span class="va">model</span>, robust <span class="op">=</span> <span class="st">"HC1"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Observations
</td>
<td style="text-align:right;">
400
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Dependent variable
</td>
<td style="text-align:right;">
outcome
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Type
</td>
<td style="text-align:right;">
Linear regression
</td>
</tr>
</tbody></table></div>
<div class="inline-table"><table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
χ²(3)
</td>
<td style="text-align:right;">
33.68
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
p
</td>
<td style="text-align:right;">
0.03
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Pseudo-R² (Cragg-Uhler)
</td>
<td style="text-align:right;">
0.02
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Pseudo-R² (McFadden)
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
AIC
</td>
<td style="text-align:right;">
1143.60
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
BIC
</td>
<td style="text-align:right;">
1163.56
</td>
</tr>
</tbody></table></div>
<div class="inline-table"><table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Est.
</th>
<th style="text-align:right;">
S.E.
</th>
<th style="text-align:right;">
t val.
</th>
<th style="text-align:right;">
p
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
(Intercept)
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
-1.93
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
relevel(treat, ref = “control”)A
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
1.74
</td>
<td style="text-align:right;">
0.08
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
relevel(treat, ref = “control”)B
</td>
<td style="text-align:right;">
-0.03
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
0.83
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
relevel(treat, ref = “control”)C
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
</tbody>
<tfoot><tr>
<td style="padding: 0; " colspan="100%">
<sup></sup> Standard errors: Robust, type = HC1
</td>
</tr></tfoot>
</table></div>
<p>Additional Notes:</p>
<ul>
<li><p>To estimate the ATT for a specific treatment (e.g., treatment A), set <code>focal = "A"</code> and <code>estimand = "ATT"</code> in <code><a href="https://ngreifer.github.io/WeightIt/reference/weightit.html">weightit()</a></code>.</p></li>
<li><p>Setting <code>method = "gbm"</code> in <code>WeightIt</code> will use boosted models, equivalent to the <code>twang</code> package.</p></li>
<li><p>Weighting approaches avoid sample size loss from discarding unmatched units and provide smoother covariate balance optimization.</p></li>
</ul>
</div>
<div id="summary-matching-vs.-weighting-in-multi-treatment-settings" class="section level4" number="35.9.11.4">
<h4>
<span class="header-section-number">35.9.11.4</span> Summary: Matching vs. Weighting in Multi-Treatment Settings<a class="anchor" aria-label="anchor" href="#summary-matching-vs.-weighting-in-multi-treatment-settings"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="7%">
<col width="21%">
<col width="12%">
<col width="24%">
<col width="34%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Approach</th>
<th>Estimands Supported</th>
<th>Pros</th>
<th>Cons</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>MatchIt</code></td>
<td>Pairwise matching (manual)</td>
<td>ATT, ATC</td>
<td>Intuitive; transparent matched pairs</td>
<td>Manual; repeated steps; limited to pairwise comparisons</td>
</tr>
<tr class="even">
<td><code>WeightIt</code></td>
<td>Simultaneous weighting</td>
<td>ATT, ATC, ATE</td>
<td>Flexible; single model; scalable</td>
<td>Requires model diagnostics</td>
</tr>
<tr class="odd">
<td><code>twang</code></td>
<td>Boosted weighting for GPS</td>
<td>ATT, ATE</td>
<td>Automatic tuning; longitudinal support</td>
<td>More complex interface</td>
</tr>
<tr class="even">
<td><code>CBPS</code></td>
<td>Balance-constrained GPS estimation</td>
<td>ATT, ATE</td>
<td>Direct balance optimization</td>
<td>May require customization</td>
</tr>
</tbody>
</table></div>
<p>In general, weighting is more scalable and coherent for estimating causal effects in multi-treatment contexts, while matching can be useful when interpretability and transparency of individual pairings is important.</p>
<hr>
</div>
</div>
<div id="matching-for-multi-level-treatments" class="section level3" number="35.9.12">
<h3>
<span class="header-section-number">35.9.12</span> Matching for Multi-Level Treatments<a class="anchor" aria-label="anchor" href="#matching-for-multi-level-treatments"><i class="fas fa-link"></i></a>
</h3>
<p>Some treatments are not just categorical, but <strong>ordinal</strong> (multi-level), such as “low”, “medium”, and “high” dosage levels. These differ from multinomial treatments in that the levels have a <strong>natural order</strong>. Incorporating this structure can improve both estimation efficiency and interpretability.</p>
<div id="propensity-score-estimation" class="section level4" number="35.9.12.1">
<h4>
<span class="header-section-number">35.9.12.1</span> Propensity Score Estimation<a class="anchor" aria-label="anchor" href="#propensity-score-estimation"><i class="fas fa-link"></i></a>
</h4>
<p>In this context, researchers often use <strong>ordinal logistic regression</strong> to estimate the probability of being in each treatment level:</p>
<p><span class="math display">\[
\text{logit}\left(\mathbb{P}(T \leq t \mid X)\right) = \alpha_t - X^\top \beta
\]</span></p>
<p>This model imposes the <strong>proportional odds assumption</strong>, where the log-odds are linear in covariates but share the same coefficients across cutoffs.</p>
</div>
<div id="matching-strategies" class="section level4" number="35.9.12.2">
<h4>
<span class="header-section-number">35.9.12.2</span> Matching Strategies<a class="anchor" aria-label="anchor" href="#matching-strategies"><i class="fas fa-link"></i></a>
</h4>
<p><span class="citation">Yang et al. (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-yang2016propensity">2016</a>)</span> provide a framework for matching with ordinal treatments, arguing that matching on the <strong>generalized propensity score</strong> derived from an ordinal model helps preserve the order and improves balance. Key considerations include:</p>
<ul>
<li>Matching on estimated ordinal probabilities or cumulative logits</li>
<li>Using Mahalanobis distance in the latent score space</li>
<li>Implementing stratification or subclassification based on predicted scores</li>
</ul>
<p>A custom package, <a href="https://github.com/shuyang1987/multilevelMatching"><code>shuyang1987/multilevelMatching</code></a>, provides tools for this kind of analysis. The package includes:</p>
<ul>
<li>Functions to estimate ordinal GPS</li>
<li>Matching and subclassification routines</li>
<li>Diagnostics to evaluate covariate balance</li>
</ul>
<hr>
</div>
</div>
<div id="matching-for-repeated-treatments-time-varying-treatments" class="section level3" number="35.9.13">
<h3>
<span class="header-section-number">35.9.13</span> Matching for Repeated Treatments (Time-Varying Treatments)<a class="anchor" aria-label="anchor" href="#matching-for-repeated-treatments-time-varying-treatments"><i class="fas fa-link"></i></a>
</h3>
<p>In longitudinal studies, treatments are often administered at multiple time points. Examples include:</p>
<ul>
<li>A patient receiving a drug in multiple doses over weeks</li>
<li>A user receiving marketing emails over several days</li>
</ul>
<p>This setting raises unique challenges, such as:</p>
<ul>
<li>
<strong>Time-varying confounding</strong>: Covariates affected by prior treatment may influence future treatment and outcomes</li>
<li>
<strong>Cumulative dose effects</strong>: Treatment assignment is no longer a one-time event</li>
</ul>
<div id="marginal-structural-models" class="section level4" number="35.9.13.1">
<h4>
<span class="header-section-number">35.9.13.1</span> Marginal Structural Models<a class="anchor" aria-label="anchor" href="#marginal-structural-models"><i class="fas fa-link"></i></a>
</h4>
<p>The most popular framework for analyzing repeated treatments is the <strong>Marginal Structural Model (MSMs)</strong>, which estimates causal effects by weighting each observation using <strong>Inverse Probability of Treatment Weights (IPTW)</strong>.</p>
<p>Let <span class="math inline">\(A_t\)</span> be the treatment at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(X_t\)</span> be time-varying covariates. The IPTW for a trajectory is:</p>
<p><span class="math display">\[
w_i = \prod_{t=1}^{T} \frac{1}{\mathbb{P}(A_{it} \mid \bar{A}_{i,t-1}, \bar{X}_{i,t})}
\]</span></p>
<p>Weights are estimated using logistic regression models at each time point. The outcome model then regresses <span class="math inline">\(Y\)</span> on <span class="math inline">\(\bar{A}_T\)</span> using the weights.</p>
<p>The <a href="https://cran.r-project.org/web/packages/twang/vignettes/iptw.pdf"><code>twang</code></a> package provides tools for:</p>
<ul>
<li>Estimating time-varying propensity scores</li>
<li>Computing IPTWs</li>
<li>Fitting marginal structural models</li>
<li>Checking covariate balance over time</li>
</ul>
<p>Practical Notes</p>
<ul>
<li>Stabilized weights help reduce variance</li>
<li>Trimming or truncating extreme weights is often necessary to maintain robust inference</li>
<li>Dynamic treatment regimes may require further generalizations such as structural nested mean models.</li>
</ul>
<hr>
</div>
</div>
</div>
<div id="sec-selection-on-unobservables" class="section level2" number="35.10">
<h2>
<span class="header-section-number">35.10</span> Selection on Unobservables<a class="anchor" aria-label="anchor" href="#sec-selection-on-unobservables"><i class="fas fa-link"></i></a>
</h2>
<p>While randomized experiments help eliminate bias from unobserved factors, observational data often leave us vulnerable to <a href="sec-matching-methods.html#sec-selection-on-unobservables">selection on unobservables</a>—a scenario where omitted variables jointly affect both treatment assignment and outcomes. Unlike <a href="sec-matching-methods.html#sec-selection-on-observables">selection on observables</a>, these unobserved confounders cannot be directly controlled by regression or matching techniques.</p>
<p>One popular strategy to mitigate bias from observable variables is <a href="sec-matching-methods.html#sec-matching-methods">matching methods</a>. These methods are widely used to estimate causal effects under the assumption of <strong>selection on observables</strong> and offer two primary advantages:</p>
<ul>
<li>They reduce reliance on functional form assumptions (unlike parametric regression).</li>
<li>They rely on the assumption that all covariates influencing treatment assignment are observed.</li>
</ul>
<p>However, this key assumption is often unrealistic. When relevant covariates are unmeasured, <strong>bias from unobservables remains a threat</strong>. To address this concern, researchers turn to <strong>Rosenbaum Bounds</strong>, a sensitivity analysis framework that quantifies how strong hidden bias must be to explain away the observed treatment effect.</p>
<p>Several econometric methods have been developed to test the robustness of causal estimates against such hidden bias. Below are key strategies that researchers commonly employ:</p>
<ol style="list-style-type: decimal">
<li><p><a href="sec-matching-methods.html#sec-rosenbaum-bounds">Rosenbaum Bounds</a><br>
This approach assesses the sensitivity of treatment effects to potential hidden bias by bounding the treatment effect under varying assumptions about the strength of unobserved confounding. It is particularly useful when treatment assignment is believed to be <em>conditionally ignorable</em>, but this assumption may be imperfect.</p></li>
<li>
<p><a href="sec-endogeneity.html#sec-endogenous-sample-selection">Endogenous Sample Selection</a> (Heckman-style correction)<br>
When sample selection is non-random and correlated with unobserved variables influencing the outcome, the Heckman selection model provides a correction. It introduces the inverse Mills ratio <span class="math inline">\(\lambda\)</span> as a control function. A statistically significant <span class="math inline">\(\lambda\)</span> indicates that unobserved factors influencing selection also affect the outcome, pointing to endogenous selection.</p>
<ul>
<li>Interpretation tip: A significant <span class="math inline">\(\lambda\)</span> suggests selection bias due to unobservables, and the Heckman model adjusts the outcome equation accordingly.</li>
<li>This method is frequently applied in labor economics and marketing analytics (e.g., correcting for self-selection in surveys or consumer choice modeling).</li>
</ul>
</li>
<li><p><a href="sec-matching-methods.html#sec-relative-correlation-restrictions">Relative Correlation Restrictions</a><br>
This method imposes assumptions about the correlation between observed and unobserved variables. For instance, by assuming that the selection on unobservables is not stronger than the selection on observables (as in <span class="citation">Altonji, Elder, and Taber (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-altonji2005selection">2005</a>)</span>), one can identify bounds on causal effects. These approaches often rely on auxiliary assumptions or symmetry restrictions to enable partial identification.</p></li>
<li>
<p><a href="sec-matching-methods.html#sec-coefficient-stability-bounds">Coefficient-Stability Bounds</a><br>
This technique evaluates how treatment effect estimates change with the inclusion of additional control variables. If the coefficient on the treatment variable remains stable as more covariates are added, it suggests robustness to omitted variable bias.</p>
<ul>
<li>This idea underlies methods like Oster’s <span class="math inline">\(\delta\)</span> method <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oster2019unobservable">Oster 2019</a>)</span>, which quantifies how much selection on unobservables would be required to nullify the observed effect, assuming proportional selection between observables and unobservables.</li>
</ul>
</li>
</ol>
<p>In applied business research—such as customer retention, credit scoring, or pricing analytics—selection on unobservables is often unavoidable. These methods do not <em>eliminate</em> the problem but provide frameworks to <strong>quantify and interpret the risk</strong> of hidden bias. The choice among these tools depends on the specific context, data availability, and the plausibility of underlying assumptions.</p>
<hr>
<div id="sec-rosenbaum-bounds" class="section level3" number="35.10.1">
<h3>
<span class="header-section-number">35.10.1</span> Rosenbaum Bounds<a class="anchor" aria-label="anchor" href="#sec-rosenbaum-bounds"><i class="fas fa-link"></i></a>
</h3>
<p>Rosenbaum Bounds assess the <strong>robustness of treatment effect estimates to hidden bias</strong> by introducing a sensitivity parameter <span class="math inline">\(\Gamma\)</span> (gamma), which captures the potential effect of an unobserved variable on treatment assignment.</p>
<ul>
<li>
<span class="math inline">\(\Gamma = 1\)</span>: Indicates <strong>perfect randomization</strong>—units in a matched pair are equally likely to receive treatment.</li>
<li>
<span class="math inline">\(\Gamma = 2\)</span>: Suggests that one unit in a matched pair could be up to <strong>twice as likely</strong> to receive treatment due to an unmeasured confounder.</li>
</ul>
<p>Since <span class="math inline">\(\Gamma\)</span> is unknown, sensitivity analysis proceeds by varying <span class="math inline">\(\Gamma\)</span> and examining how the statistical significance and magnitude of the treatment effect respond. This allows us to evaluate how strong an unobserved confounder would need to be to invalidate our findings.</p>
<p>Because the unobserved variable must affect both selection into treatment and outcomes, Rosenbaum Bounds are often described as a <strong>worst-case analysis</strong> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-diprete2004assessing">DiPrete and Gangl 2004</a>)</span>.</p>
<hr>
<p>Imagine we match two individuals based on age and education. One receives treatment, the other does not. If there’s an unmeasured trait (say, motivation) that makes one of them <strong>twice</strong> as likely to receive treatment, this is equivalent to <span class="math inline">\(\Gamma = 2\)</span>.</p>
<p>We then ask: <em>At what level of</em> <span class="math inline">\(\Gamma\)</span> does our result lose significance? If that level is very high (e.g., <span class="math inline">\(\Gamma = 3\)</span> or more), we can be more confident in our findings.</p>
<hr>
<p>In layman’s terms, consider two matched individuals who differ only in an unobserved trait (e.g., motivation). If one of them is twice as likely to receive treatment because of this unobservable, this corresponds to <span class="math inline">\(\Gamma = 2\)</span>. We then ask: <em>Would the treatment effect remain significant under this level of hidden bias?</em></p>
<p>If the estimated effect becomes insignificant only at high values of <span class="math inline">\(\Gamma\)</span> (e.g., <span class="math inline">\(\Gamma &gt; 2\)</span>), the effect is considered robust. Conversely, if statistical significance vanishes at <span class="math inline">\(\Gamma \approx 1.1\)</span>, the effect is highly sensitive to hidden bias.</p>
<hr>
<div id="technical-summary" class="section level4" number="35.10.1.1">
<h4>
<span class="header-section-number">35.10.1.1</span> Technical Summary<a class="anchor" aria-label="anchor" href="#technical-summary"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>Rosenbaum Bounds assess sensitivity without requiring knowledge of the <strong>direction</strong> of the unobserved bias.</li>
<li>They apply to <strong>matched data</strong>, typically using <strong>Wilcoxon signed-rank tests</strong> or other non-parametric statistics.</li>
<li>In the presence of <strong>random treatment assignment</strong>, such non-parametric tests are valid directly.</li>
<li>In <strong>observational data</strong>, they are valid under the assumption of <strong>selection on observables</strong>. If that assumption is questionable, Rosenbaum Bounds offer a way to <strong>test its believability</strong> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rosenbaum2002attributing">Rosenbaum 2002</a>)</span>.</li>
</ul>
<p>A typical Rosenbaum Bounds analysis presents:</p>
<ul>
<li>The <span class="math inline">\(p\)</span>-value for statistical significance at increasing levels of <span class="math inline">\(\Gamma\)</span>.</li>
<li>The Hodges-Lehmann point estimate (a robust median-based treatment effect estimator).</li>
<li>The critical <span class="math inline">\(\Gamma\)</span> value at which the treatment effect becomes insignificant.</li>
</ul>
<p>These analyses do not provide exact bounds on treatment effect estimates. For that, other approaches such as <a href="sec-matching-methods.html#sec-selection-on-unobservables">Relative Correlation Restrictions</a> are required.</p>
<hr>
</div>
<div id="technical-framework" class="section level4" number="35.10.1.2">
<h4>
<span class="header-section-number">35.10.1.2</span> Technical Framework<a class="anchor" aria-label="anchor" href="#technical-framework"><i class="fas fa-link"></i></a>
</h4>
<p>Let <span class="math inline">\(\pi_i\)</span> denote the probability that unit <span class="math inline">\(i\)</span> receives treatment. The odds of treatment are:</p>
<p><span class="math display">\[
\text{Odds}_i = \frac{\pi_i}{1 - \pi_i}
\]</span></p>
<p>Ideally, after matching, if there’s no hidden bias, <span class="math inline">\(\pi_i = \pi_j\)</span> for unit <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>.</p>
<p>Rosenbaum bounds constrain the <strong>odds ratio</strong> between two matched units <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[
\frac{1}{\Gamma} \le \frac{\text{Odds}_i}{\text{Odds}_j} \le \Gamma
\]</span></p>
<p>This relationship links the hidden bias directly to selection probabilities.</p>
<p>Suppose treatment assignment follows:</p>
<p><span class="math display">\[
\log\left( \frac{\pi_i}{1 - \pi_i} \right) = \kappa x_i + \gamma u_i
\]</span></p>
<p>where <span class="math inline">\(u_i\)</span> is an unobserved covariate, and <span class="math inline">\(x_i\)</span> is an observed covariate. The greater the <span class="math inline">\(\gamma\)</span>, the stronger the influence of the unobservable.</p>
<hr>
</div>
<div id="sensitivity-analysis-procedure" class="section level4" number="35.10.1.3">
<h4>
<span class="header-section-number">35.10.1.3</span> Sensitivity Analysis Procedure<a class="anchor" aria-label="anchor" href="#sensitivity-analysis-procedure"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li>Choose a plausible range of <span class="math inline">\(\Gamma\)</span> (typically from 1 to 2.5).</li>
<li>Assess how the p-value or the magnitude of the treatment effect <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-hodges2011estimates">Hodges Jr and Lehmann 2011</a>)</span> (for more details, see <span class="citation">Hollander, Wolfe, and Chicken (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-hollander2013nonparametric">2013</a>)</span>) changes with varying <span class="math inline">\(\Gamma\)</span> values.</li>
<li>Employ specific randomization tests based on the type of outcome to establish bounds on inferences.
<ul>
<li>Report the minimum value of <span class="math inline">\(\Gamma\)</span> at which the treatment treat is nullified (i.e., become insignificant). And the literature’s rules of thumb is that if <span class="math inline">\(\Gamma &gt; 2\)</span>, then we have strong evidence for our treatment effect is robust to large biases <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-proserpio2017online">Proserpio and Zervas 2017</a>)</span>.</li>
</ul>
</li>
</ol>
<p>If treatment is clustered (e.g., by region or school), standard Rosenbaum bounds must be adjusted. See <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-hansen2014clustered">B. B. Hansen, Rosenbaum, and Small 2014</a>)</span> for methods that extend sensitivity analysis to clustered settings—analogous to using clustered standard errors in regression.</p>
<hr>
</div>
<div id="empirical-marketing-examples" class="section level4" number="35.10.1.4">
<h4>
<span class="header-section-number">35.10.1.4</span> Empirical Marketing Examples<a class="anchor" aria-label="anchor" href="#empirical-marketing-examples"><i class="fas fa-link"></i></a>
</h4>
<p>The table below shows <span class="math inline">\(\Gamma\)</span> thresholds needed to nullify treatment effects in real-world marketing studies:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="25%">
<col width="18%">
<col width="56%">
</colgroup>
<thead><tr class="header">
<th>Study</th>
<th>Critical <span class="math inline">\(\Gamma\)</span>
</th>
<th>Context</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oestreicher2013content">Oestreicher-Singer and Zalmanson 2013</a>)</span></td>
<td>1.5 – 1.8</td>
<td>User community participation on willingness to pay</td>
</tr>
<tr class="even">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-sun2013ad">M. Sun and Zhu 2013</a>)</span></td>
<td>1.5</td>
<td>Revenue-sharing program and content popularity</td>
</tr>
<tr class="odd">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-manchanda2015social">Manchanda, Packard, and Pattabhiramaiah 2015</a>)</span></td>
<td>1.6</td>
<td>Impact of social referrals on purchase behavior</td>
</tr>
<tr class="even">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-sudhir2015peter">Sudhir and Talukdar 2015</a>)</span></td>
<td>1.9 – 2.2</td>
<td>IT adoption effects on productivity</td>
</tr>
<tr class="odd">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-proserpio2017online">Proserpio and Zervas 2017</a>)</span></td>
<td>2.0</td>
<td>Management responses and online reputation</td>
</tr>
<tr class="even">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-zhang2022makes">S. Zhang et al. 2022</a>)</span></td>
<td>1.55</td>
<td>Verified photos and Airbnb demand</td>
</tr>
<tr class="odd">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-chae2023paywall">Chae, Ha, and Schweidel 2023</a>)</span></td>
<td>27.0</td>
<td>Paywall suspensions and future subscriptions (not a typo)</td>
</tr>
</tbody>
</table></div>
<p>Packages</p>
<ul>
<li><p><code>rbounds</code> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-keele2010overview">L. Keele 2010</a>)</span></p></li>
<li><p><code>sensitivitymv</code> <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rosenbaum2015two">Rosenbaum 2015</a>)</span></p></li>
</ul>
<p>Since we typically assess our estimate sensitivity to unboservables after matching, we first do some matching.</p>
<div class="sourceCode" id="cb949"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/">MatchIt</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/JasjeetSekhon/Matching">Matching</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"lalonde"</span>, package <span class="op">=</span> <span class="st">"MatchIt"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Matching</span></span>
<span><span class="va">matched</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span><span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span>, data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>, method <span class="op">=</span> <span class="st">"nearest"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">matched</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; matchit(formula = treat ~ age + educ, data = MatchIt::lalonde, </span></span>
<span><span class="co">#&gt;     method = "nearest")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Summary of Balance for All Data:</span></span>
<span><span class="co">#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span><span class="co">#&gt; distance        0.3080        0.2984          0.2734     0.4606    0.0881</span></span>
<span><span class="co">#&gt; age            25.8162       28.0303         -0.3094     0.4400    0.0813</span></span>
<span><span class="co">#&gt; educ           10.3459       10.2354          0.0550     0.4959    0.0347</span></span>
<span><span class="co">#&gt;          eCDF Max</span></span>
<span><span class="co">#&gt; distance   0.1663</span></span>
<span><span class="co">#&gt; age        0.1577</span></span>
<span><span class="co">#&gt; educ       0.1114</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Summary of Balance for Matched Data:</span></span>
<span><span class="co">#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span><span class="co">#&gt; distance        0.3080        0.3077          0.0094     0.9963    0.0033</span></span>
<span><span class="co">#&gt; age            25.8162       25.8649         -0.0068     1.0300    0.0050</span></span>
<span><span class="co">#&gt; educ           10.3459       10.2865          0.0296     0.5886    0.0253</span></span>
<span><span class="co">#&gt;          eCDF Max Std. Pair Dist.</span></span>
<span><span class="co">#&gt; distance   0.0432          0.0146</span></span>
<span><span class="co">#&gt; age        0.0162          0.0597</span></span>
<span><span class="co">#&gt; educ       0.1189          0.8146</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample Sizes:</span></span>
<span><span class="co">#&gt;           Control Treated</span></span>
<span><span class="co">#&gt; All           429     185</span></span>
<span><span class="co">#&gt; Matched       185     185</span></span>
<span><span class="co">#&gt; Unmatched     244       0</span></span>
<span><span class="co">#&gt; Discarded       0       0</span></span>
<span><span class="va">matched_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/match_data.html">match.data</a></span><span class="op">(</span><span class="va">matched</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Split into groups</span></span>
<span><span class="va">treatment_group</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/subset.html">subset</a></span><span class="op">(</span><span class="va">matched_data</span>, <span class="va">treat</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">control_group</span>   <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/subset.html">subset</a></span><span class="op">(</span><span class="va">matched_data</span>, <span class="va">treat</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load rbounds package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">rbounds</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># P-value sensitivity</span></span>
<span><span class="va">psens_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rbounds/man/psens.html">psens</a></span><span class="op">(</span><span class="va">treatment_group</span><span class="op">$</span><span class="va">re78</span>,</span>
<span>                   <span class="va">control_group</span><span class="op">$</span><span class="va">re78</span>,</span>
<span>                   Gamma <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                   GammaInc <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">psens_res</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Signed Rank P-Value </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Unconfounded estimate ....  0.9651 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Gamma Lower bound Upper bound</span></span>
<span><span class="co">#&gt;    1.0      0.9651      0.9651</span></span>
<span><span class="co">#&gt;    1.1      0.8969      0.9910</span></span>
<span><span class="co">#&gt;    1.2      0.7778      0.9980</span></span>
<span><span class="co">#&gt;    1.3      0.6206      0.9996</span></span>
<span><span class="co">#&gt;    1.4      0.4536      0.9999</span></span>
<span><span class="co">#&gt;    1.5      0.3047      1.0000</span></span>
<span><span class="co">#&gt;    1.6      0.1893      1.0000</span></span>
<span><span class="co">#&gt;    1.7      0.1097      1.0000</span></span>
<span><span class="co">#&gt;    1.8      0.0597      1.0000</span></span>
<span><span class="co">#&gt;    1.9      0.0308      1.0000</span></span>
<span><span class="co">#&gt;    2.0      0.0151      1.0000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Note: Gamma is Odds of Differential Assignment To</span></span>
<span><span class="co">#&gt;  Treatment Due to Unobserved Factors </span></span>
<span><span class="co">#&gt; </span></span>
<span></span>
<span><span class="co"># Hodges-Lehmann estimate sensitivity</span></span>
<span><span class="va">hlsens_res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rbounds/man/hlsens.html">hlsens</a></span><span class="op">(</span><span class="va">treatment_group</span><span class="op">$</span><span class="va">re78</span>,</span>
<span>                     <span class="va">control_group</span><span class="op">$</span><span class="va">re78</span>,</span>
<span>                     Gamma <span class="op">=</span> <span class="fl">2</span>,</span>
<span>                     GammaInc <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">hlsens_res</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Rosenbaum Sensitivity Test for Hodges-Lehmann Point Estimate </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Unconfounded estimate ....  1376.248 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Gamma Lower bound Upper bound</span></span>
<span><span class="co">#&gt;    1.0     1376.20      1376.2</span></span>
<span><span class="co">#&gt;    1.1      852.45      1682.0</span></span>
<span><span class="co">#&gt;    1.2      456.55      2023.1</span></span>
<span><span class="co">#&gt;    1.3      137.25      2405.9</span></span>
<span><span class="co">#&gt;    1.4     -133.45      2765.2</span></span>
<span><span class="co">#&gt;    1.5     -461.65      3063.6</span></span>
<span><span class="co">#&gt;    1.6     -751.85      3328.5</span></span>
<span><span class="co">#&gt;    1.7     -946.45      3591.6</span></span>
<span><span class="co">#&gt;    1.8    -1185.50      3864.8</span></span>
<span><span class="co">#&gt;    1.9    -1404.70      4133.1</span></span>
<span><span class="co">#&gt;    2.0    -1624.60      4358.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Note: Gamma is Odds of Differential Assignment To</span></span>
<span><span class="co">#&gt;  Treatment Due to Unobserved Factors </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>For matching with more than one control per treated unit:</p>
<div class="sourceCode" id="cb950"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/JasjeetSekhon/Matching">Matching</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/">MatchIt</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">n_ratio</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">matched</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/matchit.html">matchit</a></span><span class="op">(</span><span class="va">treat</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span>,</span>
<span>            data <span class="op">=</span> <span class="fu">MatchIt</span><span class="fu">::</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/reference/lalonde.html">lalonde</a></span>,</span>
<span>            method <span class="op">=</span> <span class="st">"nearest"</span>,</span>
<span>            ratio <span class="op">=</span> <span class="va">n_ratio</span><span class="op">)</span></span>
<span><span class="va">matched_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://kosukeimai.github.io/MatchIt/reference/match_data.html">match.data</a></span><span class="op">(</span><span class="va">matched</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mcontrol_res</span> <span class="op">&lt;-</span> <span class="fu">rbounds</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rbounds/man/mcontrol.html">mcontrol</a></span><span class="op">(</span></span>
<span>    y          <span class="op">=</span> <span class="va">matched_data</span><span class="op">$</span><span class="va">re78</span>,</span>
<span>    grp.id     <span class="op">=</span> <span class="va">matched_data</span><span class="op">$</span><span class="va">subclass</span>,</span>
<span>    treat.id   <span class="op">=</span> <span class="va">matched_data</span><span class="op">$</span><span class="va">treat</span>,</span>
<span>    group.size <span class="op">=</span> <span class="va">n_ratio</span> <span class="op">+</span> <span class="fl">1</span>,</span>
<span>    Gamma      <span class="op">=</span> <span class="fl">2.5</span>,</span>
<span>    GammaInc   <span class="op">=</span> <span class="fl">0.1</span></span>
<span><span class="op">)</span></span>
<span><span class="va">mcontrol_res</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Rosenbaum Sensitivity Test for Wilcoxon Strat. Rank P-Value </span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Unconfounded estimate ....  0.9977 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Gamma Lower bound Upper bound</span></span>
<span><span class="co">#&gt;    1.0      0.9977      0.9977</span></span>
<span><span class="co">#&gt;    1.1      0.9892      0.9996</span></span>
<span><span class="co">#&gt;    1.2      0.9651      0.9999</span></span>
<span><span class="co">#&gt;    1.3      0.9144      1.0000</span></span>
<span><span class="co">#&gt;    1.4      0.8301      1.0000</span></span>
<span><span class="co">#&gt;    1.5      0.7149      1.0000</span></span>
<span><span class="co">#&gt;    1.6      0.5809      1.0000</span></span>
<span><span class="co">#&gt;    1.7      0.4445      1.0000</span></span>
<span><span class="co">#&gt;    1.8      0.3209      1.0000</span></span>
<span><span class="co">#&gt;    1.9      0.2195      1.0000</span></span>
<span><span class="co">#&gt;    2.0      0.1428      1.0000</span></span>
<span><span class="co">#&gt;    2.1      0.0888      1.0000</span></span>
<span><span class="co">#&gt;    2.2      0.0530      1.0000</span></span>
<span><span class="co">#&gt;    2.3      0.0305      1.0000</span></span>
<span><span class="co">#&gt;    2.4      0.0170      1.0000</span></span>
<span><span class="co">#&gt;    2.5      0.0092      1.0000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Note: Gamma is Odds of Differential Assignment To</span></span>
<span><span class="co">#&gt;  Treatment Due to Unobserved Factors </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>Alternative Sensitivity Analysis Tools</p>
<p><code>sensitivitymw</code> is faster than <code>sensitivitymw</code>. But <code>sensitivitymw</code> can match where matched sets can have differing numbers of controls <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-rosenbaum2015two">Rosenbaum 2015</a>)</span>.</p>
<div class="sourceCode" id="cb951"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">sensitivitymv</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">lead150</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sensitivitymv/man/senmv.html">senmv</a></span><span class="op">(</span><span class="va">lead150</span>, gamma <span class="op">=</span> <span class="fl">2</span>, trim <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; $pval</span></span>
<span><span class="co">#&gt; [1] 0.02665519</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $deviate</span></span>
<span><span class="co">#&gt; [1] 1.932398</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $statistic</span></span>
<span><span class="co">#&gt; [1] 27.97564</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $expectation</span></span>
<span><span class="co">#&gt; [1] 18.0064</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $variance</span></span>
<span><span class="co">#&gt; [1] 26.61524</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">sensitivitymw</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/sensitivitymw/man/senmw.html">senmw</a></span><span class="op">(</span><span class="va">lead150</span>, gamma <span class="op">=</span> <span class="fl">2</span>, trim <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; $pval</span></span>
<span><span class="co">#&gt; [1] 0.02665519</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $deviate</span></span>
<span><span class="co">#&gt; [1] 1.932398</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $statistic</span></span>
<span><span class="co">#&gt; [1] 27.97564</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $expectation</span></span>
<span><span class="co">#&gt; [1] 18.0064</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $variance</span></span>
<span><span class="co">#&gt; [1] 26.61524</span></span></code></pre></div>
<hr>
</div>
</div>
<div id="sec-relative-correlation-restrictions" class="section level3" number="35.10.2">
<h3>
<span class="header-section-number">35.10.2</span> Relative Correlation Restrictions<a class="anchor" aria-label="anchor" href="#sec-relative-correlation-restrictions"><i class="fas fa-link"></i></a>
</h3>
<p>In many observational studies, researchers are concerned about the impact of unobserved variables that are not included in the regression model. Even after including a comprehensive set of controls, there is always the possibility that omitted variables still bias the estimated treatment effect. <strong>Relative Correlation Restrictions (RCR)</strong> offer a formal way to assess the <strong>potential magnitude of this bias</strong> by comparing it to the observed selection.</p>
<hr>
<p>Let’s begin with a linear outcome model:</p>
<p><span class="math display">\[
Y_i = X_i \beta + C_i \gamma + \epsilon_i
\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(Y_i\)</span> is the outcome variable (e.g., revenue, engagement, churn),</li>
<li>
<span class="math inline">\(X_i\)</span> is the treatment or variable of interest (e.g., paywall suspension, ad exposure),</li>
<li>
<span class="math inline">\(C_i\)</span> is a set of observed control covariates,</li>
<li>
<span class="math inline">\(\epsilon_i\)</span> is the error term, which may include unobserved factors.</li>
</ul>
<p>In standard OLS regression, we assume:</p>
<p><span class="math display">\[
\text{Cov}(X_i, \epsilon_i) = 0
\]</span></p>
<p>That is, the treatment <span class="math inline">\(X_i\)</span> is uncorrelated with the omitted variables contained in <span class="math inline">\(\epsilon_i\)</span>. This assumption is crucial for the <strong>unbiased estimation of</strong> <span class="math inline">\(\beta\)</span>, the treatment effect.</p>
<p>However, in observational settings, this assumption may not hold. There may be unobserved confounders that influence both <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span>, biasing the OLS estimate of <span class="math inline">\(\beta\)</span>. The Relative Correlation Restrictions framework provides a way to bound the treatment effect under assumptions about the relative strength of selection on unobservables compared to selection on observables.</p>
<hr>
<p>The method was originally proposed by <span class="citation">Altonji, Elder, and Taber (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-altonji2005selection">2005</a>)</span> and later extended by <span class="citation">Krauth (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-krauth2016bounding">2016</a>)</span>. The core idea is to assume a proportional relationship between the correlation of the treatment with the error term and its correlation with the observed controls:</p>
<p><span class="math display">\[
\text{Corr}(X_i, \epsilon_i) = \lambda \cdot \text{Corr}(X_i, C_i \gamma)
\]</span></p>
<p>Here, <span class="math inline">\(\lambda\)</span> represents the relative strength of selection on unobservables compared to observables.</p>
<ul>
<li>If <span class="math inline">\(\lambda = 0\)</span>, then we return to the standard OLS assumption: no unobserved selection.</li>
<li>If <span class="math inline">\(\lambda = 1\)</span>, we assume that selection on unobservables is as strong as selection on observables.</li>
<li>If <span class="math inline">\(\lambda &gt; 1\)</span>, then unobserved selection is assumed to be stronger than observable selection.</li>
<li>In practice, we evaluate treatment effects over a range of plausible values for <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<p>This approach allows us to <strong>bound the treatment effect</strong> based on assumptions about the degree of omitted variable bias.</p>
<hr>
<p>The choice of <span class="math inline">\(\lambda\)</span> is crucial and inherently subjective, but some guidelines and empirical precedents help:</p>
<ul>
<li>Small values of <span class="math inline">\(\lambda\)</span> (e.g., 0–1) represent modest levels of bias and suggest that selection on unobservables is not dominant.</li>
<li>Large values (e.g., <span class="math inline">\(\lambda &gt; 2\)</span> or higher) imply that any omitted variables must be far more predictive of treatment than the observed controls—a strong and often implausible assumption in well-specified models.</li>
</ul>
<p>This makes RCR particularly useful for <em>stress testing</em> causal estimates: “How bad would unobserved selection have to be to overturn my result?”</p>
<hr>
<p>This method has been applied to various marketing and digital strategy settings to assess the robustness of estimated effects. A few notable examples:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="17%">
<col width="55%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th>Study</th>
<th>Context</th>
<th>Minimum <span class="math inline">\(\lambda\)</span> to nullify effect</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-manchanda2015social">Manchanda, Packard, and Pattabhiramaiah 2015</a>)</span></td>
<td>
<strong>Social dollar effect</strong>: impact of peer influence on purchasing behavior</td>
<td>3.23</td>
</tr>
<tr class="even">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-chae2023paywall">Chae, Ha, and Schweidel 2023</a>)</span></td>
<td>
<strong>Paywall suspension</strong>: effect on future subscription behavior</td>
<td>6.69</td>
</tr>
<tr class="odd">
<td><span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-sun2013ad">M. Sun and Zhu 2013</a>)</span></td>
<td>
<strong>Ad revenue-sharing</strong>: impact on content popularity</td>
<td></td>
</tr>
</tbody>
</table></div>
<p>These high <span class="math inline">\(\lambda\)</span> values imply that unobserved selection would need to be 3 to 7 times stronger than observable selection to eliminate the estimated treatment effect. In practical terms, this offers strong evidence that the effects are robust to omitted variable bias.</p>
<hr>
<p>We can estimate Relative Correlation Restrictions using the <code>rcrbounds</code> package in R, developed by <span class="citation">Krauth (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-krauth2016bounding">2016</a>)</span>. This package estimates the bounds of the treatment effect across a range of <span class="math inline">\(\lambda\)</span> values and provides inference on whether the effect would remain statistically significant.</p>
<div class="sourceCode" id="cb952"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Install if necessary:</span></span>
<span><span class="co"># remotes::install_github("bvkrauth/rcr/r/rcrbounds")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bvkrauth/rcr">rcrbounds</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Example using ChickWeight dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"ChickWeight"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Estimate treatment effect of Time on weight, controlling for Diet</span></span>
<span><span class="va">rcr_res</span> <span class="op">&lt;-</span> <span class="fu">rcrbounds</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rcrbounds/man/rcr.html">rcr</a></span><span class="op">(</span></span>
<span>    formula <span class="op">=</span> <span class="va">weight</span> <span class="op">~</span> <span class="va">Time</span> <span class="op">|</span> <span class="va">Diet</span>, </span>
<span>    data <span class="op">=</span> <span class="va">ChickWeight</span>, </span>
<span>    <span class="co"># rc_range = c(0, 10) # Test lambda from 0 to 10</span></span>
<span>    rc_range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Print summary</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">rcr_res</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; rcrbounds::rcr(formula = weight ~ Time | Diet, data = ChickWeight, </span></span>
<span><span class="co">#&gt;     rc_range = c(0, 1))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;            Estimate  Std. Error    t value      Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; rcInf     34.676505  50.1295005  0.6917385  4.891016e-01</span></span>
<span><span class="co">#&gt; effectInf 71.989336 112.5711682  0.6395007  5.224973e-01</span></span>
<span><span class="co">#&gt; rc0       34.741955  58.7169195  0.5916856  5.540611e-01</span></span>
<span><span class="co">#&gt; effectL    8.624677   0.3337819 25.8392614 3.212707e-147</span></span>
<span><span class="co">#&gt; effectH    8.750492   0.2607671 33.5567355 7.180405e-247</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; conservative confidence interval:</span></span>
<span><span class="co">#&gt;          2.5  %  97.5  %</span></span>
<span><span class="co">#&gt; effect 7.970477 9.261586</span></span>
<span></span>
<span><span class="co"># Test whether the treatment effect is significantly different from 0</span></span>
<span><span class="fu">rcrbounds</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rcrbounds/man/effect_test.html">effect_test</a></span><span class="op">(</span><span class="va">rcr_res</span>, h0 <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 5.960464e-08</span></span>
<span></span>
<span><span class="co"># Plot the bounds of the treatment effect</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">rcr_res</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="35-matching-methods_files/figure-html/unnamed-chunk-25-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The plot shows how the estimated treatment effect varies as we allow for stronger selection on unobservables (i.e., increasing <span class="math inline">\(\lambda\)</span>). If the effect remains consistently different from zero even at high <span class="math inline">\(\lambda\)</span>, it provides graphical evidence of robustness.</p>
<hr>
</div>
<div id="sec-coefficient-stability-bounds" class="section level3" number="35.10.3">
<h3>
<span class="header-section-number">35.10.3</span> Coefficient-Stability Bounds<a class="anchor" aria-label="anchor" href="#sec-coefficient-stability-bounds"><i class="fas fa-link"></i></a>
</h3>
<p>Robust regression analysis requires methods that account for potential <strong>omitted variable bias</strong>. A contribution to this literature is the coefficient-stability framework developed by <span class="citation">Oster (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oster2019unobservable">2019</a>)</span>, which builds on the proportional selection model of <span class="citation">Altonji, Elder, and Taber (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-altonji2005selection">2005</a>)</span>. <span class="citation">Oster (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oster2019unobservable">2019</a>)</span> derives conditions under which we can bound the bias due to unobservables using movements in the coefficient of interest and changes in model fit, as measured by <span class="math inline">\(R^2\)</span>.</p>
<p>More recently, <span class="citation">Masten and Poirier (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-masten2022effect">2022</a>)</span> have revealed that Oster’s commonly used “delta” metric is insufficient to guarantee robustness of the <strong>sign</strong> of the treatment effect. They propose distinguishing between two types of breakdown points: one where the effect becomes zero (explain-away), and another where it changes sign.</p>
<p>Suppose the data‑generating process for outcome <span class="math inline">\(Y\)</span> is</p>
<p><span class="math display">\[
Y
=\beta X+\underbrace{W_1^{\!\top}\gamma_1}_{\text{observed}}
+\underbrace{W_2^{\!\top}\gamma_2}_{\text{unobserved}}
+\varepsilon ,
\quad
\operatorname{E}[\varepsilon|X,W_1,W_2]=0,
\tag{1}
\]</span></p>
<p>but the econometrician can only regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> and the <strong>observed</strong> covariates <span class="math inline">\(W_1\)</span>. By the omitted‑variable‑bias (OVB) formula,</p>
<p><span class="math display">\[
\widehat\beta_{\text{med}}-\beta
= \frac{\operatorname{Cov}(X,W_2^{\!\top}\gamma_2)}{\operatorname{Var}(X)} .
\tag{2}
\]</span></p>
<p>Because <span class="math inline">\(W_2\)</span> is hidden, nothing inside the sample alone fixes (2). The literature therefore introduces a <em>sensitivity parameter</em> that gauges how strongly <span class="math inline">\(X\)</span> is correlated with the missing variables.</p>
<p><span class="citation">Altonji, Elder, and Taber (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-altonji2005selection">2005</a>)</span> postulated that the <em>selection on unobservables</em> is proportional to the <em>selection on observables</em>. <span class="citation">Oster (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oster2019unobservable">2019</a>)</span> formalized the idea:</p>
<p><span class="math display">\[
\frac{\operatorname{Cov}(X,W_2^{\!\top}\gamma_2)}
     {\operatorname{Var}(W_2^{\!\top}\gamma_2)}
=\delta\;
\frac{\operatorname{Cov}(X,W_1^{\!\top}\gamma_1)}
     {\operatorname{Var}(W_1^{\!\top}\gamma_1)} .
\tag{3}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\delta\)</span> is the <strong>selection ratio</strong>.</li>
<li>
<span class="math inline">\(\delta = 1\)</span> says “unobservables are as correlated with <span class="math inline">\(X\)</span> as observables,” yielding the canonical “Altonji‑Elder‑Taber benchmark.”</li>
</ul>
<p><span class="citation">Oster (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oster2019unobservable">2019</a>)</span> also assumes <strong>coefficient alignment</strong> (<span class="math inline">\(\gamma_1=C\pi_1\)</span>) so we can link bias to the <em>movement</em> of <span class="math inline">\(\widehat\beta\)</span> and <span class="math inline">\(R^2\)</span> when controls are added. Under (1)–(3) the <em>long‑run</em> coefficient (with <span class="math inline">\(W_2\)</span> observed) satisfies</p>
<p><span class="math display">\[
\boxed{\;
\beta_{\text{long}}
=\beta_{\text{med}}
+\bigl(\beta_{\text{med}}-\beta_{\text{short}}\bigr)
     \frac{R^2_{\text{long}}-R^2_{\text{med}}}
          {R^2_{\text{med}}-R^2_{\text{short}}}
\;}
\tag{4}
\]</span> where “short” means no controls, “med” means with <span class="math inline">\(W_1\)</span>, and “long” is the unfeasible full model. Equation (4) is the <strong>coefficient‑stability adjustment</strong>. The two sensitivity objects are</p>
<ul>
<li>
<p><strong>Bias‑adjusted coefficient</strong></p>
<p><span class="math display">\[
\beta^*(\delta,R^2_{\max})\equiv \beta_{\text{long}}
\quad\text{after substituting }R^2_{\text{long}}=R^2_{\max},\;
\delta\text{ into (4);} \tag{5}
\]</span></p>
</li>
<li>
<p><strong>Breakdown point</strong></p>
<p><span class="math display">\[
\delta^{\text{EA}}
\;=\;
\inf\bigl\{\delta:\beta^*(\delta,R^2_{\max})=0\bigr\}.
\tag{6}
\]</span></p>
</li>
</ul>
<p>When <span class="math inline">\(\delta^{\text{EA}}&gt;1\)</span>, unobservables must be <em>more</em> predictive of <span class="math inline">\(X\)</span> than observables to wipe out the estimate.</p>
<hr>
<p><span class="citation">Masten and Poirier (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-masten2022effect">2022</a>)</span> prove a stronger result: under Assumptions (1)–(3) the <strong>sign‑change breakdown</strong></p>
<p><span class="math display">\[
\delta^{\text{SC}}
=\inf\bigl\{\delta:\operatorname{sign}\beta^*(\delta,R^2_{\max})
                \neq \operatorname{sign}\beta_{\text{med}}\bigr\}
\tag{7}
\]</span></p>
<p>is <em>always</em> ≤ 1 if <span class="math inline">\(R^2_{\max}&gt;R^2_{\text{med}}\)</span> and <span class="math inline">\(\beta_{\text{short}}\neq\beta_{\text{med}}\)</span>. Hence the traditional “<span class="math inline">\(\delta = 1\)</span> rule” can never guarantee that the <em>direction</em> of the effect is robust; it merely speaks to <em>magnitude</em>. Putting both <span class="math inline">\(\delta^{EA}\)</span> and <span class="math inline">\(\delta^{SC}\)</span> on the table is therefore critical.</p>
<hr>
<p><span class="citation">Oster (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-oster2019unobservable">2019</a>)</span> recommends <span class="math inline">\(R^2_{\max}=1.3\,R^2_{\text{med}}\)</span> based on external evidence from randomized experiments, but researchers should vary this choice—especially if <span class="math inline">\(R^2_{\text{med}}\)</span> is modest. <span class="citation">Cinelli and Hazlett (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-cinelli2020making">2020</a>)</span> re‑express the problem in partial‑<span class="math inline">\(R^2\)</span> space and propose the <strong>robustness value</strong>, implemented in the <code>sensemakr</code> package. <span class="citation">G. W. Imbens (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-imbens2003sensitivity">2003</a>)</span> supply complementary contour‑plot tools.</p>
<hr>
<div class="sourceCode" id="cb953"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kosukeimai.github.io/MatchIt/">MatchIt</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">robomit</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"lalonde"</span>, package <span class="op">=</span> <span class="st">"MatchIt"</span><span class="op">)</span></span>
<span><span class="va">lalonde</span> <span class="op">&lt;-</span> <span class="va">lalonde</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>log_re78 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">re78</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create race dummies if needed</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="st">"black"</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">lalonde</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">lalonde</span> <span class="op">&lt;-</span> <span class="va">lalonde</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    black  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">race</span> <span class="op">==</span> <span class="st">"black"</span><span class="op">)</span>,</span>
<span>    hispan <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">race</span> <span class="op">==</span> <span class="st">"hispanic"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># nodegree naming patch</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="st">"nodegr"</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">lalonde</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"nodegree"</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">lalonde</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">lalonde</span> <span class="op">&lt;-</span> <span class="va">lalonde</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html">rename</a></span><span class="op">(</span>nodegr <span class="op">=</span> <span class="va">nodegree</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># assure 0/1 indicators</span></span>
<span><span class="va">lalonde</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">lalonde</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html">across</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">treat</span>, <span class="va">black</span>, <span class="va">hispan</span>, <span class="va">married</span>, <span class="va">nodegr</span><span class="op">)</span>,</span>
<span>                              <span class="va">as.numeric</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## analysis sample &amp; R^2</span></span>
<span><span class="va">vars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"log_re78"</span>,</span>
<span>    <span class="st">"treat"</span>,</span>
<span>    <span class="st">"age"</span>,</span>
<span>    <span class="st">"educ"</span>,</span>
<span>    <span class="st">"black"</span>,</span>
<span>    <span class="st">"hispan"</span>,</span>
<span>    <span class="st">"married"</span>,</span>
<span>    <span class="st">"nodegr"</span>,</span>
<span>    <span class="st">"re74"</span>,</span>
<span>    <span class="st">"re75"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">model_df</span> <span class="op">&lt;-</span> <span class="va">lalonde</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/all_of.html">all_of</a></span><span class="op">(</span><span class="va">vars</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">R2_med</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span></span>
<span>        <span class="va">log_re78</span> <span class="op">~</span> <span class="va">treat</span> <span class="op">+</span> <span class="va">age</span> <span class="op">+</span> <span class="va">educ</span> <span class="op">+</span> <span class="va">black</span> <span class="op">+</span> <span class="va">hispan</span> <span class="op">+</span></span>
<span>            <span class="va">married</span> <span class="op">+</span> <span class="va">nodegr</span> <span class="op">+</span> <span class="va">re74</span> <span class="op">+</span> <span class="va">re75</span>,</span>
<span>        data <span class="op">=</span> <span class="va">model_df</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">r.squared</span></span>
<span><span class="va">R2_max</span> <span class="op">&lt;-</span> <span class="fl">1.3</span> <span class="op">*</span> <span class="va">R2_med</span> <span class="co"># Oster default upper bound</span></span>
<span></span>
<span><span class="co">## β* (δ = 1) &amp; δ* (β = 0) </span></span>
<span><span class="va">beta_tbl</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/robomit/man/o_beta.html">o_beta</a></span><span class="op">(</span></span>
<span>    y <span class="op">=</span> <span class="st">"log_re78"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"treat"</span>,</span>
<span>    con <span class="op">=</span> <span class="st">"age + educ + black + hispan + married + nodegr + re74 + re75"</span>,</span>
<span>    delta <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    R2max <span class="op">=</span> <span class="va">R2_max</span>,</span>
<span>    type <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>    data <span class="op">=</span> <span class="va">model_df</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">delta_tbl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/robomit/man/o_delta.html">o_delta</a></span><span class="op">(</span></span>
<span>    y <span class="op">=</span> <span class="st">"log_re78"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"treat"</span>,</span>
<span>    con <span class="op">=</span> <span class="st">"age + educ + black + hispan + married + nodegr + re74 + re75"</span>,</span>
<span>    beta <span class="op">=</span> <span class="fl">0</span>,</span>
<span>    R2max <span class="op">=</span> <span class="va">R2_max</span>,</span>
<span>    type <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>    data <span class="op">=</span> <span class="va">model_df</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">beta_val</span>  <span class="op">&lt;-</span> <span class="va">beta_tbl</span>  <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Name</span> <span class="op">==</span> <span class="st">"beta*"</span><span class="op">)</span>  <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">Value</span><span class="op">)</span></span>
<span><span class="va">delta_val</span> <span class="op">&lt;-</span> <span class="va">delta_tbl</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Name</span> <span class="op">==</span> <span class="st">"delta*"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">Value</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span></span>
<span>  bias_adjusted_beta <span class="op">=</span> <span class="va">beta_val</span>,</span>
<span>  explain_away_delta <span class="op">=</span> <span class="va">delta_val</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; $bias_adjusted_beta</span></span>
<span><span class="co">#&gt; [1] 1.378256</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $explain_away_delta</span></span>
<span><span class="co">#&gt; [1] -1.845051</span></span></code></pre></div>
<div class="sourceCode" id="cb954"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 1.  δ* as Rmax varies (explain‑away curve)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/robomit/man/o_delta_rsq_viz.html">o_delta_rsq_viz</a></span><span class="op">(</span></span>
<span>  y   <span class="op">=</span> <span class="st">"log_re78"</span>, x <span class="op">=</span> <span class="st">"treat"</span>,</span>
<span>  con <span class="op">=</span> <span class="st">"age + educ + black + hispan + married + nodegr + re74 + re75"</span>,</span>
<span>  beta <span class="op">=</span> <span class="fl">0</span>,                     <span class="co"># explain‑away target</span></span>
<span>  type <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>  data <span class="op">=</span> <span class="va">model_df</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="35-matching-methods_files/figure-html/unnamed-chunk-26-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb955"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># 2.  bootstrap sampling distribution of δ*</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/robomit/man/o_delta_boot_viz.html">o_delta_boot_viz</a></span><span class="op">(</span></span>
<span>  y   <span class="op">=</span> <span class="st">"log_re78"</span>, x <span class="op">=</span> <span class="st">"treat"</span>,</span>
<span>  con <span class="op">=</span> <span class="st">"age + educ + black + hispan + married + nodegr + re74 + re75"</span>,</span>
<span>  beta   <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  R2max  <span class="op">=</span> <span class="va">R2_max</span>,</span>
<span>  sim    <span class="op">=</span> <span class="fl">100</span>,                 <span class="co"># number of bootstrap draws</span></span>
<span>  obs    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">nrow</a></span><span class="op">(</span><span class="va">model_df</span><span class="op">)</span>,      <span class="co"># draw full‑sample size each time</span></span>
<span>  rep    <span class="op">=</span> <span class="cn">TRUE</span>,                <span class="co"># with replacement</span></span>
<span>  CI     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">90</span>, <span class="fl">95</span>, <span class="fl">99</span><span class="op">)</span>,       <span class="co"># show three confidence bands</span></span>
<span>  type   <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>  norm   <span class="op">=</span> <span class="cn">TRUE</span>,                <span class="co"># overlay normal curve</span></span>
<span>  bin    <span class="op">=</span> <span class="fl">120</span>,                 <span class="co"># histogram bins</span></span>
<span>  data   <span class="op">=</span> <span class="va">model_df</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="35-matching-methods_files/figure-html/unnamed-chunk-26-2.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb956"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># 3.  bias‑adjusted β* over a grid of Rmax value</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/robomit/man/o_beta_rsq_viz.html">o_beta_rsq_viz</a></span><span class="op">(</span></span>
<span>  y   <span class="op">=</span> <span class="st">"log_re78"</span>, x <span class="op">=</span> <span class="st">"treat"</span>,</span>
<span>  con <span class="op">=</span> <span class="st">"age + educ + black + hispan + married + nodegr + re74 + re75"</span>,</span>
<span>  delta <span class="op">=</span> <span class="fl">1</span>,                    <span class="co"># proportional selection benchmark</span></span>
<span>  type  <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>  data  <span class="op">=</span> <span class="va">model_df</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="35-matching-methods_files/figure-html/unnamed-chunk-26-3.png" width="90%" style="display: block; margin: auto;"></div>
<ol style="list-style-type: decimal">
<li>
<strong>Explain‑away curve</strong>: plots <span class="math inline">\(\delta^*\)</span> against a range of <span class="math inline">\(R^2_{\max}\)</span>.</li>
<li>
<strong>Bootstrap histogram</strong>: sampling distribution of <span class="math inline">\(\delta^*\)</span>, with 90/95/99 % bands.</li>
<li>
<span class="math inline">\(\beta^*\)</span> vs. <span class="math inline">\(R^2_{\max}\)</span>: how the bias‑adjusted coefficient moves as you tighten or loosen the assumed upper bound on <span class="math inline">\(R^2\)</span>.</li>
</ol>
</div>
</div>
</div>



<div class="chapter-nav">
<div class="prev"><a href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></div>
<div class="next"><a href="sec-endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-matching-methods"><span class="header-section-number">35</span> Matching Methods</a></li>
<li>
<a class="nav-link" href="#introduction-and-motivation"><span class="header-section-number">35.1</span> Introduction and Motivation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#why-match"><span class="header-section-number">35.1.1</span> Why Match?</a></li>
<li><a class="nav-link" href="#matching-as-pruning"><span class="header-section-number">35.1.2</span> Matching as “Pruning”</a></li>
<li><a class="nav-link" href="#matching-with-did"><span class="header-section-number">35.1.3</span> Matching with DiD</a></li>
</ul>
</li>
<li><a class="nav-link" href="#key-assumptions-4"><span class="header-section-number">35.2</span> Key Assumptions</a></li>
<li><a class="nav-link" href="#framework-for-generalization"><span class="header-section-number">35.3</span> Framework for Generalization</a></li>
<li>
<a class="nav-link" href="#steps-for-matching"><span class="header-section-number">35.4</span> Steps for Matching</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#step-1-define-closeness-distance-metrics"><span class="header-section-number">35.4.1</span> Step 1: Define “Closeness” (Distance Metrics)</a></li>
<li><a class="nav-link" href="#step-2-matching-algorithms"><span class="header-section-number">35.4.2</span> Step 2: Matching Algorithms</a></li>
<li><a class="nav-link" href="#step-3-diagnosing-match-quality"><span class="header-section-number">35.4.3</span> Step 3: Diagnosing Match Quality</a></li>
<li><a class="nav-link" href="#step-4-estimating-treatment-effects"><span class="header-section-number">35.4.4</span> Step 4: Estimating Treatment Effects</a></li>
</ul>
</li>
<li><a class="nav-link" href="#special-considerations"><span class="header-section-number">35.5</span> Special Considerations</a></li>
<li>
<a class="nav-link" href="#choosing-a-matching-strategy"><span class="header-section-number">35.6</span> Choosing a Matching Strategy</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#based-on-estimand"><span class="header-section-number">35.6.1</span> Based on Estimand</a></li>
<li><a class="nav-link" href="#based-on-diagnostics"><span class="header-section-number">35.6.2</span> Based on Diagnostics</a></li>
<li><a class="nav-link" href="#selection-criteria"><span class="header-section-number">35.6.3</span> Selection Criteria</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#matching-vs.-regression"><span class="header-section-number">35.7</span> Matching vs. Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#matching-estimand"><span class="header-section-number">35.7.1</span> Matching Estimand</a></li>
<li><a class="nav-link" href="#regression-estimand"><span class="header-section-number">35.7.2</span> Regression Estimand</a></li>
<li><a class="nav-link" href="#interpretation-weighting-differences"><span class="header-section-number">35.7.3</span> Interpretation: Weighting Differences</a></li>
</ul>
</li>
<li><a class="nav-link" href="#software-and-practical-implementation"><span class="header-section-number">35.8</span> Software and Practical Implementation</a></li>
<li>
<a class="nav-link" href="#sec-selection-on-observables"><span class="header-section-number">35.9</span> Selection on Observables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#matching-with-matchit"><span class="header-section-number">35.9.1</span> Matching with MatchIt</a></li>
<li><a class="nav-link" href="#reporting-standards"><span class="header-section-number">35.9.2</span> Reporting Standards</a></li>
<li><a class="nav-link" href="#optimization-based-matching-via-designmatch"><span class="header-section-number">35.9.3</span> Optimization-Based Matching via designmatch</a></li>
<li><a class="nav-link" href="#matchingfrontier"><span class="header-section-number">35.9.4</span> MatchingFrontier</a></li>
<li><a class="nav-link" href="#sec-propensity-scores"><span class="header-section-number">35.9.5</span> Propensity Scores</a></li>
<li><a class="nav-link" href="#sec-mahalanobis"><span class="header-section-number">35.9.6</span> Mahalanobis Distance Matching</a></li>
<li><a class="nav-link" href="#sec-cem"><span class="header-section-number">35.9.7</span> Coarsened Exact Matching (CEM)</a></li>
<li><a class="nav-link" href="#sec-genetic-matching"><span class="header-section-number">35.9.8</span> Genetic Matching</a></li>
<li><a class="nav-link" href="#entropy-balancing"><span class="header-section-number">35.9.9</span> Entropy Balancing</a></li>
<li><a class="nav-link" href="#matching-for-high-dimensional-data"><span class="header-section-number">35.9.10</span> Matching for High-Dimensional Data</a></li>
<li><a class="nav-link" href="#matching-for-multiple-treatments"><span class="header-section-number">35.9.11</span> Matching for Multiple Treatments</a></li>
<li><a class="nav-link" href="#matching-for-multi-level-treatments"><span class="header-section-number">35.9.12</span> Matching for Multi-Level Treatments</a></li>
<li><a class="nav-link" href="#matching-for-repeated-treatments-time-varying-treatments"><span class="header-section-number">35.9.13</span> Matching for Repeated Treatments (Time-Varying Treatments)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-selection-on-unobservables"><span class="header-section-number">35.10</span> Selection on Unobservables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-rosenbaum-bounds"><span class="header-section-number">35.10.1</span> Rosenbaum Bounds</a></li>
<li><a class="nav-link" href="#sec-relative-correlation-restrictions"><span class="header-section-number">35.10.2</span> Relative Correlation Restrictions</a></li>
<li><a class="nav-link" href="#sec-coefficient-stability-bounds"><span class="header-section-number">35.10.3</span> Coefficient-Stability Bounds</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/35-matching-methods.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/35-matching-methods.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>
</div>
  

  

</div>
 <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-06-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
