<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 11 Data | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="Data can be defined broadly as any set of values, facts, or statistics that can be used for reference, analysis, and drawing inferences. In research, data drives the process of understanding...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 11 Data | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/data.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="Data can be defined broadly as any set of values, facts, or statistics that can be used for reference, analysis, and drawing inferences. In research, data drives the process of understanding...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 11 Data | A Guide on Data Analysis">
<meta name="twitter:description" content="Data can be defined broadly as any set of values, facts, or statistics that can be used for reference, analysis, and drawing inferences. In research, data drives the process of understanding...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="active" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="sec-endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="sec-directed-acyclic-graphs.html"><span class="header-section-number">38</span> Directed Acyclic Graphs</a></li>
<li><a class="" href="sec-controls.html"><span class="header-section-number">39</span> Controls</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li><a class="" href="high-performance-computing.html"><span class="header-section-number">44</span> High-Performance Computing</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="data" class="section level1" number="11">
<h1>
<span class="header-section-number">11</span> Data<a class="anchor" aria-label="anchor" href="#data"><i class="fas fa-link"></i></a>
</h1>
<p>Data can be defined broadly as any set of values, facts, or statistics that can be used for reference, analysis, and drawing inferences. In research, data drives the process of understanding phenomena, testing hypotheses, and formulating evidence-based conclusions. Choosing the right type of data (and understanding its strengths and limitations) is critical for the validity and reliability of findings.</p>
<div id="data-types" class="section level2" number="11.1">
<h2>
<span class="header-section-number">11.1</span> Data Types<a class="anchor" aria-label="anchor" href="#data-types"><i class="fas fa-link"></i></a>
</h2>
<div id="qualitative-vs.-quantitative-data" class="section level3" number="11.1.1">
<h3>
<span class="header-section-number">11.1.1</span> Qualitative vs. Quantitative Data<a class="anchor" aria-label="anchor" href="#qualitative-vs.-quantitative-data"><i class="fas fa-link"></i></a>
</h3>
<p>A foundational way to categorize data is by whether it is <strong>qualitative</strong> (non-numerical) or <strong>quantitative</strong> (numerical). These distinctions often guide research designs, data collection methods, and analytical techniques.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="50%">
<col width="49%">
</colgroup>
<thead><tr class="header">
<th><strong>Qualitative</strong></th>
<th><strong>Quantitative</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<strong>Examples</strong>: In-depth interviews, focus groups, case studies, ethnographies, open-ended questions, field notes</td>
<td>
<strong>Examples</strong>: Surveys with closed-ended questions, experiments, numerical observations, structured interviews</td>
</tr>
<tr class="even">
<td>
<strong>Nature</strong>: Text-based, often descriptive, subjective interpretations</td>
<td>
<strong>Nature</strong>: Numeric, more standardized, objective measures</td>
</tr>
<tr class="odd">
<td>
<strong>Analysis</strong>: Thematic coding, content analysis, discourse analysis</td>
<td>
<strong>Analysis</strong>: Statistical tests, regression, hypothesis testing, descriptive statistics</td>
</tr>
<tr class="even">
<td>
<strong>Outcome</strong>: Rich context, detailed understanding of phenomena</td>
<td>
<strong>Outcome</strong>: Measurable facts, generalizable findings (with appropriate sampling and design)</td>
</tr>
</tbody>
</table></div>
<div id="uses-and-advantages-of-qualitative-data" class="section level4" number="11.1.1.1">
<h4>
<span class="header-section-number">11.1.1.1</span> Uses and Advantages of Qualitative Data<a class="anchor" aria-label="anchor" href="#uses-and-advantages-of-qualitative-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Deep Understanding</strong>: Captures context, motivations, and perceptions in depth.</p></li>
<li><p><strong>Flexibility</strong>: Elicits new insights through open-ended inquiry.</p></li>
<li><p><strong>Inductive Approaches</strong>: Often used to build new theories or conceptual frameworks.</p></li>
</ul>
</div>
<div id="uses-and-advantages-of-quantitative-data" class="section level4" number="11.1.1.2">
<h4>
<span class="header-section-number">11.1.1.2</span> Uses and Advantages of Quantitative Data<a class="anchor" aria-label="anchor" href="#uses-and-advantages-of-quantitative-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Measurement and Comparison</strong>: Facilitates measuring variables and comparing across groups or over time.</p></li>
<li><p><strong>Generalizability</strong>: With proper sampling, findings can often be generalized to broader populations.</p></li>
<li><p><strong>Hypothesis Testing</strong>: Permits the use of statistical methods to test specific predictions or relationships.</p></li>
</ul>
</div>
<div id="limitations-of-qualitative-and-quantitative-data" class="section level4" number="11.1.1.3">
<h4>
<span class="header-section-number">11.1.1.3</span> Limitations of Qualitative and Quantitative Data<a class="anchor" aria-label="anchor" href="#limitations-of-qualitative-and-quantitative-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<p><strong>Qualitative</strong>:</p>
<ul>
<li><p>Findings may be difficult to generalize if samples are small or non-representative.</p></li>
<li><p>Analysis can be time-consuming due to coding and interpreting text.</p></li>
<li><p>Potential for researcher bias in interpretation.</p></li>
</ul>
</li>
<li>
<p><strong>Quantitative</strong>:</p>
<ul>
<li><p>May oversimplify complex human behaviors or contextual factors by reducing them to numbers.</p></li>
<li><p>Validity depends heavily on how well constructs are operationalized.</p></li>
<li><p>Can miss underlying meanings or nuances not captured in numeric measures.</p></li>
</ul>
</li>
</ul>
</div>
<div id="levels-of-measurement" class="section level4" number="11.1.1.4">
<h4>
<span class="header-section-number">11.1.1.4</span> Levels of Measurement<a class="anchor" aria-label="anchor" href="#levels-of-measurement"><i class="fas fa-link"></i></a>
</h4>
<p>Even within <strong>quantitative</strong> data, there are further distinctions based on the <em>level of measurement</em>. This classification is crucial for determining which statistical techniques are appropriate:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Nominal</strong>: Categorical data with no inherent order (e.g., gender, blood type, eye color).</p></li>
<li><p><strong>Ordinal</strong>: Categorical data with a specific order or ranking but without consistent intervals between ranks (e.g., Likert scale responses: “strongly disagree,” “disagree,” “neutral,” “agree,” “strongly agree”).</p></li>
<li><p><strong>Interval</strong>: Numeric data with equal intervals but no true zero (e.g., temperature in Celsius or Fahrenheit).</p></li>
<li><p><strong>Ratio</strong>: Numeric data with equal intervals and a meaningful zero (e.g., height, weight, income).</p></li>
</ol>
<p>The level of measurement affects which statistical tests (like t-tests, ANOVA, correlations, regressions) are valid and how you can interpret differences or ratios in the data.</p>
<hr>
</div>
</div>
<div id="other-ways-to-classify-data" class="section level3" number="11.1.2">
<h3>
<span class="header-section-number">11.1.2</span> Other Ways to Classify Data<a class="anchor" aria-label="anchor" href="#other-ways-to-classify-data"><i class="fas fa-link"></i></a>
</h3>
<p>Beyond <strong>observational structure</strong>, there are multiple other dimensions used to classify data:</p>
<div id="primary-vs.-secondary-data" class="section level4" number="11.1.2.1">
<h4>
<span class="header-section-number">11.1.2.1</span> Primary vs. Secondary Data<a class="anchor" aria-label="anchor" href="#primary-vs.-secondary-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Primary Data</strong>: Collected directly by the researcher for a specific purpose (e.g., firsthand surveys, experiments, direct measurements).</p></li>
<li><p><strong>Secondary Data</strong>: Originally gathered by someone else for a different purpose (e.g., government census data, administrative records, previously published datasets).</p></li>
</ul>
</div>
<div id="structured-semi-structured-and-unstructured-data" class="section level4" number="11.1.2.2">
<h4>
<span class="header-section-number">11.1.2.2</span> Structured, Semi-Structured, and Unstructured Data<a class="anchor" aria-label="anchor" href="#structured-semi-structured-and-unstructured-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Structured Data</strong>: Organized in a predefined manner, typically in rows and columns (e.g., spreadsheets, relational databases).</p></li>
<li><p><strong>Semi-Structured Data</strong>: Contains organizational markers but not strictly tabular (e.g., JSON, XML logs, HTML).</p></li>
<li>
<p><strong>Unstructured Data</strong>: Lacks a clear, consistent format (e.g., raw text, images, videos, audio files).</p>
<ul>
<li>Often analyzed using natural language processing (NLP), image recognition, or other advanced techniques.</li>
</ul>
</li>
</ul>
</div>
<div id="big-data" class="section level4" number="11.1.2.3">
<h4>
<span class="header-section-number">11.1.2.3</span> Big Data<a class="anchor" aria-label="anchor" href="#big-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p>Characterized by the “3 Vs”: <strong>Volume</strong> (large amounts), <strong>Variety</strong> (diverse forms), and <strong>Velocity</strong> (high-speed generation).</p></li>
<li><p>Requires specialized computational tools (e.g., Hadoop, Spark) and often cloud-based infrastructure for storage and processing.</p></li>
<li><p>Can be structured or unstructured (e.g., social media feeds, sensor data, clickstream data).</p></li>
</ul>
</div>
<div id="internal-vs.-external-data-in-organizational-contexts" class="section level4" number="11.1.2.4">
<h4>
<span class="header-section-number">11.1.2.4</span> Internal vs. External Data (in Organizational Contexts)<a class="anchor" aria-label="anchor" href="#internal-vs.-external-data-in-organizational-contexts"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Internal Data</strong>: Generated within an organization (e.g., sales records, HR data, production metrics).</p></li>
<li><p><strong>External Data</strong>: Sourced from outside (e.g., macroeconomic indicators, market research reports, social media analytics).</p></li>
</ul>
</div>
<div id="proprietary-vs.-public-datas" class="section level4" number="11.1.2.5">
<h4>
<span class="header-section-number">11.1.2.5</span> Proprietary vs. Public Datas<a class="anchor" aria-label="anchor" href="#proprietary-vs.-public-datas"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li><p><strong>Proprietary Data</strong>: Owned by an organization or entity, not freely available for public use.</p></li>
<li><p><strong>Public/Open Data</strong>: Freely accessible data provided by governments, NGOs, or other institutions (e.g., data.gov, World Bank Open Data).</p></li>
</ul>
</div>
</div>
<div id="data-by-observational-structure-over-time" class="section level3" number="11.1.3">
<h3>
<span class="header-section-number">11.1.3</span> Data by Observational Structure Over Time<a class="anchor" aria-label="anchor" href="#data-by-observational-structure-over-time"><i class="fas fa-link"></i></a>
</h3>
<p>Another primary way to categorize data is by <em>how</em> observations are collected over time. This classification shapes research design, analytic methods, and the types of inferences we can make. Four major types here are:</p>
<ol style="list-style-type: decimal">
<li><a href="data.html#sec-cross-sectional-data">Cross-Sectional Data</a></li>
<li><a href="data.html#sec-time-series-data">Time Series Data</a></li>
<li><a href="data.html#sec-repeated-cross-sectional-data">Repeated Cross-Sectional Data</a></li>
<li><a href="data.html#sec-panel-data">Panel (Longitudinal) Data</a></li>
</ol>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="27%">
<col width="38%">
<col width="33%">
</colgroup>
<thead><tr class="header">
<th>Type</th>
<th>Advantages</th>
<th>Limitations</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="data.html#sec-cross-sectional-data">Cross-Sectional Data</a></td>
<td>Simple, cost-effective, good for studying distributions or correlations at a single time point.</td>
<td>Lacks temporal information, can only infer associations, not causal links.</td>
</tr>
<tr class="even">
<td><a href="data.html#sec-time-series-data">Time Series Data</a></td>
<td>Enables trend analysis, seasonality detection, and forecasting.</td>
<td>Requires handling autocorrelation, stationarity issues, and structural breaks.</td>
</tr>
<tr class="odd">
<td><a href="data.html#sec-repeated-cross-sectional-data">Repeated Cross-Sectional Data</a></td>
<td>Tracks shifts in population-level parameters over time; simpler than panel data.</td>
<td>Cannot track individual changes; comparability depends on consistent methodology.</td>
</tr>
<tr class="even">
<td><a href="data.html#sec-panel-data">Panel (Longitudinal) Data</a></td>
<td>Allows causal inference, controls for unobserved heterogeneity, tracks individual trajectories.</td>
<td>Expensive, prone to attrition, requires complex statistical methods.</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
</div>
<div id="sec-cross-sectional-data" class="section level2" number="11.2">
<h2>
<span class="header-section-number">11.2</span> Cross-Sectional Data<a class="anchor" aria-label="anchor" href="#sec-cross-sectional-data"><i class="fas fa-link"></i></a>
</h2>
<p>Cross-sectional data consists of observations on <strong>multiple entities</strong> (e.g., individuals, firms, regions, or countries) at <strong>a single point in time</strong> or over a very short period, where <strong>time is not a primary dimension</strong> of variation.</p>
<ul>
<li>Each observation represents a <strong>different entity</strong>, rather than the same entity tracked over time.</li>
<li>Unlike time series data, the order of observations does not carry temporal meaning.</li>
</ul>
<p>Examples</p>
<ul>
<li>
<strong>Labor Economics</strong>: Wage and demographic data for 1,000 workers in 2024.</li>
<li>
<strong>Marketing Analytics</strong>: Customer satisfaction ratings and purchasing behavior for 500 online shoppers surveyed in Q1 of a year.</li>
<li>
<strong>Corporate Finance</strong>: Financial statements of 1,000 firms for the fiscal year 2023.</li>
</ul>
<p>Key Characteristics</p>
<ul>
<li>
<strong>Observations are independent (in an ideal setting)</strong>: Each unit is drawn from a population with no intrinsic dependence on others.</li>
<li>
<strong>No natural ordering</strong>: Unlike time series data, the sequence of observations does not affect analysis.</li>
<li>
<strong>Variation occurs across entities, not over time</strong>: Differences in observed outcomes arise from differences between individuals, firms, or regions.</li>
</ul>
<p>Advantages</p>
<ul>
<li>
<strong>Straightforward Interpretation</strong>: Since time effects are not present, the focus remains on relationships between variables at a single point.</li>
<li>
<strong>Easier to Collect and Analyze</strong>: Compared to time series or panel data, cross-sectional data is often simpler to collect and model.</li>
<li>
<strong>Suitable for causal inference</strong> (if exogeneity conditions hold).</li>
</ul>
<p>Challenges</p>
<ul>
<li>
<strong>Omitted Variable Bias</strong>: Unobserved confounders may drive both the dependent and independent variables.</li>
<li>
<strong>Endogeneity</strong>: Reverse causality or measurement error can introduce bias.</li>
<li>
<strong>Heteroskedasticity</strong>: Variance of errors may differ across entities, requiring robust standard errors.</li>
</ul>
<hr>
<p>A typical cross-sectional regression model:</p>
<p><span class="math display">\[
y_i = \beta_0 + x_{i1}\beta_1 + x_{i2}\beta_2 + \dots + x_{i(k-1)}\beta_{k-1} + \epsilon_i
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(y_i\)</span> is the outcome variable for entity <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(x_{ij}\)</span> are explanatory variables,</li>
<li>
<span class="math inline">\(\epsilon_i\)</span> is an error term capturing unobserved factors.</li>
</ul>
<hr>
</div>
<div id="sec-time-series-data" class="section level2" number="11.3">
<h2>
<span class="header-section-number">11.3</span> Time Series Data<a class="anchor" aria-label="anchor" href="#sec-time-series-data"><i class="fas fa-link"></i></a>
</h2>
<p>Time series data consists of observations on the <em>same variable(s)</em> recorded over multiple time periods for a single entity (or aggregated entity). These data points are typically collected at consistent intervals—hourly, daily, monthly, quarterly, or annually—allowing for the analysis of trends, patterns, and forecasting.</p>
<p>Examples</p>
<ul>
<li>
<strong>Stock Market</strong>: Daily closing prices of a company’s stock over five years.</li>
<li>
<strong>Economics</strong>: Monthly unemployment rates in a country over a decade.</li>
<li>
<strong>Macroeconomics</strong>: Annual GDP of a country from 1960 to 2020.</li>
</ul>
<p>Key Characteristics</p>
<ul>
<li>The primary goal is to analyze trends, seasonality, cyclic patterns, and forecast future values.</li>
<li>Time series data requires specialized statistical methods, such as:
<ul>
<li><strong>Autoregressive Integrated Moving Average (ARIMA)</strong></li>
<li><strong>Seasonal ARIMA (SARIMA)</strong></li>
<li><strong>Exponential Smoothing</strong></li>
<li><strong>Vector Autoregression (VAR)</strong></li>
</ul>
</li>
</ul>
<p>Advantages</p>
<ul>
<li>Captures temporal patterns such as trends, seasonal fluctuations, and economic cycles.</li>
<li>Essential for forecasting and policy-making, such as setting interest rates based on economic indicators.</li>
</ul>
<p>Challenges</p>
<ul>
<li>
<strong>Autocorrelation</strong>: Observations close in time are often correlated.</li>
<li>
<strong>Structural Breaks</strong>: Sudden changes due to policy shifts or economic crises can distort analysis.</li>
<li>
<strong>Seasonality</strong>: Must be accounted for to avoid misleading conclusions.</li>
</ul>
<hr>
<p>A time series typically consists of four key components:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Trend</strong>: Long-term directional movement in the data over time.</li>
<li>
<strong>Seasonality</strong>: Regular, periodic fluctuations (e.g., increased retail sales in December).</li>
<li>
<strong>Cyclical Patterns</strong>: Long-term economic cycles that are irregular but recurrent.</li>
<li>
<strong>Irregular (Random) Component</strong>: Unpredictable variations not explained by trend, seasonality, or cycles.</li>
</ol>
<hr>
<p>A general linear time series model can be expressed as:</p>
<p><span class="math display">\[
y_t = \beta_0 + x_{t1}\beta_1 + x_{t2}\beta_2 + \dots + x_{t(k-1)}\beta_{k-1} + \epsilon_t
\]</span></p>
<p>Some Common Model Types</p>
<ol style="list-style-type: decimal">
<li><strong>Static Model</strong></li>
</ol>
<p>A simple time series regression:</p>
<p><span class="math display">\[
y_t = \beta_0 + x_1\beta_1 + x_2\beta_2 + x_3\beta_3 + \epsilon_t
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Finite Distributed Lag Model</strong></li>
</ol>
<p>Captures the effect of past values of an explanatory variable:</p>
<p><span class="math display">\[
y_t = \beta_0 + pe_t\delta_0 + pe_{t-1}\delta_1 + pe_{t-2}\delta_2 + \epsilon_t
\]</span></p>
<ul>
<li>
<p><strong>Long-Run Propensity</strong>: Measures the cumulative effect of explanatory variables over time:</p>
<p><span class="math display">\[
LRP = \delta_0 + \delta_1 + \delta_2
\]</span></p>
</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Dynamic Model</strong></li>
</ol>
<p>A model incorporating lagged dependent variables:</p>
<p><span class="math display">\[
GDP_t = \beta_0 + \beta_1 GDP_{t-1} + \epsilon_t
\]</span></p>
<hr>
<div id="statistical-properties-of-time-series-models" class="section level3" number="11.3.1">
<h3>
<span class="header-section-number">11.3.1</span> Statistical Properties of Time Series Models<a class="anchor" aria-label="anchor" href="#statistical-properties-of-time-series-models"><i class="fas fa-link"></i></a>
</h3>
<p>For time series regression, standard OLS assumptions must be carefully examined. The following conditions affect estimation:</p>
<p>Finite Sample Properties</p>
<ul>
<li>
<strong>A1-A3</strong>: OLS remains unbiased.</li>
<li>
<strong>A1-A4</strong>: Standard errors are consistent, and the <a href="linear-regression.html#gauss-markov-theorem">Gauss-Markov Theorem</a> holds (OLS is BLUE).</li>
<li>
<strong>A1-A6</strong>: Finite sample <a href="hypothesis-testing.html#sec-wald-test">Wald tests</a> (e.g., t-tests and F-tests) remain valid.</li>
</ul>
<p>However, in time series settings, <a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a> often fails due to:</p>
<ul>
<li>
<strong>Spurious Time Trends</strong> (fixable by including a time trend)</li>
<li>
<strong>Strict vs. Contemporaneous Exogeneity</strong> (sometimes unavoidable)</li>
</ul>
<hr>
</div>
<div id="common-time-series-processes" class="section level3" number="11.3.2">
<h3>
<span class="header-section-number">11.3.2</span> Common Time Series Processes<a class="anchor" aria-label="anchor" href="#common-time-series-processes"><i class="fas fa-link"></i></a>
</h3>
<p>Several key models describe different time series behaviors:</p>
<ul>
<li><p><strong>Autoregressive Model (AR(p))</strong>: A process where current values depend on past values.</p></li>
<li><p><strong>Moving Average Model (MA(q))</strong>: A process where past error terms influence current values.</p></li>
<li><p><strong>Autoregressive Moving Average (ARMA(p, q))</strong>: A combination of AR and MA processes.</p></li>
<li><p><strong>Autoregressive Conditional Heteroskedasticity (ARCH(p))</strong>: Models time-varying volatility.</p></li>
<li><p><strong>Generalized ARCH (GARCH(p, q))</strong>: Extends ARCH by including past conditional variances.</p></li>
</ul>
<hr>
</div>
<div id="deterministic-time-trends" class="section level3" number="11.3.3">
<h3>
<span class="header-section-number">11.3.3</span> Deterministic Time Trends<a class="anchor" aria-label="anchor" href="#deterministic-time-trends"><i class="fas fa-link"></i></a>
</h3>
<p>When both the dependent and independent variables exhibit trending behavior, a regression may produce <strong>spurious</strong> results.</p>
<p><strong>Spurious Regression Example</strong></p>
<p>A simple regression with trending variables:</p>
<p><span class="math display">\[
y_t = \alpha_0 + t\alpha_1 + v_t
\]</span></p>
<p><span class="math display">\[
x_t = \lambda_0 + t\lambda_1 + u_t
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(\alpha_1 \neq 0\)</span> and <span class="math inline">\(\lambda_1 \neq 1\)</span></p></li>
<li><p><span class="math inline">\(v_t\)</span> and <span class="math inline">\(u_t\)</span> are independent.</p></li>
</ul>
<p>Despite no true relationship between <span class="math inline">\(x_t\)</span> and <span class="math inline">\(y_t\)</span>, estimating:</p>
<p><span class="math display">\[
y_t = \beta_0 + x_t\beta_1 + \epsilon_t
\]</span></p>
<p>results in:</p>
<ul>
<li>
<strong>Inconsistency</strong>: <span class="math inline">\(plim(\hat{\beta}_1) = \frac{\alpha_1}{\lambda_1}\)</span>
</li>
<li>
<strong>Invalid Inference</strong>: <span class="math inline">\(|t| \to^d \infty\)</span> for <span class="math inline">\(H_0: \beta_1=0\)</span>, leading to rejection of the null hypothesis as <span class="math inline">\(n \to \infty\)</span>.</li>
<li>
<strong>Misleading</strong> <span class="math inline">\(R^2\)</span>: <span class="math inline">\(plim(R^2) = 1\)</span>, falsely implying perfect predictive power.</li>
</ul>
<p>We can also rewrite the equation as:</p>
<p><span class="math display">\[
\begin{aligned}
y_t &amp;=\beta_0 + \beta_1 x_t + \epsilon_t \\
\epsilon_t &amp;= \alpha_1 t + v_t
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\beta_0 = \alpha_0\)</span> and <span class="math inline">\(\beta_1 = 0\)</span>. Since <span class="math inline">\(x_t\)</span> is a deterministic function of time, <span class="math inline">\(\epsilon_t\)</span> is correlated with <span class="math inline">\(x_t\)</span>, leading to the usual omitted variable bias.</p>
<p><strong>Solutions to Spurious Trends</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Include a Time Trend</strong> (<span class="math inline">\(t\)</span>) as a Control Variable
<ul>
<li>Provides consistent parameter estimates and valid inference.</li>
</ul>
</li>
<li>
<strong>Detrend Variables</strong>
<ul>
<li>Regress both <span class="math inline">\(y_t\)</span> and <span class="math inline">\(x_t\)</span> on time, then use residuals in a second regression.</li>
<li>Equivalent to applying the <a href="#Frisch%E2%80%93Waugh%E2%80%93Lovell%20Theorem">Frisch-Waugh-Lovell Theorem</a>.</li>
</ul>
</li>
</ol>
</div>
<div id="violations-of-exogeneity-in-time-series-models" class="section level3" number="11.3.4">
<h3>
<span class="header-section-number">11.3.4</span> Violations of Exogeneity in Time Series Models<a class="anchor" aria-label="anchor" href="#violations-of-exogeneity-in-time-series-models"><i class="fas fa-link"></i></a>
</h3>
<p>The <strong>exogeneity assumption</strong> (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>) plays a crucial role in ensuring unbiased and consistent estimation in time series models. However, in many cases, the assumption is <strong>violated</strong> due to the inherent nature of time-dependent processes.</p>
<p>In a standard regression framework, we assume:</p>
<p><span class="math display">\[
E(\epsilon_t | x_1, x_2, ..., x_T) = 0
\]</span></p>
<p>which requires that the error term is uncorrelated with all past, present, and future values of the independent variables.</p>
<p><strong>Common Violations of Exogeneity</strong></p>
<ol style="list-style-type: decimal">
<li><a href="data.html#sec-feedback-effect">Feedback Effect</a></li>
</ol>
<ul>
<li>The error term <span class="math inline">\(\epsilon_t\)</span> <strong>influences future values</strong> of the independent variables.</li>
<li>A classic example occurs in economic models where past shocks affect future decisions.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><a href="data.html#sec-dynamic-specification">Dynamic Specification</a></li>
</ol>
<ul>
<li>The dependent variable includes a <strong>lagged version of itself</strong> as an explanatory variable, introducing correlation between <span class="math inline">\(\epsilon_t\)</span> and past <span class="math inline">\(y_{t-1}\)</span>.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><a href="data.html#sec-dynamic-completeness-and-omitted-lags">Dynamic Completeness</a></li>
</ol>
<ul>
<li>In finite distributed lag (FDL) models, failing to include the <strong>correct number of lags</strong> leads to omitted variable bias and correlation between regressors and errors.</li>
</ul>
<hr>
<div id="sec-feedback-effect" class="section level4" number="11.3.4.1">
<h4>
<span class="header-section-number">11.3.4.1</span> Feedback Effect<a class="anchor" aria-label="anchor" href="#sec-feedback-effect"><i class="fas fa-link"></i></a>
</h4>
<p>In a simple regression model:</p>
<p><span class="math display">\[
y_t = \beta_0 + x_t \beta_1 + \epsilon_t
\]</span></p>
<p>the standard exogeneity assumption (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>) requires:</p>
<p><span class="math display">\[
E(\epsilon_t | x_1, x_2, ..., x_t, x_{t+1}, ..., x_T) = 0
\]</span></p>
<p>However, in the presence of feedback, past errors affect future values of <span class="math inline">\(x_t\)</span>, leading to:</p>
<p><span class="math display">\[
E(\epsilon_t | x_{t+1}, ..., x_T) \neq 0
\]</span></p>
<ul>
<li>This occurs when <strong>current shocks</strong> (e.g., economic downturns) influence <strong>future decisions</strong> (e.g., government spending, firm investments).</li>
<li>Strict exogeneity is <strong>violated</strong>, as we now have dependence across time.</li>
</ul>
<p><strong>Implication</strong>:</p>
<ul>
<li>Standard OLS estimators become <strong>biased and inconsistent</strong>.</li>
<li>One common solution is using <a href="sec-instrumental-variables.html#sec-instrumental-variables">Instrumental Variables</a> to isolate exogenous variation in <span class="math inline">\(x_t\)</span>.</li>
</ul>
<hr>
</div>
<div id="sec-dynamic-specification" class="section level4" number="11.3.4.2">
<h4>
<span class="header-section-number">11.3.4.2</span> Dynamic Specification<a class="anchor" aria-label="anchor" href="#sec-dynamic-specification"><i class="fas fa-link"></i></a>
</h4>
<p>A <strong>dynamically specified model</strong> includes lagged dependent variables:</p>
<p><span class="math display">\[
y_t = \beta_0 + y_{t-1} \beta_1 + \epsilon_t
\]</span></p>
<p>Exogeneity (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>) would require:</p>
<p><span class="math display">\[
E(\epsilon_t | y_1, y_2, ..., y_t, y_{t+1}, ..., y_T) = 0
\]</span></p>
<p>However, since <span class="math inline">\(y_{t-1}\)</span> depends on <span class="math inline">\(\epsilon_{t-1}\)</span> from the previous period, we obtain:</p>
<p><span class="math display">\[
Cov(y_{t-1}, \epsilon_t) \neq 0
\]</span></p>
<p><strong>Implication</strong>:</p>
<ul>
<li>Strict exogeneity (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>) fails, as <span class="math inline">\(y_{t-1}\)</span> and <span class="math inline">\(\epsilon_t\)</span> are correlated.</li>
<li>OLS estimates are biased and inconsistent.</li>
<li>Standard <strong>autoregressive models (AR)</strong> require alternative estimation techniques like <strong>Generalized Method of Moments</strong> or <a href="linear-regression.html#maximum-likelihood-estimator">Maximum Likelihood</a> Estimation.</li>
</ul>
<hr>
</div>
<div id="sec-dynamic-completeness-and-omitted-lags" class="section level4" number="11.3.4.3">
<h4>
<span class="header-section-number">11.3.4.3</span> Dynamic Completeness and Omitted Lags<a class="anchor" aria-label="anchor" href="#sec-dynamic-completeness-and-omitted-lags"><i class="fas fa-link"></i></a>
</h4>
<p>A finite distributed lag (FDL) model:</p>
<p><span class="math display">\[
y_t = \beta_0 + x_t \delta_0 + x_{t-1} \delta_1 + \epsilon_t
\]</span></p>
<p>assumes that the included lags <strong>fully capture</strong> the relationship between <span class="math inline">\(y_t\)</span> and past values of <span class="math inline">\(x_t\)</span>. However, if we omit relevant lags, the exogeneity assumption (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>):</p>
<p><span class="math display">\[
E(\epsilon_t | x_1, x_2, ..., x_t, x_{t+1}, ..., x_T) = 0
\]</span></p>
<p><strong>fails</strong>, as unmodeled lag effects create correlation between <span class="math inline">\(x_{t-2}\)</span> and <span class="math inline">\(\epsilon_t\)</span>.</p>
<p><strong>Implication</strong>:</p>
<ul>
<li>The regression suffers from <strong>omitted variable bias</strong>, making OLS estimates unreliable.</li>
<li>
<strong>Solution</strong>:
<ul>
<li>Include <strong>additional lags</strong> of <span class="math inline">\(x_t\)</span>.</li>
<li>Use <strong>lag selection criteria</strong> (e.g., AIC, BIC) to determine the appropriate lag structure.</li>
</ul>
</li>
</ul>
<hr>
</div>
</div>
<div id="consequences-of-exogeneity-violations" class="section level3" number="11.3.5">
<h3>
<span class="header-section-number">11.3.5</span> Consequences of Exogeneity Violations<a class="anchor" aria-label="anchor" href="#consequences-of-exogeneity-violations"><i class="fas fa-link"></i></a>
</h3>
<p>If strict exogeneity (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>) fails, standard OLS assumptions no longer hold:</p>
<ul>
<li>OLS is biased.</li>
<li>
<a href="linear-regression.html#gauss-markov-theorem">Gauss-Markov Theorem</a> no longer applies.</li>
<li>
<a href="linear-regression.html#finite-sample-properties">Finite Sample Properties</a> (such as unbiasedness) are invalid.</li>
</ul>
<p>To address these issues, we can:</p>
<ol style="list-style-type: decimal">
<li>Rely on <a href="linear-regression.html#large-sample-properties">Large Sample Properties</a>: Under certain conditions, consistency may still hold.</li>
<li>Use Weaker Forms of Exogeneity: Shift from <strong>strict exogeneity</strong> (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>) to <strong>contemporaneous exogeneity</strong> (<a href="linear-regression.html#a3a-weak-exogeneity">A3a</a>).</li>
</ol>
<hr>
<p>If strict exogeneity does not hold, we can instead assume <a href="linear-regression.html#a3a-weak-exogeneity">A3a</a> (Contemporaneous Exogeneity):</p>
<p><span class="math display">\[
E(\mathbf{x}_t' \epsilon_t) = 0
\]</span></p>
<p>This weaker assumption only requires that <span class="math inline">\(x_t\)</span> is uncorrelated with the error in the same time period.</p>
<p><strong>Key Differences from Strict Exogeneity</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="29%">
<col width="44%">
<col width="25%">
</colgroup>
<thead><tr class="header">
<th>Exogeneity Type</th>
<th>Requirement</th>
<th>Allows Dynamic Models?</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Strict Exogeneity</td>
<td><span class="math inline">\(E(\epsilon_t | x_1, x_2, ..., x_T) = 0\)</span></td>
<td><strong>No</strong></td>
</tr>
<tr class="even">
<td>Contemporaneous Exogeneity</td>
<td><span class="math inline">\(E(\mathbf{x}_t' \epsilon_t) = 0\)</span></td>
<td><strong>Yes</strong></td>
</tr>
</tbody>
</table></div>
<ul>
<li><p>With contemporaneous exogeneity, <span class="math inline">\(\epsilon_t\)</span> can be correlated with past and future values of <span class="math inline">\(x_t\)</span>.</p></li>
<li>
<p>This allows for dynamic specifications such as:</p>
<p><span class="math display">\[
y_t = \beta_0 + y_{t-1} \beta_1 + \epsilon_t
\]</span></p>
<p>while still maintaining <strong>consistency</strong> under certain assumptions.</p>
</li>
</ul>
<hr>
<p><strong>Deriving <a href="linear-regression.html#large-sample-properties">Large Sample Properties</a> for <a href="data.html#sec-time-series-data">Time Series</a></strong></p>
<p>To establish <strong>consistency</strong> and <strong>asymptotic normality</strong>, we rely on the following assumptions:</p>
<ul>
<li>
<a href="linear-regression.html#a1-linearity">A1</a>: Linearity</li>
<li>
<a href="linear-regression.html#a2-full-rank">A2</a>: Full Rank (No Perfect Multicollinearity)</li>
<li>
<a href="linear-regression.html#a3a-weak-exogeneity">A3a</a>: Contemporaneous Exogeneity</li>
</ul>
<p>However, the standard <a href="prerequisites.html#weak-law-of-large-numbers">Weak Law of Large Numbers</a> and <a href="prerequisites.html#central-limit-theorem">Central Limit Theorem</a> in OLS depend on <a href="linear-regression.html#a5-data-generation-random-sampling">A5</a> (Random Sampling), which does <strong>not</strong> hold in time series settings.</p>
<p>Since time series data exhibits dependence over time, we replace <a href="linear-regression.html#a5-data-generation-random-sampling">A5</a> (Random Sampling) with a weaker assumption:</p>
<ul>
<li>
<a href="linear-regression.html#A5a-stationarity-and-weak-dependence-in-time-series">A5a</a>: Weak Dependence (Stationarity)</li>
</ul>
<p><strong>Asymptotic Variance and Serial Correlation</strong></p>
<ul>
<li><p>The derivation of <strong>asymptotic variance</strong> depends on <a href="linear-regression.html#a4-homoskedasticity">A4</a> (Homoskedasticity).</p></li>
<li>
<p>However, in time series settings, we often encounter <strong>serial correlation</strong>:</p>
<p><span class="math display">\[
Cov(\epsilon_t, \epsilon_s) \neq 0 \quad \text{for} \quad |t - s| &gt; 0
\]</span></p>
</li>
<li><p>To ensure valid inference, standard errors must be corrected using methods such as <a href="data.html#sec-newey-west-standard-errors">Newey-West HAC</a> estimators.</p></li>
</ul>
<hr>
</div>
<div id="highly-persistent-data" class="section level3" number="11.3.6">
<h3>
<span class="header-section-number">11.3.6</span> Highly Persistent Data<a class="anchor" aria-label="anchor" href="#highly-persistent-data"><i class="fas fa-link"></i></a>
</h3>
<p>In time series analysis, a key assumption for OLS consistency is that the data-generating process exhibits <a href="linear-regression.html#A5a-stationarity-and-weak-dependence-in-time-series">A5a</a> weak dependence (i.e., observations are not too strongly correlated over time). However, when <span class="math inline">\(y_t\)</span> and <span class="math inline">\(x_t\)</span> are highly persistent, standard OLS assumptions break down.</p>
<p>If a time series is <strong>not weakly dependent</strong>, it means:</p>
<ul>
<li>
<span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-h}\)</span> remain strongly correlated even for large lags (<span class="math inline">\(h \to \infty\)</span>).</li>
<li>
<a href="linear-regression.html#A5a-stationarity-and-weak-dependence-in-time-series">A5a</a> (Weak Dependence Assumption) fails, leading to:
<ul>
<li>
<strong>OLS inconsistency</strong>.</li>
<li>
<strong>No valid limiting distribution</strong> (asymptotic normality does not hold).</li>
</ul>
</li>
</ul>
<p><strong>Example:</strong> A classic example of a highly persistent process is a random walk:</p>
<p><span class="math display">\[
y_t = y_{t-1} + u_t
\]</span></p>
<p>or with drift:</p>
<p><span class="math display">\[
y_t = \alpha + y_{t-1} + u_t
\]</span></p>
<p>where <span class="math inline">\(u_t\)</span> is a white noise error term.</p>
<ul>
<li>
<span class="math inline">\(y_t\)</span> does not revert to a mean—it has an infinite variance as <span class="math inline">\(t \to \infty\)</span>.</li>
<li>
<strong>Shocks accumulate</strong>, making standard regression analysis unreliable.</li>
</ul>
<hr>
<div id="solution-first-differencing" class="section level4" number="11.3.6.1">
<h4>
<span class="header-section-number">11.3.6.1</span> Solution: First Differencing<a class="anchor" aria-label="anchor" href="#solution-first-differencing"><i class="fas fa-link"></i></a>
</h4>
<p>A common way to transform non-stationary series into stationary ones is through first differencing:</p>
<p><span class="math display">\[
\Delta y_t = y_t - y_{t-1} = u_t
\]</span></p>
<ul>
<li>If <span class="math inline">\(u_t\)</span> is a weakly dependent process (i.e., <span class="math inline">\(I(0)\)</span>, stationary), then <span class="math inline">\(y_t\)</span> is said to be <strong>difference-stationary</strong> or <strong>integrated of order 1,</strong> <span class="math inline">\(I(1)\)</span>.</li>
<li>If both <span class="math inline">\(y_t\)</span> and <span class="math inline">\(x_t\)</span> follow a random walk (<span class="math inline">\(I(1)\)</span>), we estimate:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\Delta y_t &amp;= (\Delta \mathbf{x}_t \beta) + (\epsilon_t - \epsilon_{t-1}) \\
\Delta y_t &amp;= \Delta \mathbf{x}_t \beta + \Delta u_t
\end{aligned}
\]</span></p>
<p>This ensures <strong>OLS estimation remains valid</strong>.</p>
<hr>
</div>
</div>
<div id="sec-unit-root-testing" class="section level3" number="11.3.7">
<h3>
<span class="header-section-number">11.3.7</span> Unit Root Testing<a class="anchor" aria-label="anchor" href="#sec-unit-root-testing"><i class="fas fa-link"></i></a>
</h3>
<p>To formally determine whether a time series contains a <strong>unit root</strong> (i.e., is non-stationary), we test:</p>
<p><span class="math display">\[
y_t = \alpha + \rho y_{t-1} + u_t
\]</span></p>
<p><strong>Hypothesis Testing</strong></p>
<ul>
<li>
<span class="math inline">\(H_0: \rho = 1\)</span> (unit root, non-stationary)
<ul>
<li>OLS is <strong>not consistent or asymptotically normal</strong>.</li>
</ul>
</li>
<li>
<span class="math inline">\(H_a: \rho &lt; 1\)</span> (stationary process)
<ul>
<li>OLS is <strong>consistent and asymptotically normal</strong>.</li>
</ul>
</li>
</ul>
<p><strong>Key Issues</strong></p>
<ul>
<li>The usual <strong>t-test is not valid</strong> because OLS under <span class="math inline">\(H_0\)</span> does not have a standard distribution.</li>
<li>Instead, specialized tests such as <a href="data.html#sec-dickey-fuller-test-for-unit-roots">Dickey-Fuller</a> and <a href="data.html#sec-augmented-dickey-fuller-test">Augmented Dickey-Fuller</a> tests are required.</li>
</ul>
<hr>
<div id="sec-dickey-fuller-test-for-unit-roots" class="section level4" number="11.3.7.1">
<h4>
<span class="header-section-number">11.3.7.1</span> Dickey-Fuller Test for Unit Roots<a class="anchor" aria-label="anchor" href="#sec-dickey-fuller-test-for-unit-roots"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>Dickey-Fuller test</strong> transforms the original equation by subtracting <span class="math inline">\(y_{t-1}\)</span> from both sides:</p>
<p><span class="math display">\[
\Delta y_t = \alpha + \theta y_{t-1} + v_t
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\theta = \rho - 1
\]</span></p>
<ul>
<li>
<strong>Null Hypothesis</strong> (<span class="math inline">\(H_0: \theta = 0\)</span>) → Implies <span class="math inline">\(\rho = 1\)</span> (unit root, non-stationary).</li>
<li>
<strong>Alternative</strong> (<span class="math inline">\(H_a: \theta &lt; 0\)</span>) → Implies <span class="math inline">\(\rho &lt; 1\)</span> (stationary).</li>
</ul>
<p>Since <span class="math inline">\(y_t\)</span> follows a non-standard asymptotic distribution under <span class="math inline">\(H_0\)</span>, Dickey and Fuller derived specialized critical values.</p>
<p><strong>Decision Rule</strong></p>
<ul>
<li>If the test statistic is more negative than the critical value, reject <span class="math inline">\(H_0\)</span> → <span class="math inline">\(y_t\)</span> is stationary.</li>
<li>Otherwise, fail to reject <span class="math inline">\(H_0\)</span> → <span class="math inline">\(y_t\)</span> has a unit root (non-stationary).</li>
</ul>
<hr>
<p>The standard <a href="data.html#sec-dickey-fuller-test-for-unit-roots">DF</a> test may fail due to two key limitations:</p>
<ol style="list-style-type: decimal">
<li><strong>Simplistic Dynamic Relationship</strong></li>
</ol>
<ul>
<li>The DF test assumes only one lag in the autoregressive structure.</li>
<li>However, in reality, higher-order lags of <span class="math inline">\(\Delta y_t\)</span> may be needed.</li>
</ul>
<p><strong>Solution:</strong><br>
Use the <a href="data.html#sec-augmented-dickey-fuller-test">Augmented Dickey-Fuller</a> test, which includes extra lags:</p>
<p><span class="math display">\[
\Delta y_t = \alpha + \theta y_{t-1} + \gamma_1 \Delta y_{t-1} + \dots + \gamma_p \Delta y_{t-p} + v_t
\]</span></p>
<ul>
<li>Under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(\Delta y_t\)</span> follows an AR(1) process.</li>
<li>Under <span class="math inline">\(H_a\)</span>, <span class="math inline">\(y_t\)</span> follows an AR(2) or higher process.</li>
</ul>
<p>Including lags of <span class="math inline">\(\Delta y_t\)</span> ensures a better-specified model.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Ignoring Deterministic Time Trends</strong></li>
</ol>
<p>If a series exhibits a deterministic trend, failing to include it biases the unit root test.</p>
<p><strong>Example:</strong> If <span class="math inline">\(y_t\)</span> grows over time, a test without a trend component will falsely detect a unit root.</p>
<p><strong>Solution:</strong> Include a deterministic time trend (<span class="math inline">\(t\)</span>) in the regression:</p>
<p><span class="math display">\[
\Delta y_t = \alpha + \theta y_{t-1} + \delta t + v_t
\]</span></p>
<ul>
<li>Allows for quadratic relationships with time.</li>
<li>Changes the critical values, requiring an adjusted statistical test.</li>
</ul>
<hr>
</div>
<div id="sec-augmented-dickey-fuller-test" class="section level4" number="11.3.7.2">
<h4>
<span class="header-section-number">11.3.7.2</span> Augmented Dickey-Fuller Test<a class="anchor" aria-label="anchor" href="#sec-augmented-dickey-fuller-test"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>ADF test</strong> generalizes the DF test by allowing for:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Lags of</strong> <span class="math inline">\(\Delta y_t\)</span> (to correct for serial correlation).</li>
<li>
<strong>Time trends</strong> (to handle deterministic trends).</li>
</ol>
<p><strong>Regression Equation</strong></p>
<p><span class="math display">\[
\Delta y_t = \alpha + \theta y_{t-1} + \delta t + \gamma_1 \Delta y_{t-1} + \dots + \gamma_p \Delta y_{t-p} + v_t
\]</span></p>
<p>where <span class="math inline">\(\theta = 1 - \rho\)</span>.</p>
<p><strong>Hypotheses</strong></p>
<ul>
<li>
<span class="math inline">\(H_0: \theta = 0\)</span> (Unit root: non-stationary)</li>
<li>
<span class="math inline">\(H_a: \theta &lt; 0\)</span> (Stationary)</li>
</ul>
<hr>
</div>
</div>
<div id="sec-newey-west-standard-errors" class="section level3" number="11.3.8">
<h3>
<span class="header-section-number">11.3.8</span> Newey-West Standard Errors<a class="anchor" aria-label="anchor" href="#sec-newey-west-standard-errors"><i class="fas fa-link"></i></a>
</h3>
<p>Newey-West standard errors, also known as <strong>Heteroskedasticity and Autocorrelation Consistent (HAC) estimators</strong>, provide valid inference when errors exhibit both heteroskedasticity (i.e., <a href="linear-regression.html#a4-homoskedasticity">A4</a> Homoskedasticity assumption is violated) and serial correlation. These standard errors adjust for dependence in the error structure, ensuring that hypothesis tests remain valid.</p>
<p><strong>Key Features</strong></p>
<ul>
<li>
<strong>Accounts for autocorrelation</strong>: Handles time dependence in error terms.</li>
<li>
<strong>Accounts for heteroskedasticity</strong>: Allows for non-constant variance across observations.</li>
<li>
<strong>Ensures positive semi-definiteness</strong>: Downweights longer-lagged covariances to maintain mathematical validity.</li>
</ul>
<p>The estimator is computed as:</p>
<p><span class="math display">\[
\hat{B} = T^{-1} \sum_{t=1}^{T} e_t^2 \mathbf{x'_t x_t} + \sum_{h=1}^{g} \left(1 - \frac{h}{g+1} \right) T^{-1} \sum_{t=h+1}^{T} e_t e_{t-h} (\mathbf{x_t' x_{t-h}} + \mathbf{x_{t-h}' x_t})
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(T\)</span> is the sample size,</li>
<li>
<span class="math inline">\(g\)</span> is the chosen <strong>lag truncation parameter</strong> (bandwidth),</li>
<li>
<span class="math inline">\(e_t\)</span> are the residuals from the OLS regression,</li>
<li>
<span class="math inline">\(\mathbf{x}_t\)</span> are the explanatory variables.</li>
</ul>
<hr>
<p><strong>Choosing the Lag Length</strong> (<span class="math inline">\(g\)</span>)</p>
<p>Selecting an appropriate lag truncation parameter (<span class="math inline">\(g\)</span>) is crucial for balancing <strong>efficiency</strong> and <strong>bias</strong>. Common guidelines include:</p>
<ul>
<li>
<strong>Yearly data</strong>: <span class="math inline">\(g = 1\)</span> or <span class="math inline">\(2\)</span> usually suffices.</li>
<li>
<strong>Quarterly data</strong>: <span class="math inline">\(g = 4\)</span> or <span class="math inline">\(8\)</span> accounts for seasonal dependencies.</li>
<li>
<strong>Monthly data</strong>: <span class="math inline">\(g = 12\)</span> or <span class="math inline">\(14\)</span> captures typical cyclical effects.</li>
</ul>
<p>Alternatively, data-driven methods can be used:</p>
<ul>
<li><p><strong>Newey-West Rule</strong>: <span class="math inline">\(g = \lfloor 4(T/100)^{2/9} \rfloor\)</span></p></li>
<li><p><strong>Alternative Heuristic</strong>: <span class="math inline">\(g = \lfloor T^{1/4} \rfloor\)</span></p></li>
</ul>
<div class="sourceCode" id="cb419"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://sandwich.R-Forge.R-project.org/">sandwich</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">lmtest</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="cn">T</span> <span class="op">&lt;-</span> <span class="fl">100</span>  <span class="co"># Sample size</span></span>
<span><span class="va">time</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="cn">T</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="cn">T</span><span class="op">)</span></span>
<span><span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.sim.html">arima.sim</a></span><span class="op">(</span>n <span class="op">=</span> <span class="cn">T</span>, <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>ar <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Autocorrelated errors</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">+</span> <span class="fl">3</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span>  <span class="co"># True model</span></span>
<span></span>
<span><span class="co"># Estimate OLS model</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Newey-West standard errors</span></span>
<span><span class="va">lag_length</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">floor</a></span><span class="op">(</span><span class="fl">4</span> <span class="op">*</span> <span class="op">(</span><span class="cn">T</span> <span class="op">/</span> <span class="fl">100</span><span class="op">)</span> <span class="op">^</span> <span class="op">(</span><span class="fl">2</span> <span class="op">/</span> <span class="fl">9</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Newey-West rule</span></span>
<span><span class="va">nw_se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/NeweyWest.html">NeweyWest</a></span><span class="op">(</span><span class="va">model</span>, lag <span class="op">=</span> <span class="va">lag_length</span>, prewhite <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display robust standard errors</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">model</span>, vcov <span class="op">=</span> <span class="va">nw_se</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  1.71372    0.13189  12.993 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; x            3.15831    0.13402  23.567 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<hr>
<div id="testing-for-serial-correlation" class="section level4" number="11.3.8.1">
<h4>
<span class="header-section-number">11.3.8.1</span> Testing for Serial Correlation<a class="anchor" aria-label="anchor" href="#testing-for-serial-correlation"><i class="fas fa-link"></i></a>
</h4>
<p>Serial correlation (also known as <strong>autocorrelation</strong>) occurs when error terms are correlated across time:</p>
<p><span class="math display">\[
E(\epsilon_t \epsilon_{t-h}) \neq 0 \quad \text{for some } h \neq 0
\]</span></p>
<p><strong>Steps for Detecting Serial Correlation</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Estimate an OLS regression</strong>:
<ul>
<li>Run the regression of <span class="math inline">\(y_t\)</span> on <span class="math inline">\(\mathbf{x}_t\)</span> and obtain residuals <span class="math inline">\(e_t\)</span>.</li>
</ul>
</li>
<li>
<strong>Test for autocorrelation in residuals</strong>:
<ul>
<li>
<p>Regress <span class="math inline">\(e_t\)</span> on <span class="math inline">\(\mathbf{x}_t\)</span> and its lagged residual <span class="math inline">\(e_{t-1}\)</span>:</p>
<p><span class="math display">\[
e_t = \gamma_0 + \mathbf{x}_t' \gamma + \rho e_{t-1} + v_t
\]</span></p>
</li>
<li><p>Test whether <span class="math inline">\(\rho\)</span> is significantly different from zero.</p></li>
</ul>
</li>
<li>
<strong>Decision Rule</strong>:
<ul>
<li>If <span class="math inline">\(\rho\)</span> is statistically significant at the 5% level, reject the null hypothesis of no serial correlation.</li>
</ul>
</li>
</ol>
<p><strong>Higher-Order Serial Correlation</strong></p>
<p>To test for <strong>higher-order autocorrelation</strong>, extend the previous regression:</p>
<p><span class="math display">\[
e_t = \gamma_0 + \mathbf{x}_t' \gamma + \rho_1 e_{t-1} + \rho_2 e_{t-2} + \dots + \rho_p e_{t-p} + v_t
\]</span></p>
<ul>
<li>
<strong>Jointly test</strong> <span class="math inline">\(\rho_1 = \rho_2 = \dots = \rho_p = 0\)</span> using an <strong>F-test</strong>.</li>
<li>If the null is rejected, autocorrelation of order <span class="math inline">\(p\)</span> is present.</li>
</ul>
<p>Step 1: Estimate an OLS Regression and Obtain Residuals</p>
<div class="sourceCode" id="cb420"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">lmtest</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://sandwich.R-Forge.R-project.org/">sandwich</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate some example data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>  <span class="co"># True model: y = 1 + 0.5*x + e</span></span>
<span></span>
<span><span class="co"># Estimate the OLS regression</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Obtain residuals</span></span>
<span><span class="va">residuals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span></code></pre></div>
<p>Step 2: Test for Autocorrelation in Residuals</p>
<div class="sourceCode" id="cb421"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create lagged residuals</span></span>
<span><span class="va">lagged_residuals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">residuals</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">residuals</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Regress residuals on x and lagged residuals</span></span>
<span><span class="va">autocorr_test_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">residuals</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">lagged_residuals</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summary of the regression</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">autocorr_test_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = residuals ~ x + lagged_residuals)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -1.94809 -0.72539 -0.08105  0.58503  3.12941 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)       0.008175   0.098112   0.083    0.934</span></span>
<span><span class="co">#&gt; x                -0.002841   0.107167  -0.027    0.979</span></span>
<span><span class="co">#&gt; lagged_residuals -0.127605   0.101746  -1.254    0.213</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 0.9707 on 96 degrees of freedom</span></span>
<span><span class="co">#&gt;   (1 observation deleted due to missingness)</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.01614,    Adjusted R-squared:  -0.004354 </span></span>
<span><span class="co">#&gt; F-statistic: 0.7876 on 2 and 96 DF,  p-value: 0.4579</span></span>
<span></span>
<span><span class="co"># Test if the coefficient of lagged_residuals is significant</span></span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">autocorr_test_model</span><span class="op">)</span><span class="op">[</span><span class="st">"lagged_residuals"</span><span class="op">]</span></span>
<span><span class="va">rho_p_value</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">autocorr_test_model</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="st">"lagged_residuals"</span>, <span class="st">"Pr(&gt;|t|)"</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Decision Rule</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="va">rho_p_value</span> <span class="op">&lt;</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Reject the null hypothesis: There is evidence of serial correlation.\n"</span><span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Fail to reject the null hypothesis: No evidence of serial correlation.\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co">#&gt; Fail to reject the null hypothesis: No evidence of serial correlation.</span></span></code></pre></div>
<p>Step 3: Testing for Higher-Order Serial Correlation</p>
<div class="sourceCode" id="cb422"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Number of lags to test</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">2</span>  <span class="co"># Example: testing for 2nd order autocorrelation</span></span>
<span></span>
<span><span class="co"># Create a matrix of lagged residuals</span></span>
<span><span class="va">lagged_residuals_matrix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">p</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">i</span><span class="op">)</span>, <span class="va">residuals</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">i</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Regress residuals on x and lagged residuals</span></span>
<span><span class="va">higher_order_autocorr_test_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">residuals</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">lagged_residuals_matrix</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summary of the regression</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">higher_order_autocorr_test_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = residuals ~ x + lagged_residuals_matrix)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1.9401 -0.7290 -0.1036  0.6359  3.0253 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                           Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)               0.006263   0.099104   0.063    0.950</span></span>
<span><span class="co">#&gt; x                         0.010442   0.108370   0.096    0.923</span></span>
<span><span class="co">#&gt; lagged_residuals_matrix1 -0.140426   0.103419  -1.358    0.178</span></span>
<span><span class="co">#&gt; lagged_residuals_matrix2 -0.107385   0.103922  -1.033    0.304</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 0.975 on 94 degrees of freedom</span></span>
<span><span class="co">#&gt;   (2 observations deleted due to missingness)</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.02667,    Adjusted R-squared:  -0.004391 </span></span>
<span><span class="co">#&gt; F-statistic: 0.8587 on 3 and 94 DF,  p-value: 0.4655</span></span>
<span></span>
<span><span class="co"># Joint F-test for the significance of lagged residuals</span></span>
<span><span class="va">f_test</span> <span class="op">&lt;-</span> <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">higher_order_autocorr_test_model</span>, </span>
<span>                           <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"lagged_residuals_matrix"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">p</span>, <span class="st">" = 0"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Print the F-test results</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">f_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Linear hypothesis test:</span></span>
<span><span class="co">#&gt; lagged_residuals_matrix1 = 0</span></span>
<span><span class="co">#&gt; lagged_residuals_matrix2 = 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 1: restricted model</span></span>
<span><span class="co">#&gt; Model 2: residuals ~ x + lagged_residuals_matrix</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)</span></span>
<span><span class="co">#&gt; 1     96 91.816                           </span></span>
<span><span class="co">#&gt; 2     94 89.368  2    2.4479 1.2874 0.2808</span></span>
<span></span>
<span><span class="co"># Decision Rule</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="va">f_test</span><span class="op">$</span><span class="va">`Pr(&gt;F)`</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">&lt;</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Reject the null hypothesis: There is evidence of higher-order serial correlation.\n"</span><span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Fail to reject the null hypothesis: No evidence of higher-order serial correlation.\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co">#&gt; Fail to reject the null hypothesis: No evidence of higher-order serial correlation.</span></span></code></pre></div>
<hr>
<p><strong>Corrections for Serial Correlation</strong></p>
<p>If serial correlation is detected, the following adjustments should be made:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="25%">
<col width="74%">
</colgroup>
<thead><tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Solution</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Mild serial correlation</strong></td>
<td>Use <a href="data.html#sec-newey-west-standard-errors">Newey-West standard errors</a>
</td>
</tr>
<tr class="even">
<td><strong>Severe serial correlation</strong></td>
<td>Use <a href="linear-regression.html#generalized-least-squares">Generalized Least Squares</a> or Prais-Winsten transformation</td>
</tr>
<tr class="odd">
<td><strong>Autoregressive structure in errors</strong></td>
<td>Model as an <strong>ARMA</strong> process</td>
</tr>
<tr class="even">
<td><strong>Higher-order serial correlation</strong></td>
<td>Include lags of dependent variable or use <a href="data.html#sec-newey-west-standard-errors">HAC</a> estimators with higher lag orders</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
</div>
</div>
<div id="sec-repeated-cross-sectional-data" class="section level2" number="11.4">
<h2>
<span class="header-section-number">11.4</span> Repeated Cross-Sectional Data<a class="anchor" aria-label="anchor" href="#sec-repeated-cross-sectional-data"><i class="fas fa-link"></i></a>
</h2>
<p>Repeated cross-sectional data consists of <strong>multiple independent cross-sections</strong> collected at different points in time. Unlike panel data, where the same individuals are tracked over time, repeated cross-sections <strong>draw a fresh sample in each wave</strong>.</p>
<p>This approach allows researchers to analyze <strong>aggregate trends over time</strong>, but it does <strong>not track individual-level changes</strong>.</p>
<p><strong>Examples</strong></p>
<ul>
<li>
<strong>General Social Survey (GSS) (U.S.)</strong> – Conducted every two years with a new sample of respondents.</li>
<li>
<strong>Political Opinion Polls</strong> – Monthly voter surveys to track shifts in public sentiment.</li>
<li>
<strong>National Health Surveys</strong> – Annual studies with fresh samples to monitor <strong>population-wide</strong> health trends.</li>
<li>
<strong>Educational Surveys</strong> – Sampling different groups of students each year to assess learning outcomes.</li>
</ul>
<hr>
<div id="key-characteristics" class="section level3" number="11.4.1">
<h3>
<span class="header-section-number">11.4.1</span> Key Characteristics<a class="anchor" aria-label="anchor" href="#key-characteristics"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>
<strong>Fresh Sample in Each Wave</strong>
<ul>
<li>Each survey represents an <strong>independent</strong> cross-section.</li>
<li>No respondent is tracked across waves.</li>
</ul>
</li>
<li>
<strong>Population-Level Trends Over Time</strong>
<ul>
<li>Researchers can study <strong>how the distribution of characteristics (e.g., income, attitudes, behaviors) changes over time</strong>.</li>
<li>However, individual trajectories <strong>cannot</strong> be observed.</li>
</ul>
</li>
<li>
<strong>Sample Design Consistency</strong>
<ul>
<li>To ensure comparability across waves, researchers must maintain <strong>consistent</strong>:
<ul>
<li>Sampling methods</li>
<li>Questionnaire design</li>
<li>Definitions of key variables</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="statistical-modeling-for-repeated-cross-sections" class="section level3" number="11.4.2">
<h3>
<span class="header-section-number">11.4.2</span> Statistical Modeling for Repeated Cross-Sections<a class="anchor" aria-label="anchor" href="#statistical-modeling-for-repeated-cross-sections"><i class="fas fa-link"></i></a>
</h3>
<p>Since repeated cross-sections do not track the same individuals, specific regression methods are used to <strong>analyze changes over time</strong>.</p>
<ol style="list-style-type: decimal">
<li><strong>Pooled Cross-Sectional Regression (Time Fixed Effects)</strong></li>
</ol>
<p>Combines multiple survey waves into a single dataset while controlling for time effects:</p>
<p><span class="math display">\[
y_i = \mathbf{x}_i \beta + \delta_1 y_1 + ... + \delta_T y_T + \epsilon_i
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(y_i\)</span> is the outcome for individual <span class="math inline">\(i\)</span>,</p></li>
<li><p><span class="math inline">\(\mathbf{x}_i\)</span> are explanatory variables,</p></li>
<li><p><span class="math inline">\(y_t\)</span> are time period dummies,</p></li>
<li><p><span class="math inline">\(\delta_t\)</span> captures the <strong>average change</strong> in outcomes across time periods.</p></li>
</ul>
<p><strong>Key Features:</strong></p>
<ul>
<li><p>Allows for different intercepts across time periods, capturing shifts in baseline outcomes.</p></li>
<li><p>Tracks overall population trends without assuming a constant effect of <span class="math inline">\(\mathbf{x}_i\)</span> over time.</p></li>
</ul>
<hr>
<ol start="2" style="list-style-type: decimal">
<li><strong>Allowing for Structural Change in Pooled Cross-Sections (Time-Dependent Effects)</strong></li>
</ol>
<p>To test whether relationships between variables change over time (<strong>structural breaks</strong>), interactions between time dummies and explanatory variables can be introduced:</p>
<p><span class="math display">\[
y_i = \mathbf{x}_i \beta + \mathbf{x}_i y_1 \gamma_1 + ... + \mathbf{x}_i y_T \gamma_T + \delta_1 y_1 + ...+ \delta_T y_T + \epsilon_i
\]</span></p>
<ul>
<li>
<strong>Interacting</strong> <span class="math inline">\(x_i\)</span> with time period dummies allows for:
<ul>
<li>
<strong>Different slopes</strong> for each time period.</li>
<li>
<strong>Time-dependent effects</strong> of explanatory variables.</li>
</ul>
</li>
</ul>
<p><strong>Practical Application:</strong></p>
<ul>
<li><p>If <span class="math inline">\(\mathbf{x}_i\)</span> represents education level and <span class="math inline">\(y_t\)</span> represents survey year, an interaction term can test whether the effect of education on income has changed over time.</p></li>
<li><p>Structural break tests help determine whether such time-varying effects are statistically significant.</p></li>
<li><p>Useful for <strong>policy analysis</strong>, where a policy might impact certain subgroups differently across time.</p></li>
</ul>
<hr>
<ol start="3" style="list-style-type: decimal">
<li><strong>Difference-in-Means Over Time</strong></li>
</ol>
<p>A simple approach to comparing <strong>aggregate trends</strong>:</p>
<p><span class="math display">\[ \bar{y}_t - \bar{y}_{t-1} \]</span></p>
<ul>
<li>Measures whether the average outcome has changed over time.</li>
<li>Common in policy evaluations (e.g., assessing the effect of minimum wage increases on average income).</li>
</ul>
<hr>
<ol start="4" style="list-style-type: decimal">
<li><strong>Synthetic Cohort Analysis</strong></li>
</ol>
<p>Since repeated cross-sections do not track individuals, a <strong>synthetic cohort</strong> can be created by grouping observations based on shared characteristics:</p>
<ul>
<li>Example: If education levels are collected over multiple waves, we can track <strong>average income changes</strong> within education groups to approximate trends.</li>
</ul>
<hr>
</div>
<div id="advantages-of-repeated-cross-sectional-data" class="section level3" number="11.4.3">
<h3>
<span class="header-section-number">11.4.3</span> Advantages of Repeated Cross-Sectional Data<a class="anchor" aria-label="anchor" href="#advantages-of-repeated-cross-sectional-data"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="21%">
<col width="78%">
</colgroup>
<thead><tr class="header">
<th><strong>Advantage</strong></th>
<th><strong>Explanation</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Tracks population trends</strong></td>
<td>Useful for studying shifts in demographics, attitudes, and economic conditions over time.</td>
</tr>
<tr class="even">
<td><strong>Lower cost than panel data</strong></td>
<td>Tracking individuals across multiple waves (as in panel studies) is expensive and prone to attrition.</td>
</tr>
<tr class="odd">
<td><strong>No attrition bias</strong></td>
<td>Unlike panel surveys, where respondents drop out over time, each wave draws a new representative sample.</td>
</tr>
<tr class="even">
<td><strong>Easier implementation</strong></td>
<td>Organizations can design a single survey protocol and repeat it at set intervals without managing panel retention.</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
<div id="disadvantages-of-repeated-cross-sectional-data" class="section level3" number="11.4.4">
<h3>
<span class="header-section-number">11.4.4</span> Disadvantages of Repeated Cross-Sectional Data<a class="anchor" aria-label="anchor" href="#disadvantages-of-repeated-cross-sectional-data"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="22%">
<col width="77%">
</colgroup>
<thead><tr class="header">
<th><strong>Disadvantage</strong></th>
<th><strong>Explanation</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>No individual-level transitions</strong></td>
<td>Cannot track <strong>how specific individuals change</strong> over time (e.g., income mobility, changes in attitudes).</td>
</tr>
<tr class="even">
<td><strong>Limited causal inference</strong></td>
<td>Since we observe different people in each wave, we cannot directly infer individual <strong>cause-and-effect</strong> relationships.</td>
</tr>
<tr class="odd">
<td><strong>Comparability issues</strong></td>
<td>Small differences in survey design (e.g., question wording or sampling frame) can make it difficult to compare across waves.</td>
</tr>
</tbody>
</table></div>
<hr>
<p>To ensure valid comparisons across time:</p>
<ul>
<li>
<strong>Consistent Sampling</strong>: Each wave should use the same <strong>sampling frame and methodology</strong>.</li>
<li>
<strong>Standardized Questions</strong>: Small variations in <strong>question wording</strong> can introduce inconsistencies.</li>
<li>
<strong>Weighting Adjustments</strong>: If sampling strategies change, apply <strong>survey weights</strong> to maintain representativeness.</li>
<li>
<strong>Accounting for Structural Changes</strong>: Economic, demographic, or social changes may impact comparability.</li>
</ul>
<hr>
</div>
</div>
<div id="sec-panel-data" class="section level2" number="11.5">
<h2>
<span class="header-section-number">11.5</span> Panel Data<a class="anchor" aria-label="anchor" href="#sec-panel-data"><i class="fas fa-link"></i></a>
</h2>
<p>Panel data (also called <strong>longitudinal data</strong>) consists of <strong>observations of the same entities over multiple time periods</strong>. Unlike repeated cross-sections, where new samples are drawn in each wave, panel data <strong>tracks the same individuals, households, firms, or regions over time</strong>, enabling richer statistical analysis.</p>
<p>Panel data combines <strong>cross-sectional variation (differences across entities)</strong> and <strong>time-series variation (changes within entities over time)</strong>.</p>
<p><strong>Examples</strong></p>
<ul>
<li>
<strong>Panel Study of Income Dynamics</strong> – Follows households annually, collecting data on income, employment, and expenditures.</li>
<li>
<strong>Medical Longitudinal Studies</strong> – Tracks the same patients over months or years to study disease progression.</li>
<li>
<strong>Firm-Level Financial Data</strong> – Follows a set of companies over multiple years through financial statements.</li>
<li>
<strong>Student Achievement Studies</strong> – Follows the same students across different grade levels to assess academic progress.</li>
</ul>
<hr>
<p><strong>Structure</strong></p>
<ul>
<li>
<span class="math inline">\(N\)</span> entities (individuals, firms, etc.) observed over <span class="math inline">\(T\)</span> time periods.</li>
<li>The dataset can be:
<ul>
<li>
<strong>Balanced Panel</strong>: All entities are observed in every time period.</li>
<li>
<strong>Unbalanced Panel</strong>: Some entities have missing observations for certain periods.</li>
</ul>
</li>
</ul>
<p><strong>Types of Panels</strong></p>
<ul>
<li>
<strong>Short Panel</strong>: Many individuals (<span class="math inline">\(N\)</span>) but few time periods (<span class="math inline">\(T\)</span>).</li>
<li>
<strong>Long Panel</strong>: Many time periods (<span class="math inline">\(T\)</span>) but few individuals (<span class="math inline">\(N\)</span>).</li>
<li>
<strong>Both Large</strong>: Large <span class="math inline">\(N\)</span> and <span class="math inline">\(T\)</span> (e.g., firm-level data over decades).</li>
</ul>
<hr>
<div id="advantages-of-panel-data" class="section level3" number="11.5.1">
<h3>
<span class="header-section-number">11.5.1</span> Advantages of Panel Data<a class="anchor" aria-label="anchor" href="#advantages-of-panel-data"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="37%">
<col width="62%">
</colgroup>
<thead><tr class="header">
<th><strong>Advantage</strong></th>
<th><strong>Explanation</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Captures individual trajectories</strong></td>
<td>Allows for studying how individuals or firms evolve over time.</td>
</tr>
<tr class="even">
<td><strong>Controls for unobserved heterogeneity</strong></td>
<td>Fixed effects models remove time-invariant individual characteristics.</td>
</tr>
<tr class="odd">
<td><strong>Stronger causal inference</strong></td>
<td>Difference-in-differences and FE models improve causal interpretation.</td>
</tr>
<tr class="even">
<td><strong>More efficient estimates</strong></td>
<td>Exploits both cross-sectional and time-series variation.</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
<div id="disadvantages-of-panel-data" class="section level3" number="11.5.2">
<h3>
<span class="header-section-number">11.5.2</span> Disadvantages of Panel Data<a class="anchor" aria-label="anchor" href="#disadvantages-of-panel-data"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="30%">
<col width="69%">
</colgroup>
<thead><tr class="header">
<th><strong>Disadvantage</strong></th>
<th><strong>Explanation</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Higher cost and complexity</strong></td>
<td>Tracking individuals over time is resource-intensive.</td>
</tr>
<tr class="even">
<td><strong>Attrition bias</strong></td>
<td>If certain individuals drop out systematically, results may be biased.</td>
</tr>
<tr class="odd">
<td><strong>Measurement errors</strong></td>
<td>Errors accumulate over time, leading to potential biases.</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
<div id="sources-of-variation-in-panel-data" class="section level3" number="11.5.3">
<h3>
<span class="header-section-number">11.5.3</span> Sources of Variation in Panel Data<a class="anchor" aria-label="anchor" href="#sources-of-variation-in-panel-data"><i class="fas fa-link"></i></a>
</h3>
<p>Since we observe <strong>both individuals and time periods</strong>, we distinguish three types of variation:</p>
<ul>
<li>
<strong>Overall variation</strong>: Differences across both time and individuals.</li>
<li>
<strong>Between variation</strong>: Differences <strong>between</strong> individuals (cross-sectional variation).</li>
<li>
<strong>Within variation</strong>: Differences <strong>within</strong> individuals (time variation).</li>
</ul>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="22%">
<col width="77%">
</colgroup>
<thead><tr class="header">
<th><strong>Estimate</strong></th>
<th><strong>Formula</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Individual mean</td>
<td><span class="math inline">\(\bar{x}_i = \frac{1}{T} \sum_t x_{it}\)</span></td>
</tr>
<tr class="even">
<td>Overall mean</td>
<td><span class="math inline">\(\bar{x} = \frac{1}{NT} \sum_i \sum_t x_{it}\)</span></td>
</tr>
<tr class="odd">
<td>Overall variance</td>
<td><span class="math inline">\(s_O^2 = \frac{1}{NT-1} \sum_i \sum_t (x_{it} - \bar{x})^2\)</span></td>
</tr>
<tr class="even">
<td>Between variance</td>
<td><span class="math inline">\(s_B^2 = \frac{1}{N-1} \sum_i (\bar{x}_i - \bar{x})^2\)</span></td>
</tr>
<tr class="odd">
<td>Within variance</td>
<td><span class="math inline">\(s_W^2 = \frac{1}{NT-1} \sum_i \sum_t (x_{it} - \bar{x}_i)^2\)</span></td>
</tr>
</tbody>
</table></div>
<p><strong>Note:</strong> <span class="math inline">\(s_O^2 \approx s_B^2 + s_W^2\)</span></p>
<hr>
</div>
<div id="sec-pooled-ols-estimator" class="section level3" number="11.5.4">
<h3>
<span class="header-section-number">11.5.4</span> Pooled OLS Estimator<a class="anchor" aria-label="anchor" href="#sec-pooled-ols-estimator"><i class="fas fa-link"></i></a>
</h3>
<p>The Pooled Ordinary Least Squares estimator is the simplest way to estimate relationships in <a href="data.html#sec-panel-data">panel data</a>. It treats panel data as a <strong>large cross-sectional dataset</strong>, ignoring individual-specific effects and time dependence.</p>
<p>The pooled OLS model is specified as:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + \epsilon_{it}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(y_{it}\)</span> is the dependent variable for individual <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>,</p></li>
<li><p><span class="math inline">\(\mathbf{x}_{it}\)</span> is a vector of explanatory variables,</p></li>
<li><p><span class="math inline">\(\beta\)</span> is the vector of coefficients to be estimated,</p></li>
<li>
<p><span class="math inline">\(\epsilon_{it} = c_i + u_{it}\)</span> is the composite error term.</p>
<ul>
<li><p><span class="math inline">\(c_i\)</span> is the unobserved individual heterogeneity.</p></li>
<li><p><span class="math inline">\(u_{it}\)</span> is the idiosyncratic shock.</p></li>
</ul>
</li>
</ul>
<p>By treating all observations as <strong>independent</strong>, pooled OLS <strong>assumes no systematic differences across individuals</strong> beyond what is captured by <span class="math inline">\(\mathbf{x}_{it}\)</span>.</p>
<hr>
<p>For <strong>pooled OLS</strong> to be <strong>consistent and unbiased</strong>, the following conditions must hold:</p>
<ol style="list-style-type: decimal">
<li>Linearity in Parameters (<a href="linear-regression.html#a1-linearity">A1</a>)
<ul>
<li>The relationship between <span class="math inline">\(y_{it}\)</span> and <span class="math inline">\(\mathbf{x}_{it}\)</span> is correctly specified as linear.</li>
</ul>
</li>
<li>Full Rank Condition (<a href="linear-regression.html#a2-full-rank">A2</a>)
<ul>
<li>The regressors are not perfectly collinear across individuals and time.</li>
</ul>
</li>
<li>Strict Exogeneity (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>)
<ul>
<li>No correlation between regressors and error terms: <span class="math display">\[
E(\epsilon_{it} | \mathbf{x}_{it}) = 0
\]</span>
</li>
<li>This ensures that OLS remains unbiased.</li>
</ul>
</li>
<li>Homoskedasticity (<a href="linear-regression.html#a4-homoskedasticity">A4</a>)
<ul>
<li>Constant variance of errors: <span class="math display">\[
Var(\epsilon_{it} | \mathbf{x}_{it}) = \sigma^2
\]</span>
</li>
<li>If violated (heteroskedasticity exists), standard errors must be adjusted using clustered robust approach, but OLS is still consistent.</li>
</ul>
</li>
<li>No Autocorrelation Across Time (<a href="linear-regression.html#a5-data-generation-random-sampling">A5</a>)
<ul>
<li>The error term should not be correlated over time for a given individual: <span class="math display">\[
E(\epsilon_{it}, \epsilon_{is}) = 0, \quad \forall t \neq s
\]</span>
</li>
<li>If this assumption fails, clustered standard errors are needed.</li>
</ul>
</li>
<li>Random Sampling (<a href="linear-regression.html#a6-normal-distribution">A6</a>)
<ul>
<li>Observations are independent across individuals: <span class="math display">\[
(y_{i1},..., y_{iT}, x_{i1},..., x_{iT}) \perp (y_{j1},..., y_{jT}, x_{j1},..., x_{jT}) \quad \forall i \neq j
\]</span>
</li>
<li>This assumption is often reasonable but not always valid (e.g., in firm-level or country-level panel data).</li>
</ul>
</li>
</ol>
<hr>
<p>For <strong>pooled OLS to be consistent</strong>, we require <a href="linear-regression.html#a3a-weak-exogeneity">A3a</a>:</p>
<p><span class="math display">\[
E(\mathbf{x}_{it}'(c_i + u_{it})) = 0
\]</span></p>
<p>which holds if and only if:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Exogeneity of</strong> <span class="math inline">\(u_{it}\)</span> (Time-varying error):<br><span class="math display">\[
E(\mathbf{x}_{it}' u_{it}) = 0
\]</span>
<ul>
<li>Ensures that regressors are <strong>not correlated</strong> with the random error component.</li>
</ul>
</li>
<li>
<strong>Random Effects Assumption</strong> (Time-invariant error):<br><span class="math display">\[
E(\mathbf{x}_{it}' c_i) = 0
\]</span>
<ul>
<li>Ensures that <strong>unobserved heterogeneity (</strong><span class="math inline">\(c_i\)</span>) is uncorrelated with regressors. If this assumption fails, pooled OLS suffers from <strong>omitted variable bias</strong>.</li>
</ul>
</li>
</ol>
<p><strong>Implication</strong>:</p>
<ul>
<li><p>If <span class="math inline">\(c_i\)</span> is correlated with <span class="math inline">\(\mathbf{x}_{it}\)</span>, pooled OLS is <strong>biased and inconsistent</strong>.</p></li>
<li><p>If <span class="math inline">\(c_i\)</span> is uncorrelated with <span class="math inline">\(\mathbf{x}_{it}\)</span>, pooled OLS is <strong>consistent but inefficient</strong>.</p></li>
</ul>
<hr>
<p><strong>Variance Decomposition in Panel Data</strong></p>
<p>Since panel data contains both <strong>between-entity</strong> and <strong>within-entity</strong> variation, the total variance can be decomposed into:</p>
<p><span class="math display">\[
s_O^2 = s_B^2 + s_W^2
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(s_O^2\)</span> = <strong>Overall variance</strong> (variation over time and across individuals),</p></li>
<li><p><span class="math inline">\(s_B^2\)</span> = <strong>Between variance</strong> (variation between individuals),</p></li>
<li><p><span class="math inline">\(s_W^2\)</span> = <strong>Within variance</strong> (variation within individuals over time).</p></li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li><p><a href="data.html#sec-pooled-ols-estimator">Pooled OLS</a> does not separate within-individual and between-individual variation.</p></li>
<li><p>Fixed Effects models eliminate <span class="math inline">\(c_i\)</span> and use only within-individual variation.</p></li>
<li><p>Random Effects models use both within and between variation.</p></li>
</ul>
<hr>
<p><strong>Robust Inference in Pooled OLS</strong></p>
<p>If the standard assumptions fail, adjustments are necessary:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Heteroskedasticity:</strong> If <a href="linear-regression.html#a4-homoskedasticity">A4</a> (Homoskedasticity) is violated, standard errors must be adjusted using:
<ol style="list-style-type: decimal">
<li>White’s Robust Standard Errors (for cross-sectional heteroskedasticity).</li>
<li>Cluster-Robust Standard Errors (for panel-specific heteroskedasticity).</li>
</ol>
</li>
<li>
<strong>Serial Correlation (Autocorrelation):</strong> If errors are correlated across time:
<ol style="list-style-type: decimal">
<li>Use <a href="data.html#sec-newey-west-standard-errors">Newey-West Standard Errors</a> for time dependence.</li>
<li>Use Clustered Standard Errors at the Individual Level.</li>
</ol>
</li>
<li>
<strong>Multicollinearity:</strong> If regressors are highly correlated:
<ol style="list-style-type: decimal">
<li>Remove redundant variables.</li>
<li>Use <a href="model-specification-tests.html#sec-variance-inflation-factor">Variance Inflation Factor</a> diagnostics.</li>
</ol>
</li>
</ol>
<hr>
<p><strong>Comparing Pooled OLS with Alternative Panel Models</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="12%">
<col width="28%">
<col width="17%">
<col width="18%">
<col width="23%">
</colgroup>
<thead><tr class="header">
<th><strong>Model</strong></th>
<th>
<strong>Assumption about</strong> <span class="math inline">\(c_i\)</span>
</th>
<th><strong>Uses Within Variation?</strong></th>
<th><strong>Uses Between Variation?</strong></th>
<th><strong>Best When</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Pooled OLS</strong></td>
<td>Assumes <span class="math inline">\(c_i\)</span> is uncorrelated with <span class="math inline">\(x_{it}\)</span>
</td>
<td>✅ Yes</td>
<td>✅ Yes</td>
<td>No individual heterogeneity</td>
</tr>
<tr class="even">
<td><strong>Fixed Effects</strong></td>
<td>Removes <span class="math inline">\(c_i\)</span> via demeaning</td>
<td>✅ Yes</td>
<td>❌ No</td>
<td>
<span class="math inline">\(c_i\)</span> is correlated with <span class="math inline">\(x_{it}\)</span>
</td>
</tr>
<tr class="odd">
<td><strong>Random Effects</strong></td>
<td>Assumes <span class="math inline">\(c_i\)</span> is uncorrelated with <span class="math inline">\(x_{it}\)</span>
</td>
<td>✅ Yes</td>
<td>✅ Yes</td>
<td>
<span class="math inline">\(c_i\)</span> is uncorrelated with <span class="math inline">\(x_{it}\)</span>
</td>
</tr>
</tbody>
</table></div>
<hr>
<p><strong>When to Use Pooled OLS?</strong></p>
<ul>
<li><p>If individual heterogeneity is negligible</p></li>
<li><p>If panel is short (<span class="math inline">\(T\)</span> is small) and cross-section is large (<span class="math inline">\(N\)</span> is big)</p></li>
<li><p>If random effects assumption holds (<span class="math inline">\(E(\mathbf{x}_{it}' c_i) = 0\)</span>)</p></li>
</ul>
<p>If these conditions fail, <strong>Fixed Effects or Random Effects models</strong> should be used instead.</p>
<hr>
</div>
<div id="individual-specific-effects-model" class="section level3" number="11.5.5">
<h3>
<span class="header-section-number">11.5.5</span> Individual-Specific Effects Model<a class="anchor" aria-label="anchor" href="#individual-specific-effects-model"><i class="fas fa-link"></i></a>
</h3>
<p>In panel data, unobserved heterogeneity can arise when <strong>individual-specific factors</strong> (<span class="math inline">\(c_i\)</span>) influence the dependent variable. These effects can be:</p>
<ul>
<li>
<strong>Correlated with regressors</strong> (<span class="math inline">\(E(\mathbf{x}_{it}' c_i) \neq 0\)</span>): Use the <a href="data.html#sec-fixed-effects-estimator">Fixed Effects</a> estimator.</li>
<li>
<strong>Uncorrelated with regressors</strong> (<span class="math inline">\(E(\mathbf{x}_{it}' c_i) = 0\)</span>): Use the <a href="data.html#sec-random-effects-estimator">Random Effects</a> estimator.</li>
</ul>
<p>The general model is:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + c_i + u_{it}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(c_i\)</span> is the <strong>individual-specific effect</strong> (time-invariant),</p></li>
<li><p><span class="math inline">\(u_{it}\)</span> is the <strong>idiosyncratic error</strong> (time-variant).</p></li>
</ul>
<p><strong>Comparing Fixed Effects and Random Effects</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="13%">
<col width="24%">
<col width="18%">
<col width="18%">
<col width="25%">
</colgroup>
<thead><tr class="header">
<th><strong>Model</strong></th>
<th>
<strong>Assumption on</strong> <span class="math inline">\(c_i\)</span>
</th>
<th><strong>Uses Within Variation?</strong></th>
<th><strong>Uses Between Variation?</strong></th>
<th><strong>Best When</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Fixed Effects</strong></td>
<td>
<span class="math inline">\(c_i\)</span> is correlated with <span class="math inline">\(x_{it}\)</span>
</td>
<td>✅ Yes</td>
<td>❌ No</td>
<td>Unobserved heterogeneity bias present</td>
</tr>
<tr class="even">
<td><strong>Random Effects</strong></td>
<td>
<span class="math inline">\(c_i\)</span> is uncorrelated with <span class="math inline">\(x_{it}\)</span>
</td>
<td>✅ Yes</td>
<td>✅ Yes</td>
<td>No correlation with regressors</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
<div id="sec-random-effects-estimator" class="section level3" number="11.5.6">
<h3>
<span class="header-section-number">11.5.6</span> Random Effects Estimator<a class="anchor" aria-label="anchor" href="#sec-random-effects-estimator"><i class="fas fa-link"></i></a>
</h3>
<p>The Random Effects (RE) estimator is a <a href="linear-regression.html#feasible-generalized-least-squares">Feasible Generalized Least Squares</a> method used in panel data analysis. It assumes that individual-specific effects (<span class="math inline">\(c_i\)</span>) are uncorrelated with the explanatory variables (<span class="math inline">\(\mathbf{x}_{it}\)</span>), allowing for estimation using both within-group (time variation) and between-group (cross-sectional variation).</p>
<p>The standard <strong>Random Effects model</strong> is:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + c_i + u_{it}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(y_{it}\)</span> is the dependent variable for entity <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>,</p></li>
<li><p><span class="math inline">\(\mathbf{x}_{it}\)</span> is a vector of explanatory variables,</p></li>
<li><p><span class="math inline">\(\beta\)</span> represents the coefficients of interest,</p></li>
<li><p><span class="math inline">\(c_i\)</span> is the <strong>unobserved individual-specific effect</strong> (time-invariant),</p></li>
<li><p><span class="math inline">\(u_{it}\)</span> is the <strong>idiosyncratic error</strong> (time-varying).</p></li>
</ul>
<p>In contrast to the <a href="data.html#sec-fixed-effects-estimator">Fixed Effects</a> model, which eliminates <span class="math inline">\(c_i\)</span> by demeaning the data, the Random Effects model treats <span class="math inline">\(c_i\)</span> as a random variable and incorporates it into the error structure.</p>
<hr>
<div id="key-assumptions-for-random-effects" class="section level4" number="11.5.6.1">
<h4>
<span class="header-section-number">11.5.6.1</span> Key Assumptions for Random Effects<a class="anchor" aria-label="anchor" href="#key-assumptions-for-random-effects"><i class="fas fa-link"></i></a>
</h4>
<p>For the Random Effects estimator to be <strong>consistent</strong>, the following assumptions must hold:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Exogeneity of the Time-Varying Error</strong> (<span class="math inline">\(u_{it}\)</span>) (<a href="linear-regression.html#a3a-weak-exogeneity">A3a</a>)</li>
</ol>
<p>The idiosyncratic error term (<span class="math inline">\(u_{it}\)</span>) must be <strong>uncorrelated with regressors</strong>:</p>
<p><span class="math display">\[
E(\mathbf{x}_{it}' u_{it}) = 0
\]</span></p>
<p>This assumption ensures that within-period variation in the regressors does not systematically affect the error term.</p>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Exogeneity of Individual-Specific Effects</strong> (<span class="math inline">\(c_i\)</span>) (<a href="linear-regression.html#a3a-weak-exogeneity">A3a</a>)</li>
</ol>
<p>A crucial assumption of the RE model is that the individual effect (<span class="math inline">\(c_i\)</span>) is uncorrelated with the explanatory variables:</p>
<p><span class="math display">\[
E(\mathbf{x}_{it}' c_i) = 0
\]</span></p>
<p>This means that the individual-specific unobserved characteristics do not systematically affect the choice of explanatory variables.</p>
<ul>
<li>
<strong>If this assumption fails</strong>, the RE model produces <strong>biased and inconsistent estimates</strong> due to omitted variable bias.</li>
<li>
<strong>If this assumption holds</strong>, RE is <strong>more efficient than FE</strong> because it retains <strong>both within-group and between-group variation</strong>.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>
<strong>No Serial Correlation in</strong> <span class="math inline">\(u_{it}\)</span>
</li>
</ol>
<p>The error term (<span class="math inline">\(u_{it}\)</span>) must be <strong>uncorrelated across time</strong>:</p>
<p><span class="math display">\[
E(u_{it} u_{is}) = 0, \quad \forall t \neq s
\]</span></p>
<p>If this assumption fails:</p>
<ul>
<li><p>Standard errors will be incorrect.</p></li>
<li><p><a href="linear-regression.html#generalized-least-squares">Generalized Least Squares</a> adjustments or cluster-robust standard errors are required.</p></li>
</ul>
<hr>
</div>
<div id="efficiency-of-random-effects" class="section level4" number="11.5.6.2">
<h4>
<span class="header-section-number">11.5.6.2</span> Efficiency of Random Effects<a class="anchor" aria-label="anchor" href="#efficiency-of-random-effects"><i class="fas fa-link"></i></a>
</h4>
<p>The RE estimator is a GLS estimator, meaning it is BLUE (Best Linear Unbiased Estimator) under homoskedasticity.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="52%">
<col width="47%">
</colgroup>
<thead><tr class="header">
<th><strong>Scenario</strong></th>
<th><strong>Efficiency of RE</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<a href="linear-regression.html#a4-homoskedasticity">A4</a> (Homoskedasticity) holds</td>
<td>RE is the most efficient estimator.</td>
</tr>
<tr class="even">
<td>
<a href="linear-regression.html#a4-homoskedasticity">A4</a> fails (Heteroskedasticity or Serial Correlation)</td>
<td>RE remains more efficient than Pooled OLS but is no longer optimal.</td>
</tr>
</tbody>
</table></div>
<ul>
<li>When the variance of errors differs across individuals, RE can still be used but must be adjusted with robust standard errors.</li>
<li>If errors are correlated over time, standard <a href="data.html#sec-newey-west-standard-errors">Newey-West</a> or cluster-robust standard errors should be applied.</li>
</ul>
<hr>
<p>To efficiently estimate <span class="math inline">\(\beta\)</span>, we transform the RE model using <a href="linear-regression.html#generalized-least-squares">Generalized Least Squares</a>.</p>
<p>Define the <strong>quasi-demeaned transformation</strong>:</p>
<p><span class="math display">\[
\tilde{y}_{it} = y_{it} - \theta \bar{y}_i
\]</span></p>
<p><span class="math display">\[
\tilde{\mathbf{x}}_{it} = \mathbf{x}_{it} - \theta \bar{\mathbf{x}}_i
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\theta = 1 - \sqrt{\frac{\sigma^2_u}{T\sigma^2_c + \sigma^2_u}}
\]</span></p>
<ul>
<li>If <span class="math inline">\(\theta = 1\)</span>, RE becomes the <a href="data.html#sec-fixed-effects-estimator">FE estimator</a>.</li>
<li>If <span class="math inline">\(\theta = 0\)</span>, RE becomes <a href="data.html#sec-pooled-ols-estimator">Pooled OLS</a>.</li>
</ul>
<p>The final RE regression equation is:</p>
<p><span class="math display">\[
\tilde{y}_{it} = \tilde{\mathbf{x}}_{it} \beta + \tilde{u}_{it}
\]</span></p>
<p>which is estimated using GLS.</p>
<hr>
</div>
</div>
<div id="sec-fixed-effects-estimator" class="section level3" number="11.5.7">
<h3>
<span class="header-section-number">11.5.7</span> Fixed Effects Estimator<a class="anchor" aria-label="anchor" href="#sec-fixed-effects-estimator"><i class="fas fa-link"></i></a>
</h3>
<p>Also known as the <strong>Within Estimator</strong>, the <strong>FE model</strong> controls for individual-specific effects by removing them through transformation.</p>
<p><strong>Key Assumption</strong></p>
<p>If the <a href="data.html#sec-random-effects-estimator">RE</a> assumption fails (<span class="math inline">\(E(\mathbf{x}_{it}' c_i) \neq 0\)</span>), then:</p>
<ul>
<li>
<strong>Pooled OLS and RE become biased and inconsistent</strong> (due to omitted variable bias).</li>
<li>
<strong>FE is still consistent</strong> because it eliminates <span class="math inline">\(c_i\)</span>.</li>
</ul>
<p>However, FE only corrects bias from time-invariant factors and does not handle time-variant omitted variables.</p>
<p><strong>Challenges with FE</strong></p>
<ul>
<li>
<strong>Bias with Lagged Dependent Variables</strong>: FE is biased in dynamic models <span class="citation">(<a href="references.html#ref-nickell1981biases">Nickell 1981</a>; <a href="references.html#ref-narayanan2013estimating">Narayanan and Nair 2013</a>)</span>.</li>
<li>
<strong>Exacerbates Measurement Error</strong>: FE can worsen <strong>errors-in-variables bias</strong>.</li>
</ul>
<hr>
<div id="sec-demean-within-transformation" class="section level4" number="11.5.7.1">
<h4>
<span class="header-section-number">11.5.7.1</span> Demean (Within) Transformation<a class="anchor" aria-label="anchor" href="#sec-demean-within-transformation"><i class="fas fa-link"></i></a>
</h4>
<p>To remove <span class="math inline">\(c_i\)</span>, we take the individual mean of the regression equation:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + c_i + u_{it}
\]</span></p>
<p>Averaging over time (<span class="math inline">\(T\)</span>):</p>
<p><span class="math display">\[
\bar{y}_i = \bar{\mathbf{x}}_i \beta + c_i + \bar{u}_i
\]</span></p>
<p>Subtracting the second equation from the first (i.e., <strong>within transformation</strong>):</p>
<p><span class="math display">\[
(y_{it} - \bar{y}_i) = (\mathbf{x}_{it} - \bar{\mathbf{x}}_i) \beta + (u_{it} - \bar{u}_i)
\]</span></p>
<p>This transformation:</p>
<ul>
<li><p>Eliminates <span class="math inline">\(c_i\)</span>, solving omitted variable bias.</p></li>
<li><p>Only uses within-individual variation.</p></li>
</ul>
<p>The transformed regression is estimated via OLS:</p>
<p><span class="math display">\[
y_{it} - \bar{y}_i = (\mathbf{x}_{it} - \bar{\mathbf{x}}_i) \beta + d_1 \delta_1 + \dots + d_{T-2} \delta_{T-2} + (u_{it} - \bar{u}_i)
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(d_t\)</span> is a time dummy variable, which equals 1 if the observation in the time periods <span class="math inline">\(t\)</span>, and 0 otherwise. This variable is for period <span class="math inline">\(t = 1, \dots, T - 1\)</span> (one period omitted to avoid perfect multicollinearity).</p></li>
<li><p><span class="math inline">\(\delta_t\)</span> is the coefficient on the time dummy, capturing aggregate shocks that affect all individual in period <span class="math inline">\(t\)</span>.</p></li>
</ul>
<p><strong>Key Conditions for Consistency</strong>:</p>
<ul>
<li><p>Strict Exogeneity (<a href="linear-regression.html#a3-exogeneity-of-independent-variables">A3</a>):<br><span class="math display">\[
  E[(\mathbf{x}_{it} - \bar{\mathbf{x}}_i)' (u_{it} - \bar{u}_i)] = 0
  \]</span></p></li>
<li><p>Time-invariant variables are dropped (e.g., gender, ethnicity). If you’re interested in the effect of these time-invariant variables, consider using either OLS or the between estimator.</p></li>
<li><p>Cluster-Robust Standard Errors should be used.</p></li>
</ul>
<hr>
</div>
<div id="sec-dummy-variable-approach" class="section level4" number="11.5.7.2">
<h4>
<span class="header-section-number">11.5.7.2</span> Dummy Variable Approach<a class="anchor" aria-label="anchor" href="#sec-dummy-variable-approach"><i class="fas fa-link"></i></a>
</h4>
<p>The Dummy Variable Approach is an alternative way to estimate <a href="data.html#sec-fixed-effects-estimator">Fixed Effects</a> in panel data. Instead of transforming the data by demeaning (<a href="data.html#sec-demean-within-transformation">Within Transformation</a>), this method explicitly includes individual dummy variables to control for entity-specific heterogeneity.</p>
<p>The general FE model is:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + c_i + u_{it}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(c_i\)</span> is the unobserved, <strong>time-invariant individual effect</strong> (e.g., ability, cultural preferences, managerial style).</p></li>
<li><p><span class="math inline">\(u_{it}\)</span> is the <strong>idiosyncratic error term</strong> (fluctuates over time and across individuals).</p></li>
</ul>
<p>To estimate this model using the Dummy Variable Approach, we include a separate dummy variable for each individual:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + d_1 \delta_1 + ... + d_{T-2} \delta_{T-2} + c_1 \gamma_1 + ... + c_{n-1} \gamma_{n-1} + u_{it}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(c_i\)</span> is now modeled explicitly as a dummy variable (<span class="math inline">\(c_i \gamma_i\)</span>) for each individual.</p></li>
<li><p><span class="math inline">\(d_t\)</span> are time dummies, capturing time-specific shocks.</p></li>
<li><p><span class="math inline">\(\delta_t\)</span> are coefficients on time dummies, controlling for common time effects.</p></li>
</ul>
<p><strong>Interpretation of the Dummy Variables</strong></p>
<ul>
<li>
<p>The dummy variable <span class="math inline">\(c_i\)</span> takes a value of 1 for individual <span class="math inline">\(i\)</span> and 0 otherwise:</p>
<p><span class="math display">\[
c_i =
\begin{cases}
1 &amp;\text{if observation is for individual } i \\
0 &amp;\text{otherwise}
\end{cases}
\]</span></p>
</li>
<li><p>These <span class="math inline">\(N\)</span> dummy variables absorb all individual-specific variation, ensuring that only within-individual (over-time) variation remains.</p></li>
</ul>
<hr>
<p><strong>Advantages of the Dummy Variable Approach</strong></p>
<ol style="list-style-type: decimal">
<li>Easy to Interpret: Explicitly includes entity-specific effects, making it easier to understand how individual heterogeneity is modeled.</li>
<li>Equivalent to the <a href="data.html#sec-demean-within-transformation">Within (Demean) Transformation</a>: Mathematically, this approach produces the same coefficient estimates as the Within Transformation.</li>
<li>Allows for Inclusion of Time Dummies: The model can easily incorporate time dummies (<span class="math inline">\(d_t\)</span>) to control for period-specific shocks.</li>
</ol>
<hr>
<p><strong>Limitations of the Dummy Variable Approach</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Computational Complexity with Large</strong> <span class="math inline">\(N\)</span>
<ul>
<li>Adding <span class="math inline">\(N\)</span> dummy variables significantly increases the number of parameters estimated.</li>
<li>If <span class="math inline">\(N\)</span> is very large (e.g., 10,000 individuals), this approach can be computationally expensive.</li>
</ul>
</li>
<li>
<strong>Standard Errors Are Incorrectly Estimated</strong>
<ul>
<li>The standard errors for <span class="math inline">\(c_i\)</span> dummy variables are often incorrectly calculated, as they absorb all within-individual variation.</li>
<li>This is why the Within Transformation (Demeaning Approach) is generally preferred.</li>
</ul>
</li>
<li>
<strong>Consumes Degrees of Freedom</strong>
<ul>
<li>Introducing <span class="math inline">\(N\)</span> additional parameters reduces degrees of freedom, which can lead to overfitting.</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="sec-first-difference-approach" class="section level4" number="11.5.7.3">
<h4>
<span class="header-section-number">11.5.7.3</span> First-Difference Approach<a class="anchor" aria-label="anchor" href="#sec-first-difference-approach"><i class="fas fa-link"></i></a>
</h4>
<p>An alternative way to eliminate individual-specific effects (<span class="math inline">\(c_i\)</span>) is to <strong>take first differences across time</strong>, rather than subtracting the individual mean.</p>
<p>The FE model:</p>
<p><span class="math display">\[
y_{it} = \mathbf{x}_{it} \beta + c_i + u_{it}
\]</span></p>
<p>Since <span class="math inline">\(c_i\)</span> is constant over time, taking the first difference:</p>
<p><span class="math display">\[
y_{it} - y_{i(t-1)} = (\mathbf{x}_{it} - \mathbf{x}_{i(t-1)}) \beta + (u_{it} - u_{i(t-1)})
\]</span></p>
<p>This transformation <strong>removes</strong> <span class="math inline">\(c_i\)</span> completely, leaving a model that can be estimated using <a href="data.html#sec-pooled-ols-estimator">Pooled OLS</a>.</p>
<hr>
<p><strong>Advantages of the First-Difference Approach</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Eliminates Individual Effects</strong> (<span class="math inline">\(c_i\)</span>)
<ul>
<li>Since <span class="math inline">\(c_i\)</span> is time-invariant, differencing removes it from the equation.</li>
</ul>
</li>
<li>
<strong>Works Well with Few Time Periods (</strong><span class="math inline">\(T\)</span> is Small)
<ul>
<li>If <span class="math inline">\(T\)</span> is small, first-differencing is often preferred over the <a href="data.html#sec-demean-within-transformation">Within Transformation</a>, as it does not require averaging over many periods.</li>
</ul>
</li>
<li>
<strong>Less Computationally Intensive</strong>
<ul>
<li>Unlike the <a href="data.html#sec-dummy-variable-approach">Dummy Variable Approach</a>, which requires estimating <span class="math inline">\(N\)</span> additional parameters, the First-Difference Approach reduces the dimensionality of the problem.</li>
</ul>
</li>
</ol>
<hr>
<p><strong>Limitations of the First-Difference Approach</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Cannot Handle Missing Observations Well</strong>
<ul>
<li>If data is missing in period <span class="math inline">\(t-1\)</span> for an individual, then the corresponding first-difference observation is lost.</li>
<li>This can significantly reduce sample size in unbalanced panels.</li>
</ul>
</li>
<li>
<strong>Reduces Number of Observations by One</strong>
<ul>
<li>Since first differences require <span class="math inline">\(y_{i(t-1)}\)</span> to exist, the model loses one time period (<span class="math inline">\(T-1\)</span> observations per individual instead of <span class="math inline">\(T\)</span>).</li>
</ul>
</li>
<li>
<strong>Can Introduce Serial Correlation</strong>
<ul>
<li>Since we are differencing <span class="math inline">\(u_{it} - u_{i(t-1)}\)</span>, the error term now exhibits autocorrelation.</li>
<li>This means standard OLS assumptions (independent errors) no longer hold, requiring the use of robust standard errors.</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="comparison-of-fe-approaches" class="section level4" number="11.5.7.4">
<h4>
<span class="header-section-number">11.5.7.4</span> Comparison of FE Approaches<a class="anchor" aria-label="anchor" href="#comparison-of-fe-approaches"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="28%">
<col width="20%">
<col width="20%">
<col width="30%">
</colgroup>
<thead><tr class="header">
<th><strong>Approach</strong></th>
<th><strong>How it Works</strong></th>
<th><strong>Pros</strong></th>
<th><strong>Cons</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="data.html#sec-dummy-variable-approach">Dummy Variable</a></td>
<td>Includes individual dummies (<span class="math inline">\(c_i\)</span>) in regression</td>
<td>Intuitive, easy to interpret</td>
<td>Computationally expensive for large <span class="math inline">\(N\)</span>, standard errors may be incorrect</td>
</tr>
<tr class="even">
<td><a href="data.html#sec-demean-within-transformation">Within Transformation (Demeaning)</a></td>
<td>Subtracts individual mean from each variable</td>
<td>Computationally efficient, correct standard errors</td>
<td>Cannot estimate time-invariant variables</td>
</tr>
<tr class="odd">
<td><a href="data.html#sec-first-difference-approach">First-Difference Approach</a></td>
<td>Takes time differences to remove <span class="math inline">\(c_i\)</span>
</td>
<td>Simple, works well for small <span class="math inline">\(T\)</span>
</td>
<td>Reduces sample size, introduces autocorrelation</td>
</tr>
</tbody>
</table></div>
<hr>
<p><strong>Key Insights</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>The Dummy Variable Approach explicitly models</strong> <span class="math inline">\(c_i\)</span> but is computationally expensive for large <span class="math inline">\(N\)</span>.</li>
<li>
<strong>The Within (Demean) Transformation is the most commonly used FE method</strong> because it is <strong>computationally efficient</strong> and <strong>produces correct standard errors</strong>.</li>
<li>
<strong>The First-Difference Approach is useful when</strong> <span class="math inline">\(T\)</span> is small, but it reduces sample size and introduces autocorrelation.</li>
<li>
<strong>If data has many missing values, First-Difference is not recommended</strong> due to its sensitivity to gaps in observations.</li>
<li>
<strong>Time dummies (</strong><span class="math inline">\(d_t\)</span>) can be included in any FE model to control for time shocks that affect all individuals.</li>
<li>FE only exploits <strong>within variation</strong>, meaning only <strong>status changes contribute to</strong> <span class="math inline">\(\beta\)</span> estimates.</li>
<li>
<strong>With limited status changes, standard errors explode</strong> (small number of switchers leads to high variance).</li>
<li>
<strong>Treatment effect is non-directional</strong> but can be parameterized.</li>
<li>
<strong>Switchers vs. Non-Switchers</strong>:
<ul>
<li>If <strong>switchers differ fundamentally</strong>, the FE estimator may still be biased.</li>
<li>Descriptive statistics on switchers/non-switchers help verify robustness.</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="variance-of-errors-in-fe" class="section level4" number="11.5.7.5">
<h4>
<span class="header-section-number">11.5.7.5</span> Variance of Errors in FE<a class="anchor" aria-label="anchor" href="#variance-of-errors-in-fe"><i class="fas fa-link"></i></a>
</h4>
<p>FE reduces variation by removing <span class="math inline">\(c_i\)</span>, which affects <strong>error variance</strong>:</p>
<p><span class="math display">\[ \hat{\sigma}^2_{\epsilon} = \frac{SSR_{OLS}}{NT - K} \]</span></p>
<p><span class="math display">\[ \hat{\sigma}^2_u = \frac{SSR_{FE}}{NT - (N+K)} = \frac{SSR_{FE}}{N(T-1)-K} \]</span></p>
<p><strong>Implication</strong>:</p>
<ul>
<li>
<p>The variance of the error may increase or decrease because:</p>
<ul>
<li><p><span class="math inline">\(SSR\)</span> can increase (since FE eliminates between variation).</p></li>
<li><p>Degrees of freedom decrease (as more parameters are estimated).</p></li>
</ul>
</li>
</ul>
</div>
<div id="fixed-effects-examples" class="section level4" number="11.5.7.6">
<h4>
<span class="header-section-number">11.5.7.6</span> Fixed Effects Examples<a class="anchor" aria-label="anchor" href="#fixed-effects-examples"><i class="fas fa-link"></i></a>
</h4>
<div id="intergenerational-mobility-blau1999" class="section level5" number="11.5.7.6.1">
<h5>
<span class="header-section-number">11.5.7.6.1</span> Intergenerational Mobility – <span class="citation">Blau (<a href="references.html#ref-blau1999">1999</a>)</span><a class="anchor" aria-label="anchor" href="#intergenerational-mobility-blau1999"><i class="fas fa-link"></i></a>
</h5>
<p><strong>Research Questions</strong></p>
<ul>
<li>Does <strong>transferring resources</strong> to low-income families improve <strong>upward mobility</strong> for children?</li>
<li>What are the <strong>mechanisms</strong> of intergenerational mobility?</li>
</ul>
<p><strong>Mechanisms for Intergenerational Mobility</strong></p>
<p>There are multiple pathways through which <strong>parental income influences child outcomes</strong>:</p>
<ol style="list-style-type: decimal">
<li>Genetics (Ability Endowment)
<ul>
<li>If mobility is purely genetic, policy cannot affect outcomes.</li>
</ul>
</li>
<li>Environmental Indirect Effects
<ul>
<li>Family background, peer influences, school quality.</li>
</ul>
</li>
<li>Environmental Direct Effects
<ul>
<li>Parental investments in education, health, social capital.</li>
</ul>
</li>
<li>Financial Transfers
<ul>
<li>Direct monetary support, inheritance, wealth accumulation.</li>
</ul>
</li>
</ol>
<p>One way to measure the impact of income on human capital accumulation is:</p>
<p><span class="math display">\[
\frac{\% \Delta \text{Human Capital}}{\% \Delta \text{Parental Income}}
\]</span></p>
<p>where human capital includes education, skills, and job market outcomes.</p>
<p>Income is measured in different ways to capture its <strong>long-term effects</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Total household income</strong></li>
<li><strong>Wage income</strong></li>
<li><strong>Non-wage income</strong></li>
<li>
<strong>Annual vs. Permanent Income</strong> (important distinction for long-term analysis)</li>
</ol>
<p>Key control variables must be <strong>exogenous</strong> to avoid bias. <a href="sec-controls.html#bad-controls">Bad Controls</a> are those that are <strong>jointly determined with the dependent variable</strong> (e.g., mother’s labor force participation).</p>
<p><strong>Exogenous controls:</strong></p>
<ul>
<li><p>Mother’s race</p></li>
<li><p>Birth location</p></li>
<li><p>Parental education</p></li>
<li><p>Household structure at age 14</p></li>
</ul>
<p>The estimated model is:</p>
<p><span class="math display">\[
Y_{ijt} = X_{jt} \beta_i + I_{jt} \alpha_i + \epsilon_{ijt}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(i\)</span> = test (e.g., academic test score).</p></li>
<li><p><span class="math inline">\(j\)</span> = individual (child).</p></li>
<li><p><span class="math inline">\(t\)</span> = time.</p></li>
<li><p><span class="math inline">\(X_{jt}\)</span> = observable child characteristics.</p></li>
<li><p><span class="math inline">\(I_{jt}\)</span> = parental income.</p></li>
<li><p><span class="math inline">\(\epsilon_{ijt}\)</span> = error term.</p></li>
</ul>
<hr>
<p><strong>Grandmother’s Fixed-Effects Model</strong></p>
<p>Since a child (<span class="math inline">\(j\)</span>) is <strong>nested</strong> within a mother (<span class="math inline">\(m\)</span>), and a mother is <strong>nested</strong> within a grandmother (<span class="math inline">\(g\)</span>), we estimate:</p>
<p><span class="math display">\[
Y_{ijgmt} = X_{it} \beta_{i} + I_{jt} \alpha_i + \gamma_g + u_{ijgmt}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(g\)</span> = Grandmother, <span class="math inline">\(m\)</span> = Mother, <span class="math inline">\(j\)</span> = Child, <span class="math inline">\(t\)</span> = Time.</p></li>
<li><p><span class="math inline">\(\gamma_g\)</span> captures both grandmother and mother fixed effects.</p></li>
<li><p>The nested structure controls for genetic and fixed family environment effects.</p></li>
<li><p><strong>Cluster standard errors</strong> at the family level to <strong>account for correlation in errors</strong> across generations.</p></li>
</ul>
<p><strong>Pros of Grandmother FE Model</strong></p>
<ul>
<li><p>Controls for genetics + fixed family background</p></li>
<li><p>Allows estimation of income effects independent of family background</p></li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li><p>Might not fully control for unobserved heterogeneity</p></li>
<li><p>Measurement errors in income can exaggerate attenuation bias</p></li>
</ul>
<hr>
</div>
<div id="fixed-effects-in-teacher-quality-studies-babcock2010" class="section level5" number="11.5.7.6.2">
<h5>
<span class="header-section-number">11.5.7.6.2</span> Fixed Effects in Teacher Quality Studies – <span class="citation">Babcock (<a href="references.html#ref-babcock2010">2010</a>)</span><a class="anchor" aria-label="anchor" href="#fixed-effects-in-teacher-quality-studies-babcock2010"><i class="fas fa-link"></i></a>
</h5>
<p>The study investigates:</p>
<ul>
<li><p>How teacher quality influences student performance.</p></li>
<li><p>Whether students adjust course selection behavior based on past grading experiences.</p></li>
<li><p>How to properly estimate teacher fixed effects while addressing selection bias and measurement error.</p></li>
</ul>
<hr>
<p>The initial model estimates student performance (<span class="math inline">\(T_{ijct}\)</span>) based on class expectations and student characteristics:</p>
<p><span class="math display">\[
T_{ijct} = \alpha_0 + S_{jct} \alpha_1 + X_{ijct} \alpha_2 + u_{ijct}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(T_{ijct}\)</span> = Student test score.</p></li>
<li><p><span class="math inline">\(S_{jct}\)</span> = Class-level grading expectation (e.g., expected GPA in the course).</p></li>
<li><p><span class="math inline">\(X_{ijct}\)</span> = Individual student characteristics.</p></li>
<li><p><span class="math inline">\(i\)</span> = Student, <span class="math inline">\(j\)</span> = Instructor, <span class="math inline">\(c\)</span> = Course, <span class="math inline">\(t\)</span> = Time.</p></li>
<li><p><span class="math inline">\(u_{ijct}\)</span> = Idiosyncratic error term.</p></li>
</ul>
<p>A key issue in this model is that <strong>grading expectations</strong> may not be randomly assigned. If students select into courses based on grading expectations, <strong>simultaneity bias</strong> can arise.</p>
<hr>
<p>To control for <strong>instructor and course heterogeneity</strong>, the model introduces <strong>teacher-course fixed effects</strong> (<span class="math inline">\(\mu_{jc}\)</span>):</p>
<p><span class="math display">\[
T_{ijct} = \beta_0+ S_{jct} \beta_1+ X_{ijct} \beta_2 +\mu_{jc} + \epsilon_{ijct}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mu_{jc}\)</span> is a unique fixed effect for each instructor-course combination.</p></li>
<li><p>This controls for instructor-specific grading policies and course difficulty.</p></li>
<li><p>It differs from a simple instructor effect (<span class="math inline">\(\theta_j\)</span>) and course effect (<span class="math inline">\(\delta_c\)</span>) because it captures interaction effects.</p></li>
</ul>
<p><strong>Implications of Instructor-Course Fixed Effects</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Reduces Bias from Course Shopping</strong>
<ul>
<li>Students may select courses based on grading expectations.</li>
<li>Including <span class="math inline">\(\mu_{jc}\)</span> controls for the fact that some instructors systematically assign easier grades.</li>
</ul>
</li>
<li>
<strong>Shifts in Student Expectations</strong>
<ul>
<li>Even if course content remains constant, students adjust their expectations based on past grading experiences.</li>
<li>This influences their future course selection behavior.</li>
</ul>
</li>
</ol>
<hr>
<p><strong>Identification Strategy</strong></p>
<p>A key challenge in estimating teacher effects is <strong>endogeneity</strong> from:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Simultaneity Bias</strong>
<ol style="list-style-type: decimal">
<li>Grading expectations (<span class="math inline">\(S_{jct}\)</span>) and student performance may be jointly determined.</li>
<li>If grading expectations are based on past student performance, <strong>OLS will be biased</strong>.</li>
</ol>
</li>
</ol>
<!-- --><ol start="2" style="list-style-type: decimal">
<li>
<strong>Unobserved Teacher Characteristics</strong>
<ul>
<li>Some teachers may have innate ability to motivate students, leading to higher student performance independent of observable teacher traits.</li>
</ul>
</li>
</ol>
<p>To address these concerns, the model first controls for <strong>observable teacher characteristics</strong>:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{ijt} &amp;= X_{it} \beta_1 + \text{Teacher Experience}_{jt} \beta_2 + \text{Teacher Education}_{jt} \beta_3 \\
&amp;+ \text{Teacher Score}_{it}\beta_4 + \dots + \epsilon_{ijt}
\end{aligned}
\]</span></p>
<p>However, if <strong>teacher characteristics are correlated with unobserved ability</strong>, we replace them with <strong>teacher fixed effects</strong>:</p>
<p><span class="math display">\[
Y_{ijt} = X_{it} \alpha + \Gamma_{it} \theta_j + u_{ijt}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\theta_j\)</span> = <strong>Teacher Fixed Effect</strong>, capturing all time-invariant teacher characteristics.</p></li>
<li><p><span class="math inline">\(\Gamma_{it}\)</span> represents within-teacher variation.</p></li>
</ul>
<hr>
<p>To further analyze teacher impact, we express student test scores as:</p>
<p><span class="math display">\[
Y_{ijt} = X_{it} \gamma + \epsilon_{ijt}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\gamma\)</span> represents the between and within variation.</p></li>
<li><p><span class="math inline">\(e_{ijt}\)</span> is the prediction error.</p></li>
</ul>
<p>Decomposing the error term:</p>
<p><span class="math display">\[
e_{ijt} = T_{it} \delta_j + \tilde{e}_{ijt}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\delta_j\)</span> = Group-level teacher effect.</p></li>
<li><p><span class="math inline">\(\tilde{e}_{ijt}\)</span> = Residual error.</p></li>
</ul>
<hr>
<p>To control for <strong>prior student performance</strong>, we introduce <strong>lagged test scores</strong>:</p>
<p><span class="math display">\[
Y_{ijkt} = Y_{ijkt-1} + X_{it} \beta + T_{it} \tau_j + (W_i + P_k + \epsilon_{ijkt})
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(Y_{ijkt-1}\)</span> = Lagged student test score.</p></li>
<li><p><span class="math inline">\(\tau_j\)</span> = Teacher Fixed Effect.</p></li>
<li><p><span class="math inline">\(W_i\)</span> = Student Fixed Effect.</p></li>
<li><p><span class="math inline">\(P_k\)</span> = School Fixed Effect.</p></li>
<li><p><span class="math inline">\(u_{ijkt} = W_i + P_k + \epsilon_{ijkt}\)</span>.</p></li>
</ul>
<p>A major issue is <strong>selection bias</strong>:</p>
<ul>
<li><p>If students <strong>sort into better teachers</strong>, the teacher effect (<span class="math inline">\(\tau\)</span>) may be <strong>overestimated</strong>.</p></li>
<li><p>Bias in <span class="math inline">\(\tau\)</span> for teacher <span class="math inline">\(j\)</span> is:</p></li>
</ul>
<p><span class="math display">\[
\frac{1}{N_j} \sum_{i = 1}^{N_j} (W_i + P_k + \epsilon_{ijkt})
\]</span></p>
<ul>
<li>where <span class="math inline">\(N_j\)</span> is the number of students in class with teacher <span class="math inline">\(j\)</span>.</li>
<li>
<strong>Smaller class sizes → Higher bias</strong> in teacher effect estimates because <span class="math inline">\(\frac{1}{N_j} \sum_{i = 1}^{N_j} \epsilon_{ijkt} \neq 0\)</span> will inflate the teacher fixed effect. If we use the random teacher effects instead, <span class="math inline">\(\tau\)</span> will still contain bias and we do not know the direction of the bias.</li>
</ul>
<hr>
<p>If teachers <strong>switch schools</strong>, we can separately estimate:</p>
<ul>
<li><p>Teacher Fixed Effects (<span class="math inline">\(\tau_j\)</span>)</p></li>
<li><p>School Fixed Effects (<span class="math inline">\(P_k\)</span>)</p></li>
</ul>
<p>The <strong>mobility web</strong> refers to the network of teacher transitions across schools, which helps in identifying both teacher and school fixed effects.</p>
<ul>
<li><p>Thin mobility web: Few teachers switch schools, making it harder to separate teacher effects from school effects.</p></li>
<li><p>Thick mobility web: Many teachers switch schools, improving identification of teacher quality independent of school characteristics.</p></li>
</ul>
<p>The <strong>panel data model</strong> capturing student performance over time is:</p>
<p><span class="math display">\[
Y_{ijkt} = Y_{ijk(t-1)} \alpha + X_{it} \beta + T_{it} \tau + P_k + \epsilon_{ijkt}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(Y_{ijkt}\)</span> = Student performance at time <span class="math inline">\(t\)</span>.</p></li>
<li><p><span class="math inline">\(Y_{ijk(t-1)}\)</span> = Lagged student test score.</p></li>
<li><p><span class="math inline">\(X_{it}\)</span> = Student characteristics.</p></li>
<li><p><span class="math inline">\(T_{it}\)</span> = Teacher effect (<span class="math inline">\(\tau\)</span>).</p></li>
<li><p><span class="math inline">\(P_k\)</span> = School fixed effect.</p></li>
<li><p><span class="math inline">\(\epsilon_{ijkt}\)</span> = Idiosyncratic error term.</p></li>
</ul>
<p>If we apply fixed effects (<a href="data.html#sec-demean-within-transformation">demeaning transformation</a>):</p>
<p><span class="math display">\[
Y_{ijkt} - \bar{Y}_{ijk} = (X_{it} - \bar{X}_i) \beta + (T_{it} - \bar{T}_i) \tau + (P_k - \bar{P}) + (\epsilon_{ijkt} - \bar{\epsilon}_{ijk})
\]</span></p>
<ul>
<li>This transformation removes teacher fixed effects (<span class="math inline">\(\tau\)</span>).</li>
<li>If we want to explicitly estimate <span class="math inline">\(\tau\)</span>, we must include teacher fixed effects before demeaning.</li>
</ul>
<p>The paper argues that controlling for school fixed effects (<span class="math inline">\(P_k\)</span>) ensures no selection bias, meaning students are <strong>randomly assigned</strong> within schools.</p>
<hr>
<p>A key claim in the paper is that teacher quality (<span class="math inline">\(\tau\)</span>) does not depend on the number of students per teacher (<span class="math inline">\(N_j\)</span>).</p>
<p>To test this, we examine the variance of estimated teacher effects:</p>
<p><span class="math display">\[
var(\tau)
\]</span></p>
<p>If:</p>
<p><span class="math display">\[
var(\tau) = 0
\]</span></p>
<p>this implies <strong>teacher quality does not impact student performance</strong>.</p>
<p>To empirically test this, the study analyzes:</p>
<p><span class="math display">\[
\frac{1}{N_j} \sum_{i = 1}^{N_j} \epsilon_{ijkt}
\]</span></p>
<p>which represents <strong>teacher-level average residuals</strong>.</p>
<p><strong>Key Finding</strong>:</p>
<ul>
<li><p>The variance of teacher effects remains stable across different class sizes (<span class="math inline">\(N_j\)</span>).</p></li>
<li><p>This suggests that random assignment of students across teachers is not biasing <span class="math inline">\(\tau\)</span>.</p></li>
</ul>
<hr>
<p>Since teacher effects (<span class="math inline">\(\tau_j\)</span>) are <strong>estimated with error</strong> (Spin-off of [Measurement Error]), we decompose them as:</p>
<p><span class="math display">\[
\hat{\tau}_j = \tau_j + \lambda_j
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\tau_j\)</span> = True teacher effect.</p></li>
<li><p><span class="math inline">\(\lambda_j\)</span> = Measurement error (e.g., sampling error, estimation noise).</p></li>
</ul>
<p>Assuming <span class="math inline">\(\tau_j\)</span> and <span class="math inline">\(\lambda_j\)</span> are uncorrelated:</p>
<p><span class="math display">\[
cov(\tau_j, \lambda_j) = 0
\]</span></p>
<p>this means that <strong>the randomness in student assignments does not systematically bias teacher quality estimates</strong>.</p>
<p>The total observed variance in estimated teacher effects is:</p>
<p><span class="math display">\[
var(\hat{\tau}) = var(\tau) + var(\lambda)
\]</span></p>
<p>Rearranging:</p>
<p><span class="math display">\[
var(\tau) = var(\hat{\tau}) - var(\lambda)
\]</span></p>
<p>Since we observe <span class="math inline">\(var(\hat{\tau})\)</span>, we need to estimate <span class="math inline">\(var(\lambda)\)</span>.</p>
<p>Measurement error variance (<span class="math inline">\(var(\lambda)\)</span>) can be approximated using the average squared standard error of teacher effects:</p>
<p><span class="math display">\[
var(\lambda) = \frac{1}{J} \sum_{j=1}^J \hat{\sigma}^2_j
\]</span></p>
<p>where <span class="math inline">\(\hat{\sigma}^2_j\)</span> is the squared standard error of teacher <span class="math inline">\(j\)</span> (which depends on sample size <span class="math inline">\(N_j\)</span>).</p>
<hr>
<p>The <strong>signal-to-noise ratio</strong> (or <strong>reliability</strong>) of teacher effect estimates is:</p>
<p><span class="math display">\[
\frac{var(\tau)}{var(\hat{\tau})} = \text{Reliability}
\]</span></p>
<p>where:</p>
<ul>
<li><p><strong>Higher reliability</strong> indicates that most of the variation comes from true teacher effects (<span class="math inline">\(\tau\)</span>) rather than noise.</p></li>
<li><p><strong>Lower reliability</strong> suggests that a large portion of variation is due to <strong>measurement error</strong>.</p></li>
</ul>
<p>The proportion of <strong>error variance</strong> in estimated teacher effects is:</p>
<p><span class="math display">\[
1 - \frac{var(\tau)}{var(\hat{\tau})} = \text{Noise}
\]</span></p>
<p>Even if true teacher quality depends on class size (<span class="math inline">\(N_j\)</span>), our method for estimating <span class="math inline">\(\lambda\)</span> remains unaffected.</p>
<hr>
<p>To check whether <strong>teacher effects are biased by sampling error</strong>, we regress estimated teacher effects (<span class="math inline">\(\hat{\tau}_j\)</span>) on teacher characteristics (<span class="math inline">\(X_j\)</span>):</p>
<p><span class="math display">\[
\hat{\tau}_j = \beta_0 + X_j \beta_1 + \epsilon_j
\]</span></p>
<p>If teacher characteristics <strong>do not predict sampling error</strong>, then:</p>
<p><span class="math display">\[
R^2 \approx 0
\]</span></p>
<p>This would confirm that <strong>teacher characteristics are uncorrelated with measurement error</strong>, validating the identification strategy.</p>
<hr>
</div>
</div>
</div>
<div id="tests-for-assumptions-in-panel-data-analysis" class="section level3" number="11.5.8">
<h3>
<span class="header-section-number">11.5.8</span> Tests for Assumptions in Panel Data Analysis<a class="anchor" aria-label="anchor" href="#tests-for-assumptions-in-panel-data-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>We typically don’t test heteroskedasticity explicitly because robust covariance matrix estimation is used. However, other key assumptions should be tested before choosing the appropriate panel model.</p>
<div class="sourceCode" id="cb423"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://cran.r-project.org/package=plm">"plm"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"EmplUK"</span>, package<span class="op">=</span><span class="st">"plm"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Produc"</span>, package<span class="op">=</span><span class="st">"plm"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Grunfeld"</span>, package<span class="op">=</span><span class="st">"plm"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Wages"</span>, package<span class="op">=</span><span class="st">"plm"</span><span class="op">)</span></span></code></pre></div>
<div id="poolability-test" class="section level4" number="11.5.8.1">
<h4>
<span class="header-section-number">11.5.8.1</span> Poolability Test<a class="anchor" aria-label="anchor" href="#poolability-test"><i class="fas fa-link"></i></a>
</h4>
<p>Tests whether coefficients are the same across individuals (also known as an <span class="math inline">\(F\)</span>-test of stability or Chow test).</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: All individuals have the same coefficients (i.e., equal coefficients for all individuals).</p></li>
<li><p><span class="math inline">\(H_a\)</span>: Different individuals have different coefficients.</p></li>
</ul>
<p>Notes:</p>
<ul>
<li><p>A fixed effects model assumes different intercepts per individual.</p></li>
<li><p>A random effects model assumes a common intercept.</p></li>
</ul>
<div class="sourceCode" id="cb424"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span><span class="fu">plm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pooltest.html">pooltest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>              data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>              model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F statistic</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; F = 5.7805, df1 = 18, df2 = 170, p-value = 1.219e-10</span></span>
<span><span class="co">#&gt; alternative hypothesis: unstability</span></span></code></pre></div>
<p>If the null is rejected, we should not use a pooled OLS model.</p>
</div>
<div id="testing-for-individual-and-time-effects" class="section level4" number="11.5.8.2">
<h4>
<span class="header-section-number">11.5.8.2</span> Testing for Individual and Time Effects<a class="anchor" aria-label="anchor" href="#testing-for-individual-and-time-effects"><i class="fas fa-link"></i></a>
</h4>
<p>Checks for the presence of individual or time effects, or both.</p>
<ul>
<li>
<p><strong>Types of tests:</strong></p>
<ul>
<li><p><code>honda</code>: Default test for individual effects <span class="citation">(<a href="references.html#ref-honda1985testing">Honda 1985</a>)</span></p></li>
<li><p><code>bp</code>: Breusch-Pagan test for unbalanced panels <span class="citation">(<a href="references.html#ref-Breusch_1980">Breusch and Pagan 1980</a>)</span></p></li>
<li><p><code>kw</code>: King-Wu test for unbalanced panels with two-way effects <span class="citation">(<a href="references.html#ref-King_1997">M. L. King and Wu 1997</a>)</span></p></li>
<li><p><code>ghm</code>: Gourieroux, Holly, and Monfort test for two-way effects <span class="citation">(<a href="references.html#ref-gourieroux1982likelihood">Gourieroux, Holly, and Monfort 1982</a>)</span></p></li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb425"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pFtest.html">pFtest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>       data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>       effect <span class="op">=</span> <span class="st">"twoways"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F test for twoways effects</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; F = 17.403, df1 = 28, df2 = 169, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pFtest.html">pFtest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>       data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>       effect <span class="op">=</span> <span class="st">"individual"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F test for individual effects</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; F = 49.177, df1 = 9, df2 = 188, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pFtest.html">pFtest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>       data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>       effect <span class="op">=</span> <span class="st">"time"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F test for time effects</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; F = 0.23451, df1 = 19, df2 = 178, p-value = 0.9997</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span></code></pre></div>
<p>If the null hypothesis is rejected, a fixed effects model is more appropriate.</p>
</div>
<div id="cross-sectional-dependence-contemporaneous-correlation" class="section level4" number="11.5.8.3">
<h4>
<span class="header-section-number">11.5.8.3</span> Cross-Sectional Dependence (Contemporaneous Correlation)<a class="anchor" aria-label="anchor" href="#cross-sectional-dependence-contemporaneous-correlation"><i class="fas fa-link"></i></a>
</h4>
<p>Tests whether residuals across entities are correlated.</p>
<div id="global-cross-sectional-dependence" class="section level5" number="11.5.8.3.1">
<h5>
<span class="header-section-number">11.5.8.3.1</span> Global Cross-Sectional Dependence<a class="anchor" aria-label="anchor" href="#global-cross-sectional-dependence"><i class="fas fa-link"></i></a>
</h5>
<div class="sourceCode" id="cb426"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pcdtest.html">pcdtest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>        data <span class="op">=</span> <span class="va">Grunfeld</span>, model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pesaran CD test for cross-sectional dependence in panels</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; z = 4.6612, p-value = 3.144e-06</span></span>
<span><span class="co">#&gt; alternative hypothesis: cross-sectional dependence</span></span></code></pre></div>
</div>
<div id="local-cross-sectional-dependence" class="section level5" number="11.5.8.3.2">
<h5>
<span class="header-section-number">11.5.8.3.2</span> Local Cross-Sectional Dependence<a class="anchor" aria-label="anchor" href="#local-cross-sectional-dependence"><i class="fas fa-link"></i></a>
</h5>
<p>Uses a spatial weight matrix <strong>w</strong>.</p>
<div class="sourceCode" id="cb427"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pcdtest.html">pcdtest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>        data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>        model <span class="op">=</span> <span class="st">"within"</span>, </span>
<span>        w <span class="op">=</span> <span class="va">weight_matrix</span><span class="op">)</span></span></code></pre></div>
<p>If the null is rejected, cross-sectional correlation exists and should be addressed.</p>
</div>
</div>
<div id="serial-correlation-in-panel-data" class="section level4" number="11.5.8.4">
<h4>
<span class="header-section-number">11.5.8.4</span> Serial Correlation in Panel Data<a class="anchor" aria-label="anchor" href="#serial-correlation-in-panel-data"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<strong>Null hypothesis</strong>: There is no serial correlation.</li>
<li>Serial correlation is typically observed in macro panels with long time series (large <span class="math inline">\(N\)</span> and <span class="math inline">\(T\)</span>). It is less relevant in micro panels with short time series (small <span class="math inline">\(T\)</span> and large <span class="math inline">\(N\)</span>).</li>
<li>
<strong>Sources of Serial Correlation:</strong>
<ul>
<li>
<strong>Unobserved individual effects:</strong> Time-invariant error components.</li>
<li>
<strong>Idiosyncratic error terms:</strong> Often modeled as an autoregressive process (e.g., AR(1)).</li>
<li>Typically, “serial correlation” refers to the second type (idiosyncratic errors).</li>
</ul>
</li>
</ul>
<p>Types of Serial Correlation Tests</p>
<ul>
<li>
<strong>Marginal tests:</strong> Test for one type of dependence at a time but may be biased towards rejection.</li>
<li>
<strong>Joint tests:</strong> Detect both sources of dependence but do not distinguish the source of the problem.</li>
<li>
<strong>Conditional tests:</strong> Assume one dependence structure is correctly specified and test for additional departures.</li>
</ul>
<div id="unobserved-effects-test" class="section level5" number="11.5.8.4.1">
<h5>
<span class="header-section-number">11.5.8.4.1</span> Unobserved Effects Test<a class="anchor" aria-label="anchor" href="#unobserved-effects-test"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li>A semi-parametric test for unobserved effects, with the test statistic <span class="math inline">\(W \sim N\)</span> regardless of the error distribution.</li>
<li>Null hypothesis (<span class="math inline">\(H_0\)</span>): No unobserved effects (<span class="math inline">\(\sigma^2_\mu = 0\)</span>), which supports using pooled OLS.</li>
<li>Under <span class="math inline">\(H_0\)</span>: The covariance matrix of residuals is diagonal (no off-diagonal correlations).</li>
<li>Robustness: The test is robust to both unobserved individual effects and serial correlation.</li>
</ul>
<div class="sourceCode" id="cb428"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Produc"</span>, package <span class="op">=</span> <span class="st">"plm"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wooldridge test for unobserved individual effects</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pwtest.html">pwtest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>       data <span class="op">=</span> <span class="va">Produc</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Wooldridge's test for unobserved individual effects</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  formula</span></span>
<span><span class="co">#&gt; z = 3.9383, p-value = 8.207e-05</span></span>
<span><span class="co">#&gt; alternative hypothesis: unobserved effect</span></span></code></pre></div>
<p><strong>Interpretation:</strong> If we reject <span class="math inline">\(H_0\)</span>, pooled OLS is inappropriate due to the presence of unobserved effects.</p>
</div>
<div id="locally-robust-tests-for-serial-correlation-and-random-effects" class="section level5" number="11.5.8.4.2">
<h5>
<span class="header-section-number">11.5.8.4.2</span> Locally Robust Tests for Serial Correlation and Random Effects<a class="anchor" aria-label="anchor" href="#locally-robust-tests-for-serial-correlation-and-random-effects"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>Joint LM Test for Random Effects and Serial Correlation</p></li>
<li>
<p>A Lagrange Multiplier test to jointly detect:</p>
<ul>
<li>Random effects (panel-level variance components).</li>
<li>Serial correlation (time-series dependence).</li>
</ul>
</li>
<li>
<p>Null Hypothesis: Normality and homoskedasticity of idiosyncratic errors <span class="citation">(<a href="references.html#ref-baltagi1991joint">Baltagi and Li 1991</a>, <a href="references.html#ref-baltagi1995testing">1995</a>)</span>.</p>
<ul>
<li>This is equivalent to assuming there is no presence of serial correlation, and random effects.</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb429"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Baltagi and Li's joint test for serial correlation and random effects</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pbsytest.html">pbsytest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>         data <span class="op">=</span> <span class="va">Produc</span>, </span>
<span>         test <span class="op">=</span> <span class="st">"j"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Baltagi and Li AR-RE joint test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  formula</span></span>
<span><span class="co">#&gt; chisq = 4187.6, df = 2, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: AR(1) errors or random effects</span></span></code></pre></div>
<p>Interpretation: If we reject <span class="math inline">\(H_0\)</span>, either serial correlation, random effects, or both are present. But we don’t know the source of dependence.</p>
<p>To distinguish the source of dependence, we use either (both tests assume normality and homoskedasticity) <span class="citation">(<a href="references.html#ref-bera2001tests">Bera, Sosa-Escudero, and Yoon 2001</a>)</span>:</p>
<p><strong>BSY Test for Serial Correlation</strong></p>
<div class="sourceCode" id="cb430"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pbsytest.html">pbsytest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>         data <span class="op">=</span> <span class="va">Produc</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Bera, Sosa-Escudero and Yoon locally robust test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  formula</span></span>
<span><span class="co">#&gt; chisq = 52.636, df = 1, p-value = 4.015e-13</span></span>
<span><span class="co">#&gt; alternative hypothesis: AR(1) errors sub random effects</span></span></code></pre></div>
<p><strong>BSY Test for Random Effects</strong></p>
<div class="sourceCode" id="cb431"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pbsytest.html">pbsytest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>         data <span class="op">=</span> <span class="va">Produc</span>, </span>
<span>         test <span class="op">=</span> <span class="st">"re"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Bera, Sosa-Escudero and Yoon locally robust test (one-sided)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  formula</span></span>
<span><span class="co">#&gt; z = 57.914, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: random effects sub AR(1) errors</span></span></code></pre></div>
<p>If serial correlation is “known” to be absent (based on the BSY test), the <strong>LM test for random effects</strong> is superior.</p>
<div class="sourceCode" id="cb432"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/plmtest.html">plmtest</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>        data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>        type <span class="op">=</span> <span class="st">"honda"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Lagrange Multiplier Test - (Honda)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; normal = 28.252, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span></code></pre></div>
<p>If random effects are absent (based on the BSY test), we use <strong>Breusch-Godfrey’s serial correlation test</strong> <span class="citation">(<a href="references.html#ref-breusch1978testing">Breusch 1978</a>; <a href="references.html#ref-godfrey1978testing">Godfrey 1978</a>)</span>.</p>
<div class="sourceCode" id="cb433"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">lmtest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/bgtest.html">bgtest</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><strong>If Random Effects are Present: Use Baltagi and Li’s Test</strong></p>
<p>Baltagi and Li’s test detects serial correlation in AR(1) and MA(1) processes under random effects.</p>
<ul>
<li><p>Null hypothesis (<span class="math inline">\(H_0\)</span>): Uncorrelated errors.</p></li>
<li>
<p>Note:</p>
<ul>
<li><p>The test has power only against positive serial correlation (one-sided).</p></li>
<li><p>It is applicable only to balanced panels</p></li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb434"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pbltest.html">pbltest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>        data <span class="op">=</span> <span class="va">Produc</span>, </span>
<span>        alternative <span class="op">=</span> <span class="st">"onesided"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Baltagi and Li one-sided LM test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; z = 21.69, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: AR(1)/MA(1) errors in RE panel model</span></span></code></pre></div>
</div>
<div id="general-serial-correlation-tests" class="section level5" number="11.5.8.4.3">
<h5>
<span class="header-section-number">11.5.8.4.3</span> General Serial Correlation Tests<a class="anchor" aria-label="anchor" href="#general-serial-correlation-tests"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>Applicable to <strong>random effects, pooled OLS, and fixed effects</strong> models.</p></li>
<li><p>Can test for <strong>higher-order serial correlation</strong>.</p></li>
</ul>
<div class="sourceCode" id="cb435"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Baltagi-Griffin test for higher-order serial correlation</span></span>
<span><span class="fu">plm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pbgtest.html">pbgtest</a></span><span class="op">(</span><span class="fu">plm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, </span>
<span>                      data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>                      model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span>, </span>
<span>             order <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Breusch-Godfrey/Wooldridge test for serial correlation in panel models</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; chisq = 42.587, df = 2, p-value = 5.655e-10</span></span>
<span><span class="co">#&gt; alternative hypothesis: serial correlation in idiosyncratic errors</span></span></code></pre></div>
<p>For short panels (Small <span class="math inline">\(T\)</span>, Large <span class="math inline">\(N\)</span>), use Wooldridge’s test:</p>
<div class="sourceCode" id="cb436"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pwartest.html">pwartest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">capital</span><span class="op">)</span>, </span>
<span>         data <span class="op">=</span> <span class="va">EmplUK</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Wooldridge's test for serial correlation in FE panels</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  plm.model</span></span>
<span><span class="co">#&gt; F = 312.3, df1 = 1, df2 = 889, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: serial correlation</span></span></code></pre></div>
</div>
</div>
<div id="unit-roots-and-stationarity-in-panel-data" class="section level4" number="11.5.8.5">
<h4>
<span class="header-section-number">11.5.8.5</span> Unit Roots and Stationarity in Panel Data<a class="anchor" aria-label="anchor" href="#unit-roots-and-stationarity-in-panel-data"><i class="fas fa-link"></i></a>
</h4>
<div id="dickey-fuller-test-for-stochastic-trends" class="section level5" number="11.5.8.5.1">
<h5>
<span class="header-section-number">11.5.8.5.1</span> Dickey-Fuller Test for Stochastic Trends<a class="anchor" aria-label="anchor" href="#dickey-fuller-test-for-stochastic-trends"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li>Purpose: Tests for the presence of a unit root (non-stationarity) in a time series.</li>
<li>Null hypothesis (<span class="math inline">\(H_0\)</span>): The series is non-stationary (i.e., it has a unit root).</li>
<li>Alternative hypothesis (<span class="math inline">\(H_A\)</span>): The series is stationary (no unit root).</li>
<li>Decision Rule:
<ul>
<li>If the test statistic is less than the critical value (or <span class="math inline">\(p &lt; 0.05\)</span>), reject <span class="math inline">\(H_0\)</span>, indicating stationarity.</li>
<li>If the test statistic is greater than the critical value (or <span class="math inline">\(p \geq 0.05\)</span>), fail to reject <span class="math inline">\(H_0\)</span>, suggesting the presence of a unit root.</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb437"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">tseries</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Example: Test for unit root in GDP data</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tseries/man/adf.test.html">adf.test</a></span><span class="op">(</span><span class="va">Produc</span><span class="op">$</span><span class="va">gsp</span>, alternative <span class="op">=</span> <span class="st">"stationary"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Augmented Dickey-Fuller Test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  Produc$gsp</span></span>
<span><span class="co">#&gt; Dickey-Fuller = -6.5425, Lag order = 9, p-value = 0.01</span></span>
<span><span class="co">#&gt; alternative hypothesis: stationary</span></span></code></pre></div>
<p>If we reject <span class="math inline">\(H_0\)</span>, the series is <strong>stationary</strong> and does not exhibit a stochastic trend.</p>
</div>
<div id="levin-lin-chu-unit-root-test" class="section level5" number="11.5.8.5.2">
<h5>
<span class="header-section-number">11.5.8.5.2</span> Levin-Lin-Chu Unit Root Test<a class="anchor" aria-label="anchor" href="#levin-lin-chu-unit-root-test"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li>Purpose: Tests for the presence of a unit root in a panel dataset.</li>
<li>Null hypothesis (<span class="math inline">\(H_0\)</span>): The series has a unit root (non-stationary).</li>
<li>Alternative hypothesis (<span class="math inline">\(H_A\)</span>): The series is stationary.</li>
<li>Assumptions: Requires large <span class="math inline">\(N\)</span> (cross-sections) and moderate <span class="math inline">\(T\)</span> (time periods).</li>
<li>Decision Rule: If the test statistic is less than the critical value or <span class="math inline">\(p &lt; 0.05\)</span>, reject <span class="math inline">\(H_0\)</span> (evidence of stationarity).</li>
</ul>
<div class="sourceCode" id="cb438"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">tseries</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Levin-Lin-Chu (LLC) Unit Root Test</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/purtest.html">purtest</a></span><span class="op">(</span><span class="va">Grunfeld</span>, test <span class="op">=</span> <span class="st">"levinlin"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Levin-Lin-Chu Unit-Root Test (ex. var.: None)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  Grunfeld</span></span>
<span><span class="co">#&gt; z = 0.39906, p-value = 0.6551</span></span>
<span><span class="co">#&gt; alternative hypothesis: stationarity</span></span></code></pre></div>
<p>If we reject <span class="math inline">\(H_0\)</span>, the series is <strong>stationary</strong>.</p>
</div>
</div>
<div id="heteroskedasticity-in-panel-data" class="section level4" number="11.5.8.6">
<h4>
<span class="header-section-number">11.5.8.6</span> Heteroskedasticity in Panel Data<a class="anchor" aria-label="anchor" href="#heteroskedasticity-in-panel-data"><i class="fas fa-link"></i></a>
</h4>
<div id="breusch-pagan-test" class="section level5" number="11.5.8.6.1">
<h5>
<span class="header-section-number">11.5.8.6.1</span> Breusch-Pagan Test<a class="anchor" aria-label="anchor" href="#breusch-pagan-test"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>Purpose: Detects heteroskedasticity in regression residuals.</p></li>
<li><p>Null hypothesis (<span class="math inline">\(H_0\)</span>): The data is homoskedastic (constant variance).</p></li>
<li><p>Alternative hypothesis (<span class="math inline">\(H_A\)</span>): The data exhibits heteroskedasticity (non-constant variance).</p></li>
<li>
<p>Decision Rule:</p>
<ul>
<li><p>If the p-value is small (e.g., <span class="math inline">\(p &lt; 0.05\)</span>), reject <span class="math inline">\(H_0\)</span>, suggesting heteroskedasticity.</p></li>
<li><p>If the p-value is large (<span class="math inline">\(p \geq 0.05\)</span>), fail to reject <span class="math inline">\(H_0\)</span>, implying homoskedasticity.</p></li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb439"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">lmtest</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit a panel model (pooled OLS)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>            data <span class="op">=</span> <span class="va">Produc</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Breusch-Pagan Test for Heteroskedasticity</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/bptest.html">bptest</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  studentized Breusch-Pagan test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  model</span></span>
<span><span class="co">#&gt; BP = 80.033, df = 4, p-value &lt; 2.2e-16</span></span></code></pre></div>
<p>If heteroskedasticity is detected, we need to adjust for it using <strong>robust standard errors</strong>.</p>
</div>
<div id="robust-covariance-matrix-estimation-sandwich-estimator" class="section level5" number="11.5.8.6.2">
<h5>
<span class="header-section-number">11.5.8.6.2</span> Robust Covariance Matrix Estimation (Sandwich Estimator)<a class="anchor" aria-label="anchor" href="#robust-covariance-matrix-estimation-sandwich-estimator"><i class="fas fa-link"></i></a>
</h5>
<p>If heteroskedasticity is present, robust covariance matrix estimation is recommended. Different estimators apply depending on whether serial correlation is also an issue.</p>
<p>Choosing the Correct Robust Covariance Matrix Estimator</p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="13%">
<col width="38%">
<col width="32%">
<col width="16%">
</colgroup>
<thead><tr class="header">
<th>Estimator</th>
<th>Corrects for Heteroskedasticity?</th>
<th>Corrects for Serial Correlation?</th>
<th>Recommended For</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>"white1"</code></td>
<td>✅ Yes</td>
<td>❌ No</td>
<td>Random Effects</td>
</tr>
<tr class="even">
<td><code>"white2"</code></td>
<td>✅ Yes (common variance within groups)</td>
<td>❌ No</td>
<td>Random Effects</td>
</tr>
<tr class="odd">
<td><code>"arellano"</code></td>
<td>✅ Yes</td>
<td>✅ Yes</td>
<td>Fixed Effects</td>
</tr>
</tbody>
</table></div>
<div class="sourceCode" id="cb440"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit a fixed effects model</span></span>
<span><span class="va">fe_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pc</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>                data <span class="op">=</span> <span class="va">Produc</span>, </span>
<span>                model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute robust standard errors using Arellano's method</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">fe_model</span>, vcov <span class="op">=</span> <span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">vcovHC</a></span><span class="op">(</span><span class="va">fe_model</span>, method <span class="op">=</span> <span class="st">"arellano"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; log(pcap) -0.0261497  0.0603262 -0.4335   0.66480    </span></span>
<span><span class="co">#&gt; log(pc)    0.2920069  0.0617425  4.7294 2.681e-06 ***</span></span>
<span><span class="co">#&gt; log(emp)   0.7681595  0.0816652  9.4062 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; unemp     -0.0052977  0.0024958 -2.1226   0.03411 *  </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Using a robust covariance matrix corrects for heteroskedasticity and/or serial correlation, ensuring valid inference.</p>
<hr>
</div>
</div>
</div>
<div id="model-selection-in-panel-data" class="section level3" number="11.5.9">
<h3>
<span class="header-section-number">11.5.9</span> Model Selection in Panel Data<a class="anchor" aria-label="anchor" href="#model-selection-in-panel-data"><i class="fas fa-link"></i></a>
</h3>
<p>Panel data models must be chosen based on the structure of the data and underlying assumptions. This section provides guidance on selecting between <a href="data.html#sec-pooled-ols-estimator">Pooled OLS</a>, <a href="data.html#sec-random-effects-estimator">Random Effects</a>, and <a href="data.html#sec-fixed-effects-estimator">Fixed Effects</a> models.</p>
<hr>
<div id="pooled-ols-vs.-random-effects" class="section level4" number="11.5.9.1">
<h4>
<span class="header-section-number">11.5.9.1</span> Pooled OLS vs. Random Effects<a class="anchor" aria-label="anchor" href="#pooled-ols-vs.-random-effects"><i class="fas fa-link"></i></a>
</h4>
<p>The choice between POLS and RE depends on whether there are unobserved individual effects.</p>
<p><strong>Breusch-Pagan Lagrange Multiplier Test</strong></p>
<ul>
<li>
<strong>Purpose:</strong> Tests whether a random effects model is preferable to a pooled OLS model.</li>
<li>
<strong>Null hypothesis (</strong><span class="math inline">\(H_0\)</span>): Variance across entities is zero (i.e., no panel effect → POLS is preferred).</li>
<li>
<strong>Alternative hypothesis (</strong><span class="math inline">\(H_A\)</span>): There is significant panel-level variation → <strong>RE is preferable to POLS</strong>.</li>
<li>
<strong>Decision Rule:</strong> If <span class="math inline">\(p &lt; 0.05\)</span>, reject <span class="math inline">\(H_0\)</span>, indicating that RE is preferred.</li>
</ul>
<div class="sourceCode" id="cb441"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Breusch-Pagan LM Test</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/plmtest.html">plmtest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, data <span class="op">=</span> <span class="va">Grunfeld</span>, </span>
<span>            model <span class="op">=</span> <span class="st">"pooling"</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"bp"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Lagrange Multiplier Test - (Breusch-Pagan)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; chisq = 798.16, df = 1, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span></code></pre></div>
<p>If the test is significant, RE is more appropriate than POLS.</p>
</div>
<div id="fixed-effects-vs.-random-effects" class="section level4" number="11.5.9.2">
<h4>
<span class="header-section-number">11.5.9.2</span> Fixed Effects vs. Random Effects<a class="anchor" aria-label="anchor" href="#fixed-effects-vs.-random-effects"><i class="fas fa-link"></i></a>
</h4>
<p>The choice between <strong>FE and RE</strong> depends on whether the individual-specific effects are correlated with the regressors.</p>
<p><strong>Key Assumptions and Properties</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="33%">
<col width="66%">
</colgroup>
<thead><tr class="header">
<th>Hypothesis</th>
<th>If True</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(H_0: \text{Cov}(c_i, \mathbf{x_{it}}) = 0\)</span></td>
<td>
<span class="math inline">\(\hat{\beta}{RE}\)</span> <em>is <strong>consistent and efficient</strong>, while</em> <span class="math inline">\(\hat{\beta}{FE}\)</span> is <strong>consistent</strong>
</td>
</tr>
<tr class="even">
<td><span class="math inline">\(H_0: \text{Cov}(c_i, \mathbf{x_{it}}) \neq 0\)</span></td>
<td>
<span class="math inline">\(\hat{\beta}{RE}\)</span> <em>is <strong>inconsistent</strong>, while</em> <span class="math inline">\(\hat{\beta}{FE}\)</span> remains <strong>consistent</strong>
</td>
</tr>
</tbody>
</table></div>
<p><strong>Hausman Test</strong></p>
<ul>
<li>
<strong>Purpose:</strong> Determines whether FE or RE is appropriate.</li>
</ul>
<p>For the Hausman test to work, you need to assume that</p>
<ul>
<li>Strict exogeneity hold</li>
<li>
<a href="linear-regression.html#a4-homoskedasticity">A4</a> to hold for <span class="math inline">\(u_{it}\)</span>
</li>
</ul>
<p>Then,</p>
<ul>
<li>Hausman test statistic: <span class="math inline">\(H=(\hat{\beta}_{RE}-\hat{\beta}_{FE})'(V(\hat{\beta}_{RE})- V(\hat{\beta}_{FE}))(\hat{\beta}_{RE}-\hat{\beta}_{FE}) \sim \chi_{n(X)}^2\)</span> where <span class="math inline">\(n(X)\)</span> is the number of parameters for the time-varying regressors.</li>
<li>
<strong>Null hypothesis (</strong><span class="math inline">\(H_0\)</span><strong>):</strong> RE estimator is consistent and efficient.</li>
<li>
<strong>Alternative hypothesis (</strong><span class="math inline">\(H_A\)</span><strong>):</strong> RE estimator is inconsistent, meaning FE should be used.</li>
<li>
<strong>Decision Rule:</strong>
<ul>
<li><p>If <span class="math inline">\(p &lt; 0.05\)</span>: Reject <span class="math inline">\(H_0\)</span>, meaning FE is preferred.</p></li>
<li><p>If <span class="math inline">\(p \geq 0.05\)</span>: Fail to reject <span class="math inline">\(H_0\)</span>, meaning RE can be used.</p></li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb442"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit FE and RE models</span></span>
<span><span class="va">fe_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, data <span class="op">=</span> <span class="va">Grunfeld</span>, model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span></span>
<span><span class="va">re_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="va">inv</span> <span class="op">~</span> <span class="va">value</span> <span class="op">+</span> <span class="va">capital</span>, data <span class="op">=</span> <span class="va">Grunfeld</span>, model <span class="op">=</span> <span class="st">"random"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Hausman test</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/phtest.html">phtest</a></span><span class="op">(</span><span class="va">fe_model</span>, <span class="va">re_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hausman Test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  inv ~ value + capital</span></span>
<span><span class="co">#&gt; chisq = 2.3304, df = 2, p-value = 0.3119</span></span>
<span><span class="co">#&gt; alternative hypothesis: one model is inconsistent</span></span></code></pre></div>
<p>If the null hypothesis is rejected, use FE. If not, RE is appropriate.</p>
</div>
<div id="summary-of-model-assumptions-and-consistency" class="section level4" number="11.5.9.3">
<h4>
<span class="header-section-number">11.5.9.3</span> Summary of Model Assumptions and Consistency<a class="anchor" aria-label="anchor" href="#summary-of-model-assumptions-and-consistency"><i class="fas fa-link"></i></a>
</h4>
<p>All three estimators (POLS, RE, FE) require:</p>
<ul>
<li><p><a href="linear-regression.html#a1-linearity">A1</a> Linearity</p></li>
<li><p><a href="linear-regression.html#a2-full-rank">A2</a> Full rank</p></li>
<li><p><a href="linear-regression.html#a5-data-generation-random-sampling">A5</a> Data generation (random sampling) for individuals</p></li>
</ul>
<p>However, additional assumptions determine whether the estimator is <strong>consistent and efficient</strong>.</p>
<p><strong>POLS</strong></p>
<ul>
<li>
<p><strong>Consistent if:</strong></p>
<ul>
<li><p><a href="linear-regression.html#a3a-weak-exogeneity">A3a</a> Exogeneity holds: <span class="math inline">\(E(\mathbf{x}_{it}' u_{it}) = 0\)</span></p></li>
<li><p>RE assumption holds: <span class="math inline">\(E(\mathbf{x}_{it}' c_{i}) = 0\)</span></p></li>
</ul>
</li>
<li><p>If <a href="linear-regression.html#a4-homoskedasticity">A4</a> Homoskedasticity does not hold: Use cluster-robust standard errors, but POLS is not efficient.</p></li>
</ul>
<p><strong>RE</strong></p>
<ul>
<li>
<p><strong>Consistent if:</strong></p>
<ul>
<li><p><a href="linear-regression.html#a3a-weak-exogeneity">A3a</a> Exogeneity holds: <span class="math inline">\(E(\mathbf{x}_{it}' u_{it}) = 0\)</span></p></li>
<li><p>RE assumption holds: <span class="math inline">\(E(\mathbf{x}_{it}' c_{i}) = 0\)</span></p></li>
</ul>
</li>
<li><p>If <a href="linear-regression.html#a4-homoskedasticity">A4</a> Homoskedasticity holds: RE is most efficient.</p></li>
<li><p>If <a href="linear-regression.html#a4-homoskedasticity">A4</a> Homoskedasticity does not hold: Use cluster-robust standard errors. RE remains more efficient than POLS but is not the most efficient.</p></li>
</ul>
<p><strong>FE</strong></p>
<ul>
<li>
<p><strong>Consistent if:</strong></p>
<ul>
<li>
<a href="linear-regression.html#a3a-weak-exogeneity">A3a</a> Exogeneity holds: <span class="math inline">\(E((\mathbf{x}_{it} - \bar{\mathbf{x}}_{it})'(u_{it} - \bar{u}_{it})) = 0\)</span>
</li>
</ul>
</li>
<li>
<p><strong>Limitations:</strong></p>
<ul>
<li><p>Cannot estimate the effects of time-constant variables.</p></li>
<li><p><a href="linear-regression.html#a4-homoskedasticity">A4</a> Homoskedasticity generally does not hold, so cluster-robust SEs are required.</p></li>
</ul>
</li>
</ul>
<p><strong>Estimator Selection Guide</strong></p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="33%">
<col width="21%">
<col width="21%">
<col width="23%">
</colgroup>
<thead><tr class="header">
<th>Estimator / True Model</th>
<th>POLS</th>
<th>RE</th>
<th>FE</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>POLS</td>
<td>✅ Consistent</td>
<td>✅ Consistent</td>
<td>❌ Inconsistent</td>
</tr>
<tr class="even">
<td>FE</td>
<td>✅ Consistent</td>
<td>✅ Consistent</td>
<td>✅ Consistent</td>
</tr>
<tr class="odd">
<td>RE</td>
<td>✅ Consistent</td>
<td>✅ Consistent</td>
<td>❌ Inconsistent</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="alternative-estimators" class="section level3" number="11.5.10">
<h3>
<span class="header-section-number">11.5.10</span> Alternative Estimators<a class="anchor" aria-label="anchor" href="#alternative-estimators"><i class="fas fa-link"></i></a>
</h3>
<p>Other estimators are available depending on model violations and additional considerations:</p>
<ul>
<li><p><strong>Violation Estimators</strong>: Adjust for assumption violations.</p></li>
<li><p><strong>Basic Estimators</strong>: Standard POLS, RE, FE.</p></li>
<li><p><strong>Instrumental Variable Estimator</strong>: Used for endogeneity.</p></li>
<li><p><strong>Variable Coefficient Estimator</strong>: Allows varying coefficients.</p></li>
<li><p><strong>Generalized Method of Moments Estimator</strong>: For dynamic panel models.</p></li>
<li><p><strong>General Feasible GLS Estimator</strong>: Accounts for heteroskedasticity and serial correlation.</p></li>
<li><p><strong>Means Groups Estimator</strong>: Averages individual-specific estimates.</p></li>
<li><p><strong>Common Correlated Effects Mean Group Estimator</strong>: Accounts for cross-sectional dependence.</p></li>
<li><p><strong>Limited Dependent Variable Estimators</strong>: Used for binary or censored data.</p></li>
</ul>
</div>
<div id="application-1" class="section level3" number="11.5.11">
<h3>
<span class="header-section-number">11.5.11</span> Application<a class="anchor" aria-label="anchor" href="#application-1"><i class="fas fa-link"></i></a>
</h3>
<div id="plm-package" class="section level4" number="11.5.11.1">
<h4>
<span class="header-section-number">11.5.11.1</span> <code>plm</code> Package<a class="anchor" aria-label="anchor" href="#plm-package"><i class="fas fa-link"></i></a>
</h4>
<p>The <code>plm</code> package in R is designed for panel data analysis, allowing users to estimate various models, including <strong>pooled OLS</strong>, <strong>fixed effects</strong>, <strong>random effects</strong>, and other specifications commonly used in econometrics.</p>
<p>For a detailed guide, refer to:</p>
<ul>
<li><p>The <a href="https://cran.r-project.org/web/packages/plm/vignettes/B_plmFunction.html">official vignette</a> on <code>plm</code> functions.</p></li>
<li><p>The <a href="https://cran.r-project.org/web/packages/plm/vignettes/C_plmModelComponents.html">model components reference</a>.</p></li>
</ul>
<div class="sourceCode" id="cb443"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load the package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://cran.r-project.org/package=plm">"plm"</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Produc"</span>, package <span class="op">=</span> <span class="st">"plm"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display first few rows</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Produc</span><span class="op">)</span></span>
<span><span class="co">#&gt;     state year region     pcap     hwy   water    util       pc   gsp    emp</span></span>
<span><span class="co">#&gt; 1 ALABAMA 1970      6 15032.67 7325.80 1655.68 6051.20 35793.80 28418 1010.5</span></span>
<span><span class="co">#&gt; 2 ALABAMA 1971      6 15501.94 7525.94 1721.02 6254.98 37299.91 29375 1021.9</span></span>
<span><span class="co">#&gt; 3 ALABAMA 1972      6 15972.41 7765.42 1764.75 6442.23 38670.30 31303 1072.3</span></span>
<span><span class="co">#&gt; 4 ALABAMA 1973      6 16406.26 7907.66 1742.41 6756.19 40084.01 33430 1135.5</span></span>
<span><span class="co">#&gt; 5 ALABAMA 1974      6 16762.67 8025.52 1734.85 7002.29 42057.31 33749 1169.8</span></span>
<span><span class="co">#&gt; 6 ALABAMA 1975      6 17316.26 8158.23 1752.27 7405.76 43971.71 33604 1155.4</span></span>
<span><span class="co">#&gt;   unemp</span></span>
<span><span class="co">#&gt; 1   4.7</span></span>
<span><span class="co">#&gt; 2   5.2</span></span>
<span><span class="co">#&gt; 3   4.7</span></span>
<span><span class="co">#&gt; 4   3.9</span></span>
<span><span class="co">#&gt; 5   5.5</span></span>
<span><span class="co">#&gt; 6   7.7</span></span></code></pre></div>
<p>To specify panel data, we define the <strong>individual (cross-sectional) and time identifiers</strong>:</p>
<div class="sourceCode" id="cb444"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convert data to panel format</span></span>
<span><span class="va">pdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/pdata.frame.html">pdata.frame</a></span><span class="op">(</span><span class="va">Produc</span>, index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"state"</span>, <span class="st">"year"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check structure</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">pdata</span><span class="op">)</span></span>
<span><span class="co">#&gt;          state          year         region         pcap             hwy       </span></span>
<span><span class="co">#&gt;  ALABAMA    : 17   1970   : 48   5      :136   Min.   :  2627   Min.   : 1827  </span></span>
<span><span class="co">#&gt;  ARIZONA    : 17   1971   : 48   8      :136   1st Qu.:  7097   1st Qu.: 3858  </span></span>
<span><span class="co">#&gt;  ARKANSAS   : 17   1972   : 48   4      :119   Median : 17572   Median : 7556  </span></span>
<span><span class="co">#&gt;  CALIFORNIA : 17   1973   : 48   1      :102   Mean   : 25037   Mean   :10218  </span></span>
<span><span class="co">#&gt;  COLORADO   : 17   1974   : 48   3      : 85   3rd Qu.: 27692   3rd Qu.:11267  </span></span>
<span><span class="co">#&gt;  CONNECTICUT: 17   1975   : 48   6      : 68   Max.   :140217   Max.   :47699  </span></span>
<span><span class="co">#&gt;  (Other)    :714   (Other):528   (Other):170                                   </span></span>
<span><span class="co">#&gt;      water              util               pc              gsp        </span></span>
<span><span class="co">#&gt;  Min.   :  228.5   Min.   :  538.5   Min.   :  4053   Min.   :  4354  </span></span>
<span><span class="co">#&gt;  1st Qu.:  764.5   1st Qu.: 2488.3   1st Qu.: 21651   1st Qu.: 16503  </span></span>
<span><span class="co">#&gt;  Median : 2266.5   Median : 7008.8   Median : 40671   Median : 39987  </span></span>
<span><span class="co">#&gt;  Mean   : 3618.8   Mean   :11199.5   Mean   : 58188   Mean   : 61014  </span></span>
<span><span class="co">#&gt;  3rd Qu.: 4318.7   3rd Qu.:11598.5   3rd Qu.: 64796   3rd Qu.: 68126  </span></span>
<span><span class="co">#&gt;  Max.   :24592.3   Max.   :80728.1   Max.   :375342   Max.   :464550  </span></span>
<span><span class="co">#&gt;                                                                       </span></span>
<span><span class="co">#&gt;       emp              unemp       </span></span>
<span><span class="co">#&gt;  Min.   :  108.3   Min.   : 2.800  </span></span>
<span><span class="co">#&gt;  1st Qu.:  475.0   1st Qu.: 5.000  </span></span>
<span><span class="co">#&gt;  Median : 1164.8   Median : 6.200  </span></span>
<span><span class="co">#&gt;  Mean   : 1747.1   Mean   : 6.602  </span></span>
<span><span class="co">#&gt;  3rd Qu.: 2114.1   3rd Qu.: 7.900  </span></span>
<span><span class="co">#&gt;  Max.   :11258.0   Max.   :18.000  </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>The <code>plm</code> package allows for the estimation of several different panel data models.</p>
<ol style="list-style-type: decimal">
<li><strong>Pooled OLS Estimator</strong></li>
</ol>
<p>A simple <strong>pooled OLS</strong> model assumes a common intercept and ignores individual-specific effects.</p>
<div class="sourceCode" id="cb445"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pooling</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>               data <span class="op">=</span> <span class="va">pdata</span>, </span>
<span>               model <span class="op">=</span> <span class="st">"pooling"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">pooling</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pooling Model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; plm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "pooling")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;      Min.   1st Qu.    Median   3rd Qu.      Max. </span></span>
<span><span class="co">#&gt; -0.302260 -0.085204 -0.018166  0.051783  0.500144 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error t-value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  2.2124123  0.0790988 27.9703  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; log(pcap)    0.4121307  0.0216314 19.0525  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; log(emp)     0.6205834  0.0199495 31.1078  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; unemp       -0.0035444  0.0020539 -1.7257  0.08478 .  </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares:    849.81</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 13.326</span></span>
<span><span class="co">#&gt; R-Squared:      0.98432</span></span>
<span><span class="co">#&gt; Adj. R-Squared: 0.98426</span></span>
<span><span class="co">#&gt; F-statistic: 16990.2 on 3 and 812 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><strong>Between Estimator</strong></li>
</ol>
<p>This estimator takes the average over time for each entity, reducing within-group variation.</p>
<div class="sourceCode" id="cb446"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">between</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>               data <span class="op">=</span> <span class="va">pdata</span>, model <span class="op">=</span> <span class="st">"between"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">between</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect Between Model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; plm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "between")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; Observations used in estimation: 48</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;      Min.   1st Qu.    Median   3rd Qu.      Max. </span></span>
<span><span class="co">#&gt; -0.172055 -0.086456 -0.013203  0.038100  0.394336 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error t-value  Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  2.0784403  0.3277756  6.3410 1.063e-07 ***</span></span>
<span><span class="co">#&gt; log(pcap)    0.4585009  0.0892620  5.1366 6.134e-06 ***</span></span>
<span><span class="co">#&gt; log(emp)     0.5751005  0.0828921  6.9379 1.410e-08 ***</span></span>
<span><span class="co">#&gt; unemp       -0.0031585  0.0145683 -0.2168    0.8294    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares:    48.875</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 0.65861</span></span>
<span><span class="co">#&gt; R-Squared:      0.98652</span></span>
<span><span class="co">#&gt; Adj. R-Squared: 0.98561</span></span>
<span><span class="co">#&gt; F-statistic: 1073.73 on 3 and 44 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>First-Differences Estimator</strong></li>
</ol>
<p>The <strong>first-differences</strong> model eliminates time-invariant effects by differencing adjacent periods.</p>
<div class="sourceCode" id="cb447"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">firstdiff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>                 data <span class="op">=</span> <span class="va">pdata</span>, model <span class="op">=</span> <span class="st">"fd"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">firstdiff</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect First-Difference Model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; plm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "fd")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; Observations used in estimation: 768</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;       Min.    1st Qu.     Median    3rd Qu.       Max. </span></span>
<span><span class="co">#&gt; -0.0846921 -0.0108511  0.0016861  0.0124968  0.1018911 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error t-value  Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  0.0101353  0.0013206  7.6749 5.058e-14 ***</span></span>
<span><span class="co">#&gt; log(pcap)   -0.0167634  0.0453958 -0.3693     0.712    </span></span>
<span><span class="co">#&gt; log(emp)     0.8212694  0.0362737 22.6409 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; unemp       -0.0061615  0.0007516 -8.1978 1.032e-15 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares:    1.0802</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 0.33394</span></span>
<span><span class="co">#&gt; R-Squared:      0.69086</span></span>
<span><span class="co">#&gt; Adj. R-Squared: 0.68965</span></span>
<span><span class="co">#&gt; F-statistic: 569.123 on 3 and 764 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li><strong>Fixed Effects (Within) Estimator</strong></li>
</ol>
<p>Controls for time-invariant heterogeneity by demeaning data within individuals.</p>
<div class="sourceCode" id="cb448"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fixed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>             data <span class="op">=</span> <span class="va">pdata</span>, model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fixed</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect Within Model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; plm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "within")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;       Min.    1st Qu.     Median    3rd Qu.       Max. </span></span>
<span><span class="co">#&gt; -0.1253873 -0.0248746 -0.0054276  0.0184698  0.2026394 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;              Estimate  Std. Error t-value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; log(pcap)  0.03488447  0.03092191  1.1281   0.2596    </span></span>
<span><span class="co">#&gt; log(emp)   1.03017988  0.02161353 47.6636   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp     -0.00021084  0.00096121 -0.2194   0.8264    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares:    18.941</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 1.3077</span></span>
<span><span class="co">#&gt; R-Squared:      0.93096</span></span>
<span><span class="co">#&gt; Adj. R-Squared: 0.92645</span></span>
<span><span class="co">#&gt; F-statistic: 3438.48 on 3 and 765 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li><strong>Random Effects Estimator</strong></li>
</ol>
<p>Accounts for unobserved heterogeneity by modeling it as a random component.</p>
<div class="sourceCode" id="cb449"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">random</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>              data <span class="op">=</span> <span class="va">pdata</span>, model <span class="op">=</span> <span class="st">"random"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">random</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect Random Effect Model </span></span>
<span><span class="co">#&gt;    (Swamy-Arora's transformation)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; plm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "random")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Effects:</span></span>
<span><span class="co">#&gt;                    var  std.dev share</span></span>
<span><span class="co">#&gt; idiosyncratic 0.001709 0.041345 0.103</span></span>
<span><span class="co">#&gt; individual    0.014868 0.121934 0.897</span></span>
<span><span class="co">#&gt; theta: 0.918</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;       Min.    1st Qu.     Median    3rd Qu.       Max. </span></span>
<span><span class="co">#&gt; -0.1246674 -0.0268273 -0.0049657  0.0214145  0.2389889 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error z-value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept) 3.10569727 0.14715985 21.1042   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; log(pcap)   0.03708054 0.02747015  1.3498   0.1771    </span></span>
<span><span class="co">#&gt; log(emp)    1.00937552 0.02103951 47.9752   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp       0.00004806 0.00092301  0.0521   0.9585    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares:    24.523</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 1.4425</span></span>
<span><span class="co">#&gt; R-Squared:      0.94118</span></span>
<span><span class="co">#&gt; Adj. R-Squared: 0.94096</span></span>
<span><span class="co">#&gt; Chisq: 12992.5 on 3 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<p><strong>Model Selection and Diagnostic Tests</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Lagrange Multiplier Test for Random Effects</strong></li>
</ol>
<p>The <strong>Breusch-Pagan LM test</strong> compares random effects with pooled OLS.</p>
<ul>
<li><p><strong>Null Hypothesis:</strong> OLS is preferred.</p></li>
<li><p><strong>Alternative Hypothesis:</strong> Random effects model is appropriate.</p></li>
</ul>
<div class="sourceCode" id="cb450"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/plmtest.html">plmtest</a></span><span class="op">(</span><span class="va">pooling</span>, effect <span class="op">=</span> <span class="st">"individual"</span>, type <span class="op">=</span> <span class="st">"bp"</span><span class="op">)</span> </span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Lagrange Multiplier Test - (Breusch-Pagan)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; chisq = 4567.1, df = 1, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span></code></pre></div>
<p>Other test types: <code>"honda"</code>, <code>"kw"</code>, <code>"ghm"</code>. Other effects: <code>"time"</code>, <code>"twoways"</code>.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Cross-Sectional Dependence Tests</strong></li>
</ol>
<p>Breusch-Pagan LM test for cross-sectional dependence</p>
<div class="sourceCode" id="cb451"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pcdtest.html">pcdtest</a></span><span class="op">(</span><span class="va">fixed</span>, test <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Breusch-Pagan LM test for cross-sectional dependence in panels</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; chisq = 6490.4, df = 1128, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: cross-sectional dependence</span></span></code></pre></div>
<p>Pesaran’s CD statistic</p>
<div class="sourceCode" id="cb452"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pcdtest.html">pcdtest</a></span><span class="op">(</span><span class="va">fixed</span>, test <span class="op">=</span> <span class="st">"cd"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pesaran CD test for cross-sectional dependence in panels</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; z = 37.13, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: cross-sectional dependence</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Serial Correlation Test (Panel Version of the Breusch-Godfrey Test)</strong></li>
</ol>
<p>Used to check for autocorrelation in panel data.</p>
<div class="sourceCode" id="cb453"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pbgtest.html">pbgtest</a></span><span class="op">(</span><span class="va">fixed</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Breusch-Godfrey/Wooldridge test for serial correlation in panel models</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; chisq = 476.92, df = 17, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: serial correlation in idiosyncratic errors</span></span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li><strong>Stationarity Test (Augmented Dickey-Fuller Test)</strong></li>
</ol>
<p>Checks whether a time series variable is stationary.</p>
<div class="sourceCode" id="cb454"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">tseries</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tseries/man/adf.test.html">adf.test</a></span><span class="op">(</span><span class="va">pdata</span><span class="op">$</span><span class="va">gsp</span>, k <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Augmented Dickey-Fuller Test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  pdata$gsp</span></span>
<span><span class="co">#&gt; Dickey-Fuller = -5.9028, Lag order = 2, p-value = 0.01</span></span>
<span><span class="co">#&gt; alternative hypothesis: stationary</span></span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li><strong>F-Test for Fixed Effects vs. Pooled OLS</strong></li>
</ol>
<ul>
<li><p><strong>Null Hypothesis:</strong> Pooled OLS is appropriate.</p></li>
<li><p><strong>Alternative Hypothesis:</strong> Fixed effects model is preferred.</p></li>
</ul>
<div class="sourceCode" id="cb455"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/pFtest.html">pFtest</a></span><span class="op">(</span><span class="va">fixed</span>, <span class="va">pooling</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F test for individual effects</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; F = 149.58, df1 = 47, df2 = 765, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: significant effects</span></span></code></pre></div>
<ol start="6" style="list-style-type: decimal">
<li><strong>Hausman Test for Fixed vs. Random Effects</strong></li>
</ol>
<ul>
<li><p><strong>Null Hypothesis:</strong> Random effects are appropriate.</p></li>
<li><p><strong>Alternative Hypothesis:</strong> Fixed effects are preferred (RE assumptions are violated).</p></li>
</ul>
<div class="sourceCode" id="cb456"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/phtest.html">phtest</a></span><span class="op">(</span><span class="va">random</span>, <span class="va">fixed</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hausman Test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; chisq = 84.924, df = 3, p-value &lt; 2.2e-16</span></span>
<span><span class="co">#&gt; alternative hypothesis: one model is inconsistent</span></span></code></pre></div>
<p><strong>Heteroskedasticity and Robust Standard Errors</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Breusch-Pagan Test for Heteroskedasticity</strong></li>
</ol>
<p>Tests whether heteroskedasticity is present in the panel dataset.</p>
<div class="sourceCode" id="cb457"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">lmtest</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/bptest.html">bptest</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>,  data <span class="op">=</span> <span class="va">pdata</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  studentized Breusch-Pagan test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  log(gsp) ~ log(pcap) + log(emp) + unemp</span></span>
<span><span class="co">#&gt; BP = 98.223, df = 3, p-value &lt; 2.2e-16</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><strong>Correcting for Heteroskedasticity</strong></li>
</ol>
<p>If heteroskedasticity is detected, use robust standard errors:</p>
<p><strong>For Random Effects Model</strong></p>
<div class="sourceCode" id="cb458"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Original coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">random</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept) 3.10569727 0.14715985 21.1042   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; log(pcap)   0.03708054 0.02747015  1.3498   0.1774    </span></span>
<span><span class="co">#&gt; log(emp)    1.00937552 0.02103951 47.9752   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp       0.00004806 0.00092301  0.0521   0.9585    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Heteroskedasticity-consistent standard errors</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">random</span>, <span class="va">vcovHC</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept) 3.10569727 0.23261788 13.3511   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; log(pcap)   0.03708054 0.06125725  0.6053   0.5451    </span></span>
<span><span class="co">#&gt; log(emp)    1.00937552 0.06395880 15.7817   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp       0.00004806 0.00215219  0.0223   0.9822    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Different HC types</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"HC0"</span>, <span class="st">"HC1"</span>, <span class="st">"HC2"</span>, <span class="st">"HC3"</span>, <span class="st">"HC4"</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">vcovHC</a></span><span class="op">(</span><span class="va">random</span>, type <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt;     (Intercept)  log(pcap)   log(emp)       unemp</span></span>
<span><span class="co">#&gt; HC0   0.2326179 0.06125725 0.06395880 0.002152189</span></span>
<span><span class="co">#&gt; HC1   0.2331901 0.06140795 0.06411614 0.002157484</span></span>
<span><span class="co">#&gt; HC2   0.2334857 0.06161618 0.06439057 0.002160392</span></span>
<span><span class="co">#&gt; HC3   0.2343595 0.06197939 0.06482756 0.002168646</span></span>
<span><span class="co">#&gt; HC4   0.2342815 0.06235576 0.06537813 0.002168867</span></span></code></pre></div>
<ul>
<li><p><strong>HC0</strong>: Default heteroskedasticity-consistent (White’s estimator).</p></li>
<li><p><strong>HC1, HC2, HC3</strong>: Recommended for small samples.</p></li>
<li><p><strong>HC4</strong>: Useful for small samples with influential observations.</p></li>
</ul>
<p><strong>For Fixed Effects Model</strong></p>
<div class="sourceCode" id="cb459"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Original coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">fixed</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              Estimate  Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; log(pcap)  0.03488447  0.03092191  1.1281   0.2596    </span></span>
<span><span class="co">#&gt; log(emp)   1.03017988  0.02161353 47.6636   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp     -0.00021084  0.00096121 -0.2194   0.8264    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Heteroskedasticity-consistent standard errors</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">fixed</span>, <span class="va">vcovHC</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              Estimate  Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; log(pcap)  0.03488447  0.06661083  0.5237   0.6006    </span></span>
<span><span class="co">#&gt; log(emp)   1.03017988  0.06413365 16.0630   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp     -0.00021084  0.00217453 -0.0970   0.9228    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Arellano method for robust errors</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/lmtest/man/coeftest.html">coeftest</a></span><span class="op">(</span><span class="va">fixed</span>, <span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">vcovHC</a></span><span class="op">(</span><span class="va">fixed</span>, method <span class="op">=</span> <span class="st">"arellano"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; t test of coefficients:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              Estimate  Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; log(pcap)  0.03488447  0.06661083  0.5237   0.6006    </span></span>
<span><span class="co">#&gt; log(emp)   1.03017988  0.06413365 16.0630   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; unemp     -0.00021084  0.00217453 -0.0970   0.9228    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Different HC types</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"HC0"</span>, <span class="st">"HC1"</span>, <span class="st">"HC2"</span>, <span class="st">"HC3"</span>, <span class="st">"HC4"</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">vcovHC</a></span><span class="op">(</span><span class="va">fixed</span>, type <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt;      log(pcap)   log(emp)       unemp</span></span>
<span><span class="co">#&gt; HC0 0.06661083 0.06413365 0.002174525</span></span>
<span><span class="co">#&gt; HC1 0.06673362 0.06425187 0.002178534</span></span>
<span><span class="co">#&gt; HC2 0.06689078 0.06441024 0.002182114</span></span>
<span><span class="co">#&gt; HC3 0.06717278 0.06468886 0.002189747</span></span>
<span><span class="co">#&gt; HC4 0.06742431 0.06496436 0.002193150</span></span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<caption>Summary of Model Selection</caption>
<colgroup>
<col width="26%">
<col width="36%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th>Test</th>
<th>Null Hypothesis (H₀)</th>
<th>Decision Rule</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>LM Test</strong></td>
<td>OLS is appropriate</td>
<td>Reject H₀ → Use RE</td>
</tr>
<tr class="even">
<td><strong>Hausman Test</strong></td>
<td>Random effects preferred</td>
<td>Reject H₀ → Use FE</td>
</tr>
<tr class="odd">
<td><strong>pFtest</strong></td>
<td>OLS is appropriate</td>
<td>Reject H₀ → Use FE</td>
</tr>
<tr class="even">
<td><strong>Breusch-Pagan</strong></td>
<td>No heteroskedasticity</td>
<td>Reject H₀ → Use robust SE</td>
</tr>
</tbody>
</table></div>
<hr>
<p><strong>Variance Components Structure</strong></p>
<p>Beyond the standard random effects model, the <code>plm</code> package provides additional methods for estimating <strong>variance components models</strong> and instrumental variable techniques for dealing with endogeneity in panel data.</p>
<p>Different estimators for the <strong>variance components structure</strong> exist in the literature, and <code>plm</code> allows users to specify them through the <code>random.method</code> argument.</p>
<p><strong>Random Effects Estimators:</strong></p>
<ul>
<li><p><code>"swar"</code> (<em>default</em>): Swamy and Arora estimator <span class="citation">(<a href="references.html#ref-swamy1972exact">Swamy and Arora 1972</a>)</span>.</p></li>
<li><p><code>"walhus"</code>: Wallace and Hussain estimator <span class="citation">(<a href="references.html#ref-wallace1969use">Wallace and Hussain 1969</a>)</span>.</p></li>
<li><p><code>"amemiya"</code>: Amemiya estimator <span class="citation">(<a href="references.html#ref-amemiya1971estimation">Amemiya 1971</a>)</span>.</p></li>
<li><p><code>"nerlove"</code>: Nerlove estimator <span class="citation">(<a href="references.html#ref-nerlove1971further">Nerlove 1971</a>)</span> (<strong>Note:</strong> Not available for two-way random effects).</p></li>
</ul>
<p><strong>Effects in Panel Models:</strong></p>
<ul>
<li><p><strong>Individual effects</strong> (<em>default</em>).</p></li>
<li><p><strong>Time effects</strong> (<code>effect = "time"</code>).</p></li>
<li><p><strong>Two-way effects</strong> (<code>effect = "twoways"</code>).</p></li>
</ul>
<div class="sourceCode" id="cb460"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">amemiya</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/plm.html">plm</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>    data <span class="op">=</span> <span class="va">pdata</span>,</span>
<span>    model <span class="op">=</span> <span class="st">"random"</span>,</span>
<span>    random.method <span class="op">=</span> <span class="st">"amemiya"</span>,</span>
<span>    effect <span class="op">=</span> <span class="st">"twoways"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">amemiya</span><span class="op">)</span></span>
<span><span class="co">#&gt; Twoways effects Random Effect Model </span></span>
<span><span class="co">#&gt;    (Amemiya's transformation)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; plm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     effect = "twoways", model = "random", random.method = "amemiya")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Effects:</span></span>
<span><span class="co">#&gt;                    var  std.dev share</span></span>
<span><span class="co">#&gt; idiosyncratic 0.001228 0.035039 0.028</span></span>
<span><span class="co">#&gt; individual    0.041201 0.202981 0.941</span></span>
<span><span class="co">#&gt; time          0.001359 0.036859 0.031</span></span>
<span><span class="co">#&gt; theta: 0.9582 (id) 0.8641 (time) 0.8622 (total)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;        Min.     1st Qu.      Median     3rd Qu.        Max. </span></span>
<span><span class="co">#&gt; -0.13796209 -0.01951506 -0.00053384  0.01807398  0.20452581 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error z-value  Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  3.9581876  0.1767036 22.4001 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; log(pcap)    0.0378443  0.0253963  1.4902  0.136184    </span></span>
<span><span class="co">#&gt; log(emp)     0.8891887  0.0227677 39.0548 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; unemp       -0.0031568  0.0011240 -2.8086  0.004976 ** </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares:    5.3265</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 0.98398</span></span>
<span><span class="co">#&gt; R-Squared:      0.81527</span></span>
<span><span class="co">#&gt; Adj. R-Squared: 0.81458</span></span>
<span><span class="co">#&gt; Chisq: 3583.53 on 3 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/pkg/plm/man/ercomp.html">ercomp()</a></code> function retrieves estimates of the <strong>variance components</strong> in a random effects model. Below, we extract the variance decomposition using Amemiya’s method:</p>
<div class="sourceCode" id="cb461"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/ercomp.html">ercomp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>, </span>
<span>       data <span class="op">=</span> <span class="va">pdata</span>,</span>
<span>       method <span class="op">=</span> <span class="st">"amemiya"</span>,</span>
<span>       effect <span class="op">=</span> <span class="st">"twoways"</span><span class="op">)</span></span>
<span><span class="co">#&gt;                    var  std.dev share</span></span>
<span><span class="co">#&gt; idiosyncratic 0.001228 0.035039 0.028</span></span>
<span><span class="co">#&gt; individual    0.041201 0.202981 0.941</span></span>
<span><span class="co">#&gt; time          0.001359 0.036859 0.031</span></span>
<span><span class="co">#&gt; theta: 0.9582 (id) 0.8641 (time) 0.8622 (total)</span></span></code></pre></div>
<p>This output includes:</p>
<ul>
<li><p>Variance of the <strong>individual effect</strong>.</p></li>
<li><p>Variance of the <strong>time effect</strong> (if applicable).</p></li>
<li><p>Variance of the <strong>idiosyncratic error</strong>.</p></li>
</ul>
<hr>
<p><strong>Checking Panel Data Balance</strong></p>
<p>Panel datasets may be balanced (each individual has observations for all time periods) or unbalanced (some individuals are missing observations). The <code><a href="https://rdrr.io/pkg/plm/man/punbalancedness.html">punbalancedness()</a></code> function measures the degree of balance in the data, with values closer to 1 indicating a balanced panel <span class="citation">(<a href="references.html#ref-ahrens1981two">Ahrens and Pincus 1981</a>)</span>.</p>
<div class="sourceCode" id="cb462"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/plm/man/punbalancedness.html">punbalancedness</a></span><span class="op">(</span><span class="va">random</span><span class="op">)</span></span>
<span><span class="co">#&gt; gamma    nu </span></span>
<span><span class="co">#&gt;     1     1</span></span></code></pre></div>
<hr>
<p><strong>Instrumental Variables in Panel Data</strong></p>
<p>Instrumental variables (IV) are used to address <strong>endogeneity</strong>, which arises when regressors are correlated with the error term. <code>plm</code> provides various IV estimation methods through the <code>inst.method</code> argument.</p>
<p><strong>Instrumental Variable Estimators</strong></p>
<ul>
<li><p><code>"bvk"</code>: Balestra-Varadharajan-Krishnakumar estimator (<em>default</em>) <span class="citation">(<a href="references.html#ref-balestra1987full">Balestra and Varadharajan-Krishnakumar 1987</a>)</span>.</p></li>
<li><p><code>"baltagi"</code>: Baltagi estimator <span class="citation">(<a href="references.html#ref-baltagi1981simultaneous">Baltagi 1981</a>)</span>.</p></li>
<li><p><code>"am"</code>: Amemiya-MaCurdy estimator <span class="citation">(<a href="references.html#ref-amemiya1986instrumental">Amemiya and MaCurdy 1986</a>)</span>.</p></li>
<li><p><code>"bms"</code>: Breusch-Mizon-Schmidt estimator <span class="citation">(<a href="references.html#ref-breusch1989efficient">Breusch, Mizon, and Schmidt 1989</a>)</span>.</p></li>
</ul>
<hr>
<p><strong>Other Estimators in Panel Data Models</strong></p>
<p>Beyond standard fixed effects and random effects models, the <code>plm</code> package provides additional estimation techniques tailored for heterogeneous coefficients, dynamic panel models, and feasible generalized least squares (FGLS) methods.</p>
<p><strong>Variable Coefficients Model (<code>pvcm</code>)</strong></p>
<p>The variable coefficients model (VCM) allows coefficients to vary across cross-sectional units, accounting for unobserved heterogeneity more flexibly.</p>
<p><strong>Two Estimation Approaches:</strong></p>
<ul>
<li><p><strong>Fixed effects (<code>within</code>)</strong>: Assumes coefficients are constant over time but vary across individuals.</p></li>
<li><p><strong>Random effects (<code>random</code>)</strong>: Assumes coefficients are drawn from a random distribution.</p></li>
</ul>
<div class="sourceCode" id="cb463"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fixed_pvcm</span>  <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/plm/man/pvcm.html">pvcm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>,</span>
<span>         data <span class="op">=</span> <span class="va">pdata</span>,</span>
<span>         model <span class="op">=</span> <span class="st">"within"</span><span class="op">)</span></span>
<span><span class="va">random_pvcm</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/plm/man/pvcm.html">pvcm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">gsp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">pcap</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">+</span> <span class="va">unemp</span>,</span>
<span>         data <span class="op">=</span> <span class="va">pdata</span>,</span>
<span>         model <span class="op">=</span> <span class="st">"random"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fixed_pvcm</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect No-pooling model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; pvcm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "within")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;         Min.      1st Qu.       Median      3rd Qu.         Max. </span></span>
<span><span class="co">#&gt; -0.075247625 -0.013247956  0.000666934  0.013852996  0.118966807 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;   (Intercept)        log(pcap)           log(emp)          unemp           </span></span>
<span><span class="co">#&gt;  Min.   :-3.8868   Min.   :-1.11962   Min.   :0.3790   Min.   :-1.597e-02  </span></span>
<span><span class="co">#&gt;  1st Qu.: 0.9917   1st Qu.:-0.38475   1st Qu.:0.8197   1st Qu.:-5.319e-03  </span></span>
<span><span class="co">#&gt;  Median : 2.9848   Median :-0.03147   Median :1.1506   Median : 5.335e-05  </span></span>
<span><span class="co">#&gt;  Mean   : 2.8079   Mean   :-0.06028   Mean   :1.1656   Mean   : 9.024e-04  </span></span>
<span><span class="co">#&gt;  3rd Qu.: 4.3553   3rd Qu.: 0.25573   3rd Qu.:1.3779   3rd Qu.: 8.374e-03  </span></span>
<span><span class="co">#&gt;  Max.   :12.8800   Max.   : 1.16922   Max.   :2.4276   Max.   : 2.507e-02  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares: 15729</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 0.40484</span></span>
<span><span class="co">#&gt; Multiple R-Squared: 0.99997</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">random_pvcm</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect Random coefficients model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; pvcm(formula = log(gsp) ~ log(pcap) + log(emp) + unemp, data = pdata, </span></span>
<span><span class="co">#&gt;     model = "random")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Balanced Panel: n = 48, T = 17, N = 816</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. </span></span>
<span><span class="co">#&gt; -0.23364 -0.03401  0.05558  0.09811  0.19349  1.14326 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated mean of the coefficients:</span></span>
<span><span class="co">#&gt;                Estimate  Std. Error z-value  Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  2.79030044  0.53104167  5.2544 1.485e-07 ***</span></span>
<span><span class="co">#&gt; log(pcap)   -0.04195768  0.08621579 -0.4867    0.6265    </span></span>
<span><span class="co">#&gt; log(emp)     1.14988911  0.07225221 15.9149 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; unemp        0.00031135  0.00163864  0.1900    0.8493    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated variance of the coefficients:</span></span>
<span><span class="co">#&gt;             (Intercept) log(pcap)   log(emp)       unemp</span></span>
<span><span class="co">#&gt; (Intercept)  11.2648882 -1.335932  0.2035824  0.00827707</span></span>
<span><span class="co">#&gt; log(pcap)    -1.3359322  0.287021 -0.1872915 -0.00345298</span></span>
<span><span class="co">#&gt; log(emp)      0.2035824 -0.187291  0.2134845  0.00336374</span></span>
<span><span class="co">#&gt; unemp         0.0082771 -0.003453  0.0033637  0.00009425</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Total Sum of Squares: 15729</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 40.789</span></span>
<span><span class="co">#&gt; Multiple R-Squared: 0.99741</span></span>
<span><span class="co">#&gt; Chisq: 739.334 on 3 DF, p-value: &lt; 2.22e-16</span></span>
<span><span class="co">#&gt; Test for parameter homogeneity: Chisq = 21768.8 on 188 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<p><strong>Generalized Method of Moments Estimator (<code>pgmm</code>)</strong></p>
<p>The <strong>Generalized Method of Moments</strong> estimator is commonly used for <strong>dynamic panel models</strong>, especially when:</p>
<ul>
<li><p>There is concern over <strong>endogeneity</strong> in lagged dependent variables.</p></li>
<li><p>Instrumental variables are used for estimation.</p></li>
</ul>
<div class="sourceCode" id="cb464"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://cran.r-project.org/package=plm">plm</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># estimates a dynamic labor demand function using one-step GMM, </span></span>
<span><span class="co"># applying lagged variables as instruments</span></span>
<span><span class="va">z2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/pgmm.html">pgmm</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span>, <span class="fl">0</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">capital</span><span class="op">)</span>, <span class="fl">0</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span> <span class="op">|</span> </span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">99</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">99</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/lag.html">lag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">capital</span><span class="op">)</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">99</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">EmplUK</span>,</span>
<span>    effect <span class="op">=</span> <span class="st">"twoways"</span>,</span>
<span>    model <span class="op">=</span> <span class="st">"onestep"</span>,</span>
<span>    transformation <span class="op">=</span> <span class="st">"ld"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">z2</span>, robust <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Twoways effects One-step model System GMM </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; pgmm(formula = log(emp) ~ lag(log(emp), 1) + lag(log(wage), 0:1) + </span></span>
<span><span class="co">#&gt;     lag(log(capital), 0:1) | lag(log(emp), 2:99) + lag(log(wage), </span></span>
<span><span class="co">#&gt;     2:99) + lag(log(capital), 2:99), data = EmplUK, effect = "twoways", </span></span>
<span><span class="co">#&gt;     model = "onestep", transformation = "ld")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Unbalanced Panel: n = 140, T = 7-9, N = 1031</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Observations Used: 1642</span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;       Min.    1st Qu.     Median       Mean    3rd Qu.       Max. </span></span>
<span><span class="co">#&gt; -0.7530341 -0.0369030  0.0000000  0.0002882  0.0466069  0.6001503 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                          Estimate Std. Error z-value  Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; lag(log(emp), 1)         0.935605   0.026295 35.5810 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; lag(log(wage), 0:1)0    -0.630976   0.118054 -5.3448 9.050e-08 ***</span></span>
<span><span class="co">#&gt; lag(log(wage), 0:1)1     0.482620   0.136887  3.5257 0.0004224 ***</span></span>
<span><span class="co">#&gt; lag(log(capital), 0:1)0  0.483930   0.053867  8.9838 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; lag(log(capital), 0:1)1 -0.424393   0.058479 -7.2572 3.952e-13 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sargan test: chisq(100) = 118.763 (p-value = 0.097096)</span></span>
<span><span class="co">#&gt; Autocorrelation test (1): normal = -4.808434 (p-value = 1.5212e-06)</span></span>
<span><span class="co">#&gt; Autocorrelation test (2): normal = -0.2800133 (p-value = 0.77947)</span></span>
<span><span class="co">#&gt; Wald test for coefficients: chisq(5) = 11174.82 (p-value = &lt; 2.22e-16)</span></span>
<span><span class="co">#&gt; Wald test for time dummies: chisq(7) = 14.71138 (p-value = 0.039882)</span></span></code></pre></div>
<p><strong>Explanation of Arguments:</strong></p>
<ul>
<li><p><code>log(emp) ~ lag(log(emp), 1) + lag(log(wage), 0:1) + lag(log(capital), 0:1)</code><br>
→ Specifies the <strong>dynamic model</strong>, where <code>log(emp)</code> depends on its first lag and contemporaneous plus lagged values of <code>log(wage)</code> and <code>log(capital)</code>.</p></li>
<li><p><code>| lag(log(emp), 2:99) + lag(log(wage), 2:99) + lag(log(capital), 2:99)</code><br>
→ Instruments for endogenous regressors, using <strong>further lags</strong>.</p></li>
<li><p><code>effect = "twoways"</code><br>
→ Includes both <strong>individual and time effects</strong>.</p></li>
<li><p><code>model = "onestep"</code><br>
→ Uses <strong>one-step GMM</strong> (alternative: <code>"twostep"</code> for efficiency gain).</p></li>
<li><p><code>transformation = "ld"</code><br>
→ Uses <strong>lagged differences</strong> as transformation.</p></li>
</ul>
<p><strong>Generalized Feasible Generalized Least Squares Models (<code>pggls</code>)</strong></p>
<p>The FGLS estimator (<code>pggls</code>) is robust against:</p>
<ul>
<li><p><strong>Intragroup heteroskedasticity</strong>.</p></li>
<li><p><strong>Serial correlation</strong> (within groups).</p></li>
</ul>
<p>However, it assumes <strong>no cross-sectional correlation</strong> and is most suitable when NNN (cross-sectional units) is much larger than TTT (time periods), i.e., <strong>long panels</strong>.</p>
<p><strong>Random Effects FGLS Model:</strong></p>
<div class="sourceCode" id="cb465"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">zz</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/pggls.html">pggls</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">capital</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">EmplUK</span>,</span>
<span>    model <span class="op">=</span> <span class="st">"pooling"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">zz</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect General FGLS model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; pggls(formula = log(emp) ~ log(wage) + log(capital), data = EmplUK, </span></span>
<span><span class="co">#&gt;     model = "pooling")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Unbalanced Panel: n = 140, T = 7-9, N = 1031</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. </span></span>
<span><span class="co">#&gt; -1.80696 -0.36552  0.06181  0.03230  0.44279  1.58719 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error z-value  Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)   2.023480   0.158468 12.7690 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; log(wage)    -0.232329   0.048001 -4.8401 1.298e-06 ***</span></span>
<span><span class="co">#&gt; log(capital)  0.610484   0.017434 35.0174 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; Total Sum of Squares: 1853.6</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 402.55</span></span>
<span><span class="co">#&gt; Multiple R-squared: 0.78283</span></span></code></pre></div>
<p><strong>Fixed Effects FGLS Model:</strong></p>
<div class="sourceCode" id="cb466"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">zz</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/plm/man/pggls.html">pggls</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">emp</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">wage</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">capital</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">EmplUK</span>,</span>
<span>    model <span class="op">=</span> <span class="st">"within"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">zz</span><span class="op">)</span></span>
<span><span class="co">#&gt; Oneway (individual) effect Within FGLS model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; pggls(formula = log(emp) ~ log(wage) + log(capital), data = EmplUK, </span></span>
<span><span class="co">#&gt;     model = "within")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Unbalanced Panel: n = 140, T = 7-9, N = 1031</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;         Min.      1st Qu.       Median      3rd Qu.         Max. </span></span>
<span><span class="co">#&gt; -0.508362414 -0.074254395 -0.002442181  0.076139063  0.601442300 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error z-value  Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; log(wage)    -0.617617   0.030794 -20.056 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; log(capital)  0.561049   0.017185  32.648 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; Total Sum of Squares: 1853.6</span></span>
<span><span class="co">#&gt; Residual Sum of Squares: 17.368</span></span>
<span><span class="co">#&gt; Multiple R-squared: 0.99063</span></span></code></pre></div>
<p><strong>Key Considerations:</strong></p>
<ul>
<li><p>Efficient under the assumption of homoskedasticity.</p></li>
<li><p>Inefficient if there is group-wise heteroskedasticity.</p></li>
<li><p>Ideal for large-N, small-T panels.</p></li>
</ul>
<div class="inline-table"><table class="table table-sm">
<caption>Summary of Alternative Panel Data Estimators</caption>
<colgroup>
<col width="21%">
<col width="22%">
<col width="56%">
</colgroup>
<thead><tr class="header">
<th>Estimator</th>
<th>Method</th>
<th>Application</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Variable Coefficients (<code>pvcm</code>)</strong></td>
<td>Fixed (<code>within</code>), Random (<code>random</code>)</td>
<td>Allows coefficients to vary across individuals.</td>
</tr>
<tr class="even">
<td><strong>GMM (<code>pgmm</code>)</strong></td>
<td>One-step, Two-step</td>
<td>Used in dynamic models with endogeneity.</td>
</tr>
<tr class="odd">
<td><strong>Feasible GLS (<code>pggls</code>)</strong></td>
<td>Fixed (<code>within</code>), Random (<code>pooling</code>)</td>
<td>Handles heteroskedasticity and serial correlation but assumes no cross-sectional correlation.</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
<div id="fixest-package" class="section level4" number="11.5.11.2">
<h4>
<span class="header-section-number">11.5.11.2</span> <code>fixest</code> Package<a class="anchor" aria-label="anchor" href="#fixest-package"><i class="fas fa-link"></i></a>
</h4>
<p>The <code>fixest</code> package provides <strong>efficient</strong> and <strong>flexible</strong> methods for estimating <strong>fixed effects</strong> and <a href="generalized-linear-models.html#generalized-linear-models">generalized linear models</a> in panel data. It is optimized for handling large datasets with high-dimensional fixed effects and allows for multiple model estimation, robust standard errors, and split-sample estimation.</p>
<p>For further details, refer to the official <a href="https://cran.r-project.org/web/packages/fixest/vignettes/exporting_tables.html">fixest vignette</a>.</p>
<p><strong>Available Estimation Functions in <code>fixest</code></strong></p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th>Function</th>
<th>Model Type</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>feols</code></td>
<td>Fixed effects OLS (linear regression)</td>
</tr>
<tr class="even">
<td><code>feglm</code></td>
<td>Generalized linear models (GLMs)</td>
</tr>
<tr class="odd">
<td><code>femlm</code></td>
<td>Maximum likelihood estimation (MLE)</td>
</tr>
<tr class="even">
<td><code>feNmlm</code></td>
<td>Non-linear models (non-linear in RHS parameters)</td>
</tr>
<tr class="odd">
<td><code>fepois</code></td>
<td>Poisson fixed-effects regression</td>
</tr>
<tr class="even">
<td><code>fenegbin</code></td>
<td>Negative binomial fixed-effects regression</td>
</tr>
</tbody>
</table></div>
<blockquote>
<p><strong>Note:</strong> These functions work only for <code>fixest</code> objects.</p>
</blockquote>
<div class="sourceCode" id="cb467"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lrberge.github.io/fixest/">fixest</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Setting a variable dictionary for output labeling</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/setFixest_dict.html">setFixest_dict</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span></span>
<span>        Ozone   <span class="op">=</span> <span class="st">"Ozone (ppb)"</span>,</span>
<span>        Solar.R <span class="op">=</span> <span class="st">"Solar Radiation (Langleys)"</span>,</span>
<span>        Wind    <span class="op">=</span> <span class="st">"Wind Speed (mph)"</span>,</span>
<span>        Temp    <span class="op">=</span> <span class="st">"Temperature"</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fixed effects OLS with stepwise estimation and clustering</span></span>
<span><span class="va">est</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span></span>
<span>    <span class="va">Ozone</span> <span class="op">~</span> <span class="va">Solar.R</span> <span class="op">+</span> <span class="fu">sw0</span><span class="op">(</span><span class="va">Wind</span> <span class="op">+</span> <span class="va">Temp</span><span class="op">)</span> <span class="op">|</span> <span class="fu">csw</span><span class="op">(</span><span class="va">Month</span>, <span class="va">Day</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">airquality</span>,</span>
<span>    cluster <span class="op">=</span> <span class="op">~</span> <span class="va">Day</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display results</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="va">est</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                         est.1              est.2</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)        Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                                                 </span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1148*** (0.0234)   0.0522* (0.0202)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)                              -3.109*** (0.7986)</span></span>
<span><span class="co">#&gt; Temperature                                    1.875*** (0.3671)</span></span>
<span><span class="co">#&gt; Fixed-Effects:             ------------------ ------------------</span></span>
<span><span class="co">#&gt; Month                                     Yes                Yes</span></span>
<span><span class="co">#&gt; Day                                        No                 No</span></span>
<span><span class="co">#&gt; __________________________ __________________ __________________</span></span>
<span><span class="co">#&gt; S.E.: Clustered                       by: Day            by: Day</span></span>
<span><span class="co">#&gt; Observations                              111                111</span></span>
<span><span class="co">#&gt; R2                                    0.31974            0.63686</span></span>
<span><span class="co">#&gt; Within R2                             0.12245            0.53154</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                                        est.3              est.4</span></span>
<span><span class="co">#&gt; Dependent Var.:                  Ozone (ppb)        Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                                                </span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1078** (0.0329)   0.0509* (0.0236)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)                             -3.289*** (0.7777)</span></span>
<span><span class="co">#&gt; Temperature                                   2.052*** (0.2415)</span></span>
<span><span class="co">#&gt; Fixed-Effects:             ----------------- ------------------</span></span>
<span><span class="co">#&gt; Month                                    Yes                Yes</span></span>
<span><span class="co">#&gt; Day                                      Yes                Yes</span></span>
<span><span class="co">#&gt; __________________________ _________________ __________________</span></span>
<span><span class="co">#&gt; S.E.: Clustered                      by: Day            by: Day</span></span>
<span><span class="co">#&gt; Observations                             111                111</span></span>
<span><span class="co">#&gt; R2                                   0.58018            0.81604</span></span>
<span><span class="co">#&gt; Within R2                            0.12074            0.61471</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Output in LaTeX format</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="va">est</span>, tex <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; \begingroup</span></span>
<span><span class="co">#&gt; \centering</span></span>
<span><span class="co">#&gt; \begin{tabular}{lcccc}</span></span>
<span><span class="co">#&gt;    \tabularnewline \midrule \midrule</span></span>
<span><span class="co">#&gt;    Dependent Variable: &amp; \multicolumn{4}{c}{Ozone (ppb)}\\</span></span>
<span><span class="co">#&gt;    Model:                     &amp; (1)            &amp; (2)            &amp; (3)            &amp; (4)\\  </span></span>
<span><span class="co">#&gt;    \midrule</span></span>
<span><span class="co">#&gt;    \emph{Variables}\\</span></span>
<span><span class="co">#&gt;    Solar Radiation (Langleys) &amp; 0.1148$^{***}$ &amp; 0.0522$^{**}$  &amp; 0.1078$^{***}$ &amp; 0.0509$^{**}$\\   </span></span>
<span><span class="co">#&gt;                               &amp; (0.0234)       &amp; (0.0202)       &amp; (0.0329)       &amp; (0.0236)\\   </span></span>
<span><span class="co">#&gt;    Wind Speed (mph)           &amp;                &amp; -3.109$^{***}$ &amp;                &amp; -3.289$^{***}$\\   </span></span>
<span><span class="co">#&gt;                               &amp;                &amp; (0.7986)       &amp;                &amp; (0.7777)\\   </span></span>
<span><span class="co">#&gt;    Temperature                &amp;                &amp; 1.875$^{***}$  &amp;                &amp; 2.052$^{***}$\\   </span></span>
<span><span class="co">#&gt;                               &amp;                &amp; (0.3671)       &amp;                &amp; (0.2415)\\   </span></span>
<span><span class="co">#&gt;    \midrule</span></span>
<span><span class="co">#&gt;    \emph{Fixed-effects}\\</span></span>
<span><span class="co">#&gt;    Month                      &amp; Yes            &amp; Yes            &amp; Yes            &amp; Yes\\  </span></span>
<span><span class="co">#&gt;    Day                        &amp;                &amp;                &amp; Yes            &amp; Yes\\  </span></span>
<span><span class="co">#&gt;    \midrule</span></span>
<span><span class="co">#&gt;    \emph{Fit statistics}\\</span></span>
<span><span class="co">#&gt;    Observations               &amp; 111            &amp; 111            &amp; 111            &amp; 111\\  </span></span>
<span><span class="co">#&gt;    R$^2$                      &amp; 0.31974        &amp; 0.63686        &amp; 0.58018        &amp; 0.81604\\  </span></span>
<span><span class="co">#&gt;    Within R$^2$               &amp; 0.12245        &amp; 0.53154        &amp; 0.12074        &amp; 0.61471\\  </span></span>
<span><span class="co">#&gt;    \midrule \midrule</span></span>
<span><span class="co">#&gt;    \multicolumn{5}{l}{\emph{Clustered (Day) standard-errors in parentheses}}\\</span></span>
<span><span class="co">#&gt;    \multicolumn{5}{l}{\emph{Signif. Codes: ***: 0.01, **: 0.05, *: 0.1}}\\</span></span>
<span><span class="co">#&gt; \end{tabular}</span></span>
<span><span class="co">#&gt; \par\endgroup</span></span>
<span></span>
<span><span class="co"># Extract fixed-effects coefficients</span></span>
<span><span class="va">fixedEffects</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">est</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fixedEffects</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fixed_effects coefficients</span></span>
<span><span class="co">#&gt; Number of fixed-effects for variable Month is 5.</span></span>
<span><span class="co">#&gt;  Mean = 19.6 Variance = 272</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; COEFFICIENTS:</span></span>
<span><span class="co">#&gt;   Month:     5     6     7     8     9</span></span>
<span><span class="co">#&gt;          3.219 8.288 34.26 40.12 12.13</span></span>
<span></span>
<span><span class="co"># View fixed effects for one dimension</span></span>
<span><span class="va">fixedEffects</span><span class="op">$</span><span class="va">Month</span></span>
<span><span class="co">#&gt;         5         6         7         8         9 </span></span>
<span><span class="co">#&gt;  3.218876  8.287899 34.260812 40.122257 12.130971</span></span>
<span></span>
<span><span class="co"># Plot fixed effects</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fixedEffects</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="11-data_files/figure-html/unnamed-chunk-49-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>This example demonstrates:</p>
<ul>
<li><p>Fixed effects estimation (<code>| csw(Month, Day)</code>).</p></li>
<li><p>Stepwise selection (<code>sw0(Wind + Temp)</code>).</p></li>
<li><p>Clustering of standard errors (<code>cluster = ~ Day</code>).</p></li>
<li><p>Extracting and plotting fixed effects.</p></li>
</ul>
<hr>
<p><strong>Multiple Model Estimation</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Estimating Multiple Dependent Variables (LHS)</strong></li>
</ol>
<p>Use <code><a href="https://lrberge.github.io/fixest/reference/feols.html">feols()</a></code> to estimate models with multiple dependent variables simultaneously:</p>
<div class="sourceCode" id="cb468"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">Sepal.Length</span>, <span class="va">Sepal.Width</span><span class="op">)</span> <span class="op">~</span></span>
<span>                 <span class="va">Petal.Length</span> <span class="op">+</span> <span class="va">Petal.Width</span>,</span>
<span>             data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                 feols(c(Sepal.L..1 feols(c(Sepal.Le..2</span></span>
<span><span class="co">#&gt; Dependent Var.:       Sepal.Length         Sepal.Width</span></span>
<span><span class="co">#&gt;                                                       </span></span>
<span><span class="co">#&gt; Constant         4.191*** (0.0970)   3.587*** (0.0937)</span></span>
<span><span class="co">#&gt; Petal.Length    0.5418*** (0.0693) -0.2571*** (0.0669)</span></span>
<span><span class="co">#&gt; Petal.Width      -0.3196* (0.1605)    0.3640* (0.1550)</span></span>
<span><span class="co">#&gt; _______________ __________________ ___________________</span></span>
<span><span class="co">#&gt; S.E. type                      IID                 IID</span></span>
<span><span class="co">#&gt; Observations                   150                 150</span></span>
<span><span class="co">#&gt; R2                         0.76626             0.21310</span></span>
<span><span class="co">#&gt; Adj. R2                    0.76308             0.20240</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Alternatively, define a list of dependent variables and loop over them:</p>
<div class="sourceCode" id="cb469"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">depvars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Sepal.Length"</span>, <span class="st">"Sepal.Width"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">depvars</span>, <span class="kw">function</span><span class="op">(</span><span class="va">var</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/xpd.html">xpd</a></span><span class="op">(</span><span class="va">..lhs</span> <span class="op">~</span> <span class="va">Petal.Length</span> <span class="op">+</span> <span class="va">Petal.Width</span>, ..lhs <span class="op">=</span> <span class="va">var</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            model 1             model 2</span></span>
<span><span class="co">#&gt; Dependent Var.:       Sepal.Length         Sepal.Width</span></span>
<span><span class="co">#&gt;                                                       </span></span>
<span><span class="co">#&gt; Constant         4.191*** (0.0970)   3.587*** (0.0937)</span></span>
<span><span class="co">#&gt; Petal.Length    0.5418*** (0.0693) -0.2571*** (0.0669)</span></span>
<span><span class="co">#&gt; Petal.Width      -0.3196* (0.1605)    0.3640* (0.1550)</span></span>
<span><span class="co">#&gt; _______________ __________________ ___________________</span></span>
<span><span class="co">#&gt; S.E. type                      IID                 IID</span></span>
<span><span class="co">#&gt; Observations                   150                 150</span></span>
<span><span class="co">#&gt; R2                         0.76626             0.21310</span></span>
<span><span class="co">#&gt; Adj. R2                    0.76308             0.20240</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><strong>Estimating Multiple Specifications (RHS)</strong></li>
</ol>
<p>Use <strong>stepwise functions</strong> to estimate different model specifications efficiently.</p>
<p>Options to write the functions</p>
<ul>
<li>
<p><code>sw</code> (stepwise): sequentially analyze each elements</p>
<ul>
<li>
<code>y ~ sw(x1, x2)</code> will be estimated as <code>y ~ x1</code> and <code>y ~ x2</code>
</li>
</ul>
</li>
<li>
<p><code>sw0</code> (stepwise 0): similar to <code>sw</code> but also estimate a model without the elements in the set first</p>
<ul>
<li>
<code>y ~ sw(x1, x2)</code> will be estimated as <code>y ~ 1</code> and <code>y ~ x1</code> and <code>y ~ x2</code>
</li>
</ul>
</li>
<li>
<p><code>csw</code> (cumulative stepwise): sequentially add each element of the set to the formula</p>
<ul>
<li>
<code>y ~ csw(x1, x2)</code> will be estimated as <code>y ~ x1</code> and <code>y ~ x1 + x2</code>
</li>
</ul>
</li>
<li>
<p><code>csw0</code> (cumulative stepwise 0): similar to <code>csw</code> but also estimate a model without the elements in the set first</p>
<ul>
<li>
<code>y ~ csw(x1, x2)</code> will be estimated as <code>y~ 1</code> <code>y ~ x1</code> and <code>y ~ x1 + x2</code>
</li>
</ul>
</li>
<li>
<p><code>mvsw</code> (multiverse stepwise): all possible combination of the elements in the set (it will get large very quick).</p>
<ul>
<li>
<code>mvsw(x1, x2, x3)</code> will be <code>sw0(x1, x2, x3, x1 + x2, x1 + x3, x2 + x3, x1 + x2 + x3)</code>
</li>
</ul>
</li>
</ul>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="79%">
</colgroup>
<thead><tr class="header">
<th>Stepwise Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>sw(x1, x2)</code></td>
<td>Sequentially estimates models with each element separately.</td>
</tr>
<tr class="even">
<td><code>sw0(x1, x2)</code></td>
<td>Same as <code><a href="https://rdrr.io/pkg/MuMIn/man/sumofweights.html">sw()</a></code>, but also estimates a <strong>baseline model</strong> without the elements.</td>
</tr>
<tr class="odd">
<td><code>csw(x1, x2)</code></td>
<td>Sequentially adds each element to the formula.</td>
</tr>
<tr class="even">
<td><code>csw0(x1, x2)</code></td>
<td>Same as <code>csw()</code>, but also includes a <strong>baseline model</strong>.</td>
</tr>
<tr class="odd">
<td><code>mvsw(x1, x2, x3)</code></td>
<td>Estimates <strong>all possible combinations</strong> of the variables.</td>
</tr>
</tbody>
</table></div>
<div class="sourceCode" id="cb470"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example: Cumulative Stepwise Estimation</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">Ozone</span> <span class="op">~</span> <span class="fu">csw</span><span class="op">(</span><span class="va">Solar.R</span>, <span class="va">Wind</span>, <span class="va">Temp</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">airquality</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ c..1 feols(Ozone ~ c..2</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)        Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                                                 </span></span>
<span><span class="co">#&gt; Constant                      18.60** (6.748)   77.25*** (9.068)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1272*** (0.0328) 0.1004*** (0.0263)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)                              -5.402*** (0.6732)</span></span>
<span><span class="co">#&gt; Temperature                                                     </span></span>
<span><span class="co">#&gt; __________________________ __________________ __________________</span></span>
<span><span class="co">#&gt; S.E. type                                 IID                IID</span></span>
<span><span class="co">#&gt; Observations                              111                111</span></span>
<span><span class="co">#&gt; R2                                    0.12134            0.44949</span></span>
<span><span class="co">#&gt; Adj. R2                               0.11328            0.43930</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ c..3</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                              </span></span>
<span><span class="co">#&gt; Constant                     -64.34** (23.05)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys)   0.0598* (0.0232)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -3.334*** (0.6544)</span></span>
<span><span class="co">#&gt; Temperature                 1.652*** (0.2535)</span></span>
<span><span class="co">#&gt; __________________________ __________________</span></span>
<span><span class="co">#&gt; S.E. type                                 IID</span></span>
<span><span class="co">#&gt; Observations                              111</span></span>
<span><span class="co">#&gt; R2                                    0.60589</span></span>
<span><span class="co">#&gt; Adj. R2                               0.59484</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<hr>
<p><strong>Split-Sample Estimation</strong></p>
<p>Estimate separate regressions for different subgroups in the dataset using <code>fsplit</code>.</p>
<div class="sourceCode" id="cb471"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">Ozone</span> <span class="op">~</span> <span class="va">Solar.R</span> <span class="op">+</span> <span class="va">Wind</span>, fsplit <span class="op">=</span> <span class="op">~</span> <span class="va">Month</span>, data <span class="op">=</span> <span class="va">airquality</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ S..1 feols(Ozone ..2 feols(Ozone ~..3</span></span>
<span><span class="co">#&gt; Sample (Month)                    Full sample               5                6</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)     Ozone (ppb)      Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                                                               </span></span>
<span><span class="co">#&gt; Constant                     77.25*** (9.068)  50.55* (18.30)    8.997 (16.83)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1004*** (0.0263) 0.0294 (0.0379) 0.1518. (0.0676)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -5.402*** (0.6732) -2.762* (1.300)  -0.6177 (1.674)</span></span>
<span><span class="co">#&gt; __________________________ __________________ _______________ ________________</span></span>
<span><span class="co">#&gt; S.E. type                                 IID             IID              IID</span></span>
<span><span class="co">#&gt; Observations                              111              24                9</span></span>
<span><span class="co">#&gt; R2                                    0.44949         0.22543          0.52593</span></span>
<span><span class="co">#&gt; Adj. R2                               0.43930         0.15166          0.36790</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ ..4 feols(Ozone ~ ..5</span></span>
<span><span class="co">#&gt; Sample (Month)                             7                 8</span></span>
<span><span class="co">#&gt; Dependent Var.:                  Ozone (ppb)       Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                                               </span></span>
<span><span class="co">#&gt; Constant                    88.39*** (20.81)  95.76*** (19.83)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys)  0.1135. (0.0582) 0.2146** (0.0654)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -6.319*** (1.559) -8.228*** (1.528)</span></span>
<span><span class="co">#&gt; __________________________ _________________ _________________</span></span>
<span><span class="co">#&gt; S.E. type                                IID               IID</span></span>
<span><span class="co">#&gt; Observations                              26                23</span></span>
<span><span class="co">#&gt; R2                                   0.52423           0.70640</span></span>
<span><span class="co">#&gt; Adj. R2                              0.48286           0.67704</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ ..6</span></span>
<span><span class="co">#&gt; Sample (Month)                             9</span></span>
<span><span class="co">#&gt; Dependent Var.:                  Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                             </span></span>
<span><span class="co">#&gt; Constant                    67.10*** (14.35)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys)   0.0373 (0.0463)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -4.161*** (1.071)</span></span>
<span><span class="co">#&gt; __________________________ _________________</span></span>
<span><span class="co">#&gt; S.E. type                                IID</span></span>
<span><span class="co">#&gt; Observations                              29</span></span>
<span><span class="co">#&gt; R2                                   0.38792</span></span>
<span><span class="co">#&gt; Adj. R2                              0.34084</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>This estimates models separately for each <strong>Month</strong> in the dataset.</p>
<hr>
<p><strong>Robust Standard Errors in <code>fixest</code></strong></p>
<p><code>fixest</code> supports a variety of <strong>robust standard error estimators</strong>, including:</p>
<ul>
<li><p><code>iid</code>: errors are homoskedastic and independent and identically distributed</p></li>
<li><p><code>hetero</code>: errors are heteroskedastic using White correction</p></li>
<li><p><code>cluster</code>: errors are correlated within the cluster groups</p></li>
<li>
<p><code>newey_west</code>: <span class="citation">(<a href="references.html#ref-newey1986simple">Newey and West 1986</a>)</span> use for time series or panel data. Errors are heteroskedastic and serially correlated.</p>
<ul>
<li><p><code>vcov = newey_west ~ id + period</code> where <code>id</code> is the subject id and <code>period</code> is time period of the panel.</p></li>
<li><p>to specify lag period to consider <code>vcov = newey_west(2) ~ id + period</code> where we’re considering 2 lag periods.</p></li>
</ul>
</li>
<li>
<p><code>driscoll_kraay</code> <span class="citation">(<a href="references.html#ref-driscoll1998consistent">Driscoll and Kraay 1998</a>)</span> use for panel data. Errors are cross-sectionally and serially correlated.</p>
<ul>
<li><code>vcov = discoll_kraay ~ period</code></li>
</ul>
</li>
<li>
<p><code>conley</code>: <span class="citation">(<a href="references.html#ref-conley1999gmm">Conley 1999</a>)</span> for cross-section data. Errors are spatially correlated</p>
<ul>
<li><p><code>vcov = conley ~ latitude + longitude</code></p></li>
<li><p>to specify the distance cutoff, <code>vcov = vcov_conley(lat = "lat", lon = "long", cutoff = 100, distance = "spherical")</code>, which will use the <code><a href="https://lrberge.github.io/fixest/reference/vcov_conley.html">conley()</a></code> helper function.</p></li>
</ul>
</li>
<li>
<p><code>hc</code>: from the <code>sandwich</code> package</p>
<ul>
<li><code>vcov = function(x) sandwich::vcovHC(x, type = "HC1"))</code></li>
</ul>
</li>
</ul>
<p>To let R know which SE estimation you want to use, insert <code>vcov = vcov_type ~ variables</code></p>
<p><strong>Example: Newey-West Standard Errors</strong></p>
<div class="sourceCode" id="cb472"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span></span>
<span>    <span class="va">Ozone</span> <span class="op">~</span> <span class="va">Solar.R</span> <span class="op">+</span> <span class="va">Wind</span>,</span>
<span>    data <span class="op">=</span> <span class="va">airquality</span>,</span>
<span>    vcov <span class="op">=</span> <span class="va">newey_west</span> <span class="op">~</span> <span class="va">Month</span> <span class="op">+</span> <span class="va">Day</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ So..</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                              </span></span>
<span><span class="co">#&gt; Constant                     77.25*** (10.03)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1004*** (0.0258)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -5.402*** (0.8353)</span></span>
<span><span class="co">#&gt; __________________________ __________________</span></span>
<span><span class="co">#&gt; S.E. type                    Newey-West (L=2)</span></span>
<span><span class="co">#&gt; Observations                              111</span></span>
<span><span class="co">#&gt; R2                                    0.44949</span></span>
<span><span class="co">#&gt; Adj. R2                               0.43930</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Specify the number of lag periods to consider:</p>
<div class="sourceCode" id="cb473"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span></span>
<span>    <span class="va">Ozone</span> <span class="op">~</span> <span class="va">Solar.R</span> <span class="op">+</span> <span class="va">Wind</span>,</span>
<span>    data <span class="op">=</span> <span class="va">airquality</span>,</span>
<span>    vcov <span class="op">=</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/vcov_hac.html">newey_west</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op">~</span> <span class="va">Month</span> <span class="op">+</span> <span class="va">Day</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ So..</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                              </span></span>
<span><span class="co">#&gt; Constant                     77.25*** (10.03)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1004*** (0.0258)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -5.402*** (0.8353)</span></span>
<span><span class="co">#&gt; __________________________ __________________</span></span>
<span><span class="co">#&gt; S.E. type                    Newey-West (L=2)</span></span>
<span><span class="co">#&gt; Observations                              111</span></span>
<span><span class="co">#&gt; R2                                    0.44949</span></span>
<span><span class="co">#&gt; Adj. R2                               0.43930</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Conley Spatial Correlation: <code>vcov = conley ~ latitude + longitude</code></p>
<p>To specify a distance cutoff: <code>vcov = vcov_conley(lat = "lat", lon = "long", cutoff = 100, distance = "spherical")</code></p>
<p>Using Standard Errors from the <code>sandwich</code> Package</p>
<div class="sourceCode" id="cb474"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span></span>
<span>    <span class="va">Ozone</span> <span class="op">~</span> <span class="va">Solar.R</span> <span class="op">+</span> <span class="va">Wind</span>,</span>
<span>    data <span class="op">=</span> <span class="va">airquality</span>,</span>
<span>    vcov <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>        <span class="fu">sandwich</span><span class="fu">::</span><span class="fu"><a href="https://sandwich.R-Forge.R-project.org/reference/vcovHC.html">vcovHC</a></span><span class="op">(</span><span class="va">x</span>, type <span class="op">=</span> <span class="st">"HC1"</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ So..</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                              </span></span>
<span><span class="co">#&gt; Constant                     77.25*** (9.590)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1004*** (0.0231)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -5.402*** (0.8134)</span></span>
<span><span class="co">#&gt; __________________________ __________________</span></span>
<span><span class="co">#&gt; S.E. type                  vcovHC(type="HC1")</span></span>
<span><span class="co">#&gt; Observations                              111</span></span>
<span><span class="co">#&gt; R2                                    0.44949</span></span>
<span><span class="co">#&gt; Adj. R2                               0.43930</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p><strong>Small Sample Correction</strong></p>
<p>Apply small sample adjustments using <code><a href="https://lrberge.github.io/fixest/reference/ssc.html">ssc()</a></code>:</p>
<div class="sourceCode" id="cb475"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span></span>
<span>    <span class="va">Ozone</span> <span class="op">~</span> <span class="va">Solar.R</span> <span class="op">+</span> <span class="va">Wind</span>,</span>
<span>    data <span class="op">=</span> <span class="va">airquality</span>,</span>
<span>    ssc <span class="op">=</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/ssc.html">ssc</a></span><span class="op">(</span>adj <span class="op">=</span> <span class="cn">TRUE</span>, cluster.adj <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                            feols(Ozone ~ So..</span></span>
<span><span class="co">#&gt; Dependent Var.:                   Ozone (ppb)</span></span>
<span><span class="co">#&gt;                                              </span></span>
<span><span class="co">#&gt; Constant                     77.25*** (9.068)</span></span>
<span><span class="co">#&gt; Solar Radiation (Langleys) 0.1004*** (0.0263)</span></span>
<span><span class="co">#&gt; Wind Speed (mph)           -5.402*** (0.6732)</span></span>
<span><span class="co">#&gt; __________________________ __________________</span></span>
<span><span class="co">#&gt; S.E. type                                 IID</span></span>
<span><span class="co">#&gt; Observations                              111</span></span>
<span><span class="co">#&gt; R2                                    0.44949</span></span>
<span><span class="co">#&gt; Adj. R2                               0.43930</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>This corrects for <strong>bias</strong> when working with small samples.</p>
<hr>
</div>
</div>
</div>
<div id="choosing-the-right-type-of-data" class="section level2" number="11.6">
<h2>
<span class="header-section-number">11.6</span> Choosing the Right Type of Data<a class="anchor" aria-label="anchor" href="#choosing-the-right-type-of-data"><i class="fas fa-link"></i></a>
</h2>
<p>Selecting the appropriate data type depends on:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Research Questions</strong>: Do you need to understand changes over time at the individual level (panel) or just a snapshot comparison at one point (cross-sectional)?</p></li>
<li><p><strong>Resources</strong>: Longitudinal or panel studies can be resource-intensive.</p></li>
<li><p><strong>Time Constraints</strong>: If you need fast results, cross-sectional or repeated cross-sectional might be more practical.</p></li>
<li><p><strong>Analytical Goals</strong>: Time-series forecasting, causal inference, or descriptive comparison each has different data requirements.</p></li>
<li><p><strong>Availability</strong>: Sometimes only secondary or repeated cross-sectional data is available, which constrains the design.</p></li>
</ol>
</div>
<div id="data-quality-and-ethical-considerations" class="section level2" number="11.7">
<h2>
<span class="header-section-number">11.7</span> Data Quality and Ethical Considerations<a class="anchor" aria-label="anchor" href="#data-quality-and-ethical-considerations"><i class="fas fa-link"></i></a>
</h2>
<p>Regardless of data type, <strong>data quality</strong> is crucial. Poor data—be it incomplete, biased, or improperly measured—can lead to incorrect conclusions. Researchers should:</p>
<ul>
<li><p><strong>Ensure Validity and Reliability</strong>: Use well-designed instruments and consistent measurement techniques.</p></li>
<li><p><strong>Address Missing Data</strong>: Apply appropriate imputation methods if feasible.</p></li>
<li><p><strong>Manage Attrition</strong> (in Panel Data): Consider weighting or sensitivity analyses to deal with dropouts.</p></li>
<li><p><strong>Check Representativeness</strong>: Especially in cross-sectional and repeated cross-sectional surveys, ensure sampling frames match the target population.</p></li>
<li><p><strong>Protect Confidentiality and Privacy</strong>: Particularly in panel studies with repeated contact, store data securely and follow ethical guidelines.</p></li>
<li><p><strong>Obtain Proper Consent</strong>: Inform participants about study details, usage of data, and rights to withdraw.</p></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></div>
<div class="next"><a href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#data"><span class="header-section-number">11</span> Data</a></li>
<li>
<a class="nav-link" href="#data-types"><span class="header-section-number">11.1</span> Data Types</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#qualitative-vs.-quantitative-data"><span class="header-section-number">11.1.1</span> Qualitative vs. Quantitative Data</a></li>
<li><a class="nav-link" href="#other-ways-to-classify-data"><span class="header-section-number">11.1.2</span> Other Ways to Classify Data</a></li>
<li><a class="nav-link" href="#data-by-observational-structure-over-time"><span class="header-section-number">11.1.3</span> Data by Observational Structure Over Time</a></li>
</ul>
</li>
<li><a class="nav-link" href="#sec-cross-sectional-data"><span class="header-section-number">11.2</span> Cross-Sectional Data</a></li>
<li>
<a class="nav-link" href="#sec-time-series-data"><span class="header-section-number">11.3</span> Time Series Data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#statistical-properties-of-time-series-models"><span class="header-section-number">11.3.1</span> Statistical Properties of Time Series Models</a></li>
<li><a class="nav-link" href="#common-time-series-processes"><span class="header-section-number">11.3.2</span> Common Time Series Processes</a></li>
<li><a class="nav-link" href="#deterministic-time-trends"><span class="header-section-number">11.3.3</span> Deterministic Time Trends</a></li>
<li><a class="nav-link" href="#violations-of-exogeneity-in-time-series-models"><span class="header-section-number">11.3.4</span> Violations of Exogeneity in Time Series Models</a></li>
<li><a class="nav-link" href="#consequences-of-exogeneity-violations"><span class="header-section-number">11.3.5</span> Consequences of Exogeneity Violations</a></li>
<li><a class="nav-link" href="#highly-persistent-data"><span class="header-section-number">11.3.6</span> Highly Persistent Data</a></li>
<li><a class="nav-link" href="#sec-unit-root-testing"><span class="header-section-number">11.3.7</span> Unit Root Testing</a></li>
<li><a class="nav-link" href="#sec-newey-west-standard-errors"><span class="header-section-number">11.3.8</span> Newey-West Standard Errors</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-repeated-cross-sectional-data"><span class="header-section-number">11.4</span> Repeated Cross-Sectional Data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#key-characteristics"><span class="header-section-number">11.4.1</span> Key Characteristics</a></li>
<li><a class="nav-link" href="#statistical-modeling-for-repeated-cross-sections"><span class="header-section-number">11.4.2</span> Statistical Modeling for Repeated Cross-Sections</a></li>
<li><a class="nav-link" href="#advantages-of-repeated-cross-sectional-data"><span class="header-section-number">11.4.3</span> Advantages of Repeated Cross-Sectional Data</a></li>
<li><a class="nav-link" href="#disadvantages-of-repeated-cross-sectional-data"><span class="header-section-number">11.4.4</span> Disadvantages of Repeated Cross-Sectional Data</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-panel-data"><span class="header-section-number">11.5</span> Panel Data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#advantages-of-panel-data"><span class="header-section-number">11.5.1</span> Advantages of Panel Data</a></li>
<li><a class="nav-link" href="#disadvantages-of-panel-data"><span class="header-section-number">11.5.2</span> Disadvantages of Panel Data</a></li>
<li><a class="nav-link" href="#sources-of-variation-in-panel-data"><span class="header-section-number">11.5.3</span> Sources of Variation in Panel Data</a></li>
<li><a class="nav-link" href="#sec-pooled-ols-estimator"><span class="header-section-number">11.5.4</span> Pooled OLS Estimator</a></li>
<li><a class="nav-link" href="#individual-specific-effects-model"><span class="header-section-number">11.5.5</span> Individual-Specific Effects Model</a></li>
<li><a class="nav-link" href="#sec-random-effects-estimator"><span class="header-section-number">11.5.6</span> Random Effects Estimator</a></li>
<li><a class="nav-link" href="#sec-fixed-effects-estimator"><span class="header-section-number">11.5.7</span> Fixed Effects Estimator</a></li>
<li><a class="nav-link" href="#tests-for-assumptions-in-panel-data-analysis"><span class="header-section-number">11.5.8</span> Tests for Assumptions in Panel Data Analysis</a></li>
<li><a class="nav-link" href="#model-selection-in-panel-data"><span class="header-section-number">11.5.9</span> Model Selection in Panel Data</a></li>
<li><a class="nav-link" href="#alternative-estimators"><span class="header-section-number">11.5.10</span> Alternative Estimators</a></li>
<li><a class="nav-link" href="#application-1"><span class="header-section-number">11.5.11</span> Application</a></li>
</ul>
</li>
<li><a class="nav-link" href="#choosing-the-right-type-of-data"><span class="header-section-number">11.6</span> Choosing the Right Type of Data</a></li>
<li><a class="nav-link" href="#data-quality-and-ethical-considerations"><span class="header-section-number">11.7</span> Data Quality and Ethical Considerations</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/11-data.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/11-data.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-05-24.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
