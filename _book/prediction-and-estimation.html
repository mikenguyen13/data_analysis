<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 20 Prediction and Estimation | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="In modern statistics, econometrics, and machine learning, two primary goals often motivate data analysis: Prediction: To build a function \(\hat{f}\) that accurately predicts an outcome \(Y\) from...">
<meta name="generator" content="bookdown 0.42 with bs4_book()">
<meta property="og:title" content="Chapter 20 Prediction and Estimation | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/prediction-and-estimation.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="In modern statistics, econometrics, and machine learning, two primary goals often motivate data analysis: Prediction: To build a function \(\hat{f}\) that accurately predicts an outcome \(Y\) from...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 20 Prediction and Estimation | A Guide on Data Analysis">
<meta name="twitter:description" content="In modern statistics, econometrics, and machine learning, two primary goals often motivate data analysis: Prediction: To build a function \(\hat{f}\) that accurately predicts an outcome \(Y\) from...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="active" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="controls.html"><span class="header-section-number">38</span> Controls</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">39</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li><a class="" href="high-performance-computing.html"><span class="header-section-number">44</span> High-Performance Computing</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="prediction-and-estimation" class="section level1" number="20">
<h1>
<span class="header-section-number">20</span> Prediction and Estimation<a class="anchor" aria-label="anchor" href="#prediction-and-estimation"><i class="fas fa-link"></i></a>
</h1>
<p>In modern statistics, econometrics, and machine learning, two primary goals often motivate data analysis:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Prediction</strong>: To build a function <span class="math inline">\(\hat{f}\)</span> that <strong>accurately predicts</strong> an outcome <span class="math inline">\(Y\)</span> from observed features (predictors) <span class="math inline">\(X\)</span>.</p></li>
<li><p><strong>Estimation or Causal Inference</strong>: To <strong>uncover and quantify</strong> the relationship (often causal) between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, typically by estimating parameters like <span class="math inline">\(\beta\)</span> in a model <span class="math inline">\(Y = g(X; \beta)\)</span>.</p></li>
</ol>
<p>These goals, while superficially similar, rest on distinct philosophical and mathematical foundations. Below, we explore the difference in detail, illustrating key ideas with formal definitions, theorems, proofs (where relevant), and references to seminal works.</p>
<div id="conceptual-framing" class="section level2" number="20.1">
<h2>
<span class="header-section-number">20.1</span> Conceptual Framing<a class="anchor" aria-label="anchor" href="#conceptual-framing"><i class="fas fa-link"></i></a>
</h2>
<div id="predictive-modeling" class="section level3" number="20.1.1">
<h3>
<span class="header-section-number">20.1.1</span> Predictive Modeling<a class="anchor" aria-label="anchor" href="#predictive-modeling"><i class="fas fa-link"></i></a>
</h3>
<p>Predictive modeling focuses on building a function <span class="math inline">\(\hat{f}: \mathcal{X} \rightarrow \mathcal{Y}\)</span> that maps inputs <span class="math inline">\(X\)</span> to outputs <span class="math inline">\(Y\)</span>. For simplicity, assume:</p>
<ul>
<li>
<span class="math inline">\(X \in \mathbb{R}^p\)</span> (though in practice <span class="math inline">\(X\)</span> can be images, text, time series, etc.).</li>
<li>
<span class="math inline">\(Y \in \mathbb{R}\)</span> for regression or <span class="math inline">\(Y \in \{0, 1\}\)</span> (or other finite set) for classification.</li>
</ul>
<p>The yardstick for success is the function’s accuracy in out-of-sample predictions, often measured by a loss function <span class="math inline">\(L(\hat{y}, y)\)</span>. We typically choose <span class="math inline">\(\hat{f}\)</span> to minimize expected loss:</p>
<p><span class="math display">\[
\text{(Predictive Problem)} \quad \hat{f} = \arg \min_{f \in \mathcal{F}} \mathbb{E}[L(f(X), Y)],
\]</span></p>
<p>where <span class="math inline">\(\mathcal{F}\)</span> is a class of functions (models) and <span class="math inline">\(\mathbb{E}[\cdot]\)</span> is taken over the joint distribution of <span class="math inline">\((X, Y)\)</span>.</p>
</div>
<div id="estimation-or-causal-inference" class="section level3" number="20.1.2">
<h3>
<span class="header-section-number">20.1.2</span> Estimation or Causal Inference<a class="anchor" aria-label="anchor" href="#estimation-or-causal-inference"><i class="fas fa-link"></i></a>
</h3>
<p>By contrast, estimation or causal inference generally aims to uncover the underlying mechanism: <em>how does</em> <span class="math inline">\(X\)</span> <em>(or a particular component</em> <span class="math inline">\(T \subseteq X\)</span><em>) cause changes in</em> <span class="math inline">\(Y\)</span>? The canonical problem is to estimate parameters <span class="math inline">\(\beta\)</span> in a model <span class="math inline">\(m_\beta(x)\)</span> such that:</p>
<p><span class="math display">\[
Y = m_\beta(X) + \varepsilon,
\]</span></p>
<p>or, in linear form,</p>
<p><span class="math display">\[
Y = X\beta + \varepsilon.
\]</span></p>
<p>A variety of statistical properties—<strong>consistency, unbiasedness, efficiency, confidence intervals, hypothesis tests</strong>—are relevant here. <em>Causal</em> interpretations usually require assumptions beyond typical i.i.d. sampling: unconfoundedness, exogeneity, or random assignment, so that <span class="math inline">\(\beta\)</span> indeed captures how changes in <span class="math inline">\(X\)</span> cause changes in <span class="math inline">\(Y\)</span>.</p>
<p>Key Distinction:</p>
<ul>
<li>
<strong>Prediction</strong> does not require that the parameters used in <span class="math inline">\(\hat{f}\)</span> reflect any real-world mechanism. As long as out-of-sample predictive performance is good, the model is deemed successful—even if it’s a “black box.”</li>
<li>
<strong>Causal inference</strong> demands interpretability in terms of structural or exogenous relationships. The main objective is consistent estimation of the true (or theoretically defined) parameter <span class="math inline">\(\beta\)</span>, which has an economic, biomedical, or policy interpretation.</li>
</ul>
<hr>
</div>
</div>
<div id="mathematical-setup" class="section level2" number="20.2">
<h2>
<span class="header-section-number">20.2</span> Mathematical Setup<a class="anchor" aria-label="anchor" href="#mathematical-setup"><i class="fas fa-link"></i></a>
</h2>
<div id="probability-space-and-data" class="section level3" number="20.2.1">
<h3>
<span class="header-section-number">20.2.1</span> Probability Space and Data<a class="anchor" aria-label="anchor" href="#probability-space-and-data"><i class="fas fa-link"></i></a>
</h3>
<p>We posit a probability space <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> and random variables <span class="math inline">\((X, Y)\)</span> on it. We typically have an i.i.d. sample <span class="math inline">\(\{(X_i, Y_i)\}_{i=1}^n\)</span> from the true distribution <span class="math inline">\(\mathcal{D}\)</span>. Let:</p>
<p><span class="math display">\[
(X, Y) \sim \mathcal{D}, \quad (X_i, Y_i) \overset{\text{i.i.d.}}{\sim} \mathcal{D}.
\]</span></p>
<p>In prediction, we train on <span class="math inline">\(\{(X_i, Y_i)\}_{i=1}^n\)</span> to obtain <span class="math inline">\(\hat{f}\)</span>, and we evaluate on a test point <span class="math inline">\((\tilde{X}, \tilde{Y})\)</span> drawn from <span class="math inline">\(\mathcal{D}\)</span>. In causal inference, we scrutinize the data generating process carefully, ensuring that we can identify a causal effect. For example, we may require:</p>
<ul>
<li>Potential outcomes <span class="math inline">\(\{Y_i(0), Y_i(1)\}\)</span> for treatment effect settings.</li>
<li>Unconfoundedness or randomization assumptions.</li>
</ul>
</div>
<div id="loss-functions-and-risk" class="section level3" number="20.2.2">
<h3>
<span class="header-section-number">20.2.2</span> Loss Functions and Risk<a class="anchor" aria-label="anchor" href="#loss-functions-and-risk"><i class="fas fa-link"></i></a>
</h3>
<p>A general framework for both tasks is the risk minimization approach. For a function <span class="math inline">\(f\)</span>, define:</p>
<ul>
<li>The population (or expected) risk: <span class="math display">\[
\mathcal{R}(f) = \mathbb{E}[L(f(X), Y)].
\]</span>
</li>
<li>The empirical risk (on a sample of size <span class="math inline">\(n\)</span>): <span class="math display">\[
\hat{\mathcal{R}}_n(f) = \frac{1}{n} \sum_{i=1}^n L(f(X_i), Y_i).
\]</span>
</li>
</ul>
<p><strong>Prediction:</strong> We often solve the empirical risk minimization (ERM) problem:</p>
<p><span class="math display">\[
\hat{f} = \arg \min_{f \in \mathcal{F}} \hat{\mathcal{R}}_n(f),
\]</span></p>
<p>possibly with regularization. The measure of success is <span class="math inline">\(\mathcal{R}(\hat{f})\)</span>, i.e., how well <span class="math inline">\(\hat{f}\)</span> generalizes beyond the training sample.</p>
<p><strong>Causal/Parameter Estimation:</strong> We might define an <span class="math inline">\(M\)</span>-estimator for <span class="math inline">\(\beta\)</span> <span class="citation">(<a href="references.html#ref-newey1994large">Newey and McFadden 1994</a>)</span>. Consider a function <span class="math inline">\(\psi(\beta; X, Y)\)</span> such that the true parameter <span class="math inline">\(\beta_0\)</span> satisfies:</p>
<p><span class="math display">\[
\mathbb{E}[\psi(\beta_0; X, Y)] = 0.
\]</span></p>
<p>The empirical <span class="math inline">\(M\)</span>-estimator solves</p>
<p><span class="math display">\[
\hat{\beta} = \arg \min_\beta \left\| \frac{1}{n} \sum_{i=1}^n \psi(\beta; X_i, Y_i) \right\|,
\]</span></p>
<p>or equivalently sets it to zero in a method-of-moments sense:</p>
<p><span class="math display">\[
\frac{1}{n} \sum_{i=1}^n \psi(\hat{\beta}; X_i, Y_i) = 0.
\]</span></p>
<p>Properties like consistency (<span class="math inline">\(\hat{\beta} \overset{p}{\to} \beta_0\)</span>) or asymptotic normality (<span class="math inline">\(\sqrt{n}(\hat{\beta} - \beta_0) \overset{d}{\to} N(0, \Sigma)\)</span>) are central. The emphasis is on <em>uncovering the true</em> <span class="math inline">\(\beta_0\)</span> rather than purely predictive accuracy.</p>
<hr>
</div>
</div>
<div id="prediction-in-detail" class="section level2" number="20.3">
<h2>
<span class="header-section-number">20.3</span> Prediction in Detail<a class="anchor" aria-label="anchor" href="#prediction-in-detail"><i class="fas fa-link"></i></a>
</h2>
<div id="empirical-risk-minimization-and-generalization" class="section level3" number="20.3.1">
<h3>
<span class="header-section-number">20.3.1</span> Empirical Risk Minimization and Generalization<a class="anchor" aria-label="anchor" href="#empirical-risk-minimization-and-generalization"><i class="fas fa-link"></i></a>
</h3>
<p>In supervised learning, the goal is to find a function <span class="math inline">\(f\)</span> from a class of candidate models <span class="math inline">\(\mathcal{F}\)</span> (e.g., linear models, neural networks, tree-based models) that accurately predicts an outcome <span class="math inline">\(Y\)</span> given an input <span class="math inline">\(X\)</span>. This is typically formulated as an <strong>Empirical Risk Minimization problem</strong>, where we seek to minimize the average loss over the training data:</p>
<p><span class="math display">\[
\hat{f} = \arg \min_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n L(f(X_i), Y_i).
\]</span></p>
<p>where <span class="math inline">\(L(\cdot, \cdot)\)</span> is a <strong>loss function</strong> that quantifies the error between predictions and actual values. Common choices include:</p>
<ul>
<li>
<strong>Squared Error (Regression):</strong> <span class="math inline">\(L(\hat{y}, y) = (\hat{y} - y)^2\)</span>.</li>
<li>
<strong>Absolute Error (Regression):</strong> <span class="math inline">\(L(\hat{y}, y) = |\hat{y} - y|\)</span>.</li>
<li>
<strong>Logistic Loss (Classification):</strong> <span class="math inline">\(L(\hat{p}, y) = -[y \log \hat{p} + (1 - y) \log(1 - \hat{p})]\)</span>.</li>
</ul>
<p>By minimizing empirical risk, we find a function <span class="math inline">\(\hat{f}\)</span> that best fits the observed data. However, <strong>minimizing training error does not guarantee good generalization</strong>—the ability of <span class="math inline">\(\hat{f}\)</span> to perform well on unseen data.</p>
<div id="overfitting-and-regularization" class="section level4" number="20.3.1.1">
<h4>
<span class="header-section-number">20.3.1.1</span> Overfitting and Regularization<a class="anchor" aria-label="anchor" href="#overfitting-and-regularization"><i class="fas fa-link"></i></a>
</h4>
<p>If <span class="math inline">\(\mathcal{F}\)</span> is very large or expressive (e.g., deep neural networks with millions of parameters), <span class="math inline">\(\hat{f}\)</span> can become too <strong>complex</strong>, learning patterns that exist in the training set but do not generalize to new data. This is called <strong>overfitting</strong>.</p>
<p>To mitigate overfitting, we introduce <strong>regularization</strong>, modifying the optimization objective to penalize complex models:</p>
<p><span class="math display">\[
\hat{f}_\lambda = \arg \min_{f \in \mathcal{F}} \left\{ \hat{\mathcal{R}}_n(f) + \lambda \Omega(f) \right\}.
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\hat{\mathcal{R}}_n(f) = \frac{1}{n} \sum_{i=1}^{n} L(f(X_i), Y_i)\)</span> is the empirical risk.</p></li>
<li><p><span class="math inline">\(\Omega(f)\)</span> is a <strong>complexity penalty</strong> that discourages overly flexible models.</p></li>
<li><p><span class="math inline">\(\lambda\)</span> controls the strength of regularization.</p></li>
</ul>
<p>Common choices of <span class="math inline">\(\Omega(f)\)</span> include:</p>
<ul>
<li><p><strong>LASSO penalty:</strong> <span class="math inline">\(\|\beta\|_1\)</span> (sparsity constraint in linear models).</p></li>
<li><p><strong>Ridge penalty:</strong> <span class="math inline">\(\|\beta\|_2^2\)</span> (shrinking coefficients to reduce variance).</p></li>
<li><p><strong>Neural network weight decay:</strong> <span class="math inline">\(\sum w^2\)</span> (prevents exploding weights).</p></li>
</ul>
<p>Regularization encourages <strong>simpler models</strong>, which are more likely to generalize well.</p>
</div>
<div id="generalization-and-statistical-learning-theory" class="section level4" number="20.3.1.2">
<h4>
<span class="header-section-number">20.3.1.2</span> Generalization and Statistical Learning Theory<a class="anchor" aria-label="anchor" href="#generalization-and-statistical-learning-theory"><i class="fas fa-link"></i></a>
</h4>
<p>A fundamental question in machine learning is: <em>How well does</em> <span class="math inline">\(\hat{f}\)</span> perform on unseen data? This is captured by the <strong>expected risk</strong>:</p>
<p><span class="math display">\[
R(f) = \mathbb{E}[L(f(X), Y)].
\]</span></p>
<p>Ideally, we want to minimize the gap between the <strong>true risk</strong> <span class="math inline">\(R(\hat{f})\)</span> and the best possible risk <span class="math inline">\(R(f^*)\)</span> within <span class="math inline">\(\mathcal{F}\)</span>:</p>
<p><span class="math display">\[
R(\hat{f}) - \min_{f \in \mathcal{F}} R(f).
\]</span></p>
<p>This difference, called the <strong>excess risk</strong>, measures how well <span class="math inline">\(\hat{f}\)</span> generalizes beyond the training sample. <strong>Statistical Learning Theory</strong> provides theoretical tools to analyze this gap <span class="citation">(<a href="references.html#ref-vapnik2013nature">Vapnik 2013</a>; <a href="references.html#ref-hastie2009elements">Hastie et al. 2009</a>)</span>. In particular, it establishes generalization bounds that depend on the <strong>capacity</strong> of the function class <span class="math inline">\(\mathcal{F}\)</span>.</p>
</div>
<div id="complexity-measures" class="section level4" number="20.3.1.3">
<h4>
<span class="header-section-number">20.3.1.3</span> Complexity Measures<a class="anchor" aria-label="anchor" href="#complexity-measures"><i class="fas fa-link"></i></a>
</h4>
<p>Two important ways to quantify the complexity of <span class="math inline">\(\mathcal{F}\)</span> are</p>
<ul>
<li><p><a href="prediction-and-estimation.html#vc-dimension">VC Dimension</a></p></li>
<li><p><a href="prediction-and-estimation.html#rademacher-complexity">Rademacher Complexity</a></p></li>
</ul>
<div id="vc-dimension" class="section level5" number="20.3.1.3.1">
<h5>
<span class="header-section-number">20.3.1.3.1</span> VC Dimension<a class="anchor" aria-label="anchor" href="#vc-dimension"><i class="fas fa-link"></i></a>
</h5>
<p>The VC dimension measures the ability of a hypothesis class <span class="math inline">\(\mathcal{F}\)</span> to fit arbitrary labels. Formally, the VC dimension of <span class="math inline">\(\mathcal{F}\)</span>, denoted as <span class="math inline">\(\operatorname{VC}(\mathcal{F})\)</span>, is the largest number of points that can be shattered by some function in <span class="math inline">\(\mathcal{F}\)</span>.</p>
<ul>
<li>A set of points is shattered by <span class="math inline">\(\mathcal{F}\)</span> if, for every possible labeling of these points, there exists a function <span class="math inline">\(f \in \mathcal{F}\)</span> that perfectly classifies them.</li>
</ul>
<p><strong>Example 1: Linear Classifiers in 2D</strong></p>
<ul>
<li><p>Consider a set of points in <span class="math inline">\(\mathbb{R}^2\)</span> (the plane).</p></li>
<li><p>If <span class="math inline">\(\mathcal{F}\)</span> consists of linear decision boundaries, we can shatter at most three points in general position (because a single line can separate them in any way).</p></li>
<li><p>However, four points cannot always be shattered (e.g., if arranged in an XOR pattern). - Thus, the VC dimension of linear classifiers in <span class="math inline">\(\mathbb{R}^2\)</span> is 3.</p></li>
</ul>
<p><strong>Key Property:</strong></p>
<ul>
<li><p>A higher VC dimension means a more expressive model class (higher capacity).</p></li>
<li><p>If <span class="math inline">\(\operatorname{VC}(\mathcal{F})\)</span> is too large, the model can memorize the training set, leading to poor generalization.</p></li>
</ul>
</div>
<div id="rademacher-complexity" class="section level5" number="20.3.1.3.2">
<h5>
<span class="header-section-number">20.3.1.3.2</span> Rademacher Complexity<a class="anchor" aria-label="anchor" href="#rademacher-complexity"><i class="fas fa-link"></i></a>
</h5>
<p>VC dimension is a combinatorial measure, but Rademacher complexity is a more refined, data-dependent measure of function class flexibility.</p>
<p><strong>Intuition:</strong> Rademacher complexity quantifies how well functions in <span class="math inline">\(\mathcal{F}\)</span> can <strong>correlate with random noise</strong>. If a function class can fit random labels well, it is too flexible and likely to overfit.</p>
<p><strong>Definition:</strong><br>
Given <span class="math inline">\(n\)</span> training samples, let <span class="math inline">\(\sigma_1, \dots, \sigma_n\)</span> be <strong>independent Rademacher variables</strong> (i.e., random variables taking values <span class="math inline">\(\pm1\)</span> with equal probability). The <strong>empirical Rademacher complexity</strong> of <span class="math inline">\(\mathcal{F}\)</span> is:</p>
<p><span class="math display">\[
\hat{\mathcal{R}}_n(\mathcal{F}) = \mathbb{E}_{\sigma} \left[ \sup_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^{n} \sigma_i f(X_i) \right].
\]</span></p>
<p><strong>Interpretation:</strong></p>
<ul>
<li><p>If <span class="math inline">\(\hat{\mathcal{R}}_n(\mathcal{F})\)</span> is large, then <span class="math inline">\(\mathcal{F}\)</span> can fit random noise well <span class="math inline">\(\Rightarrow\)</span> high risk of overfitting.</p></li>
<li><p>If <span class="math inline">\(\hat{\mathcal{R}}_n(\mathcal{F})\)</span> is small, then <span class="math inline">\(\mathcal{F}\)</span> is more stable <span class="math inline">\(\Rightarrow\)</span> better generalization.</p></li>
</ul>
<p><strong>Example 2: Linear Models with Bounded Norm</strong></p>
<ul>
<li><p>Suppose <span class="math inline">\(\mathcal{F}\)</span> consists of linear models <span class="math inline">\(f(X) = w^\top X\)</span>, where <span class="math inline">\(\|w\| \leq C\)</span>.</p></li>
<li><p>The <strong>Rademacher complexity</strong> of this class scales as <span class="math inline">\(\mathcal{O}(C/\sqrt{n})\)</span>.</p></li>
<li><p>This suggests that controlling the norm of <span class="math inline">\(w\)</span> (e.g., via <a href="linear-regression.html#ridge-regression">Ridge Regression</a>) improves generalization.</p></li>
</ul>
</div>
</div>
</div>
<div id="bias-variance-decomposition" class="section level3" number="20.3.2">
<h3>
<span class="header-section-number">20.3.2</span> Bias-Variance Decomposition<a class="anchor" aria-label="anchor" href="#bias-variance-decomposition"><i class="fas fa-link"></i></a>
</h3>
<p>For a regression problem with squared-error loss, a classic decomposition is:</p>
<p><span class="math display">\[
\mathbb{E}_{\text{train}}[(\hat{f}(X) - Y)^2] = \underbrace{(\mathbb{E}[\hat{f}(X)] - f^*(X))^2}_{\text{Bias}^2} + \underbrace{\mathbb{E}[(\hat{f}(X) - \mathbb{E}[\hat{f}(X)])^2]}_{\text{Variance}} + \underbrace{\sigma_\varepsilon^2}_{\text{Irreducible Error}}
\]</span></p>
<p>where <span class="math inline">\(f^*(X) = \mathbb{E}[Y \mid X]\)</span>. Minimizing the sum of bias<span class="math inline">\(^2\)</span> and variance is key.</p>
<p>In prediction, a small increase in bias is often acceptable if it yields a large reduction in variance—this can improve out-of-sample performance. However, for causal inference, any added bias is problematic if it distorts the interpretation of parameters.</p>
</div>
<div id="example-linear-regression-for-prediction" class="section level3" number="20.3.3">
<h3>
<span class="header-section-number">20.3.3</span> Example: Linear Regression for Prediction<a class="anchor" aria-label="anchor" href="#example-linear-regression-for-prediction"><i class="fas fa-link"></i></a>
</h3>
<p>Consider a linear predictor:</p>
<p><span class="math display">\[
\hat{y} = x^\top \hat{\beta}.
\]</span></p>
<p>We choose <span class="math inline">\(\hat{\beta}\)</span> to minimize:</p>
<p><span class="math display">\[
\sum_{i=1}^n (y_i - x_i^\top \beta)^2 \quad \text{or with a penalty:} \quad \sum_{i=1}^n (y_i - x_i^\top \beta)^2 + \lambda \|\beta\|_2^2.
\]</span></p>
<p><strong>Goal:</strong> Achieve minimal prediction error on unseen data <span class="math inline">\((\tilde{x}, \tilde{y})\)</span>.</p>
<p>The estimated <span class="math inline">\(\hat{\beta}\)</span> might be biased if we use regularization (e.g., ridge). But from a purely predictive lens, that bias can be advantageous if it lowers variance substantially and thus lowers expected prediction error.</p>
</div>
<div id="applications-in-economics" class="section level3" number="20.3.4">
<h3>
<span class="header-section-number">20.3.4</span> Applications in Economics<a class="anchor" aria-label="anchor" href="#applications-in-economics"><i class="fas fa-link"></i></a>
</h3>
<p>In economics (and related social sciences), <strong>prediction</strong> plays an increasingly prominent role <span class="citation">(<a href="references.html#ref-mullainathan2017machine">Mullainathan and Spiess 2017</a>; <a href="references.html#ref-athey2019machine">Athey and Imbens 2019</a>)</span>:</p>
<ul>
<li>
<strong>Measure Variables</strong>: Predicting missing or proxy variables (e.g., predicting income from observable covariates, or predicting individual preferences from online behaviors).</li>
<li>
<strong>Embed Prediction Tasks Within Parameter Estimation or Treatment Effects</strong>: Sometimes, a first-stage prediction (e.g., imputing missing data or generating prognostic scores) is used as an input for subsequent causal analyses.</li>
<li>
<strong>Control for Observed Confounders</strong>: Machine learning methods—such as LASSO, random forests, or neural nets—can be used to control for high-dimensional <span class="math inline">\(X\)</span> when doing partial-out adjustments or residualizing outcomes <span class="citation">(<a href="references.html#ref-belloni2014high">Belloni, Chernozhukov, and Hansen 2014</a>; <a href="references.html#ref-chernozhukov2018double">Chernozhukov et al. 2018</a>)</span>.</li>
</ul>
<hr>
</div>
</div>
<div id="parameter-estimation-and-causal-inference" class="section level2" number="20.4">
<h2>
<span class="header-section-number">20.4</span> Parameter Estimation and Causal Inference<a class="anchor" aria-label="anchor" href="#parameter-estimation-and-causal-inference"><i class="fas fa-link"></i></a>
</h2>
<div id="estimation-in-parametric-models" class="section level3" number="20.4.1">
<h3>
<span class="header-section-number">20.4.1</span> Estimation in Parametric Models<a class="anchor" aria-label="anchor" href="#estimation-in-parametric-models"><i class="fas fa-link"></i></a>
</h3>
<p>In a simple parametric form:</p>
<p><span class="math display">\[
Y = X\beta + \varepsilon, \quad \mathbb{E}[\varepsilon \mid X] = 0, \quad \text{Var}(\varepsilon \mid X) = \sigma^2 I.
\]</span></p>
<p>The <a href="linear-regression.html#ordinary-least-squares">Ordinary Least Squares</a> estimator is:</p>
<p><span class="math display">\[
\hat{\beta}_{\text{OLS}} = \arg \min_\beta \|Y - X\beta\|_2^2 = (X^\top X)^{-1} X^\top Y.
\]</span></p>
<p>Under classical assumptions (e.g., no perfect collinearity, homoskedastic errors), <span class="math inline">\(\hat{\beta}_{\text{OLS}}\)</span> is BLUE—the Best Linear Unbiased Estimator.</p>
<p>In a more general form, <strong>parameter estimation</strong>, denoted <span class="math inline">\(\hat{\beta}\)</span>, focuses on <strong>estimating the relationship</strong> between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, often with a view toward <strong>causality</strong>. In many econometric or statistical settings, we write:</p>
<p><span class="math display">\[ y = x^\top \beta + \varepsilon, \]</span></p>
<p>or more generally <span class="math inline">\(y = g\bigl(x;\beta\bigr) + \varepsilon,\)</span> where <span class="math inline">\(\beta\)</span> encodes the structural or causal parameters we wish to recover.</p>
<p>The core aim is <strong>consistency</strong>—that is, for large <span class="math inline">\(n\)</span>, we want <span class="math inline">\(\hat{\beta}\)</span> to converge to the true <span class="math inline">\(\beta\)</span> that defines the underlying relationship. In other words:</p>
<p><span class="math display">\[ \hat{\beta}  \xrightarrow{p}  \beta, \quad \text{as } n \to \infty. \]</span></p>
<p>Some texts phrase it informally as requiring that</p>
<p><span class="math display">\[ \mathbb{E}\bigl[\hat{f}\bigr] = f, \]</span></p>
<p>meaning the estimator is (asymptotically) unbiased for the true function or parameters.</p>
<p>However, <strong>consistency</strong> alone may not suffice for scientific inference. One often also examines:</p>
<ul>
<li>
<strong>Asymptotic Normality</strong>: <span class="math inline">\(\sqrt{n}(\hat{\beta} - \beta) \;\;\xrightarrow{d}\;\; \mathcal{N}(0,\Sigma).\)</span>
</li>
<li>
<strong>Confidence Intervals</strong>: <span class="math inline">\(\hat{\beta}_j \;\pm\; z_{\alpha/2}\,\mathrm{SE}\bigl(\hat{\beta}_j\bigr).\)</span>
</li>
<li>
<strong>Hypothesis Tests</strong>: <span class="math inline">\(H_0\colon \beta_j = 0 \quad\text{vs.}\quad H_1\colon \beta_j \neq 0.\)</span>
</li>
</ul>
</div>
<div id="causal-inference-fundamentals" class="section level3" number="20.4.2">
<h3>
<span class="header-section-number">20.4.2</span> Causal Inference Fundamentals<a class="anchor" aria-label="anchor" href="#causal-inference-fundamentals"><i class="fas fa-link"></i></a>
</h3>
<p>To interpret <span class="math inline">\(\beta\)</span> in <span class="math inline">\(Y = X\beta + \varepsilon\)</span> as “causal,” we typically require that changes in <span class="math inline">\(X\)</span> (or at least in one component of <span class="math inline">\(X\)</span>) lead to changes in <span class="math inline">\(Y\)</span> that are not confounded by omitted variables or simultaneity. In a prototypical potential-outcomes framework (for a binary treatment <span class="math inline">\(D\)</span>):</p>
<ul>
<li>
<span class="math inline">\(Y_i(1)\)</span>: outcome if unit <span class="math inline">\(i\)</span> receives treatment <span class="math inline">\(D = 1\)</span>.</li>
<li>
<span class="math inline">\(Y_i(0)\)</span>: outcome if unit <span class="math inline">\(i\)</span> receives no treatment <span class="math inline">\(D = 0\)</span>.</li>
</ul>
<p>The observed outcome <span class="math inline">\(Y_i\)</span> is</p>
<p><span class="math display">\[
Y_i = D_i Y_i(1) + (1 - D_i) Y_i(0).
\]</span></p>
<p>The <strong>Average Treatment Effect</strong> (ATE) is:</p>
<p><span class="math display">\[
\tau = \mathbb{E}[Y(1) - Y(0)].
\]</span></p>
<p>Identification of <span class="math inline">\(\tau\)</span> requires an assumption like unconfoundedness:</p>
<p><span class="math display">\[
\{Y(0), Y(1)\} \perp D \mid X,
\]</span></p>
<p>i.e., after conditioning on <span class="math inline">\(X\)</span>, the treatment assignment is as-if random. Estimation strategies then revolve around properly adjusting for <span class="math inline">\(X\)</span>.</p>
<p>Such assumptions are not necessary for raw prediction of <span class="math inline">\(Y\)</span>: a black-box function can yield <span class="math inline">\(\hat{Y} \approx Y\)</span> without ensuring that <span class="math inline">\(\hat{Y}(1) - \hat{Y}(0)\)</span> is an unbiased estimate of <span class="math inline">\(\tau\)</span>.</p>
</div>
<div id="role-of-identification" class="section level3" number="20.4.3">
<h3>
<span class="header-section-number">20.4.3</span> Role of Identification<a class="anchor" aria-label="anchor" href="#role-of-identification"><i class="fas fa-link"></i></a>
</h3>
<p>Identification means that the parameter of interest (<span class="math inline">\(\beta\)</span> or <span class="math inline">\(\tau\)</span>) is uniquely pinned down by the distribution of observables (under assumptions). If <span class="math inline">\(\beta\)</span> is not identified (e.g., because of endogeneity or insufficient variation in <span class="math inline">\(X\)</span>), no matter how large the sample, we cannot estimate <span class="math inline">\(\beta\)</span> consistently.</p>
<p>In prediction, “identification” is not usually the main concern. The function <span class="math inline">\(\hat{f}(x)\)</span> could be a complicated ensemble method that just fits well, without guaranteeing any structural or causal interpretation of its parameters.</p>
</div>
<div id="challenges-1" class="section level3" number="20.4.4">
<h3>
<span class="header-section-number">20.4.4</span> Challenges<a class="anchor" aria-label="anchor" href="#challenges-1"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>
<strong>High-Dimensional Spaces</strong>: With large <span class="math inline">\(p\)</span> (number of predictors), covariance among variables (multicollinearity) can hamper classical estimation. This is the setting of the well-known <strong>bias-variance tradeoff</strong> <span class="citation">(<a href="references.html#ref-hastie2009elements">Hastie et al. 2009</a>; <a href="references.html#ref-bishop2006pattern">Bishop and Nasrabadi 2006</a>)</span>.</li>
<li>
<strong>Endogeneity</strong>: If <span class="math inline">\(x\)</span> is correlated with the error term <span class="math inline">\(\varepsilon\)</span>, ordinary least squares (OLS) is biased. Causal inference demands identifying exogenous variation in <span class="math inline">\(x\)</span>, which requires additional assumptions or designs (e.g., randomization).</li>
<li>
<strong>Model Misspecification</strong>: If the functional form <span class="math inline">\(g\bigl(x;\beta\bigr)\)</span> is incorrect, parameter estimates can systematically deviate from capturing the true underlying mechanism.</li>
</ol>
</div>
</div>
<div id="causation-versus-prediction" class="section level2" number="20.5">
<h2>
<span class="header-section-number">20.5</span> Causation versus Prediction<a class="anchor" aria-label="anchor" href="#causation-versus-prediction"><i class="fas fa-link"></i></a>
</h2>
<p>Understanding the relationship between <strong>causation</strong> and <strong>prediction</strong> is crucial in statistical modeling. Building on <span class="citation">Kleinberg et al. (<a href="references.html#ref-kleinberg2015prediction">2015</a>)</span> and <span class="citation">Mullainathan and Spiess (<a href="references.html#ref-mullainathan2017machine">2017</a>)</span>, consider a scenario where <span class="math inline">\(Y\)</span> is an outcome variable dependent on <span class="math inline">\(X\)</span>, and we want to <strong>manipulate</strong> <span class="math inline">\(X\)</span> to maximize some payoff function <span class="math inline">\(\pi(X,Y)\)</span>. Formally:</p>
<p><span class="math display">\[
\pi(X,Y)
=
\mathbb{E}\bigl[\,U(X,Y)\bigr]
\quad
\text{or some other objective measure}.
\]</span></p>
<p>The decision on <span class="math inline">\(X\)</span> depends on <strong>how changes in</strong> <span class="math inline">\(X\)</span> influence <span class="math inline">\(\pi\)</span>. Taking a derivative:</p>
<p><span class="math display">\[
\frac{d\,\pi(X,Y)}{dX}
=
\frac{\partial \pi}{\partial X}(Y)
+
\frac{\partial \pi}{\partial Y}\,\frac{\partial Y}{\partial X}.
\]</span></p>
<p>We can interpret the terms:</p>
<ul>
<li>
<span class="math inline">\(\displaystyle \frac{\partial \pi}{\partial X}\)</span>: The <em>direct</em> dependence of the payoff on <span class="math inline">\(X\)</span>, which can be predicted if we can forecast how <span class="math inline">\(\pi\)</span> changes with <span class="math inline">\(X\)</span>.</li>
<li>
<span class="math inline">\(\displaystyle \frac{\partial Y}{\partial X}\)</span>: The <em>causal</em> effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, essential for understanding how interventions on <span class="math inline">\(X\)</span> shift <span class="math inline">\(Y\)</span>.</li>
<li>
<span class="math inline">\(\displaystyle \frac{\partial \pi}{\partial Y}\)</span>: The marginal effect of <span class="math inline">\(Y\)</span> on the payoff.</li>
</ul>
<p>Hence, <span class="citation">Kleinberg et al. (<a href="references.html#ref-kleinberg2015prediction">2015</a>)</span> frames this distinction as one between <strong>predicting</strong> <span class="math inline">\(Y\)</span> effectively (for instance, “If I observe <span class="math inline">\(X\)</span>, can I guess <span class="math inline">\(Y\)</span>?”) versus <strong>managing</strong> or <strong>causing</strong> <span class="math inline">\(Y\)</span> to change via <strong>interventions</strong> on <span class="math inline">\(X\)</span>. Empirically:</p>
<ul>
<li>To <strong>predict</strong> <span class="math inline">\(Y\)</span>, we model <span class="math inline">\(\mathbb{E}\bigl[Y\mid X\bigr]\)</span>.</li>
<li>To <strong>infer causality</strong>, we require identification strategies that isolate exogenous variation in <span class="math inline">\(X\)</span>.</li>
</ul>
<p>Empirical work in economics, or social science often aims to estimate partial derivatives of structural or reduced-form equations:</p>
<ul>
<li>
<span class="math inline">\(\displaystyle \frac{\partial Y}{\partial X}\)</span>: The <strong>causal derivative</strong>; tells us how <span class="math inline">\(Y\)</span> changes if we <strong>intervene</strong> on <span class="math inline">\(X\)</span>.</li>
<li>
<span class="math inline">\(\displaystyle \frac{\partial \pi}{\partial X}\)</span>: The <strong>effect of</strong> <span class="math inline">\(X\)</span> on payoff, partially mediated by changes in <span class="math inline">\(Y\)</span>.</li>
</ul>
<p>Without proper identification (e.g., <strong>randomization, instrumental variables, difference-in-differences, or other quasi-experimental designs</strong>), we risk <strong>conflating association</strong> (<span class="math inline">\(\hat{f}\)</span> that predicts <span class="math inline">\(Y\)</span>) with <strong>causation</strong> (<span class="math inline">\(\hat{\beta}\)</span> that truly captures how <span class="math inline">\(X\)</span> shifts <span class="math inline">\(Y\)</span>).</p>
<p>To illustrate these concepts, consider the following directed acyclic graph (DAG):</p>
<div class="sourceCode" id="cb650"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/r-causal/ggdag">ggdag</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.dagitty.net">dagitty</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Define the DAG structure with custom coordinates</span></span>
<span><span class="va">dag</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dagitty/man/dagitty.html">dagitty</a></span><span class="op">(</span><span class="st">'</span></span>
<span><span class="st">dag {</span></span>
<span><span class="st">  X0 [pos="0,1"]</span></span>
<span><span class="st">  X [pos="1,2"]</span></span>
<span><span class="st">  Y [pos="1,1"]</span></span>
<span><span class="st">  II [pos="1,0"]</span></span>
<span><span class="st"></span></span>
<span><span class="st">  X0 -&gt; Y</span></span>
<span><span class="st">  X0 -&gt; II</span></span>
<span><span class="st">  X -&gt; Y</span></span>
<span><span class="st">  Y -&gt; II</span></span>
<span><span class="st">}</span></span>
<span><span class="st">'</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert to ggdag format with manual layout</span></span>
<span><span class="va">dag_plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r-causal.github.io/ggdag/reference/ggdag.html">ggdag</a></span><span class="op">(</span><span class="va">dag</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_void</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="fl">1.2</span>, label <span class="op">=</span> <span class="st">"Causation"</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.3</span>, y <span class="op">=</span> <span class="fl">0.5</span>, label <span class="op">=</span> <span class="st">"Prediction"</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Display the DAG</span></span>
<span><span class="va">dag_plot</span></span></code></pre></div>
<div class="inline-figure"><img src="20-prediction_estimation_files/figure-html/unnamed-chunk-1-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="illustrative-equations-and-mathematical-contrasts" class="section level2" number="20.6">
<h2>
<span class="header-section-number">20.6</span> Illustrative Equations and Mathematical Contrasts<a class="anchor" aria-label="anchor" href="#illustrative-equations-and-mathematical-contrasts"><i class="fas fa-link"></i></a>
</h2>
<p>Below, we showcase a few derivations that highlight how predictive modeling vs. causal inference differ in their mathematical structure and interpretation.</p>
<div id="risk-minimization-vs.-consistency" class="section level3" number="20.6.1">
<h3>
<span class="header-section-number">20.6.1</span> Risk Minimization vs. Consistency<a class="anchor" aria-label="anchor" href="#risk-minimization-vs.-consistency"><i class="fas fa-link"></i></a>
</h3>
<p>Consider a real-valued outcome <span class="math inline">\(Y\)</span> and predictors <span class="math inline">\(X\)</span>. Let <span class="math inline">\(\ell(y, \hat{y})\)</span> be a loss function, and define the Bayes regressor <span class="math inline">\(f^*\)</span> as:</p>
<p><span class="math display">\[
f^* = \arg \min_f \mathbb{E}[\ell(Y, f(X))].
\]</span></p>
<p>For squared error loss, the Bayes regressor is <span class="math inline">\(f^*(x) = \mathbb{E}[Y \mid X = x]\)</span>.</p>
<p>A learning algorithm tries to approximate <span class="math inline">\(f^*\)</span>. If we parametrize <span class="math inline">\(f_\beta(x) = x^\top \beta\)</span> and do empirical risk minimization with a large enough sample, <span class="math inline">\(\beta\)</span> converges to the minimizer of:</p>
<p><span class="math display">\[
\beta^* = \arg \min_\beta \mathbb{E}[(Y - X^\top \beta)^2].
\]</span></p>
<p>Note that <span class="math inline">\(\beta^*\)</span> is the solution to <span class="math inline">\(\mathbb{E}[XX^\top] \beta = \mathbb{E}[XY]\)</span>. If <span class="math inline">\(\text{Cov}(X, X)\)</span> is invertible, then</p>
<p><span class="math display">\[
\beta^* = \text{Cov}(X, X)^{-1} \text{Cov}(X, Y).
\]</span></p>
<p>This <span class="math inline">\(\beta^*\)</span> is not necessarily the same as the “true” <span class="math inline">\(\beta_0\)</span> from a structural equation <span class="math inline">\(Y = X\beta_0 + \varepsilon\)</span> unless <span class="math inline">\(\mathbb{E}[\varepsilon \mid X] = 0\)</span>.</p>
<p>From a predictive standpoint, <span class="math inline">\(\beta^*\)</span> is the best linear predictor in the sense of mean squared error. From a causal standpoint, we want <span class="math inline">\(\beta_0\)</span> such that <span class="math inline">\(\varepsilon\)</span> is mean-independent of <span class="math inline">\(X\)</span>. If that fails, <span class="math inline">\(\beta^* \neq \beta_0\)</span>.</p>
</div>
<div id="partial-derivatives-vs.-predictions" class="section level3" number="20.6.2">
<h3>
<span class="header-section-number">20.6.2</span> Partial Derivatives vs. Predictions<a class="anchor" aria-label="anchor" href="#partial-derivatives-vs.-predictions"><i class="fas fa-link"></i></a>
</h3>
<p>A powerful way to see the difference is to compare:</p>
<ul>
<li>
<span class="math inline">\(\frac{\partial}{\partial x} f^*(x)\)</span> – The partial derivative of the best predictor w.r.t. <span class="math inline">\(x\)</span>. This is about how the model’s <em>prediction</em> changes with <span class="math inline">\(x\)</span>.</li>
<li>
<span class="math inline">\(\frac{\partial}{\partial x} m_\beta(x)\)</span> – The partial derivative of the structural function <span class="math inline">\(m_\beta(\cdot)\)</span>. This is about how the <em>true outcome</em> <span class="math inline">\(Y\)</span> changes with <span class="math inline">\(x\)</span>, i.e., a causal effect if <span class="math inline">\(m_\beta\)</span> is indeed structural.</li>
</ul>
<p>Unless the model was identified and the assumptions hold (exogeneity, no omitted variables, etc.), the partial derivative from a purely predictive model does not represent the causal effect.</p>
<p>In short: “slopes” from a black-box predictive model are not guaranteed to reflect how interventions on <span class="math inline">\(X\)</span> would shift <span class="math inline">\(Y\)</span>.</p>
</div>
<div id="example-high-dimensional-regularization" class="section level3" number="20.6.3">
<h3>
<span class="header-section-number">20.6.3</span> Example: High-Dimensional Regularization<a class="anchor" aria-label="anchor" href="#example-high-dimensional-regularization"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose we have a large number of predictors <span class="math inline">\(p\)</span>, possibly <span class="math inline">\(p \gg n\)</span>. A common approach in both prediction and inference is LASSO:</p>
<p><span class="math display">\[
\hat{\beta}_{\text{LASSO}} = \arg \min_\beta \left\{ \frac{1}{n} \sum_{i=1}^n (y_i - x_i^\top \beta)^2 + \lambda \|\beta\|_1 \right\}.
\]</span></p>
<ul>
<li>
<strong>Prediction:</strong> Choose <span class="math inline">\(\lambda\)</span> to optimize out-of-sample MSE. Some bias is introduced in <span class="math inline">\(\hat{\beta}\)</span>, but the final model might predict extremely well, especially if many true coefficients are near zero.</li>
<li>
<strong>Causal Estimation:</strong> We must worry about whether the LASSO is shrinking or zeroing out confounders. If a crucial confounder’s coefficient is set to zero, the resulting estimate for a treatment variable’s coefficient will be biased. Therefore, special procedures (like the double/debiased machine learning approach <span class="citation">(<a href="references.html#ref-chernozhukov2018double">Chernozhukov et al. 2018</a>)</span>) are introduced to correct for the selection bias or to do post-selection inference <span class="citation">(<a href="references.html#ref-belloni2014high">Belloni, Chernozhukov, and Hansen 2014</a>)</span>.</li>
</ul>
<p>The mathematics of “best subset” for prediction vs. valid coverage intervals for parameters diverges significantly.</p>
</div>
<div id="potential-outcomes-notation" class="section level3" number="20.6.4">
<h3>
<span class="header-section-number">20.6.4</span> Potential Outcomes Notation<a class="anchor" aria-label="anchor" href="#potential-outcomes-notation"><i class="fas fa-link"></i></a>
</h3>
<p>Let <span class="math inline">\(D \in \{0, 1\}\)</span> be a treatment indicator, and define potential outcomes:</p>
<p><span class="math display">\[
Y_i(0), Y_i(1).
\]</span></p>
<p>The observed outcome is:</p>
<p><span class="math display">\[
Y_i = D_i Y_i(1) + (1 - D_i) Y_i(0).
\]</span></p>
<ul>
<li>
<strong>Prediction:</strong> One might train a model <span class="math inline">\(\hat{Y} = \hat{f}(X, D)\)</span> to guess <span class="math inline">\(Y\)</span> from <span class="math inline">\((X, D)\)</span>. That model could be a black box with no guarantee that <span class="math inline">\(\hat{Y}(1) - \hat{Y}(0)\)</span> is an unbiased estimate of <span class="math inline">\(Y_i(1) - Y_i(0)\)</span>.</li>
<li>
<strong>Causal Inference:</strong> We want to estimate <span class="math inline">\(\mathbb{E}[Y(1) - Y(0)]\)</span> or <span class="math inline">\(\mathbb{E}[Y(1) - Y(0) \mid X = x]\)</span>. Identification typically requires <span class="math inline">\(\{Y(0), Y(1)\} \perp D \mid X\)</span>, i.e., after conditioning on <span class="math inline">\(X\)</span>, the treatment assignment is as-if random. Under such an assumption, the difference <span class="math inline">\(\hat{f}(x, 1) - \hat{f}(x, 0)\)</span> can be interpreted as a causal effect.</li>
</ul>
</div>
</div>
<div id="extended-mathematical-points" class="section level2" number="20.7">
<h2>
<span class="header-section-number">20.7</span> Extended Mathematical Points<a class="anchor" aria-label="anchor" href="#extended-mathematical-points"><i class="fas fa-link"></i></a>
</h2>
<p>We now delve deeper into some mathematical nuances that are especially relevant when distinguishing between predictive vs. causal modeling.</p>
<div id="m-estimation-and-asymptotic-theory" class="section level3" number="20.7.1">
<h3>
<span class="header-section-number">20.7.1</span> M-Estimation and Asymptotic Theory<a class="anchor" aria-label="anchor" href="#m-estimation-and-asymptotic-theory"><i class="fas fa-link"></i></a>
</h3>
<p><span class="math inline">\(M\)</span>-Estimators unify many approaches: maximum likelihood, method of moments, generalized method of moments, and quasi-likelihood estimators. Let <span class="math inline">\(\beta_0\)</span> be the true parameter and define the population criterion function:</p>
<p><span class="math display">\[
Q(\beta) = \mathbb{E}[m(\beta; X, Y)],
\]</span></p>
<p>for some function <span class="math inline">\(m\)</span>. The M-estimator <span class="math inline">\(\hat{\beta}\)</span> solves:</p>
<p><span class="math display">\[
\hat{\beta} = \arg \max_{\beta \in \Theta} \frac{1}{n} \sum_{i=1}^n m(\beta; X_i, Y_i).
\]</span></p>
<p>(Or <span class="math inline">\(\arg \min\)</span>, depending on convention.)</p>
<p>Under regularity conditions <span class="citation">(<a href="references.html#ref-newey1994large">Newey and McFadden 1994</a>; <a href="references.html#ref-white1980heteroskedasticity">White 1980</a>)</span>, we have:</p>
<ul>
<li>
<strong>Consistency:</strong> <span class="math inline">\(\hat{\beta} \overset{p}{\to} \beta_0\)</span>.</li>
<li>
<strong>Asymptotic Normality:</strong> <span class="math inline">\(\sqrt{n}(\hat{\beta} - \beta_0) \overset{d}{\to} N(0, \Sigma)\)</span>,</li>
</ul>
<p>where <span class="math inline">\(\Sigma\)</span> is derived from derivatives of <span class="math inline">\(m(\cdot; \cdot, \cdot)\)</span> and the distribution of <span class="math inline">\((X, Y)\)</span>.</p>
<p>For prediction, such classical asymptotic properties may be of less interest unless we want to build confidence intervals around predictions. For causal inference, the entire enterprise revolves around these properties to ensure valid inference about <span class="math inline">\(\beta_0\)</span>.</p>
</div>
<div id="the-danger-of-omitted-variables" class="section level3" number="20.7.2">
<h3>
<span class="header-section-number">20.7.2</span> The Danger of Omitted Variables<a class="anchor" aria-label="anchor" href="#the-danger-of-omitted-variables"><i class="fas fa-link"></i></a>
</h3>
<p>Consider a structural equation:</p>
<p><span class="math display">\[
Y = \beta_1 X_1 + \beta_2 X_2 + \varepsilon,
\quad
\mathbb{E}[\varepsilon \mid X_1, X_2] = 0.
\]</span></p>
<p>If we ignore <span class="math inline">\(X_2\)</span> and regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X_1\)</span> only, the resulting <span class="math inline">\(\hat{\beta}_1\)</span> can be severely biased:</p>
<p><span class="math display">\[
\hat{\beta}_1
=
\arg\min_{b} \sum_{i=1}^n \bigl(y_i - b\,x_{i1}\bigr)^2.
\]</span></p>
<p>The expected value of <span class="math inline">\(\hat{\beta}_1\)</span> in large samples is:</p>
<p><span class="math display">\[
\beta_1
\;+\;
\beta_2 \,\frac{\mathrm{Cov}(X_1, X_2)}{\mathrm{Var}(X_1)}.
\]</span></p>
<p>This extra term <span class="math inline">\(\displaystyle \beta_2 \,\frac{\mathrm{Cov}(X_1, X_2)}{\mathrm{Var}(X_1)}\)</span> is the <strong>omitted variables bias</strong>. For <strong>prediction</strong>, omitting <span class="math inline">\(X_2\)</span> might sometimes be acceptable if <span class="math inline">\(X_2\)</span> has little incremental predictive value or if we only care about accuracy in some domain. However, for <strong>inference</strong> on <span class="math inline">\(\beta_1\)</span>, ignoring <span class="math inline">\(X_2\)</span> invalidates the causal interpretation.</p>
</div>
<div id="cross-validation-vs.-statistical-testing" class="section level3" number="20.7.3">
<h3>
<span class="header-section-number">20.7.3</span> Cross-Validation vs. Statistical Testing<a class="anchor" aria-label="anchor" href="#cross-validation-vs.-statistical-testing"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p><strong>Cross-Validation</strong>: Predominantly used in <strong>prediction</strong> tasks. We split the data into training and validation sets, measure out-of-sample error, and select hyperparameters that minimize CV error.</p></li>
<li><p><strong>Statistical Testing</strong>: Predominantly used in <strong>inference</strong> tasks. We compute test statistics (e.g., <span class="math inline">\(t\)</span>-test, Wald test), form confidence intervals, or test hypotheses about parameters (<span class="math inline">\(H_0: \beta_j = 0\)</span>).</p></li>
</ul>
<p>They serve different objectives:</p>
<ol style="list-style-type: decimal">
<li>
<strong>CV</strong> is about <strong>predictive model selection</strong>.</li>
<li>
<strong>Testing</strong> is about <strong>scientific or policy conclusions</strong> on whether <span class="math inline">\(\beta_j\)</span> differs from zero (i.e., “Does a particular variable have a causal effect?”).</li>
</ol>
<hr>
</div>
</div>
<div id="putting-it-all-together-comparing-objectives" class="section level2" number="20.8">
<h2>
<span class="header-section-number">20.8</span> Putting It All Together: Comparing Objectives<a class="anchor" aria-label="anchor" href="#putting-it-all-together-comparing-objectives"><i class="fas fa-link"></i></a>
</h2>
<p>As an overarching illustration, let <span class="math inline">\(\hat{f}\)</span> be any trained predictor (ML model, regression, etc.) and let <span class="math inline">\(\hat{\beta}\)</span> be a parameter estimator from a structural or causal model. Their respective tasks differ:</p>
<ul>
<li>
<strong>Form of Output</strong>
<ul>
<li>
<span class="math inline">\(\hat{f}\)</span> is a <em>function</em> from <span class="math inline">\(\mathcal{X} \to \mathcal{Y}\)</span>.</li>
<li>
<span class="math inline">\(\hat{\beta}\)</span> is a <em>vector of parameters</em> with theoretical meaning.</li>
</ul>
</li>
<li>
<strong>Criterion</strong>
<ul>
<li>
<strong>Prediction</strong>: Minimizes predictive loss <span class="math inline">\(\mathbb{E}[L(Y,\hat{f}(X))]\)</span>.</li>
<li>
<strong>Causal Inference</strong>: Seeks <span class="math inline">\(\beta\)</span> such that <span class="math inline">\(Y = m_\beta(X)\)</span> is a correct <em>structural</em> representation. Minimizes bias in <span class="math inline">\(\beta\)</span>, or satisfies orthogonality conditions in method-of-moments style, etc.</li>
</ul>
</li>
<li>
<strong>Validity</strong>
<ul>
<li>
<strong>Prediction</strong>: Usually validated by out-of-sample experiments or cross-validation.</li>
<li>
<strong>Estimation</strong>: Validated by theoretical identification arguments, assumptions about exogeneity, randomization, or no omitted confounders.</li>
</ul>
</li>
<li>
<strong>Interpretation</strong>
<ul>
<li>
<strong>Prediction</strong>: “<span class="math inline">\(\hat{f}(x)\)</span> is our best guess of <span class="math inline">\(Y\)</span> for new <span class="math inline">\(x\)</span>.”</li>
<li>
<strong>Causal Inference</strong>: “<span class="math inline">\(\beta\)</span> measures how <span class="math inline">\(Y\)</span> changes if we intervene on <span class="math inline">\(X\)</span>.”</li>
</ul>
</li>
</ul>
<hr>
</div>
<div id="conclusion" class="section level2" number="20.9">
<h2>
<span class="header-section-number">20.9</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Prediction</strong> and <strong>Estimation/Causal Inference</strong> serve distinctly different roles in data analysis:</p>
<ul>
<li><p><strong>Prediction</strong>: The emphasis is on <strong>predictive accuracy</strong>. The final model <span class="math inline">\(\hat{f}\)</span> may have uninterpretable parameters (e.g., deep neural networks) yet excel at forecasting <span class="math inline">\(Y\)</span>. Bias in parameter estimates is not necessarily problematic if it reduces variance and improves out-of-sample performance.</p></li>
<li><p><strong>Estimation/Causal Inference</strong>: The emphasis is on obtaining <strong>consistent</strong> and <strong>unbiased</strong> estimates of parameters (<span class="math inline">\(\beta\)</span>, or a treatment effect <span class="math inline">\(\tau\)</span>). We impose stronger assumptions about data collection and the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(\varepsilon\)</span>. The success criterion is whether <span class="math inline">\(\hat{\beta}\approx\beta_0\)</span> in a formal sense, with valid confidence intervals and robust identification strategies.</p></li>
</ul>
<blockquote>
<p><strong>Key Takeaway</strong>:</p>
<ul>
<li><p>If your question is “How do I <strong>predict</strong> <span class="math inline">\(Y\)</span> for new <span class="math inline">\(X\)</span> as accurately as possible?”, you prioritize <strong>prediction</strong>.</p></li>
<li><p>If your question is “How does <strong>changing</strong> <span class="math inline">\(X\)</span> (or assigning treatment <span class="math inline">\(D\)</span>) affect <span class="math inline">\(Y\)</span> in a <strong>causal</strong> sense?”, you focus on <strong>estimation</strong> with a fully developed identification strategy.</p></li>
</ul>
</blockquote>

</div>
</div>



<div class="chapter-nav">
<div class="prev"><a href="mediation.html"><span class="header-section-number">19</span> Mediation</a></div>
<div class="next"><a href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#prediction-and-estimation"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li>
<a class="nav-link" href="#conceptual-framing"><span class="header-section-number">20.1</span> Conceptual Framing</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#predictive-modeling"><span class="header-section-number">20.1.1</span> Predictive Modeling</a></li>
<li><a class="nav-link" href="#estimation-or-causal-inference"><span class="header-section-number">20.1.2</span> Estimation or Causal Inference</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#mathematical-setup"><span class="header-section-number">20.2</span> Mathematical Setup</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#probability-space-and-data"><span class="header-section-number">20.2.1</span> Probability Space and Data</a></li>
<li><a class="nav-link" href="#loss-functions-and-risk"><span class="header-section-number">20.2.2</span> Loss Functions and Risk</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#prediction-in-detail"><span class="header-section-number">20.3</span> Prediction in Detail</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#empirical-risk-minimization-and-generalization"><span class="header-section-number">20.3.1</span> Empirical Risk Minimization and Generalization</a></li>
<li><a class="nav-link" href="#bias-variance-decomposition"><span class="header-section-number">20.3.2</span> Bias-Variance Decomposition</a></li>
<li><a class="nav-link" href="#example-linear-regression-for-prediction"><span class="header-section-number">20.3.3</span> Example: Linear Regression for Prediction</a></li>
<li><a class="nav-link" href="#applications-in-economics"><span class="header-section-number">20.3.4</span> Applications in Economics</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#parameter-estimation-and-causal-inference"><span class="header-section-number">20.4</span> Parameter Estimation and Causal Inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#estimation-in-parametric-models"><span class="header-section-number">20.4.1</span> Estimation in Parametric Models</a></li>
<li><a class="nav-link" href="#causal-inference-fundamentals"><span class="header-section-number">20.4.2</span> Causal Inference Fundamentals</a></li>
<li><a class="nav-link" href="#role-of-identification"><span class="header-section-number">20.4.3</span> Role of Identification</a></li>
<li><a class="nav-link" href="#challenges-1"><span class="header-section-number">20.4.4</span> Challenges</a></li>
</ul>
</li>
<li><a class="nav-link" href="#causation-versus-prediction"><span class="header-section-number">20.5</span> Causation versus Prediction</a></li>
<li>
<a class="nav-link" href="#illustrative-equations-and-mathematical-contrasts"><span class="header-section-number">20.6</span> Illustrative Equations and Mathematical Contrasts</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#risk-minimization-vs.-consistency"><span class="header-section-number">20.6.1</span> Risk Minimization vs. Consistency</a></li>
<li><a class="nav-link" href="#partial-derivatives-vs.-predictions"><span class="header-section-number">20.6.2</span> Partial Derivatives vs. Predictions</a></li>
<li><a class="nav-link" href="#example-high-dimensional-regularization"><span class="header-section-number">20.6.3</span> Example: High-Dimensional Regularization</a></li>
<li><a class="nav-link" href="#potential-outcomes-notation"><span class="header-section-number">20.6.4</span> Potential Outcomes Notation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#extended-mathematical-points"><span class="header-section-number">20.7</span> Extended Mathematical Points</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#m-estimation-and-asymptotic-theory"><span class="header-section-number">20.7.1</span> M-Estimation and Asymptotic Theory</a></li>
<li><a class="nav-link" href="#the-danger-of-omitted-variables"><span class="header-section-number">20.7.2</span> The Danger of Omitted Variables</a></li>
<li><a class="nav-link" href="#cross-validation-vs.-statistical-testing"><span class="header-section-number">20.7.3</span> Cross-Validation vs. Statistical Testing</a></li>
</ul>
</li>
<li><a class="nav-link" href="#putting-it-all-together-comparing-objectives"><span class="header-section-number">20.8</span> Putting It All Together: Comparing Objectives</a></li>
<li><a class="nav-link" href="#conclusion"><span class="header-section-number">20.9</span> Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/20-prediction_estimation.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/20-prediction_estimation.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>
</div>
  

  

</div>
 <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-04-09.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
