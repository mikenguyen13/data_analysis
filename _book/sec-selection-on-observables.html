<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>35.9 Selection on Observables | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="35.9 Selection on Observables | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="35.9 Selection on Observables | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2025-06-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="software-and-practical-implementation.html"/>
<link rel="next" href="sec-selection-on-unobservables.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="how-to-cite-this-book.html"><a href="how-to-cite-this-book.html"><i class="fa fa-check"></i>How to cite this book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="general-recommendations.html"><a href="general-recommendations.html"><i class="fa fa-check"></i><b>1.1</b> General Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="matrix-theory.html"><a href="matrix-theory.html"><i class="fa fa-check"></i><b>2.1</b> Matrix Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="matrix-theory.html"><a href="matrix-theory.html#rank-of-a-matrix"><i class="fa fa-check"></i><b>2.1.1</b> Rank of a Matrix</a></li>
<li class="chapter" data-level="2.1.2" data-path="matrix-theory.html"><a href="matrix-theory.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>2.1.2</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="2.1.3" data-path="matrix-theory.html"><a href="matrix-theory.html#definiteness-of-a-matrix"><i class="fa fa-check"></i><b>2.1.3</b> Definiteness of a Matrix</a></li>
<li class="chapter" data-level="2.1.4" data-path="matrix-theory.html"><a href="matrix-theory.html#matrix-calculus"><i class="fa fa-check"></i><b>2.1.4</b> Matrix Calculus</a></li>
<li class="chapter" data-level="2.1.5" data-path="matrix-theory.html"><a href="matrix-theory.html#optimization-in-scalar-and-vector-spaces"><i class="fa fa-check"></i><b>2.1.5</b> Optimization in Scalar and Vector Spaces</a></li>
<li class="chapter" data-level="2.1.6" data-path="matrix-theory.html"><a href="matrix-theory.html#cholesky-decomposition"><i class="fa fa-check"></i><b>2.1.6</b> Cholesky Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#axioms-and-theorems-of-probability"><i class="fa fa-check"></i><b>2.2.1</b> Axioms and Theorems of Probability</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.3" data-path="probability-theory.html"><a href="probability-theory.html#random-variable"><i class="fa fa-check"></i><b>2.2.3</b> Random Variable</a></li>
<li class="chapter" data-level="2.2.4" data-path="probability-theory.html"><a href="probability-theory.html#moment-generating-function"><i class="fa fa-check"></i><b>2.2.4</b> Moment Generating Function</a></li>
<li class="chapter" data-level="2.2.5" data-path="probability-theory.html"><a href="probability-theory.html#moments"><i class="fa fa-check"></i><b>2.2.5</b> Moments</a></li>
<li class="chapter" data-level="2.2.6" data-path="probability-theory.html"><a href="probability-theory.html#skewness"><i class="fa fa-check"></i><b>2.2.6</b> Skewness</a></li>
<li class="chapter" data-level="2.2.7" data-path="probability-theory.html"><a href="probability-theory.html#kurtosis"><i class="fa fa-check"></i><b>2.2.7</b> Kurtosis</a></li>
<li class="chapter" data-level="2.2.8" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>2.2.8</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="general-math.html"><a href="general-math.html"><i class="fa fa-check"></i><b>2.3</b> General Math</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="general-math.html"><a href="general-math.html#number-sets"><i class="fa fa-check"></i><b>2.3.1</b> Number Sets</a></li>
<li class="chapter" data-level="2.3.2" data-path="general-math.html"><a href="general-math.html#summation-notation-and-series"><i class="fa fa-check"></i><b>2.3.2</b> Summation Notation and Series</a></li>
<li class="chapter" data-level="2.3.3" data-path="general-math.html"><a href="general-math.html#taylor-expansion"><i class="fa fa-check"></i><b>2.3.3</b> Taylor Expansion</a></li>
<li class="chapter" data-level="2.3.4" data-path="general-math.html"><a href="general-math.html#law-of-large-numbers"><i class="fa fa-check"></i><b>2.3.4</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="2.3.5" data-path="general-math.html"><a href="general-math.html#convergence"><i class="fa fa-check"></i><b>2.3.5</b> Convergence</a></li>
<li class="chapter" data-level="2.3.6" data-path="general-math.html"><a href="general-math.html#sufficient-statistics-and-likelihood"><i class="fa fa-check"></i><b>2.3.6</b> Sufficient Statistics and Likelihood</a></li>
<li class="chapter" data-level="2.3.7" data-path="general-math.html"><a href="general-math.html#parameter-transformations"><i class="fa fa-check"></i><b>2.3.7</b> Parameter Transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-importexport.html"><a href="data-importexport.html"><i class="fa fa-check"></i><b>2.4</b> Data Import/Export</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="data-importexport.html"><a href="data-importexport.html#key-limitations-of-r"><i class="fa fa-check"></i><b>2.4.1</b> Key Limitations of R</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-importexport.html"><a href="data-importexport.html#solutions-and-workarounds"><i class="fa fa-check"></i><b>2.4.2</b> Solutions and Workarounds</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-importexport.html"><a href="data-importexport.html#medium-size"><i class="fa fa-check"></i><b>2.4.3</b> Medium size</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-importexport.html"><a href="data-importexport.html#large-size"><i class="fa fa-check"></i><b>2.4.4</b> Large size</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2.5</b> Data Manipulation</a></li>
</ul></li>
<li class="part"><span><b>I. BASIC</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="numerical-measures.html"><a href="numerical-measures.html"><i class="fa fa-check"></i><b>3.1</b> Numerical Measures</a></li>
<li class="chapter" data-level="3.2" data-path="graphical-measures.html"><a href="graphical-measures.html"><i class="fa fa-check"></i><b>3.2</b> Graphical Measures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="graphical-measures.html"><a href="graphical-measures.html#shape"><i class="fa fa-check"></i><b>3.2.1</b> Shape</a></li>
<li class="chapter" data-level="3.2.2" data-path="graphical-measures.html"><a href="graphical-measures.html#scatterplot"><i class="fa fa-check"></i><b>3.2.2</b> Scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="normality-assessment.html"><a href="normality-assessment.html"><i class="fa fa-check"></i><b>3.3</b> Normality Assessment</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normality-assessment.html"><a href="normality-assessment.html#graphical-assessment"><i class="fa fa-check"></i><b>3.3.1</b> Graphical Assessment</a></li>
<li class="chapter" data-level="3.3.2" data-path="normality-assessment.html"><a href="normality-assessment.html#summary-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html"><i class="fa fa-check"></i><b>3.4</b> Bivariate Statistics</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#two-continuous"><i class="fa fa-check"></i><b>3.4.1</b> Two Continuous</a></li>
<li class="chapter" data-level="3.4.2" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#categorical-and-continuous"><i class="fa fa-check"></i><b>3.4.2</b> Categorical and Continuous</a></li>
<li class="chapter" data-level="3.4.3" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#two-discrete"><i class="fa fa-check"></i><b>3.4.3</b> Two Discrete</a></li>
<li class="chapter" data-level="3.4.4" data-path="bivariate-statistics.html"><a href="bivariate-statistics.html#general-approach-to-bivariate-statistics"><i class="fa fa-check"></i><b>3.4.4</b> General Approach to Bivariate Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistical-inference.html"><a href="basic-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html"><i class="fa fa-check"></i><b>4.1</b> Hypothesis Testing Framework</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>4.1.1</b> Null and Alternative Hypotheses</a></li>
<li class="chapter" data-level="4.1.2" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.2</b> Errors in Hypothesis Testing</a></li>
<li class="chapter" data-level="4.1.3" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#the-role-of-distributions-in-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.3</b> The Role of Distributions in Hypothesis Testing</a></li>
<li class="chapter" data-level="4.1.4" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#the-test-statistic"><i class="fa fa-check"></i><b>4.1.4</b> The Test Statistic</a></li>
<li class="chapter" data-level="4.1.5" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#critical-values-and-rejection-regions-1"><i class="fa fa-check"></i><b>4.1.5</b> Critical Values and Rejection Regions</a></li>
<li class="chapter" data-level="4.1.6" data-path="hypothesis-testing-framework.html"><a href="hypothesis-testing-framework.html#visualizing-hypothesis-testing"><i class="fa fa-check"></i><b>4.1.6</b> Visualizing Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html"><i class="fa fa-check"></i><b>4.2</b> Key Concepts and Definitions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html#random-sample"><i class="fa fa-check"></i><b>4.2.1</b> Random Sample</a></li>
<li class="chapter" data-level="4.2.2" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html#sample-statistics"><i class="fa fa-check"></i><b>4.2.2</b> Sample Statistics</a></li>
<li class="chapter" data-level="4.2.3" data-path="key-concepts-and-definitions.html"><a href="key-concepts-and-definitions.html#distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>4.2.3</b> Distribution of the Sample Mean</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>4.3</b> One-Sample Inference</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-single-mean"><i class="fa fa-check"></i><b>4.3.1</b> For Single Mean</a></li>
<li class="chapter" data-level="4.3.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-difference-of-means-independent-samples"><i class="fa fa-check"></i><b>4.3.2</b> For Difference of Means, Independent Samples</a></li>
<li class="chapter" data-level="4.3.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-difference-of-means-paired-samples"><i class="fa fa-check"></i><b>4.3.3</b> For Difference of Means, Paired Samples</a></li>
<li class="chapter" data-level="4.3.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-difference-of-two-proportions"><i class="fa fa-check"></i><b>4.3.4</b> For Difference of Two Proportions</a></li>
<li class="chapter" data-level="4.3.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-single-proportion"><i class="fa fa-check"></i><b>4.3.5</b> For Single Proportion</a></li>
<li class="chapter" data-level="4.3.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#for-single-variance"><i class="fa fa-check"></i><b>4.3.6</b> For Single Variance</a></li>
<li class="chapter" data-level="4.3.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#non-parametric-tests"><i class="fa fa-check"></i><b>4.3.7</b> Non-parametric Tests</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>4.4</b> Two-Sample Inference</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#for-means"><i class="fa fa-check"></i><b>4.4.1</b> For Means</a></li>
<li class="chapter" data-level="4.4.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#for-variances"><i class="fa fa-check"></i><b>4.4.2</b> For Variances</a></li>
<li class="chapter" data-level="4.4.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#power"><i class="fa fa-check"></i><b>4.4.3</b> Power</a></li>
<li class="chapter" data-level="4.4.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#matched-pair-designs"><i class="fa fa-check"></i><b>4.4.4</b> Matched Pair Designs</a></li>
<li class="chapter" data-level="4.4.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#nonparametric-tests-for-two-samples"><i class="fa fa-check"></i><b>4.4.5</b> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>4.5</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#association-tests"><i class="fa fa-check"></i><b>4.5.1</b> Association Tests</a></li>
<li class="chapter" data-level="4.5.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-association"><i class="fa fa-check"></i><b>4.5.2</b> Ordinal Association</a></li>
<li class="chapter" data-level="4.5.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-trend"><i class="fa fa-check"></i><b>4.5.3</b> Ordinal Trend</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html"><i class="fa fa-check"></i><b>4.6</b> Divergence Metrics and Tests for Comparing Distributions</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-kolmogorov-smirnov-test"><i class="fa fa-check"></i><b>4.6.1</b> Kolmogorov-Smirnov Test</a></li>
<li class="chapter" data-level="4.6.2" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-anderson-darling-test"><i class="fa fa-check"></i><b>4.6.2</b> Anderson-Darling Test</a></li>
<li class="chapter" data-level="4.6.3" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>4.6.3</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="4.6.4" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-cramer-von-mises-test"><i class="fa fa-check"></i><b>4.6.4</b> Cram√©r-von Mises Test</a></li>
<li class="chapter" data-level="4.6.5" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-kullback-leibler-divergence"><i class="fa fa-check"></i><b>4.6.5</b> Kullback-Leibler Divergence</a></li>
<li class="chapter" data-level="4.6.6" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-jensen-shannon-divergence"><i class="fa fa-check"></i><b>4.6.6</b> Jensen-Shannon Divergence</a></li>
<li class="chapter" data-level="4.6.7" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-hellinger-distance"><i class="fa fa-check"></i><b>4.6.7</b> Hellinger Distance</a></li>
<li class="chapter" data-level="4.6.8" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-bhattacharyya-distance"><i class="fa fa-check"></i><b>4.6.8</b> Bhattacharyya Distance</a></li>
<li class="chapter" data-level="4.6.9" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-wasserstein-distance"><i class="fa fa-check"></i><b>4.6.9</b> Wasserstein Distance</a></li>
<li class="chapter" data-level="4.6.10" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-energy-distance"><i class="fa fa-check"></i><b>4.6.10</b> Energy Distance</a></li>
<li class="chapter" data-level="4.6.11" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#sec-total-variation-distance"><i class="fa fa-check"></i><b>4.6.11</b> Total Variation Distance</a></li>
<li class="chapter" data-level="4.6.12" data-path="divergence-metrics-and-tests-for-comparing-distributions.html"><a href="divergence-metrics-and-tests-for-comparing-distributions.html#summary"><i class="fa fa-check"></i><b>4.6.12</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II. REGRESSION</b></span></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5.1</b> Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#simple-regression-basic-model"><i class="fa fa-check"></i><b>5.1.1</b> Simple Regression (Basic) Model</a></li>
<li class="chapter" data-level="5.1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.2</b> Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5.2</b> Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#infeasible-generalized-least-squares"><i class="fa fa-check"></i><b>5.2.1</b> Infeasible Generalized Least Squares</a></li>
<li class="chapter" data-level="5.2.2" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#feasible-generalized-least-squares"><i class="fa fa-check"></i><b>5.2.2</b> Feasible Generalized Least Squares</a></li>
<li class="chapter" data-level="5.2.3" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html#weighted-least-squares"><i class="fa fa-check"></i><b>5.2.3</b> Weighted Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html"><i class="fa fa-check"></i><b>5.3</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#motivation-for-mle"><i class="fa fa-check"></i><b>5.3.1</b> Motivation for MLE</a></li>
<li class="chapter" data-level="5.3.2" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#key-quantities-for-inference"><i class="fa fa-check"></i><b>5.3.2</b> Key Quantities for Inference</a></li>
<li class="chapter" data-level="5.3.3" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#assumptions-of-mle"><i class="fa fa-check"></i><b>5.3.3</b> Assumptions of MLE</a></li>
<li class="chapter" data-level="5.3.4" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#properties-of-mle"><i class="fa fa-check"></i><b>5.3.4</b> Properties of MLE</a></li>
<li class="chapter" data-level="5.3.5" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#practical-considerations"><i class="fa fa-check"></i><b>5.3.5</b> Practical Considerations</a></li>
<li class="chapter" data-level="5.3.6" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#comparison-of-mle-and-ols"><i class="fa fa-check"></i><b>5.3.6</b> Comparison of MLE and OLS</a></li>
<li class="chapter" data-level="5.3.7" data-path="maximum-likelihood-estimator.html"><a href="maximum-likelihood-estimator.html#applications-of-mle"><i class="fa fa-check"></i><b>5.3.7</b> Applications of MLE</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html"><i class="fa fa-check"></i><b>5.4</b> Penalized (Regularized) Estimators</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#motivation-for-penalized-estimators"><i class="fa fa-check"></i><b>5.4.1</b> Motivation for Penalized Estimators</a></li>
<li class="chapter" data-level="5.4.2" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#ridge-regression"><i class="fa fa-check"></i><b>5.4.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="5.4.3" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#lasso-regression"><i class="fa fa-check"></i><b>5.4.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="5.4.4" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#elastic-net"><i class="fa fa-check"></i><b>5.4.4</b> Elastic Net</a></li>
<li class="chapter" data-level="5.4.5" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#tuning-parameter-selection"><i class="fa fa-check"></i><b>5.4.5</b> Tuning Parameter Selection</a></li>
<li class="chapter" data-level="5.4.6" data-path="penalized-regularized-estimators.html"><a href="penalized-regularized-estimators.html#properties-of-penalized-estimators"><i class="fa fa-check"></i><b>5.4.6</b> Properties of Penalized Estimators</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="robust-estimators.html"><a href="robust-estimators.html"><i class="fa fa-check"></i><b>5.5</b> Robust Estimators</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="robust-estimators.html"><a href="robust-estimators.html#motivation-for-robust-estimation"><i class="fa fa-check"></i><b>5.5.1</b> Motivation for Robust Estimation</a></li>
<li class="chapter" data-level="5.5.2" data-path="robust-estimators.html"><a href="robust-estimators.html#m-estimators"><i class="fa fa-check"></i><b>5.5.2</b> <span class="math inline">\(M\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.3" data-path="robust-estimators.html"><a href="robust-estimators.html#r-estimators"><i class="fa fa-check"></i><b>5.5.3</b> <span class="math inline">\(R\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.4" data-path="robust-estimators.html"><a href="robust-estimators.html#l-estimators"><i class="fa fa-check"></i><b>5.5.4</b> <span class="math inline">\(L\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.5" data-path="robust-estimators.html"><a href="robust-estimators.html#least-trimmed-squares-lts"><i class="fa fa-check"></i><b>5.5.5</b> Least Trimmed Squares (LTS)</a></li>
<li class="chapter" data-level="5.5.6" data-path="robust-estimators.html"><a href="robust-estimators.html#s-estimators"><i class="fa fa-check"></i><b>5.5.6</b> <span class="math inline">\(S\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.7" data-path="robust-estimators.html"><a href="robust-estimators.html#mm-estimators"><i class="fa fa-check"></i><b>5.5.7</b> <span class="math inline">\(MM\)</span>-Estimators</a></li>
<li class="chapter" data-level="5.5.8" data-path="robust-estimators.html"><a href="robust-estimators.html#practical-considerations-1"><i class="fa fa-check"></i><b>5.5.8</b> Practical Considerations</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="partial-least-squares.html"><a href="partial-least-squares.html"><i class="fa fa-check"></i><b>5.6</b> Partial Least Squares</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="partial-least-squares.html"><a href="partial-least-squares.html#motivation-for-pls"><i class="fa fa-check"></i><b>5.6.1</b> Motivation for PLS</a></li>
<li class="chapter" data-level="5.6.2" data-path="partial-least-squares.html"><a href="partial-least-squares.html#steps-to-construct-pls-components"><i class="fa fa-check"></i><b>5.6.2</b> Steps to Construct PLS Components</a></li>
<li class="chapter" data-level="5.6.3" data-path="partial-least-squares.html"><a href="partial-least-squares.html#properties-of-pls"><i class="fa fa-check"></i><b>5.6.3</b> Properties of PLS</a></li>
<li class="chapter" data-level="5.6.4" data-path="partial-least-squares.html"><a href="partial-least-squares.html#comparison-with-related-methods"><i class="fa fa-check"></i><b>5.6.4</b> Comparison with Related Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Non-Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>6.1</b> Inference</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="inference.html"><a href="inference.html#linear-functions-of-the-parameters"><i class="fa fa-check"></i><b>6.1.1</b> Linear Functions of the Parameters</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference.html"><a href="inference.html#nonlinear-functions-of-parameters"><i class="fa fa-check"></i><b>6.1.2</b> Nonlinear Functions of Parameters</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html"><i class="fa fa-check"></i><b>6.2</b> Non-linear Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#iterative-optimization-nonlinear-regression"><i class="fa fa-check"></i><b>6.2.1</b> Iterative Optimization</a></li>
<li class="chapter" data-level="6.2.2" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#derivative-free"><i class="fa fa-check"></i><b>6.2.2</b> Derivative-Free</a></li>
<li class="chapter" data-level="6.2.3" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#stochastic-heuristic-nolinear-regression"><i class="fa fa-check"></i><b>6.2.3</b> Stochastic Heuristic</a></li>
<li class="chapter" data-level="6.2.4" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#linearization-nonlinear-regression-optimization"><i class="fa fa-check"></i><b>6.2.4</b> Linearization</a></li>
<li class="chapter" data-level="6.2.5" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#hybrid-nonlinear-regression-optimization"><i class="fa fa-check"></i><b>6.2.5</b> Hybrid</a></li>
<li class="chapter" data-level="6.2.6" data-path="non-linear-least-squares-estimation.html"><a href="non-linear-least-squares-estimation.html#comparison-of-nonlinear-optimizers"><i class="fa fa-check"></i><b>6.2.6</b> Comparison of Nonlinear Optimizers</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html"><i class="fa fa-check"></i><b>6.3</b> Practical Considerations</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#selecting-starting-values"><i class="fa fa-check"></i><b>6.3.1</b> Selecting Starting Values</a></li>
<li class="chapter" data-level="6.3.2" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#handling-constrained-parameters"><i class="fa fa-check"></i><b>6.3.2</b> Handling Constrained Parameters</a></li>
<li class="chapter" data-level="6.3.3" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#failure-to-converge"><i class="fa fa-check"></i><b>6.3.3</b> Failure to Converge</a></li>
<li class="chapter" data-level="6.3.4" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#convergence-to-a-local-minimum"><i class="fa fa-check"></i><b>6.3.4</b> Convergence to a Local Minimum</a></li>
<li class="chapter" data-level="6.3.5" data-path="practical-considerations-2.html"><a href="practical-considerations-2.html#model-adequacy-and-estimation-considerations"><i class="fa fa-check"></i><b>6.3.5</b> Model Adequacy and Estimation Considerations</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="application.html"><a href="application.html"><i class="fa fa-check"></i><b>6.4</b> Application</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="application.html"><a href="application.html#nonlinear-estimation-using-gauss-newton-algorithm"><i class="fa fa-check"></i><b>6.4.1</b> Nonlinear Estimation Using Gauss-Newton Algorithm</a></li>
<li class="chapter" data-level="6.4.2" data-path="application.html"><a href="application.html#logistic-growth-model"><i class="fa fa-check"></i><b>6.4.2</b> Logistic Growth Model</a></li>
<li class="chapter" data-level="6.4.3" data-path="application.html"><a href="application.html#nonlinear-plateau-model"><i class="fa fa-check"></i><b>6.4.3</b> Nonlinear Plateau Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec-logistic-regression.html"><a href="sec-logistic-regression.html"><i class="fa fa-check"></i><b>7.1</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="sec-logistic-regression.html"><a href="sec-logistic-regression.html#logistic-model"><i class="fa fa-check"></i><b>7.1.1</b> Logistic Model</a></li>
<li class="chapter" data-level="7.1.2" data-path="sec-logistic-regression.html"><a href="sec-logistic-regression.html#sec-likelihood-function-logistic"><i class="fa fa-check"></i><b>7.1.2</b> Likelihood Function</a></li>
<li class="chapter" data-level="7.1.3" data-path="sec-logistic-regression.html"><a href="sec-logistic-regression.html#fisher-information-matrix"><i class="fa fa-check"></i><b>7.1.3</b> Fisher Information Matrix</a></li>
<li class="chapter" data-level="7.1.4" data-path="sec-logistic-regression.html"><a href="sec-logistic-regression.html#inference-in-logistic-regression"><i class="fa fa-check"></i><b>7.1.4</b> Inference in Logistic Regression</a></li>
<li class="chapter" data-level="7.1.5" data-path="sec-logistic-regression.html"><a href="sec-logistic-regression.html#application-logistic-regression"><i class="fa fa-check"></i><b>7.1.5</b> Application: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="sec-probit-regression.html"><a href="sec-probit-regression.html"><i class="fa fa-check"></i><b>7.2</b> Probit Regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="sec-probit-regression.html"><a href="sec-probit-regression.html#probit-model"><i class="fa fa-check"></i><b>7.2.1</b> Probit Model</a></li>
<li class="chapter" data-level="7.2.2" data-path="sec-probit-regression.html"><a href="sec-probit-regression.html#application-probit-regression"><i class="fa fa-check"></i><b>7.2.2</b> Application: Probit Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sec-binomial-regression.html"><a href="sec-binomial-regression.html"><i class="fa fa-check"></i><b>7.3</b> Binomial Regression</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="sec-binomial-regression.html"><a href="sec-binomial-regression.html#dataset-overview"><i class="fa fa-check"></i><b>7.3.1</b> Dataset Overview</a></li>
<li class="chapter" data-level="7.3.2" data-path="sec-binomial-regression.html"><a href="sec-binomial-regression.html#apply-logistic-model"><i class="fa fa-check"></i><b>7.3.2</b> Apply Logistic Model</a></li>
<li class="chapter" data-level="7.3.3" data-path="sec-binomial-regression.html"><a href="sec-binomial-regression.html#apply-probit-model"><i class="fa fa-check"></i><b>7.3.3</b> Apply Probit Model</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sec-poisson-regression.html"><a href="sec-poisson-regression.html"><i class="fa fa-check"></i><b>7.4</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="sec-poisson-regression.html"><a href="sec-poisson-regression.html#the-poisson-distribution"><i class="fa fa-check"></i><b>7.4.1</b> The Poisson Distribution</a></li>
<li class="chapter" data-level="7.4.2" data-path="sec-poisson-regression.html"><a href="sec-poisson-regression.html#poisson-model"><i class="fa fa-check"></i><b>7.4.2</b> Poisson Model</a></li>
<li class="chapter" data-level="7.4.3" data-path="sec-poisson-regression.html"><a href="sec-poisson-regression.html#link-function-choices"><i class="fa fa-check"></i><b>7.4.3</b> Link Function Choices</a></li>
<li class="chapter" data-level="7.4.4" data-path="sec-poisson-regression.html"><a href="sec-poisson-regression.html#application-poisson-regression"><i class="fa fa-check"></i><b>7.4.4</b> Application: Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="sec-negative-binomial-regression.html"><a href="sec-negative-binomial-regression.html"><i class="fa fa-check"></i><b>7.5</b> Negative Binomial Regression</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="sec-negative-binomial-regression.html"><a href="sec-negative-binomial-regression.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>7.5.1</b> Negative Binomial Distribution</a></li>
<li class="chapter" data-level="7.5.2" data-path="sec-negative-binomial-regression.html"><a href="sec-negative-binomial-regression.html#application-negative-binomial-regression"><i class="fa fa-check"></i><b>7.5.2</b> Application: Negative Binomial Regression</a></li>
<li class="chapter" data-level="7.5.3" data-path="sec-negative-binomial-regression.html"><a href="sec-negative-binomial-regression.html#fitting-a-zero-inflated-negative-binomial-model"><i class="fa fa-check"></i><b>7.5.3</b> Fitting a Zero-Inflated Negative Binomial Model</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sec-quasi-poisson-regression.html"><a href="sec-quasi-poisson-regression.html"><i class="fa fa-check"></i><b>7.6</b> Quasi-Poisson Regression</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="sec-quasi-poisson-regression.html"><a href="sec-quasi-poisson-regression.html#is-quasi-poisson-regression-a-generalized-linear-model"><i class="fa fa-check"></i><b>7.6.1</b> Is Quasi-Poisson Regression a Generalized Linear Model?</a></li>
<li class="chapter" data-level="7.6.2" data-path="sec-quasi-poisson-regression.html"><a href="sec-quasi-poisson-regression.html#application-quasi-poisson-regression"><i class="fa fa-check"></i><b>7.6.2</b> Application: Quasi-Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>7.7</b> Multinomial Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#the-multinomial-distribution"><i class="fa fa-check"></i><b>7.7.1</b> The Multinomial Distribution</a></li>
<li class="chapter" data-level="7.7.2" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#modeling-probabilities-using-log-odds"><i class="fa fa-check"></i><b>7.7.2</b> Modeling Probabilities Using Log-Odds</a></li>
<li class="chapter" data-level="7.7.3" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#softmax-representation"><i class="fa fa-check"></i><b>7.7.3</b> Softmax Representation</a></li>
<li class="chapter" data-level="7.7.4" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#log-odds-ratio-between-two-categories"><i class="fa fa-check"></i><b>7.7.4</b> Log-Odds Ratio Between Two Categories</a></li>
<li class="chapter" data-level="7.7.5" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#estimation"><i class="fa fa-check"></i><b>7.7.5</b> Estimation</a></li>
<li class="chapter" data-level="7.7.6" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>7.7.6</b> Interpretation of Coefficients</a></li>
<li class="chapter" data-level="7.7.7" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#application-multinomial-logistic-regression"><i class="fa fa-check"></i><b>7.7.7</b> Application: Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="7.7.8" data-path="sec-multinomial-logistic-regression.html"><a href="sec-multinomial-logistic-regression.html#application-gamma-regression"><i class="fa fa-check"></i><b>7.7.8</b> Application: Gamma Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html"><i class="fa fa-check"></i><b>7.8</b> Generalization of Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#exponential-family"><i class="fa fa-check"></i><b>7.8.1</b> Exponential Family</a></li>
<li class="chapter" data-level="7.8.2" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#properties-of-glm-exponential-families"><i class="fa fa-check"></i><b>7.8.2</b> Properties of GLM Exponential Families</a></li>
<li class="chapter" data-level="7.8.3" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#structure-of-a-generalized-linear-model"><i class="fa fa-check"></i><b>7.8.3</b> Structure of a Generalized Linear Model</a></li>
<li class="chapter" data-level="7.8.4" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#components-of-a-glm"><i class="fa fa-check"></i><b>7.8.4</b> Components of a GLM</a></li>
<li class="chapter" data-level="7.8.5" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#canonical-link"><i class="fa fa-check"></i><b>7.8.5</b> Canonical Link</a></li>
<li class="chapter" data-level="7.8.6" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#inverse-link-functions"><i class="fa fa-check"></i><b>7.8.6</b> Inverse Link Functions</a></li>
<li class="chapter" data-level="7.8.7" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#estimation-of-parameters-in-glms"><i class="fa fa-check"></i><b>7.8.7</b> Estimation of Parameters in GLMs</a></li>
<li class="chapter" data-level="7.8.8" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#inference-1"><i class="fa fa-check"></i><b>7.8.8</b> Inference</a></li>
<li class="chapter" data-level="7.8.9" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#deviance"><i class="fa fa-check"></i><b>7.8.9</b> Deviance</a></li>
<li class="chapter" data-level="7.8.10" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.8.10</b> Diagnostic Plots</a></li>
<li class="chapter" data-level="7.8.11" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.8.11</b> Goodness of Fit</a></li>
<li class="chapter" data-level="7.8.12" data-path="sec-generalization-of-generalized-linear-models.html"><a href="sec-generalization-of-generalized-linear-models.html#over-dispersion"><i class="fa fa-check"></i><b>7.8.12</b> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sec-linear-mixed-models.html"><a href="sec-linear-mixed-models.html"><i class="fa fa-check"></i><b>8</b> Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dependent-data.html"><a href="dependent-data.html"><i class="fa fa-check"></i><b>8.1</b> Dependent Data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="dependent-data.html"><a href="dependent-data.html#motivation-a-repeated-measurements-example"><i class="fa fa-check"></i><b>8.1.1</b> Motivation: A Repeated Measurements Example</a></li>
<li class="chapter" data-level="8.1.2" data-path="dependent-data.html"><a href="dependent-data.html#example-linear-mixed-model-for-repeated-measurements"><i class="fa fa-check"></i><b>8.1.2</b> Example: Linear Mixed Model for Repeated Measurements</a></li>
<li class="chapter" data-level="8.1.3" data-path="dependent-data.html"><a href="dependent-data.html#sec-random-intercepts-model-lmm"><i class="fa fa-check"></i><b>8.1.3</b> Random-Intercepts Model</a></li>
<li class="chapter" data-level="8.1.4" data-path="dependent-data.html"><a href="dependent-data.html#covariance-models-in-linear-mixed-models"><i class="fa fa-check"></i><b>8.1.4</b> Covariance Models in Linear Mixed Models</a></li>
<li class="chapter" data-level="8.1.5" data-path="dependent-data.html"><a href="dependent-data.html#covariance-structures-in-mixed-models"><i class="fa fa-check"></i><b>8.1.5</b> Covariance Structures in Mixed Models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="estimation-in-linear-mixed-models.html"><a href="estimation-in-linear-mixed-models.html"><i class="fa fa-check"></i><b>8.2</b> Estimation in Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="estimation-in-linear-mixed-models.html"><a href="estimation-in-linear-mixed-models.html#interpretation-of-the-mixed-model-equations"><i class="fa fa-check"></i><b>8.2.1</b> Interpretation of the Mixed Model Equations</a></li>
<li class="chapter" data-level="8.2.2" data-path="estimation-in-linear-mixed-models.html"><a href="estimation-in-linear-mixed-models.html#derivation-of-the-mixed-model-equations"><i class="fa fa-check"></i><b>8.2.2</b> Derivation of the Mixed Model Equations</a></li>
<li class="chapter" data-level="8.2.3" data-path="estimation-in-linear-mixed-models.html"><a href="estimation-in-linear-mixed-models.html#bayesian-interpretation-of-linear-mixed-models"><i class="fa fa-check"></i><b>8.2.3</b> Bayesian Interpretation of Linear Mixed Models</a></li>
<li class="chapter" data-level="8.2.4" data-path="estimation-in-linear-mixed-models.html"><a href="estimation-in-linear-mixed-models.html#estimating-the-variance-covariance-matrix"><i class="fa fa-check"></i><b>8.2.4</b> Estimating the Variance-Covariance Matrix</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inference-in-linear-mixed-models.html"><a href="inference-in-linear-mixed-models.html"><i class="fa fa-check"></i><b>8.3</b> Inference in Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="inference-in-linear-mixed-models.html"><a href="inference-in-linear-mixed-models.html#inference-for-fixed-effects-beta"><i class="fa fa-check"></i><b>8.3.1</b> Inference for Fixed Effects (<span class="math inline">\(\beta\)</span>)</a></li>
<li class="chapter" data-level="8.3.2" data-path="inference-in-linear-mixed-models.html"><a href="inference-in-linear-mixed-models.html#inference-for-variance-components-theta"><i class="fa fa-check"></i><b>8.3.2</b> Inference for Variance Components (<span class="math inline">\(\theta\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html"><i class="fa fa-check"></i><b>8.4</b> Information Criteria for Model Selection</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#sec-akaike-information-criterion-lmm"><i class="fa fa-check"></i><b>8.4.1</b> Akaike Information Criterion</a></li>
<li class="chapter" data-level="8.4.2" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#sec-corrected-aic-lmm"><i class="fa fa-check"></i><b>8.4.2</b> Corrected AIC</a></li>
<li class="chapter" data-level="8.4.3" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#sec-bayesian-information-criterion-lmm"><i class="fa fa-check"></i><b>8.4.3</b> Bayesian Information Criterion</a></li>
<li class="chapter" data-level="8.4.4" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#practical-example-with-linear-mixed-models"><i class="fa fa-check"></i><b>8.4.4</b> Practical Example with Linear Mixed Models</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="split-plot-designs.html"><a href="split-plot-designs.html"><i class="fa fa-check"></i><b>8.5</b> Split-Plot Designs</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="split-plot-designs.html"><a href="split-plot-designs.html#example-setup"><i class="fa fa-check"></i><b>8.5.1</b> Example Setup</a></li>
<li class="chapter" data-level="8.5.2" data-path="split-plot-designs.html"><a href="split-plot-designs.html#statistical-model-for-split-plot-designs"><i class="fa fa-check"></i><b>8.5.2</b> Statistical Model for Split-Plot Designs</a></li>
<li class="chapter" data-level="8.5.3" data-path="split-plot-designs.html"><a href="split-plot-designs.html#approaches-to-analyzing-split-plot-designs"><i class="fa fa-check"></i><b>8.5.3</b> Approaches to Analyzing Split-Plot Designs</a></li>
<li class="chapter" data-level="8.5.4" data-path="split-plot-designs.html"><a href="split-plot-designs.html#application-split-plot-design"><i class="fa fa-check"></i><b>8.5.4</b> Application: Split-Plot Design</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="repeated-measures-in-mixed-models.html"><a href="repeated-measures-in-mixed-models.html"><i class="fa fa-check"></i><b>8.6</b> Repeated Measures in Mixed Models</a></li>
<li class="chapter" data-level="8.7" data-path="unbalanced-or-unequally-spaced-data.html"><a href="unbalanced-or-unequally-spaced-data.html"><i class="fa fa-check"></i><b>8.7</b> Unbalanced or Unequally Spaced Data</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="unbalanced-or-unequally-spaced-data.html"><a href="unbalanced-or-unequally-spaced-data.html#variance-covariance-structure-power-model"><i class="fa fa-check"></i><b>8.7.1</b> Variance-Covariance Structure: Power Model</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="application-mixed-models-in-practice.html"><a href="application-mixed-models-in-practice.html"><i class="fa fa-check"></i><b>8.8</b> Application: Mixed Models in Practice</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="application-mixed-models-in-practice.html"><a href="application-mixed-models-in-practice.html#example-1-pulp-brightness-analysis"><i class="fa fa-check"></i><b>8.8.1</b> Example 1: Pulp Brightness Analysis</a></li>
<li class="chapter" data-level="8.8.2" data-path="application-mixed-models-in-practice.html"><a href="application-mixed-models-in-practice.html#example-2-penicillin-yield-glmm-with-blocking"><i class="fa fa-check"></i><b>8.8.2</b> Example 2: Penicillin Yield (GLMM with Blocking)</a></li>
<li class="chapter" data-level="8.8.3" data-path="application-mixed-models-in-practice.html"><a href="application-mixed-models-in-practice.html#example-3-growth-in-rats-over-time"><i class="fa fa-check"></i><b>8.8.3</b> Example 3: Growth in Rats Over Time</a></li>
<li class="chapter" data-level="8.8.4" data-path="application-mixed-models-in-practice.html"><a href="application-mixed-models-in-practice.html#example-4-tree-water-use-agridat"><i class="fa fa-check"></i><b>8.8.4</b> Example 4: Tree Water Use (Agridat)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sec-nonlinear-and-generalized-linear-mixed-models.html"><a href="sec-nonlinear-and-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9</b> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sec-nonlinear-mixed-models.html"><a href="sec-nonlinear-mixed-models.html"><i class="fa fa-check"></i><b>9.1</b> Nonlinear Mixed Models</a></li>
<li class="chapter" data-level="9.2" data-path="sec-generalized-linear-mixed-models.html"><a href="sec-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9.2</b> Generalized Linear Mixed Models</a></li>
<li class="chapter" data-level="9.3" data-path="relationship-between-nlmms-and-glmms.html"><a href="relationship-between-nlmms-and-glmms.html"><i class="fa fa-check"></i><b>9.3</b> Relationship Between NLMMs and GLMMs</a></li>
<li class="chapter" data-level="9.4" data-path="marginal-properties-of-glmms.html"><a href="marginal-properties-of-glmms.html"><i class="fa fa-check"></i><b>9.4</b> Marginal Properties of GLMMs</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="marginal-properties-of-glmms.html"><a href="marginal-properties-of-glmms.html#marginal-mean-of-y_i"><i class="fa fa-check"></i><b>9.4.1</b> Marginal Mean of <span class="math inline">\(y_i\)</span></a></li>
<li class="chapter" data-level="9.4.2" data-path="marginal-properties-of-glmms.html"><a href="marginal-properties-of-glmms.html#marginal-variance-of-y_i"><i class="fa fa-check"></i><b>9.4.2</b> Marginal Variance of <span class="math inline">\(y_i\)</span></a></li>
<li class="chapter" data-level="9.4.3" data-path="marginal-properties-of-glmms.html"><a href="marginal-properties-of-glmms.html#marginal-covariance-of-mathbfy"><i class="fa fa-check"></i><b>9.4.3</b> Marginal Covariance of <span class="math inline">\(\mathbf{y}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="estimation-in-nonlinear-and-generalized-linear-mixed-models.html"><a href="estimation-in-nonlinear-and-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9.5</b> Estimation in Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="estimation-in-nonlinear-and-generalized-linear-mixed-models.html"><a href="estimation-in-nonlinear-and-generalized-linear-mixed-models.html#estimation-by-numerical-integration"><i class="fa fa-check"></i><b>9.5.1</b> Estimation by Numerical Integration</a></li>
<li class="chapter" data-level="9.5.2" data-path="estimation-in-nonlinear-and-generalized-linear-mixed-models.html"><a href="estimation-in-nonlinear-and-generalized-linear-mixed-models.html#sec-estimation-by-linearization-glmm"><i class="fa fa-check"></i><b>9.5.2</b> Estimation by Linearization</a></li>
<li class="chapter" data-level="9.5.3" data-path="estimation-in-nonlinear-and-generalized-linear-mixed-models.html"><a href="estimation-in-nonlinear-and-generalized-linear-mixed-models.html#estimation-by-bayesian-hierarchical-models"><i class="fa fa-check"></i><b>9.5.3</b> Estimation by Bayesian Hierarchical Models</a></li>
<li class="chapter" data-level="9.5.4" data-path="estimation-in-nonlinear-and-generalized-linear-mixed-models.html"><a href="estimation-in-nonlinear-and-generalized-linear-mixed-models.html#practical-implementation-in-r"><i class="fa fa-check"></i><b>9.5.4</b> Practical Implementation in R</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="application-nonlinear-and-generalized-linear-mixed-models.html"><a href="application-nonlinear-and-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9.6</b> Application: Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="application-nonlinear-and-generalized-linear-mixed-models.html"><a href="application-nonlinear-and-generalized-linear-mixed-models.html#binomial-data-cbpp-dataset"><i class="fa fa-check"></i><b>9.6.1</b> Binomial Data: CBPP Dataset</a></li>
<li class="chapter" data-level="9.6.2" data-path="application-nonlinear-and-generalized-linear-mixed-models.html"><a href="application-nonlinear-and-generalized-linear-mixed-models.html#count-data-owl-dataset"><i class="fa fa-check"></i><b>9.6.2</b> Count Data: Owl Dataset</a></li>
<li class="chapter" data-level="9.6.3" data-path="application-nonlinear-and-generalized-linear-mixed-models.html"><a href="application-nonlinear-and-generalized-linear-mixed-models.html#binomial-example-gotway-hessian-fly-data"><i class="fa fa-check"></i><b>9.6.3</b> Binomial Example: Gotway Hessian Fly Data</a></li>
<li class="chapter" data-level="9.6.4" data-path="application-nonlinear-and-generalized-linear-mixed-models.html"><a href="application-nonlinear-and-generalized-linear-mixed-models.html#nonlinear-mixed-model-yellow-poplar-data"><i class="fa fa-check"></i><b>9.6.4</b> Nonlinear Mixed Model: Yellow Poplar Data</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>9.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sec-nonparametric-regression.html"><a href="sec-nonparametric-regression.html"><i class="fa fa-check"></i><b>10</b> Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="why-nonparametric.html"><a href="why-nonparametric.html"><i class="fa fa-check"></i><b>10.1</b> Why Nonparametric?</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="why-nonparametric.html"><a href="why-nonparametric.html#flexibility"><i class="fa fa-check"></i><b>10.1.1</b> Flexibility</a></li>
<li class="chapter" data-level="10.1.2" data-path="why-nonparametric.html"><a href="why-nonparametric.html#fewer-assumptions"><i class="fa fa-check"></i><b>10.1.2</b> Fewer Assumptions</a></li>
<li class="chapter" data-level="10.1.3" data-path="why-nonparametric.html"><a href="why-nonparametric.html#interpretability"><i class="fa fa-check"></i><b>10.1.3</b> Interpretability</a></li>
<li class="chapter" data-level="10.1.4" data-path="why-nonparametric.html"><a href="why-nonparametric.html#practical-considerations-3"><i class="fa fa-check"></i><b>10.1.4</b> Practical Considerations</a></li>
<li class="chapter" data-level="10.1.5" data-path="why-nonparametric.html"><a href="why-nonparametric.html#balancing-parametric-and-nonparametric-approaches"><i class="fa fa-check"></i><b>10.1.5</b> Balancing Parametric and Nonparametric Approaches</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="basic-concepts-in-nonparametric-estimation.html"><a href="basic-concepts-in-nonparametric-estimation.html"><i class="fa fa-check"></i><b>10.2</b> Basic Concepts in Nonparametric Estimation</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="basic-concepts-in-nonparametric-estimation.html"><a href="basic-concepts-in-nonparametric-estimation.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>10.2.1</b> Bias-Variance Trade-Off</a></li>
<li class="chapter" data-level="10.2.2" data-path="basic-concepts-in-nonparametric-estimation.html"><a href="basic-concepts-in-nonparametric-estimation.html#kernel-smoothing-and-local-averages"><i class="fa fa-check"></i><b>10.2.2</b> Kernel Smoothing and Local Averages</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html"><i class="fa fa-check"></i><b>10.3</b> Kernel Regression</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#basic-setup"><i class="fa fa-check"></i><b>10.3.1</b> Basic Setup</a></li>
<li class="chapter" data-level="10.3.2" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#sec-nadaraya-watson-kernel-estimator"><i class="fa fa-check"></i><b>10.3.2</b> Nadaraya-Watson Kernel Estimator</a></li>
<li class="chapter" data-level="10.3.3" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#sec-priestley-chao-kernel-estimator"><i class="fa fa-check"></i><b>10.3.3</b> Priestley‚ÄìChao Kernel Estimator</a></li>
<li class="chapter" data-level="10.3.4" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#sec-gasser-mueller-kernel-estimator"><i class="fa fa-check"></i><b>10.3.4</b> Gasser‚ÄìM√ºller Kernel Estimator</a></li>
<li class="chapter" data-level="10.3.5" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#comparison-of-kernel-based-estimators"><i class="fa fa-check"></i><b>10.3.5</b> Comparison of Kernel-Based Estimators</a></li>
<li class="chapter" data-level="10.3.6" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#bandwidth-selection"><i class="fa fa-check"></i><b>10.3.6</b> Bandwidth Selection</a></li>
<li class="chapter" data-level="10.3.7" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#asymptotic-properties"><i class="fa fa-check"></i><b>10.3.7</b> Asymptotic Properties</a></li>
<li class="chapter" data-level="10.3.8" data-path="sec-kernel-regression.html"><a href="sec-kernel-regression.html#derivation-of-the-nadaraya-watson-estimator"><i class="fa fa-check"></i><b>10.3.8</b> Derivation of the Nadaraya-Watson Estimator</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html"><i class="fa fa-check"></i><b>10.4</b> Local Polynomial Regression</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html#local-polynomial-fitting"><i class="fa fa-check"></i><b>10.4.1</b> Local Polynomial Fitting</a></li>
<li class="chapter" data-level="10.4.2" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html#mathematical-form-of-the-solution"><i class="fa fa-check"></i><b>10.4.2</b> Mathematical Form of the Solution</a></li>
<li class="chapter" data-level="10.4.3" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html#bias-variance-and-asymptotics"><i class="fa fa-check"></i><b>10.4.3</b> Bias, Variance, and Asymptotics</a></li>
<li class="chapter" data-level="10.4.4" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html#sec-special-case-local-linear-regression"><i class="fa fa-check"></i><b>10.4.4</b> Special Case: Local Linear Regression</a></li>
<li class="chapter" data-level="10.4.5" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html#bandwidth-selection-1"><i class="fa fa-check"></i><b>10.4.5</b> Bandwidth Selection</a></li>
<li class="chapter" data-level="10.4.6" data-path="sec-local-polynomial-regression.html"><a href="sec-local-polynomial-regression.html#asymptotic-properties-summary"><i class="fa fa-check"></i><b>10.4.6</b> Asymptotic Properties Summary</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sec-smoothing-splines.html"><a href="sec-smoothing-splines.html"><i class="fa fa-check"></i><b>10.5</b> Smoothing Splines</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="sec-smoothing-splines.html"><a href="sec-smoothing-splines.html#properties-and-form-of-the-smoothing-spline"><i class="fa fa-check"></i><b>10.5.1</b> Properties and Form of the Smoothing Spline</a></li>
<li class="chapter" data-level="10.5.2" data-path="sec-smoothing-splines.html"><a href="sec-smoothing-splines.html#choice-of-lambda"><i class="fa fa-check"></i><b>10.5.2</b> Choice of <span class="math inline">\(\lambda\)</span></a></li>
<li class="chapter" data-level="10.5.3" data-path="sec-smoothing-splines.html"><a href="sec-smoothing-splines.html#connection-to-reproducing-kernel-hilbert-spaces"><i class="fa fa-check"></i><b>10.5.3</b> Connection to Reproducing Kernel Hilbert Spaces</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="confidence-intervals-in-nonparametric-regression.html"><a href="confidence-intervals-in-nonparametric-regression.html"><i class="fa fa-check"></i><b>10.6</b> Confidence Intervals in Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="confidence-intervals-in-nonparametric-regression.html"><a href="confidence-intervals-in-nonparametric-regression.html#asymptotic-normality"><i class="fa fa-check"></i><b>10.6.1</b> Asymptotic Normality</a></li>
<li class="chapter" data-level="10.6.2" data-path="confidence-intervals-in-nonparametric-regression.html"><a href="confidence-intervals-in-nonparametric-regression.html#bootstrap-methods"><i class="fa fa-check"></i><b>10.6.2</b> Bootstrap Methods</a></li>
<li class="chapter" data-level="10.6.3" data-path="confidence-intervals-in-nonparametric-regression.html"><a href="confidence-intervals-in-nonparametric-regression.html#practical-considerations-4"><i class="fa fa-check"></i><b>10.6.3</b> Practical Considerations</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="sec-generalized-additive-models.html"><a href="sec-generalized-additive-models.html"><i class="fa fa-check"></i><b>10.7</b> Generalized Additive Models</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="sec-generalized-additive-models.html"><a href="sec-generalized-additive-models.html#estimation-via-penalized-likelihood"><i class="fa fa-check"></i><b>10.7.1</b> Estimation via Penalized Likelihood</a></li>
<li class="chapter" data-level="10.7.2" data-path="sec-generalized-additive-models.html"><a href="sec-generalized-additive-models.html#interpretation-of-gams"><i class="fa fa-check"></i><b>10.7.2</b> Interpretation of GAMs</a></li>
<li class="chapter" data-level="10.7.3" data-path="sec-generalized-additive-models.html"><a href="sec-generalized-additive-models.html#model-selection-and-smoothing-parameter-estimation"><i class="fa fa-check"></i><b>10.7.3</b> Model Selection and Smoothing Parameter Estimation</a></li>
<li class="chapter" data-level="10.7.4" data-path="sec-generalized-additive-models.html"><a href="sec-generalized-additive-models.html#extensions-of-gams"><i class="fa fa-check"></i><b>10.7.4</b> Extensions of GAMs</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="regression-trees-and-random-forests.html"><a href="regression-trees-and-random-forests.html"><i class="fa fa-check"></i><b>10.8</b> Regression Trees and Random Forests</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="regression-trees-and-random-forests.html"><a href="regression-trees-and-random-forests.html#sec-regression-trees"><i class="fa fa-check"></i><b>10.8.1</b> Regression Trees</a></li>
<li class="chapter" data-level="10.8.2" data-path="regression-trees-and-random-forests.html"><a href="regression-trees-and-random-forests.html#sec-random-forests"><i class="fa fa-check"></i><b>10.8.2</b> Random Forests</a></li>
<li class="chapter" data-level="10.8.3" data-path="regression-trees-and-random-forests.html"><a href="regression-trees-and-random-forests.html#theoretical-insights"><i class="fa fa-check"></i><b>10.8.3</b> Theoretical Insights</a></li>
<li class="chapter" data-level="10.8.4" data-path="regression-trees-and-random-forests.html"><a href="regression-trees-and-random-forests.html#feature-importance-in-random-forests"><i class="fa fa-check"></i><b>10.8.4</b> Feature Importance in Random Forests</a></li>
<li class="chapter" data-level="10.8.5" data-path="regression-trees-and-random-forests.html"><a href="regression-trees-and-random-forests.html#advantages-and-limitations-of-tree-based-methods"><i class="fa fa-check"></i><b>10.8.5</b> Advantages and Limitations of Tree-Based Methods</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="sec-wavelet-regression.html"><a href="sec-wavelet-regression.html"><i class="fa fa-check"></i><b>10.9</b> Wavelet Regression</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="sec-wavelet-regression.html"><a href="sec-wavelet-regression.html#wavelet-series-expansion"><i class="fa fa-check"></i><b>10.9.1</b> Wavelet Series Expansion</a></li>
<li class="chapter" data-level="10.9.2" data-path="sec-wavelet-regression.html"><a href="sec-wavelet-regression.html#wavelet-regression-model"><i class="fa fa-check"></i><b>10.9.2</b> Wavelet Regression Model</a></li>
<li class="chapter" data-level="10.9.3" data-path="sec-wavelet-regression.html"><a href="sec-wavelet-regression.html#wavelet-shrinkage-and-thresholding"><i class="fa fa-check"></i><b>10.9.3</b> Wavelet Shrinkage and Thresholding</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="multivariate-nonparametric-regression.html"><a href="multivariate-nonparametric-regression.html"><i class="fa fa-check"></i><b>10.10</b> Multivariate Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="10.10.1" data-path="multivariate-nonparametric-regression.html"><a href="multivariate-nonparametric-regression.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>10.10.1</b> The Curse of Dimensionality</a></li>
<li class="chapter" data-level="10.10.2" data-path="multivariate-nonparametric-regression.html"><a href="multivariate-nonparametric-regression.html#multivariate-kernel-regression"><i class="fa fa-check"></i><b>10.10.2</b> Multivariate Kernel Regression</a></li>
<li class="chapter" data-level="10.10.3" data-path="multivariate-nonparametric-regression.html"><a href="multivariate-nonparametric-regression.html#multivariate-splines"><i class="fa fa-check"></i><b>10.10.3</b> Multivariate Splines</a></li>
<li class="chapter" data-level="10.10.4" data-path="multivariate-nonparametric-regression.html"><a href="multivariate-nonparametric-regression.html#additive-models-gams"><i class="fa fa-check"></i><b>10.10.4</b> Additive Models (GAMs)</a></li>
<li class="chapter" data-level="10.10.5" data-path="multivariate-nonparametric-regression.html"><a href="multivariate-nonparametric-regression.html#radial-basis-functions"><i class="fa fa-check"></i><b>10.10.5</b> Radial Basis Functions</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="conclusion-the-evolving-landscape-of-regression-analysis.html"><a href="conclusion-the-evolving-landscape-of-regression-analysis.html"><i class="fa fa-check"></i><b>10.11</b> Conclusion: The Evolving Landscape of Regression Analysis</a>
<ul>
<li class="chapter" data-level="10.11.1" data-path="conclusion-the-evolving-landscape-of-regression-analysis.html"><a href="conclusion-the-evolving-landscape-of-regression-analysis.html#key-takeaways-1"><i class="fa fa-check"></i><b>10.11.1</b> Key Takeaways</a></li>
<li class="chapter" data-level="10.11.2" data-path="conclusion-the-evolving-landscape-of-regression-analysis.html"><a href="conclusion-the-evolving-landscape-of-regression-analysis.html#the-art-and-science-of-regression"><i class="fa fa-check"></i><b>10.11.2</b> The Art and Science of Regression</a></li>
<li class="chapter" data-level="10.11.3" data-path="conclusion-the-evolving-landscape-of-regression-analysis.html"><a href="conclusion-the-evolving-landscape-of-regression-analysis.html#looking-forward"><i class="fa fa-check"></i><b>10.11.3</b> Looking Forward</a></li>
<li class="chapter" data-level="10.11.4" data-path="conclusion-the-evolving-landscape-of-regression-analysis.html"><a href="conclusion-the-evolving-landscape-of-regression-analysis.html#final-thoughts"><i class="fa fa-check"></i><b>10.11.4</b> Final Thoughts</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III. RAMIFICATIONS</b></span></li>
<li class="chapter" data-level="11" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>11</b> Data</a>
<ul>
<li class="chapter" data-level="11.1" data-path="data-types.html"><a href="data-types.html"><i class="fa fa-check"></i><b>11.1</b> Data Types</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="data-types.html"><a href="data-types.html#qualitative-vs.-quantitative-data"><i class="fa fa-check"></i><b>11.1.1</b> Qualitative vs.¬†Quantitative Data</a></li>
<li class="chapter" data-level="11.1.2" data-path="data-types.html"><a href="data-types.html#other-ways-to-classify-data"><i class="fa fa-check"></i><b>11.1.2</b> Other Ways to Classify Data</a></li>
<li class="chapter" data-level="11.1.3" data-path="data-types.html"><a href="data-types.html#data-by-observational-structure-over-time"><i class="fa fa-check"></i><b>11.1.3</b> Data by Observational Structure Over Time</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sec-cross-sectional-data.html"><a href="sec-cross-sectional-data.html"><i class="fa fa-check"></i><b>11.2</b> Cross-Sectional Data</a></li>
<li class="chapter" data-level="11.3" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html"><i class="fa fa-check"></i><b>11.3</b> Time Series Data</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#statistical-properties-of-time-series-models"><i class="fa fa-check"></i><b>11.3.1</b> Statistical Properties of Time Series Models</a></li>
<li class="chapter" data-level="11.3.2" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#common-time-series-processes"><i class="fa fa-check"></i><b>11.3.2</b> Common Time Series Processes</a></li>
<li class="chapter" data-level="11.3.3" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#deterministic-time-trends"><i class="fa fa-check"></i><b>11.3.3</b> Deterministic Time Trends</a></li>
<li class="chapter" data-level="11.3.4" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#violations-of-exogeneity-in-time-series-models"><i class="fa fa-check"></i><b>11.3.4</b> Violations of Exogeneity in Time Series Models</a></li>
<li class="chapter" data-level="11.3.5" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#consequences-of-exogeneity-violations"><i class="fa fa-check"></i><b>11.3.5</b> Consequences of Exogeneity Violations</a></li>
<li class="chapter" data-level="11.3.6" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#highly-persistent-data"><i class="fa fa-check"></i><b>11.3.6</b> Highly Persistent Data</a></li>
<li class="chapter" data-level="11.3.7" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#sec-unit-root-testing"><i class="fa fa-check"></i><b>11.3.7</b> Unit Root Testing</a></li>
<li class="chapter" data-level="11.3.8" data-path="sec-time-series-data.html"><a href="sec-time-series-data.html#sec-newey-west-standard-errors"><i class="fa fa-check"></i><b>11.3.8</b> Newey-West Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="sec-repeated-cross-sectional-data.html"><a href="sec-repeated-cross-sectional-data.html"><i class="fa fa-check"></i><b>11.4</b> Repeated Cross-Sectional Data</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="sec-repeated-cross-sectional-data.html"><a href="sec-repeated-cross-sectional-data.html#key-characteristics"><i class="fa fa-check"></i><b>11.4.1</b> Key Characteristics</a></li>
<li class="chapter" data-level="11.4.2" data-path="sec-repeated-cross-sectional-data.html"><a href="sec-repeated-cross-sectional-data.html#statistical-modeling-for-repeated-cross-sections"><i class="fa fa-check"></i><b>11.4.2</b> Statistical Modeling for Repeated Cross-Sections</a></li>
<li class="chapter" data-level="11.4.3" data-path="sec-repeated-cross-sectional-data.html"><a href="sec-repeated-cross-sectional-data.html#advantages-of-repeated-cross-sectional-data"><i class="fa fa-check"></i><b>11.4.3</b> Advantages of Repeated Cross-Sectional Data</a></li>
<li class="chapter" data-level="11.4.4" data-path="sec-repeated-cross-sectional-data.html"><a href="sec-repeated-cross-sectional-data.html#disadvantages-of-repeated-cross-sectional-data"><i class="fa fa-check"></i><b>11.4.4</b> Disadvantages of Repeated Cross-Sectional Data</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="sec-panel-data.html"><a href="sec-panel-data.html"><i class="fa fa-check"></i><b>11.5</b> Panel Data</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="sec-panel-data.html"><a href="sec-panel-data.html#advantages-of-panel-data"><i class="fa fa-check"></i><b>11.5.1</b> Advantages of Panel Data</a></li>
<li class="chapter" data-level="11.5.2" data-path="sec-panel-data.html"><a href="sec-panel-data.html#disadvantages-of-panel-data"><i class="fa fa-check"></i><b>11.5.2</b> Disadvantages of Panel Data</a></li>
<li class="chapter" data-level="11.5.3" data-path="sec-panel-data.html"><a href="sec-panel-data.html#sources-of-variation-in-panel-data"><i class="fa fa-check"></i><b>11.5.3</b> Sources of Variation in Panel Data</a></li>
<li class="chapter" data-level="11.5.4" data-path="sec-panel-data.html"><a href="sec-panel-data.html#sec-pooled-ols-estimator"><i class="fa fa-check"></i><b>11.5.4</b> Pooled OLS Estimator</a></li>
<li class="chapter" data-level="11.5.5" data-path="sec-panel-data.html"><a href="sec-panel-data.html#individual-specific-effects-model"><i class="fa fa-check"></i><b>11.5.5</b> Individual-Specific Effects Model</a></li>
<li class="chapter" data-level="11.5.6" data-path="sec-panel-data.html"><a href="sec-panel-data.html#sec-random-effects-estimator"><i class="fa fa-check"></i><b>11.5.6</b> Random Effects Estimator</a></li>
<li class="chapter" data-level="11.5.7" data-path="sec-panel-data.html"><a href="sec-panel-data.html#sec-fixed-effects-estimator"><i class="fa fa-check"></i><b>11.5.7</b> Fixed Effects Estimator</a></li>
<li class="chapter" data-level="11.5.8" data-path="sec-panel-data.html"><a href="sec-panel-data.html#tests-for-assumptions-in-panel-data-analysis"><i class="fa fa-check"></i><b>11.5.8</b> Tests for Assumptions in Panel Data Analysis</a></li>
<li class="chapter" data-level="11.5.9" data-path="sec-panel-data.html"><a href="sec-panel-data.html#model-selection-in-panel-data"><i class="fa fa-check"></i><b>11.5.9</b> Model Selection in Panel Data</a></li>
<li class="chapter" data-level="11.5.10" data-path="sec-panel-data.html"><a href="sec-panel-data.html#alternative-estimators"><i class="fa fa-check"></i><b>11.5.10</b> Alternative Estimators</a></li>
<li class="chapter" data-level="11.5.11" data-path="sec-panel-data.html"><a href="sec-panel-data.html#application-1"><i class="fa fa-check"></i><b>11.5.11</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="choosing-the-right-type-of-data.html"><a href="choosing-the-right-type-of-data.html"><i class="fa fa-check"></i><b>11.6</b> Choosing the Right Type of Data</a></li>
<li class="chapter" data-level="11.7" data-path="data-quality-and-ethical-considerations.html"><a href="data-quality-and-ethical-considerations.html"><i class="fa fa-check"></i><b>11.7</b> Data Quality and Ethical Considerations</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="variable-transformation.html"><a href="variable-transformation.html"><i class="fa fa-check"></i><b>12</b> Variable Transformation</a>
<ul>
<li class="chapter" data-level="12.1" data-path="continuous-variables.html"><a href="continuous-variables.html"><i class="fa fa-check"></i><b>12.1</b> Continuous Variables</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="continuous-variables.html"><a href="continuous-variables.html#standardization-z-score-normalization"><i class="fa fa-check"></i><b>12.1.1</b> Standardization (Z-score Normalization)</a></li>
<li class="chapter" data-level="12.1.2" data-path="continuous-variables.html"><a href="continuous-variables.html#min-max-scaling-normalization"><i class="fa fa-check"></i><b>12.1.2</b> Min-Max Scaling (Normalization)</a></li>
<li class="chapter" data-level="12.1.3" data-path="continuous-variables.html"><a href="continuous-variables.html#square-root-and-cube-root-transformations"><i class="fa fa-check"></i><b>12.1.3</b> Square Root and Cube Root Transformations</a></li>
<li class="chapter" data-level="12.1.4" data-path="continuous-variables.html"><a href="continuous-variables.html#sec-logarithmic-transformation"><i class="fa fa-check"></i><b>12.1.4</b> Logarithmic Transformation</a></li>
<li class="chapter" data-level="12.1.5" data-path="continuous-variables.html"><a href="continuous-variables.html#exponential-transformation"><i class="fa fa-check"></i><b>12.1.5</b> Exponential Transformation</a></li>
<li class="chapter" data-level="12.1.6" data-path="continuous-variables.html"><a href="continuous-variables.html#power-transformation"><i class="fa fa-check"></i><b>12.1.6</b> Power Transformation</a></li>
<li class="chapter" data-level="12.1.7" data-path="continuous-variables.html"><a href="continuous-variables.html#inverse-reciprocal-transformation"><i class="fa fa-check"></i><b>12.1.7</b> Inverse (Reciprocal) Transformation</a></li>
<li class="chapter" data-level="12.1.8" data-path="continuous-variables.html"><a href="continuous-variables.html#hyperbolic-arcsine-transformation"><i class="fa fa-check"></i><b>12.1.8</b> Hyperbolic Arcsine Transformation</a></li>
<li class="chapter" data-level="12.1.9" data-path="continuous-variables.html"><a href="continuous-variables.html#ordered-quantile-normalization-rank-based-transformation"><i class="fa fa-check"></i><b>12.1.9</b> Ordered Quantile Normalization (Rank-Based Transformation)</a></li>
<li class="chapter" data-level="12.1.10" data-path="continuous-variables.html"><a href="continuous-variables.html#lambert-w-x-f-transformation"><i class="fa fa-check"></i><b>12.1.10</b> Lambert W x F Transformation</a></li>
<li class="chapter" data-level="12.1.11" data-path="continuous-variables.html"><a href="continuous-variables.html#inverse-hyperbolic-sine-transformation"><i class="fa fa-check"></i><b>12.1.11</b> Inverse Hyperbolic Sine Transformation</a></li>
<li class="chapter" data-level="12.1.12" data-path="continuous-variables.html"><a href="continuous-variables.html#sec-box-cox-transformation"><i class="fa fa-check"></i><b>12.1.12</b> Box-Cox Transformation</a></li>
<li class="chapter" data-level="12.1.13" data-path="continuous-variables.html"><a href="continuous-variables.html#yeo-johnson-transformation"><i class="fa fa-check"></i><b>12.1.13</b> Yeo-Johnson Transformation</a></li>
<li class="chapter" data-level="12.1.14" data-path="continuous-variables.html"><a href="continuous-variables.html#rankgauss-transformation"><i class="fa fa-check"></i><b>12.1.14</b> RankGauss Transformation</a></li>
<li class="chapter" data-level="12.1.15" data-path="continuous-variables.html"><a href="continuous-variables.html#automatically-choosing-the-best-transformation"><i class="fa fa-check"></i><b>12.1.15</b> Automatically Choosing the Best Transformation</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="categorical-variables.html"><a href="categorical-variables.html"><i class="fa fa-check"></i><b>12.2</b> Categorical Variables</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="categorical-variables.html"><a href="categorical-variables.html#one-hot-encoding-dummy-variables"><i class="fa fa-check"></i><b>12.2.1</b> One-Hot Encoding (Dummy Variables)</a></li>
<li class="chapter" data-level="12.2.2" data-path="categorical-variables.html"><a href="categorical-variables.html#label-encoding"><i class="fa fa-check"></i><b>12.2.2</b> Label Encoding</a></li>
<li class="chapter" data-level="12.2.3" data-path="categorical-variables.html"><a href="categorical-variables.html#feature-hashing-hash-encoding"><i class="fa fa-check"></i><b>12.2.3</b> Feature Hashing (Hash Encoding)</a></li>
<li class="chapter" data-level="12.2.4" data-path="categorical-variables.html"><a href="categorical-variables.html#binary-encoding"><i class="fa fa-check"></i><b>12.2.4</b> Binary Encoding</a></li>
<li class="chapter" data-level="12.2.5" data-path="categorical-variables.html"><a href="categorical-variables.html#base-n-encoding-generalized-binary-encoding"><i class="fa fa-check"></i><b>12.2.5</b> Base-N Encoding (Generalized Binary Encoding)</a></li>
<li class="chapter" data-level="12.2.6" data-path="categorical-variables.html"><a href="categorical-variables.html#frequency-encoding"><i class="fa fa-check"></i><b>12.2.6</b> Frequency Encoding</a></li>
<li class="chapter" data-level="12.2.7" data-path="categorical-variables.html"><a href="categorical-variables.html#target-encoding-mean-encoding"><i class="fa fa-check"></i><b>12.2.7</b> Target Encoding (Mean Encoding)</a></li>
<li class="chapter" data-level="12.2.8" data-path="categorical-variables.html"><a href="categorical-variables.html#ordinal-encoding"><i class="fa fa-check"></i><b>12.2.8</b> Ordinal Encoding</a></li>
<li class="chapter" data-level="12.2.9" data-path="categorical-variables.html"><a href="categorical-variables.html#weight-of-evidence-encoding"><i class="fa fa-check"></i><b>12.2.9</b> Weight of Evidence Encoding</a></li>
<li class="chapter" data-level="12.2.10" data-path="categorical-variables.html"><a href="categorical-variables.html#helmert-encoding"><i class="fa fa-check"></i><b>12.2.10</b> Helmert Encoding</a></li>
<li class="chapter" data-level="12.2.11" data-path="categorical-variables.html"><a href="categorical-variables.html#probability-ratio-encoding"><i class="fa fa-check"></i><b>12.2.11</b> Probability Ratio Encoding</a></li>
<li class="chapter" data-level="12.2.12" data-path="categorical-variables.html"><a href="categorical-variables.html#backward-difference-encoding"><i class="fa fa-check"></i><b>12.2.12</b> Backward Difference Encoding</a></li>
<li class="chapter" data-level="12.2.13" data-path="categorical-variables.html"><a href="categorical-variables.html#leave-one-out-encoding"><i class="fa fa-check"></i><b>12.2.13</b> Leave-One-Out Encoding</a></li>
<li class="chapter" data-level="12.2.14" data-path="categorical-variables.html"><a href="categorical-variables.html#james-stein-encoding"><i class="fa fa-check"></i><b>12.2.14</b> James-Stein Encoding</a></li>
<li class="chapter" data-level="12.2.15" data-path="categorical-variables.html"><a href="categorical-variables.html#m-estimator-encoding"><i class="fa fa-check"></i><b>12.2.15</b> M-Estimator Encoding</a></li>
<li class="chapter" data-level="12.2.16" data-path="categorical-variables.html"><a href="categorical-variables.html#thermometer-encoding"><i class="fa fa-check"></i><b>12.2.16</b> Thermometer Encoding</a></li>
<li class="chapter" data-level="12.2.17" data-path="categorical-variables.html"><a href="categorical-variables.html#choosing-the-right-encoding-method"><i class="fa fa-check"></i><b>12.2.17</b> Choosing the Right Encoding Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="imputation-missing-data.html"><a href="imputation-missing-data.html"><i class="fa fa-check"></i><b>13</b> Imputation (Missing Data)</a>
<ul>
<li class="chapter" data-level="13.1" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html"><i class="fa fa-check"></i><b>13.1</b> Introduction to Missing Data</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#types-of-imputation"><i class="fa fa-check"></i><b>13.1.1</b> Types of Imputation</a></li>
<li class="chapter" data-level="13.1.2" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#when-and-why-to-use-imputation"><i class="fa fa-check"></i><b>13.1.2</b> When and Why to Use Imputation</a></li>
<li class="chapter" data-level="13.1.3" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#importance-of-missing-data-treatment-in-statistical-modeling"><i class="fa fa-check"></i><b>13.1.3</b> Importance of Missing Data Treatment in Statistical Modeling</a></li>
<li class="chapter" data-level="13.1.4" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#prevalence-of-missing-data-across-domains"><i class="fa fa-check"></i><b>13.1.4</b> Prevalence of Missing Data Across Domains</a></li>
<li class="chapter" data-level="13.1.5" data-path="introduction-to-missing-data.html"><a href="introduction-to-missing-data.html#practical-considerations-for-imputation"><i class="fa fa-check"></i><b>13.1.5</b> Practical Considerations for Imputation</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html"><i class="fa fa-check"></i><b>13.2</b> Theoretical Foundations of Missing Data</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html#definition-and-classification-of-missing-data"><i class="fa fa-check"></i><b>13.2.1</b> Definition and Classification of Missing Data</a></li>
<li class="chapter" data-level="13.2.2" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>13.2.2</b> Missing Data Mechanisms</a></li>
<li class="chapter" data-level="13.2.3" data-path="theoretical-foundations-of-missing-data.html"><a href="theoretical-foundations-of-missing-data.html#relationship-between-mechanisms-and-ignorability"><i class="fa fa-check"></i><b>13.2.3</b> Relationship Between Mechanisms and Ignorability</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html"><i class="fa fa-check"></i><b>13.3</b> Diagnosing the Missing Data Mechanism</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html#descriptive-methods"><i class="fa fa-check"></i><b>13.3.1</b> Descriptive Methods</a></li>
<li class="chapter" data-level="13.3.2" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html#statistical-tests-for-missing-data-mechanisms"><i class="fa fa-check"></i><b>13.3.2</b> Statistical Tests for Missing Data Mechanisms</a></li>
<li class="chapter" data-level="13.3.3" data-path="diagnosing-the-missing-data-mechanism.html"><a href="diagnosing-the-missing-data-mechanism.html#assessing-mar-and-mnar"><i class="fa fa-check"></i><b>13.3.3</b> Assessing MAR and MNAR</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html"><i class="fa fa-check"></i><b>13.4</b> Methods for Handling Missing Data</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#basic-methods"><i class="fa fa-check"></i><b>13.4.1</b> Basic Methods</a></li>
<li class="chapter" data-level="13.4.2" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#single-imputation-techniques"><i class="fa fa-check"></i><b>13.4.2</b> Single Imputation Techniques</a></li>
<li class="chapter" data-level="13.4.3" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#machine-learning-and-modern-approaches"><i class="fa fa-check"></i><b>13.4.3</b> Machine Learning and Modern Approaches</a></li>
<li class="chapter" data-level="13.4.4" data-path="methods-for-handling-missing-data.html"><a href="methods-for-handling-missing-data.html#multiple-imputation"><i class="fa fa-check"></i><b>13.4.4</b> Multiple Imputation</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html"><i class="fa fa-check"></i><b>13.5</b> Evaluation of Imputation Methods</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#statistical-metrics-for-assessing-imputation-quality"><i class="fa fa-check"></i><b>13.5.1</b> Statistical Metrics for Assessing Imputation Quality</a></li>
<li class="chapter" data-level="13.5.2" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#bias-variance-tradeoff-in-imputation"><i class="fa fa-check"></i><b>13.5.2</b> Bias-Variance Tradeoff in Imputation</a></li>
<li class="chapter" data-level="13.5.3" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#sensitivity-analysis-1"><i class="fa fa-check"></i><b>13.5.3</b> Sensitivity Analysis</a></li>
<li class="chapter" data-level="13.5.4" data-path="evaluation-of-imputation-methods.html"><a href="evaluation-of-imputation-methods.html#validation-using-simulated-data-and-real-world-case-studies"><i class="fa fa-check"></i><b>13.5.4</b> Validation Using Simulated Data and Real-World Case Studies</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="criteria-for-choosing-an-effective-approach.html"><a href="criteria-for-choosing-an-effective-approach.html"><i class="fa fa-check"></i><b>13.6</b> Criteria for Choosing an Effective Approach</a></li>
<li class="chapter" data-level="13.7" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html"><i class="fa fa-check"></i><b>13.7</b> Challenges and Ethical Considerations</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html#challenges-in-high-dimensional-data"><i class="fa fa-check"></i><b>13.7.1</b> Challenges in High-Dimensional Data</a></li>
<li class="chapter" data-level="13.7.2" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html#missing-data-in-big-data-contexts"><i class="fa fa-check"></i><b>13.7.2</b> Missing Data in Big Data Contexts</a></li>
<li class="chapter" data-level="13.7.3" data-path="challenges-and-ethical-considerations.html"><a href="challenges-and-ethical-considerations.html#ethical-concerns"><i class="fa fa-check"></i><b>13.7.3</b> Ethical Concerns</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html"><i class="fa fa-check"></i><b>13.8</b> Emerging Trends in Missing Data Handling</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#advances-in-neural-network-approaches"><i class="fa fa-check"></i><b>13.8.1</b> Advances in Neural Network Approaches</a></li>
<li class="chapter" data-level="13.8.2" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#integration-with-reinforcement-learning"><i class="fa fa-check"></i><b>13.8.2</b> Integration with Reinforcement Learning</a></li>
<li class="chapter" data-level="13.8.3" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#synthetic-data-generation-for-missing-data"><i class="fa fa-check"></i><b>13.8.3</b> Synthetic Data Generation for Missing Data</a></li>
<li class="chapter" data-level="13.8.4" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#federated-learning-and-privacy-preserving-imputation"><i class="fa fa-check"></i><b>13.8.4</b> Federated Learning and Privacy-Preserving Imputation</a></li>
<li class="chapter" data-level="13.8.5" data-path="emerging-trends-in-missing-data-handling.html"><a href="emerging-trends-in-missing-data-handling.html#imputation-in-streaming-and-online-data-environments"><i class="fa fa-check"></i><b>13.8.5</b> Imputation in Streaming and Online Data Environments</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="application-of-imputation.html"><a href="application-of-imputation.html"><i class="fa fa-check"></i><b>13.9</b> Application of Imputation</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="application-of-imputation.html"><a href="application-of-imputation.html#visualizing-missing-data"><i class="fa fa-check"></i><b>13.9.1</b> Visualizing Missing Data</a></li>
<li class="chapter" data-level="13.9.2" data-path="application-of-imputation.html"><a href="application-of-imputation.html#how-many-imputations"><i class="fa fa-check"></i><b>13.9.2</b> How Many Imputations?</a></li>
<li class="chapter" data-level="13.9.3" data-path="application-of-imputation.html"><a href="application-of-imputation.html#generating-missing-data-for-demonstration"><i class="fa fa-check"></i><b>13.9.3</b> Generating Missing Data for Demonstration</a></li>
<li class="chapter" data-level="13.9.4" data-path="application-of-imputation.html"><a href="application-of-imputation.html#imputation-with-mean-median-and-mode"><i class="fa fa-check"></i><b>13.9.4</b> Imputation with Mean, Median, and Mode</a></li>
<li class="chapter" data-level="13.9.5" data-path="application-of-imputation.html"><a href="application-of-imputation.html#k-nearest-neighbors-knn-imputation"><i class="fa fa-check"></i><b>13.9.5</b> K-Nearest Neighbors (KNN) Imputation</a></li>
<li class="chapter" data-level="13.9.6" data-path="application-of-imputation.html"><a href="application-of-imputation.html#imputation-with-decision-trees-rpart"><i class="fa fa-check"></i><b>13.9.6</b> Imputation with Decision Trees (rpart)</a></li>
<li class="chapter" data-level="13.9.7" data-path="application-of-imputation.html"><a href="application-of-imputation.html#mice-multivariate-imputation-via-chained-equations"><i class="fa fa-check"></i><b>13.9.7</b> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li class="chapter" data-level="13.9.8" data-path="application-of-imputation.html"><a href="application-of-imputation.html#amelia"><i class="fa fa-check"></i><b>13.9.8</b> Amelia</a></li>
<li class="chapter" data-level="13.9.9" data-path="application-of-imputation.html"><a href="application-of-imputation.html#missforest"><i class="fa fa-check"></i><b>13.9.9</b> missForest</a></li>
<li class="chapter" data-level="13.9.10" data-path="application-of-imputation.html"><a href="application-of-imputation.html#hmisc"><i class="fa fa-check"></i><b>13.9.10</b> Hmisc</a></li>
<li class="chapter" data-level="13.9.11" data-path="application-of-imputation.html"><a href="application-of-imputation.html#mi"><i class="fa fa-check"></i><b>13.9.11</b> mi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="model-specification-tests.html"><a href="model-specification-tests.html"><i class="fa fa-check"></i><b>14</b> Model Specification Tests</a>
<ul>
<li class="chapter" data-level="14.1" data-path="nested-model-tests.html"><a href="nested-model-tests.html"><i class="fa fa-check"></i><b>14.1</b> Nested Model Tests</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="nested-model-tests.html"><a href="nested-model-tests.html#sec-wald-test-nested"><i class="fa fa-check"></i><b>14.1.1</b> Wald Test</a></li>
<li class="chapter" data-level="14.1.2" data-path="nested-model-tests.html"><a href="nested-model-tests.html#sec-likelihood-ratio-test-nested"><i class="fa fa-check"></i><b>14.1.2</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="14.1.3" data-path="nested-model-tests.html"><a href="nested-model-tests.html#sec-f-test-for-linear-regression-nested"><i class="fa fa-check"></i><b>14.1.3</b> F-Test (for Linear Regression)</a></li>
<li class="chapter" data-level="14.1.4" data-path="nested-model-tests.html"><a href="nested-model-tests.html#sec-chow-test"><i class="fa fa-check"></i><b>14.1.4</b> Chow Test</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="non-nested-model-tests.html"><a href="non-nested-model-tests.html"><i class="fa fa-check"></i><b>14.2</b> Non-Nested Model Tests</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="non-nested-model-tests.html"><a href="non-nested-model-tests.html#sec-vuong-test"><i class="fa fa-check"></i><b>14.2.1</b> Vuong Test</a></li>
<li class="chapter" data-level="14.2.2" data-path="non-nested-model-tests.html"><a href="non-nested-model-tests.html#sec-davidson--mackinnon-j-test"><i class="fa fa-check"></i><b>14.2.2</b> Davidson‚ÄìMacKinnon J-Test</a></li>
<li class="chapter" data-level="14.2.3" data-path="non-nested-model-tests.html"><a href="non-nested-model-tests.html#adjusted-r2"><i class="fa fa-check"></i><b>14.2.3</b> Adjusted <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="14.2.4" data-path="non-nested-model-tests.html"><a href="non-nested-model-tests.html#comparing-models-with-transformed-dependent-variables"><i class="fa fa-check"></i><b>14.2.4</b> Comparing Models with Transformed Dependent Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html"><i class="fa fa-check"></i><b>14.3</b> Heteroskedasticity Tests</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html#sec-breusch--pagan-test"><i class="fa fa-check"></i><b>14.3.1</b> Breusch‚ÄìPagan Test</a></li>
<li class="chapter" data-level="14.3.2" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html#sec-white-test-hetero"><i class="fa fa-check"></i><b>14.3.2</b> White Test</a></li>
<li class="chapter" data-level="14.3.3" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html#sec-goldfeld--quandt-test"><i class="fa fa-check"></i><b>14.3.3</b> Goldfeld‚ÄìQuandt Test</a></li>
<li class="chapter" data-level="14.3.4" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html#sec-park-test"><i class="fa fa-check"></i><b>14.3.4</b> Park Test</a></li>
<li class="chapter" data-level="14.3.5" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html#sec-glejser-test"><i class="fa fa-check"></i><b>14.3.5</b> Glejser Test</a></li>
<li class="chapter" data-level="14.3.6" data-path="heteroskedasticity-tests.html"><a href="heteroskedasticity-tests.html#summary-of-heteroskedasticity-tests"><i class="fa fa-check"></i><b>14.3.6</b> Summary of Heteroskedasticity Tests</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="functional-form-tests.html"><a href="functional-form-tests.html"><i class="fa fa-check"></i><b>14.4</b> Functional Form Tests</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="functional-form-tests.html"><a href="functional-form-tests.html#sec-ramsey-reset-test"><i class="fa fa-check"></i><b>14.4.1</b> Ramsey RESET Test (Regression Equation Specification Error Test)</a></li>
<li class="chapter" data-level="14.4.2" data-path="functional-form-tests.html"><a href="functional-form-tests.html#sec-harvey--collier-test"><i class="fa fa-check"></i><b>14.4.2</b> Harvey‚ÄìCollier Test</a></li>
<li class="chapter" data-level="14.4.3" data-path="functional-form-tests.html"><a href="functional-form-tests.html#sec-rainbow-test"><i class="fa fa-check"></i><b>14.4.3</b> Rainbow Test</a></li>
<li class="chapter" data-level="14.4.4" data-path="functional-form-tests.html"><a href="functional-form-tests.html#summary-of-functional-form-tests"><i class="fa fa-check"></i><b>14.4.4</b> Summary of Functional Form Tests</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="autocorrelation-tests.html"><a href="autocorrelation-tests.html"><i class="fa fa-check"></i><b>14.5</b> Autocorrelation Tests</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="autocorrelation-tests.html"><a href="autocorrelation-tests.html#sec-durbin--watson-test"><i class="fa fa-check"></i><b>14.5.1</b> Durbin‚ÄìWatson Test</a></li>
<li class="chapter" data-level="14.5.2" data-path="autocorrelation-tests.html"><a href="autocorrelation-tests.html#sec-breusch--godfrey-test"><i class="fa fa-check"></i><b>14.5.2</b> Breusch‚ÄìGodfrey Test</a></li>
<li class="chapter" data-level="14.5.3" data-path="autocorrelation-tests.html"><a href="autocorrelation-tests.html#sec-ljung--box-test"><i class="fa fa-check"></i><b>14.5.3</b> Ljung‚ÄìBox Test (or Box‚ÄìPierce Test)</a></li>
<li class="chapter" data-level="14.5.4" data-path="autocorrelation-tests.html"><a href="autocorrelation-tests.html#sec-runs-test"><i class="fa fa-check"></i><b>14.5.4</b> Runs Test</a></li>
<li class="chapter" data-level="14.5.5" data-path="autocorrelation-tests.html"><a href="autocorrelation-tests.html#summary-of-autocorrelation-tests"><i class="fa fa-check"></i><b>14.5.5</b> Summary of Autocorrelation Tests</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html"><i class="fa fa-check"></i><b>14.6</b> Multicollinearity Diagnostics</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#sec-variance-inflation-factor"><i class="fa fa-check"></i><b>14.6.1</b> Variance Inflation Factor</a></li>
<li class="chapter" data-level="14.6.2" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#sec-tolerance-statistic"><i class="fa fa-check"></i><b>14.6.2</b> Tolerance Statistic</a></li>
<li class="chapter" data-level="14.6.3" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#sec-condition-index-and-eigenvalue-decomposition"><i class="fa fa-check"></i><b>14.6.3</b> Condition Index and Eigenvalue Decomposition</a></li>
<li class="chapter" data-level="14.6.4" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#sec-pairwise-correlation-matrix"><i class="fa fa-check"></i><b>14.6.4</b> Pairwise Correlation Matrix</a></li>
<li class="chapter" data-level="14.6.5" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#sec-determinant-of-the-correlation-matrix"><i class="fa fa-check"></i><b>14.6.5</b> Determinant of the Correlation Matrix</a></li>
<li class="chapter" data-level="14.6.6" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#summary-of-multicollinearity-diagnostics"><i class="fa fa-check"></i><b>14.6.6</b> Summary of Multicollinearity Diagnostics</a></li>
<li class="chapter" data-level="14.6.7" data-path="multicollinearity-diagnostics.html"><a href="multicollinearity-diagnostics.html#addressing-multicollinearity"><i class="fa fa-check"></i><b>14.6.7</b> Addressing Multicollinearity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="variable-selection.html"><a href="variable-selection.html"><i class="fa fa-check"></i><b>15</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="15.1" data-path="sec-filter-methods.html"><a href="sec-filter-methods.html"><i class="fa fa-check"></i><b>15.1</b> Filter Methods (Statistical Criteria, Model-Agnostic)</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="sec-filter-methods.html"><a href="sec-filter-methods.html#information-criteria-based-selection"><i class="fa fa-check"></i><b>15.1.1</b> Information Criteria-Based Selection</a></li>
<li class="chapter" data-level="15.1.2" data-path="sec-filter-methods.html"><a href="sec-filter-methods.html#univariate-selection-methods"><i class="fa fa-check"></i><b>15.1.2</b> Univariate Selection Methods</a></li>
<li class="chapter" data-level="15.1.3" data-path="sec-filter-methods.html"><a href="sec-filter-methods.html#correlation-based-feature-selection"><i class="fa fa-check"></i><b>15.1.3</b> Correlation-Based Feature Selection</a></li>
<li class="chapter" data-level="15.1.4" data-path="sec-filter-methods.html"><a href="sec-filter-methods.html#variance-thresholding"><i class="fa fa-check"></i><b>15.1.4</b> Variance Thresholding</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="wrapper-methods-model-based-subset-evaluation.html"><a href="wrapper-methods-model-based-subset-evaluation.html"><i class="fa fa-check"></i><b>15.2</b> Wrapper Methods (Model-Based Subset Evaluation)</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="wrapper-methods-model-based-subset-evaluation.html"><a href="wrapper-methods-model-based-subset-evaluation.html#best-subsets-algorithm-1"><i class="fa fa-check"></i><b>15.2.1</b> Best Subsets Algorithm</a></li>
<li class="chapter" data-level="15.2.2" data-path="wrapper-methods-model-based-subset-evaluation.html"><a href="wrapper-methods-model-based-subset-evaluation.html#stepwise-selection-methods-1"><i class="fa fa-check"></i><b>15.2.2</b> Stepwise Selection Methods</a></li>
<li class="chapter" data-level="15.2.3" data-path="wrapper-methods-model-based-subset-evaluation.html"><a href="wrapper-methods-model-based-subset-evaluation.html#branch-and-bound-algorithm-1"><i class="fa fa-check"></i><b>15.2.3</b> Branch-and-Bound Algorithm</a></li>
<li class="chapter" data-level="15.2.4" data-path="wrapper-methods-model-based-subset-evaluation.html"><a href="wrapper-methods-model-based-subset-evaluation.html#recursive-feature-elimination"><i class="fa fa-check"></i><b>15.2.4</b> Recursive Feature Elimination</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="embedded-methods-integrated-into-model-training.html"><a href="embedded-methods-integrated-into-model-training.html"><i class="fa fa-check"></i><b>15.3</b> Embedded Methods (Integrated into Model Training)</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="embedded-methods-integrated-into-model-training.html"><a href="embedded-methods-integrated-into-model-training.html#regularization-based-selection"><i class="fa fa-check"></i><b>15.3.1</b> Regularization-Based Selection</a></li>
<li class="chapter" data-level="15.3.2" data-path="embedded-methods-integrated-into-model-training.html"><a href="embedded-methods-integrated-into-model-training.html#tree-based-feature-importance"><i class="fa fa-check"></i><b>15.3.2</b> Tree-Based Feature Importance</a></li>
<li class="chapter" data-level="15.3.3" data-path="embedded-methods-integrated-into-model-training.html"><a href="embedded-methods-integrated-into-model-training.html#genetic-algorithms-1"><i class="fa fa-check"></i><b>15.3.3</b> Genetic Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="summary-table-1.html"><a href="summary-table-1.html"><i class="fa fa-check"></i><b>15.4</b> Summary Table</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>16</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="16.1" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html"><i class="fa fa-check"></i><b>16.1</b> Null Hypothesis Significance Testing</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#error-types-in-hypothesis-testing"><i class="fa fa-check"></i><b>16.1.1</b> Error Types in Hypothesis Testing</a></li>
<li class="chapter" data-level="16.1.2" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#hypothesis-testing-framework-1"><i class="fa fa-check"></i><b>16.1.2</b> Hypothesis Testing Framework</a></li>
<li class="chapter" data-level="16.1.3" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#interpreting-hypothesis-testing-results"><i class="fa fa-check"></i><b>16.1.3</b> Interpreting Hypothesis Testing Results</a></li>
<li class="chapter" data-level="16.1.4" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#understanding-p-values"><i class="fa fa-check"></i><b>16.1.4</b> Understanding p-Values</a></li>
<li class="chapter" data-level="16.1.5" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#the-role-of-sample-size"><i class="fa fa-check"></i><b>16.1.5</b> The Role of Sample Size</a></li>
<li class="chapter" data-level="16.1.6" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#p-value-hacking"><i class="fa fa-check"></i><b>16.1.6</b> p-Value Hacking</a></li>
<li class="chapter" data-level="16.1.7" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#practical-vs.-statistical-significance"><i class="fa fa-check"></i><b>16.1.7</b> Practical vs.¬†Statistical Significance</a></li>
<li class="chapter" data-level="16.1.8" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#mitigating-the-misuse-of-p-values"><i class="fa fa-check"></i><b>16.1.8</b> Mitigating the Misuse of p-Values</a></li>
<li class="chapter" data-level="16.1.9" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#sec-wald-test"><i class="fa fa-check"></i><b>16.1.9</b> Wald Test</a></li>
<li class="chapter" data-level="16.1.10" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#sec-likelihood-ratio-test"><i class="fa fa-check"></i><b>16.1.10</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="16.1.11" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#lagrange-multiplier-score"><i class="fa fa-check"></i><b>16.1.11</b> Lagrange Multiplier (Score) Test</a></li>
<li class="chapter" data-level="16.1.12" data-path="sec-null-hypothesis-significance-testing.html"><a href="sec-null-hypothesis-significance-testing.html#comparing-hypothesis-tests"><i class="fa fa-check"></i><b>16.1.12</b> Comparing Hypothesis Tests</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html"><i class="fa fa-check"></i><b>16.2</b> Two One-Sided Tests Equivalence Testing</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html#when-to-use-tost"><i class="fa fa-check"></i><b>16.2.1</b> When to Use TOST?</a></li>
<li class="chapter" data-level="16.2.2" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html#interpretation-of-the-tost-procedure"><i class="fa fa-check"></i><b>16.2.2</b> Interpretation of the TOST Procedure</a></li>
<li class="chapter" data-level="16.2.3" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html#relationship-to-confidence-intervals"><i class="fa fa-check"></i><b>16.2.3</b> Relationship to Confidence Intervals</a></li>
<li class="chapter" data-level="16.2.4" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html#example-1-testing-the-equivalence-of-two-means"><i class="fa fa-check"></i><b>16.2.4</b> Example 1: Testing the Equivalence of Two Means</a></li>
<li class="chapter" data-level="16.2.5" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html#advantages-of-tost-equivalence-testing"><i class="fa fa-check"></i><b>16.2.5</b> Advantages of TOST Equivalence Testing</a></li>
<li class="chapter" data-level="16.2.6" data-path="sec-two-one-sided-tests-equivalence-testing.html"><a href="sec-two-one-sided-tests-equivalence-testing.html#when-not-to-use-tost"><i class="fa fa-check"></i><b>16.2.6</b> When <em>Not</em> to Use TOST</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="sec-false-discovery-rate.html"><a href="sec-false-discovery-rate.html"><i class="fa fa-check"></i><b>16.3</b> False Discovery Rate</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="sec-false-discovery-rate.html"><a href="sec-false-discovery-rate.html#sec-benjamini-hochberg-procedure"><i class="fa fa-check"></i><b>16.3.1</b> Benjamini-Hochberg Procedure</a></li>
<li class="chapter" data-level="16.3.2" data-path="sec-false-discovery-rate.html"><a href="sec-false-discovery-rate.html#sec-benjamini-yekutieli-procedure"><i class="fa fa-check"></i><b>16.3.2</b> Benjamini-Yekutieli Procedure</a></li>
<li class="chapter" data-level="16.3.3" data-path="sec-false-discovery-rate.html"><a href="sec-false-discovery-rate.html#sec-storeys-q-value-approach"><i class="fa fa-check"></i><b>16.3.3</b> Storey‚Äôs q-value Approach</a></li>
<li class="chapter" data-level="16.3.4" data-path="sec-false-discovery-rate.html"><a href="sec-false-discovery-rate.html#summary-false-discovery-rate-methods"><i class="fa fa-check"></i><b>16.3.4</b> Summary: False Discovery Rate Methods</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="comparison-of-testing-frameworks.html"><a href="comparison-of-testing-frameworks.html"><i class="fa fa-check"></i><b>16.4</b> Comparison of Testing Frameworks</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="sec-marginal-effects.html"><a href="sec-marginal-effects.html"><i class="fa fa-check"></i><b>17</b> Marginal Effects</a>
<ul>
<li class="chapter" data-level="17.1" data-path="definition-of-marginal-effects.html"><a href="definition-of-marginal-effects.html"><i class="fa fa-check"></i><b>17.1</b> Definition of Marginal Effects</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="definition-of-marginal-effects.html"><a href="definition-of-marginal-effects.html#sec-analytical-derivation-of-marginal-effects"><i class="fa fa-check"></i><b>17.1.1</b> Analytical Derivation of Marginal Effects</a></li>
<li class="chapter" data-level="17.1.2" data-path="definition-of-marginal-effects.html"><a href="definition-of-marginal-effects.html#sec-numerical-approximation-of-marginal-effects"><i class="fa fa-check"></i><b>17.1.2</b> Numerical Approximation of Marginal Effects</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="marginal-effects-in-different-contexts.html"><a href="marginal-effects-in-different-contexts.html"><i class="fa fa-check"></i><b>17.2</b> Marginal Effects in Different Contexts</a></li>
<li class="chapter" data-level="17.3" data-path="marginal-effects-interpretation.html"><a href="marginal-effects-interpretation.html"><i class="fa fa-check"></i><b>17.3</b> Marginal Effects Interpretation</a></li>
<li class="chapter" data-level="17.4" data-path="sec-delta-method.html"><a href="sec-delta-method.html"><i class="fa fa-check"></i><b>17.4</b> Delta Method</a></li>
<li class="chapter" data-level="17.5" data-path="comparison-delta-method-vs.-alternative-approaches.html"><a href="comparison-delta-method-vs.-alternative-approaches.html"><i class="fa fa-check"></i><b>17.5</b> Comparison: Delta Method vs.¬†Alternative Approaches</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="comparison-delta-method-vs.-alternative-approaches.html"><a href="comparison-delta-method-vs.-alternative-approaches.html#example-applying-the-delta-method-in-a-logistic-regression"><i class="fa fa-check"></i><b>17.5.1</b> Example: Applying the Delta Method in a logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="types-of-marginal-effect.html"><a href="types-of-marginal-effect.html"><i class="fa fa-check"></i><b>17.6</b> Types of Marginal Effect</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="types-of-marginal-effect.html"><a href="types-of-marginal-effect.html#sec-average-marginal-effect"><i class="fa fa-check"></i><b>17.6.1</b> Average Marginal Effect</a></li>
<li class="chapter" data-level="17.6.2" data-path="types-of-marginal-effect.html"><a href="types-of-marginal-effect.html#sec-marginal-effects-at-the-mean"><i class="fa fa-check"></i><b>17.6.2</b> Marginal Effects at the Mean</a></li>
<li class="chapter" data-level="17.6.3" data-path="types-of-marginal-effect.html"><a href="types-of-marginal-effect.html#sec-marginal-effects-at-the-average"><i class="fa fa-check"></i><b>17.6.3</b> Marginal Effects at the Average</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="packages-for-marginal-effects.html"><a href="packages-for-marginal-effects.html"><i class="fa fa-check"></i><b>17.7</b> Packages for Marginal Effects</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="packages-for-marginal-effects.html"><a href="packages-for-marginal-effects.html#marginaleffects-package-recommended"><i class="fa fa-check"></i><b>17.7.1</b> <code>marginaleffects</code> Package (Recommended)</a></li>
<li class="chapter" data-level="17.7.2" data-path="packages-for-marginal-effects.html"><a href="packages-for-marginal-effects.html#margins-package"><i class="fa fa-check"></i><b>17.7.2</b> <code>margins</code> Package</a></li>
<li class="chapter" data-level="17.7.3" data-path="packages-for-marginal-effects.html"><a href="packages-for-marginal-effects.html#mfx-package"><i class="fa fa-check"></i><b>17.7.3</b> <code>mfx</code> Package</a></li>
<li class="chapter" data-level="17.7.4" data-path="packages-for-marginal-effects.html"><a href="packages-for-marginal-effects.html#comparison-of-packages"><i class="fa fa-check"></i><b>17.7.4</b> Comparison of Packages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="moderation.html"><a href="moderation.html"><i class="fa fa-check"></i><b>18</b> Moderation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="types-of-moderation-analyses.html"><a href="types-of-moderation-analyses.html"><i class="fa fa-check"></i><b>18.1</b> Types of Moderation Analyses</a></li>
<li class="chapter" data-level="18.2" data-path="key-terminology.html"><a href="key-terminology.html"><i class="fa fa-check"></i><b>18.2</b> Key Terminology</a></li>
<li class="chapter" data-level="18.3" data-path="moderation-model.html"><a href="moderation-model.html"><i class="fa fa-check"></i><b>18.3</b> Moderation Model</a></li>
<li class="chapter" data-level="18.4" data-path="types-of-interactions.html"><a href="types-of-interactions.html"><i class="fa fa-check"></i><b>18.4</b> Types of Interactions</a></li>
<li class="chapter" data-level="18.5" data-path="three-way-interactions.html"><a href="three-way-interactions.html"><i class="fa fa-check"></i><b>18.5</b> Three-Way Interactions</a></li>
<li class="chapter" data-level="18.6" data-path="additional-resources.html"><a href="additional-resources.html"><i class="fa fa-check"></i><b>18.6</b> Additional Resources</a></li>
<li class="chapter" data-level="18.7" data-path="application-2.html"><a href="application-2.html"><i class="fa fa-check"></i><b>18.7</b> Application</a>
<ul>
<li class="chapter" data-level="18.7.1" data-path="application-2.html"><a href="application-2.html#emmeans-package"><i class="fa fa-check"></i><b>18.7.1</b> <code>emmeans</code> Package</a></li>
<li class="chapter" data-level="18.7.2" data-path="application-2.html"><a href="application-2.html#probemod-package"><i class="fa fa-check"></i><b>18.7.2</b> <code>probemod</code> Package</a></li>
<li class="chapter" data-level="18.7.3" data-path="application-2.html"><a href="application-2.html#interactions-package"><i class="fa fa-check"></i><b>18.7.3</b> <code>interactions</code> Package</a></li>
<li class="chapter" data-level="18.7.4" data-path="application-2.html"><a href="application-2.html#interactionr-package"><i class="fa fa-check"></i><b>18.7.4</b> <code>interactionR</code> Package</a></li>
<li class="chapter" data-level="18.7.5" data-path="application-2.html"><a href="application-2.html#sjplot-package"><i class="fa fa-check"></i><b>18.7.5</b> <code>sjPlot</code> Package</a></li>
<li class="chapter" data-level="18.7.6" data-path="application-2.html"><a href="application-2.html#summary-of-moderation-analysis-packages"><i class="fa fa-check"></i><b>18.7.6</b> Summary of Moderation Analysis Packages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="mediation.html"><a href="mediation.html"><i class="fa fa-check"></i><b>19</b> Mediation</a>
<ul>
<li class="chapter" data-level="19.1" data-path="traditional-approach.html"><a href="traditional-approach.html"><i class="fa fa-check"></i><b>19.1</b> Traditional Approach</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="traditional-approach.html"><a href="traditional-approach.html#steps-in-the-traditional-mediation-model"><i class="fa fa-check"></i><b>19.1.1</b> Steps in the Traditional Mediation Model</a></li>
<li class="chapter" data-level="19.1.2" data-path="traditional-approach.html"><a href="traditional-approach.html#graphical-representation-of-mediation"><i class="fa fa-check"></i><b>19.1.2</b> Graphical Representation of Mediation</a></li>
<li class="chapter" data-level="19.1.3" data-path="traditional-approach.html"><a href="traditional-approach.html#measuring-mediation"><i class="fa fa-check"></i><b>19.1.3</b> Measuring Mediation</a></li>
<li class="chapter" data-level="19.1.4" data-path="traditional-approach.html"><a href="traditional-approach.html#assumptions-in-linear-mediation-models"><i class="fa fa-check"></i><b>19.1.4</b> Assumptions in Linear Mediation Models</a></li>
<li class="chapter" data-level="19.1.5" data-path="traditional-approach.html"><a href="traditional-approach.html#testing-for-mediation"><i class="fa fa-check"></i><b>19.1.5</b> Testing for Mediation</a></li>
<li class="chapter" data-level="19.1.6" data-path="traditional-approach.html"><a href="traditional-approach.html#additional-considerations"><i class="fa fa-check"></i><b>19.1.6</b> Additional Considerations</a></li>
<li class="chapter" data-level="19.1.7" data-path="traditional-approach.html"><a href="traditional-approach.html#assumptions-in-mediation-analysis"><i class="fa fa-check"></i><b>19.1.7</b> Assumptions in Mediation Analysis</a></li>
<li class="chapter" data-level="19.1.8" data-path="traditional-approach.html"><a href="traditional-approach.html#indirect-effect-tests"><i class="fa fa-check"></i><b>19.1.8</b> Indirect Effect Tests</a></li>
<li class="chapter" data-level="19.1.9" data-path="traditional-approach.html"><a href="traditional-approach.html#power-analysis-for-mediation"><i class="fa fa-check"></i><b>19.1.9</b> Power Analysis for Mediation</a></li>
<li class="chapter" data-level="19.1.10" data-path="traditional-approach.html"><a href="traditional-approach.html#multiple-mediation-analysis"><i class="fa fa-check"></i><b>19.1.10</b> Multiple Mediation Analysis</a></li>
<li class="chapter" data-level="19.1.11" data-path="traditional-approach.html"><a href="traditional-approach.html#multiple-treatments-in-mediation"><i class="fa fa-check"></i><b>19.1.11</b> Multiple Treatments in Mediation</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="causal-inference-approach-to-mediation.html"><a href="causal-inference-approach-to-mediation.html"><i class="fa fa-check"></i><b>19.2</b> Causal Inference Approach to Mediation</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="causal-inference-approach-to-mediation.html"><a href="causal-inference-approach-to-mediation.html#sec-example-traditional-mediation-analysis"><i class="fa fa-check"></i><b>19.2.1</b> Example: Traditional Mediation Analysis</a></li>
<li class="chapter" data-level="19.2.2" data-path="causal-inference-approach-to-mediation.html"><a href="causal-inference-approach-to-mediation.html#two-approaches-in-causal-mediation-analysis"><i class="fa fa-check"></i><b>19.2.2</b> Two Approaches in Causal Mediation Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="prediction-and-estimation.html"><a href="prediction-and-estimation.html"><i class="fa fa-check"></i><b>20</b> Prediction and Estimation</a>
<ul>
<li class="chapter" data-level="20.1" data-path="conceptual-framing.html"><a href="conceptual-framing.html"><i class="fa fa-check"></i><b>20.1</b> Conceptual Framing</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="conceptual-framing.html"><a href="conceptual-framing.html#predictive-modeling"><i class="fa fa-check"></i><b>20.1.1</b> Predictive Modeling</a></li>
<li class="chapter" data-level="20.1.2" data-path="conceptual-framing.html"><a href="conceptual-framing.html#estimation-or-causal-inference"><i class="fa fa-check"></i><b>20.1.2</b> Estimation or Causal Inference</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="mathematical-setup.html"><a href="mathematical-setup.html"><i class="fa fa-check"></i><b>20.2</b> Mathematical Setup</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="mathematical-setup.html"><a href="mathematical-setup.html#probability-space-and-data"><i class="fa fa-check"></i><b>20.2.1</b> Probability Space and Data</a></li>
<li class="chapter" data-level="20.2.2" data-path="mathematical-setup.html"><a href="mathematical-setup.html#loss-functions-and-risk"><i class="fa fa-check"></i><b>20.2.2</b> Loss Functions and Risk</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="prediction-in-detail.html"><a href="prediction-in-detail.html"><i class="fa fa-check"></i><b>20.3</b> Prediction in Detail</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="prediction-in-detail.html"><a href="prediction-in-detail.html#empirical-risk-minimization-and-generalization"><i class="fa fa-check"></i><b>20.3.1</b> Empirical Risk Minimization and Generalization</a></li>
<li class="chapter" data-level="20.3.2" data-path="prediction-in-detail.html"><a href="prediction-in-detail.html#bias-variance-decomposition"><i class="fa fa-check"></i><b>20.3.2</b> Bias-Variance Decomposition</a></li>
<li class="chapter" data-level="20.3.3" data-path="prediction-in-detail.html"><a href="prediction-in-detail.html#example-linear-regression-for-prediction"><i class="fa fa-check"></i><b>20.3.3</b> Example: Linear Regression for Prediction</a></li>
<li class="chapter" data-level="20.3.4" data-path="prediction-in-detail.html"><a href="prediction-in-detail.html#applications-in-economics"><i class="fa fa-check"></i><b>20.3.4</b> Applications in Economics</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="parameter-estimation-and-causal-inference.html"><a href="parameter-estimation-and-causal-inference.html"><i class="fa fa-check"></i><b>20.4</b> Parameter Estimation and Causal Inference</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="parameter-estimation-and-causal-inference.html"><a href="parameter-estimation-and-causal-inference.html#estimation-in-parametric-models"><i class="fa fa-check"></i><b>20.4.1</b> Estimation in Parametric Models</a></li>
<li class="chapter" data-level="20.4.2" data-path="parameter-estimation-and-causal-inference.html"><a href="parameter-estimation-and-causal-inference.html#causal-inference-fundamentals"><i class="fa fa-check"></i><b>20.4.2</b> Causal Inference Fundamentals</a></li>
<li class="chapter" data-level="20.4.3" data-path="parameter-estimation-and-causal-inference.html"><a href="parameter-estimation-and-causal-inference.html#role-of-identification"><i class="fa fa-check"></i><b>20.4.3</b> Role of Identification</a></li>
<li class="chapter" data-level="20.4.4" data-path="parameter-estimation-and-causal-inference.html"><a href="parameter-estimation-and-causal-inference.html#challenges-1"><i class="fa fa-check"></i><b>20.4.4</b> Challenges</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="causation-versus-prediction.html"><a href="causation-versus-prediction.html"><i class="fa fa-check"></i><b>20.5</b> Causation versus Prediction</a></li>
<li class="chapter" data-level="20.6" data-path="illustrative-equations-and-mathematical-contrasts.html"><a href="illustrative-equations-and-mathematical-contrasts.html"><i class="fa fa-check"></i><b>20.6</b> Illustrative Equations and Mathematical Contrasts</a>
<ul>
<li class="chapter" data-level="20.6.1" data-path="illustrative-equations-and-mathematical-contrasts.html"><a href="illustrative-equations-and-mathematical-contrasts.html#risk-minimization-vs.-consistency"><i class="fa fa-check"></i><b>20.6.1</b> Risk Minimization vs.¬†Consistency</a></li>
<li class="chapter" data-level="20.6.2" data-path="illustrative-equations-and-mathematical-contrasts.html"><a href="illustrative-equations-and-mathematical-contrasts.html#partial-derivatives-vs.-predictions"><i class="fa fa-check"></i><b>20.6.2</b> Partial Derivatives vs.¬†Predictions</a></li>
<li class="chapter" data-level="20.6.3" data-path="illustrative-equations-and-mathematical-contrasts.html"><a href="illustrative-equations-and-mathematical-contrasts.html#example-high-dimensional-regularization"><i class="fa fa-check"></i><b>20.6.3</b> Example: High-Dimensional Regularization</a></li>
<li class="chapter" data-level="20.6.4" data-path="illustrative-equations-and-mathematical-contrasts.html"><a href="illustrative-equations-and-mathematical-contrasts.html#potential-outcomes-notation"><i class="fa fa-check"></i><b>20.6.4</b> Potential Outcomes Notation</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="extended-mathematical-points.html"><a href="extended-mathematical-points.html"><i class="fa fa-check"></i><b>20.7</b> Extended Mathematical Points</a>
<ul>
<li class="chapter" data-level="20.7.1" data-path="extended-mathematical-points.html"><a href="extended-mathematical-points.html#m-estimation-and-asymptotic-theory"><i class="fa fa-check"></i><b>20.7.1</b> M-Estimation and Asymptotic Theory</a></li>
<li class="chapter" data-level="20.7.2" data-path="extended-mathematical-points.html"><a href="extended-mathematical-points.html#the-danger-of-omitted-variables"><i class="fa fa-check"></i><b>20.7.2</b> The Danger of Omitted Variables</a></li>
<li class="chapter" data-level="20.7.3" data-path="extended-mathematical-points.html"><a href="extended-mathematical-points.html#cross-validation-vs.-statistical-testing"><i class="fa fa-check"></i><b>20.7.3</b> Cross-Validation vs.¬†Statistical Testing</a></li>
</ul></li>
<li class="chapter" data-level="20.8" data-path="putting-it-all-together-comparing-objectives.html"><a href="putting-it-all-together-comparing-objectives.html"><i class="fa fa-check"></i><b>20.8</b> Putting It All Together: Comparing Objectives</a></li>
<li class="chapter" data-level="20.9" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>20.9</b> Conclusion</a></li>
</ul></li>
<li class="part"><span><b>IV. CAUSAL INFERENCE</b></span></li>
<li class="chapter" data-level="21" data-path="sec-causal-inference.html"><a href="sec-causal-inference.html"><i class="fa fa-check"></i><b>21</b> Causal Inference</a>
<ul>
<li class="chapter" data-level="21.1" data-path="sec-the-ladder-of-causation.html"><a href="sec-the-ladder-of-causation.html"><i class="fa fa-check"></i><b>21.1</b> The Ladder of Causation</a></li>
<li class="chapter" data-level="21.2" data-path="the-formal-notation-of-causality.html"><a href="the-formal-notation-of-causality.html"><i class="fa fa-check"></i><b>21.2</b> The Formal Notation of Causality</a></li>
<li class="chapter" data-level="21.3" data-path="the-7-tools-of-structural-causal-models.html"><a href="the-7-tools-of-structural-causal-models.html"><i class="fa fa-check"></i><b>21.3</b> The 7 Tools of Structural Causal Models</a></li>
<li class="chapter" data-level="21.4" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html"><i class="fa fa-check"></i><b>21.4</b> Simpson‚Äôs Paradox</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#what-is-simpsons-paradox"><i class="fa fa-check"></i><b>21.4.1</b> What is Simpson‚Äôs Paradox?</a></li>
<li class="chapter" data-level="21.4.2" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#why-is-this-important"><i class="fa fa-check"></i><b>21.4.2</b> Why is this Important?</a></li>
<li class="chapter" data-level="21.4.3" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#comparison-between-simpsons-paradox-and-omitted-variable-bias"><i class="fa fa-check"></i><b>21.4.3</b> Comparison between Simpson‚Äôs Paradox and Omitted Variable Bias</a></li>
<li class="chapter" data-level="21.4.4" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#illustrating-simpsons-paradox-marketing-campaign-success-rates"><i class="fa fa-check"></i><b>21.4.4</b> Illustrating Simpson‚Äôs Paradox: Marketing Campaign Success Rates</a></li>
<li class="chapter" data-level="21.4.5" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#why-does-this-happen"><i class="fa fa-check"></i><b>21.4.5</b> Why Does This Happen?</a></li>
<li class="chapter" data-level="21.4.6" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#how-does-causal-inference-solve-this"><i class="fa fa-check"></i><b>21.4.6</b> How Does Causal Inference Solve This?</a></li>
<li class="chapter" data-level="21.4.7" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#correcting-simpsons-paradox-with-regression-adjustment"><i class="fa fa-check"></i><b>21.4.7</b> Correcting Simpson‚Äôs Paradox with Regression Adjustment</a></li>
<li class="chapter" data-level="21.4.8" data-path="simpsons-paradox.html"><a href="simpsons-paradox.html#key-takeaways-3"><i class="fa fa-check"></i><b>21.4.8</b> Key Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="additional-resources-1.html"><a href="additional-resources-1.html"><i class="fa fa-check"></i><b>21.5</b> Additional Resources</a></li>
<li class="chapter" data-level="21.6" data-path="experimental-vs.-quasi-experimental-designs.html"><a href="experimental-vs.-quasi-experimental-designs.html"><i class="fa fa-check"></i><b>21.6</b> Experimental vs.¬†Quasi-Experimental Designs</a>
<ul>
<li class="chapter" data-level="21.6.1" data-path="experimental-vs.-quasi-experimental-designs.html"><a href="experimental-vs.-quasi-experimental-designs.html#criticisms-of-quasi-experimental-designs"><i class="fa fa-check"></i><b>21.6.1</b> Criticisms of Quasi-Experimental Designs</a></li>
</ul></li>
<li class="chapter" data-level="21.7" data-path="hierarchical-ordering-of-causal-tools.html"><a href="hierarchical-ordering-of-causal-tools.html"><i class="fa fa-check"></i><b>21.7</b> Hierarchical Ordering of Causal Tools</a></li>
<li class="chapter" data-level="21.8" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html"><i class="fa fa-check"></i><b>21.8</b> Types of Validity in Research</a>
<ul>
<li class="chapter" data-level="21.8.1" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-measurement-validity"><i class="fa fa-check"></i><b>21.8.1</b> Measurement Validity</a></li>
<li class="chapter" data-level="21.8.2" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-construct-validity"><i class="fa fa-check"></i><b>21.8.2</b> Construct Validity</a></li>
<li class="chapter" data-level="21.8.3" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-criterion-validity"><i class="fa fa-check"></i><b>21.8.3</b> Criterion Validity</a></li>
<li class="chapter" data-level="21.8.4" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-internal-validity"><i class="fa fa-check"></i><b>21.8.4</b> Internal Validity</a></li>
<li class="chapter" data-level="21.8.5" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-external-validity"><i class="fa fa-check"></i><b>21.8.5</b> External Validity</a></li>
<li class="chapter" data-level="21.8.6" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-ecological-validity"><i class="fa fa-check"></i><b>21.8.6</b> Ecological Validity</a></li>
<li class="chapter" data-level="21.8.7" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#sec-statistical-conclusion-validity"><i class="fa fa-check"></i><b>21.8.7</b> Statistical Conclusion Validity</a></li>
<li class="chapter" data-level="21.8.8" data-path="types-of-validity-in-research.html"><a href="types-of-validity-in-research.html#putting-it-all-together"><i class="fa fa-check"></i><b>21.8.8</b> Putting It All Together</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="types-of-subjects-in-a-treatment-setting.html"><a href="types-of-subjects-in-a-treatment-setting.html"><i class="fa fa-check"></i><b>21.9</b> Types of Subjects in a Treatment Setting</a>
<ul>
<li class="chapter" data-level="21.9.1" data-path="types-of-subjects-in-a-treatment-setting.html"><a href="types-of-subjects-in-a-treatment-setting.html#non-switchers"><i class="fa fa-check"></i><b>21.9.1</b> Non-Switchers</a></li>
<li class="chapter" data-level="21.9.2" data-path="types-of-subjects-in-a-treatment-setting.html"><a href="types-of-subjects-in-a-treatment-setting.html#switchers"><i class="fa fa-check"></i><b>21.9.2</b> Switchers</a></li>
<li class="chapter" data-level="21.9.3" data-path="types-of-subjects-in-a-treatment-setting.html"><a href="types-of-subjects-in-a-treatment-setting.html#classification-of-individuals-based-on-treatment-assignment"><i class="fa fa-check"></i><b>21.9.3</b> Classification of Individuals Based on Treatment Assignment</a></li>
</ul></li>
<li class="chapter" data-level="21.10" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html"><i class="fa fa-check"></i><b>21.10</b> Types of Treatment Effects</a>
<ul>
<li class="chapter" data-level="21.10.1" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#sec-average-treatment-effect"><i class="fa fa-check"></i><b>21.10.1</b> Average Treatment Effect</a></li>
<li class="chapter" data-level="21.10.2" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#sec-conditional-average-treatment-effect-"><i class="fa fa-check"></i><b>21.10.2</b> Conditional Average Treatment Effect</a></li>
<li class="chapter" data-level="21.10.3" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#sec-intention-to-treat-effect"><i class="fa fa-check"></i><b>21.10.3</b> Intention-to-Treat Effect</a></li>
<li class="chapter" data-level="21.10.4" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#sec-local-average-treatment-effects"><i class="fa fa-check"></i><b>21.10.4</b> Local Average Treatment Effects</a></li>
<li class="chapter" data-level="21.10.5" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#population-vs.-sample-average-treatment-effects"><i class="fa fa-check"></i><b>21.10.5</b> Population vs.¬†Sample Average Treatment Effects</a></li>
<li class="chapter" data-level="21.10.6" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#average-treatment-effects-on-the-treated-and-control"><i class="fa fa-check"></i><b>21.10.6</b> Average Treatment Effects on the Treated and Control</a></li>
<li class="chapter" data-level="21.10.7" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#sec-quantile-average-treatment-effects"><i class="fa fa-check"></i><b>21.10.7</b> Quantile Average Treatment Effects</a></li>
<li class="chapter" data-level="21.10.8" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#sec-log-odds-treatment-effects-for-binary-outcomes"><i class="fa fa-check"></i><b>21.10.8</b> Log-Odds Treatment Effects for Binary Outcomes</a></li>
<li class="chapter" data-level="21.10.9" data-path="types-of-treatment-effects.html"><a href="types-of-treatment-effects.html#summary-table-treatment-effect-estimands"><i class="fa fa-check"></i><b>21.10.9</b> Summary Table: Treatment Effect Estimands</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>A. EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="22" data-path="sec-experimental-design.html"><a href="sec-experimental-design.html"><i class="fa fa-check"></i><b>22</b> Experimental Design</a>
<ul>
<li class="chapter" data-level="22.1" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html"><i class="fa fa-check"></i><b>22.1</b> Principles of Experimental Design</a></li>
<li class="chapter" data-level="22.2" data-path="sec-the-gold-standard-randomized-controlled-trials.html"><a href="sec-the-gold-standard-randomized-controlled-trials.html"><i class="fa fa-check"></i><b>22.2</b> The Gold Standard: Randomized Controlled Trials</a></li>
<li class="chapter" data-level="22.3" data-path="selection-problem.html"><a href="selection-problem.html"><i class="fa fa-check"></i><b>22.3</b> Selection Problem</a>
<ul>
<li class="chapter" data-level="22.3.1" data-path="selection-problem.html"><a href="selection-problem.html#the-observed-difference-in-outcomes"><i class="fa fa-check"></i><b>22.3.1</b> The Observed Difference in Outcomes</a></li>
<li class="chapter" data-level="22.3.2" data-path="selection-problem.html"><a href="selection-problem.html#eliminating-selection-bias-with-random-assignment"><i class="fa fa-check"></i><b>22.3.2</b> Eliminating Selection Bias with Random Assignment</a></li>
<li class="chapter" data-level="22.3.3" data-path="selection-problem.html"><a href="selection-problem.html#another-representation-under-regression"><i class="fa fa-check"></i><b>22.3.3</b> Another Representation Under Regression</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html"><i class="fa fa-check"></i><b>22.4</b> Classical Experimental Designs</a>
<ul>
<li class="chapter" data-level="22.4.1" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html#completely-randomized-design"><i class="fa fa-check"></i><b>22.4.1</b> Completely Randomized Design</a></li>
<li class="chapter" data-level="22.4.2" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html#randomized-block-design"><i class="fa fa-check"></i><b>22.4.2</b> Randomized Block Design</a></li>
<li class="chapter" data-level="22.4.3" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html#factorial-design"><i class="fa fa-check"></i><b>22.4.3</b> Factorial Design</a></li>
<li class="chapter" data-level="22.4.4" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html#crossover-design"><i class="fa fa-check"></i><b>22.4.4</b> Crossover Design</a></li>
<li class="chapter" data-level="22.4.5" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html#split-plot-design"><i class="fa fa-check"></i><b>22.4.5</b> Split-Plot Design</a></li>
<li class="chapter" data-level="22.4.6" data-path="classical-experimental-designs.html"><a href="classical-experimental-designs.html#latin-square-design"><i class="fa fa-check"></i><b>22.4.6</b> Latin Square Design</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="advanced-experimental-designs.html"><a href="advanced-experimental-designs.html"><i class="fa fa-check"></i><b>22.5</b> Advanced Experimental Designs</a>
<ul>
<li class="chapter" data-level="22.5.1" data-path="advanced-experimental-designs.html"><a href="advanced-experimental-designs.html#semi-random-experiments"><i class="fa fa-check"></i><b>22.5.1</b> Semi-Random Experiments</a></li>
<li class="chapter" data-level="22.5.2" data-path="advanced-experimental-designs.html"><a href="advanced-experimental-designs.html#re-randomization"><i class="fa fa-check"></i><b>22.5.2</b> Re-Randomization</a></li>
<li class="chapter" data-level="22.5.3" data-path="advanced-experimental-designs.html"><a href="advanced-experimental-designs.html#two-stage-randomized-experiments"><i class="fa fa-check"></i><b>22.5.3</b> Two-Stage Randomized Experiments</a></li>
<li class="chapter" data-level="22.5.4" data-path="advanced-experimental-designs.html"><a href="advanced-experimental-designs.html#two-stage-randomized-experiments-with-interference-and-noncompliance"><i class="fa fa-check"></i><b>22.5.4</b> Two-Stage Randomized Experiments with Interference and Noncompliance</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="emerging-research.html"><a href="emerging-research.html"><i class="fa fa-check"></i><b>22.6</b> Emerging Research</a>
<ul>
<li class="chapter" data-level="22.6.1" data-path="emerging-research.html"><a href="emerging-research.html#covariate-balancing-in-online-ab-testing-the-pigeonhole-design"><i class="fa fa-check"></i><b>22.6.1</b> Covariate Balancing in Online A/B Testing: The Pigeonhole Design</a></li>
<li class="chapter" data-level="22.6.2" data-path="emerging-research.html"><a href="emerging-research.html#sec-handling-zero-valued-outcomes"><i class="fa fa-check"></i><b>22.6.2</b> Handling Zero-Valued Outcomes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>23</b> Sampling</a>
<ul>
<li class="chapter" data-level="23.1" data-path="population-and-sample.html"><a href="population-and-sample.html"><i class="fa fa-check"></i><b>23.1</b> Population and Sample</a></li>
<li class="chapter" data-level="23.2" data-path="probability-sampling.html"><a href="probability-sampling.html"><i class="fa fa-check"></i><b>23.2</b> Probability Sampling</a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="probability-sampling.html"><a href="probability-sampling.html#sec-simple-random-sampling"><i class="fa fa-check"></i><b>23.2.1</b> Simple Random Sampling</a></li>
<li class="chapter" data-level="23.2.2" data-path="probability-sampling.html"><a href="probability-sampling.html#sec-stratified-sampling"><i class="fa fa-check"></i><b>23.2.2</b> Stratified Sampling</a></li>
<li class="chapter" data-level="23.2.3" data-path="probability-sampling.html"><a href="probability-sampling.html#systematic-sampling"><i class="fa fa-check"></i><b>23.2.3</b> Systematic Sampling</a></li>
<li class="chapter" data-level="23.2.4" data-path="probability-sampling.html"><a href="probability-sampling.html#cluster-sampling"><i class="fa fa-check"></i><b>23.2.4</b> Cluster Sampling</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="non-probability-sampling.html"><a href="non-probability-sampling.html"><i class="fa fa-check"></i><b>23.3</b> Non-Probability Sampling</a>
<ul>
<li class="chapter" data-level="23.3.1" data-path="non-probability-sampling.html"><a href="non-probability-sampling.html#convenience-sampling"><i class="fa fa-check"></i><b>23.3.1</b> Convenience Sampling</a></li>
<li class="chapter" data-level="23.3.2" data-path="non-probability-sampling.html"><a href="non-probability-sampling.html#quota-sampling"><i class="fa fa-check"></i><b>23.3.2</b> Quota Sampling</a></li>
<li class="chapter" data-level="23.3.3" data-path="non-probability-sampling.html"><a href="non-probability-sampling.html#snowball-sampling"><i class="fa fa-check"></i><b>23.3.3</b> Snowball Sampling</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="sec-unequal-probability-sampling.html"><a href="sec-unequal-probability-sampling.html"><i class="fa fa-check"></i><b>23.4</b> Unequal Probability Sampling</a></li>
<li class="chapter" data-level="23.5" data-path="sec-balanced-sampling.html"><a href="sec-balanced-sampling.html"><i class="fa fa-check"></i><b>23.5</b> Balanced Sampling</a>
<ul>
<li class="chapter" data-level="23.5.1" data-path="sec-balanced-sampling.html"><a href="sec-balanced-sampling.html#cube-method-for-balanced-sampling"><i class="fa fa-check"></i><b>23.5.1</b> Cube Method for Balanced Sampling</a></li>
<li class="chapter" data-level="23.5.2" data-path="sec-balanced-sampling.html"><a href="sec-balanced-sampling.html#balanced-sampling-with-stratification"><i class="fa fa-check"></i><b>23.5.2</b> Balanced Sampling with Stratification</a></li>
<li class="chapter" data-level="23.5.3" data-path="sec-balanced-sampling.html"><a href="sec-balanced-sampling.html#balanced-sampling-in-cluster-sampling"><i class="fa fa-check"></i><b>23.5.3</b> Balanced Sampling in Cluster Sampling</a></li>
<li class="chapter" data-level="23.5.4" data-path="sec-balanced-sampling.html"><a href="sec-balanced-sampling.html#balanced-sampling-in-two-stage-sampling"><i class="fa fa-check"></i><b>23.5.4</b> Balanced Sampling in Two-Stage Sampling</a></li>
</ul></li>
<li class="chapter" data-level="23.6" data-path="sample-size-determination.html"><a href="sample-size-determination.html"><i class="fa fa-check"></i><b>23.6</b> Sample Size Determination</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="sec-analysis-of-variance-anova.html"><a href="sec-analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>24</b> Analysis of Variance</a>
<ul>
<li class="chapter" data-level="24.1" data-path="sec-completely-randomized-design.html"><a href="sec-completely-randomized-design.html"><i class="fa fa-check"></i><b>24.1</b> Completely Randomized Design</a>
<ul>
<li class="chapter" data-level="24.1.1" data-path="sec-completely-randomized-design.html"><a href="sec-completely-randomized-design.html#sec-single-factor-fixed-effects-model"><i class="fa fa-check"></i><b>24.1.1</b> Single-Factor Fixed Effects ANOVA</a></li>
<li class="chapter" data-level="24.1.2" data-path="sec-completely-randomized-design.html"><a href="sec-completely-randomized-design.html#sec-single-factor-random-effects-model"><i class="fa fa-check"></i><b>24.1.2</b> Single Factor Random Effects ANOVA</a></li>
<li class="chapter" data-level="24.1.3" data-path="sec-completely-randomized-design.html"><a href="sec-completely-randomized-design.html#sec-two-factor-fixed-effects-anova"><i class="fa fa-check"></i><b>24.1.3</b> Two-Factor Fixed Effects ANOVA</a></li>
<li class="chapter" data-level="24.1.4" data-path="sec-completely-randomized-design.html"><a href="sec-completely-randomized-design.html#sec-two-way-random-effects-anova"><i class="fa fa-check"></i><b>24.1.4</b> Two-Way Random Effects ANOVA</a></li>
<li class="chapter" data-level="24.1.5" data-path="sec-completely-randomized-design.html"><a href="sec-completely-randomized-design.html#sec-two-way-mixed-effects-anova"><i class="fa fa-check"></i><b>24.1.5</b> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="sec-nonparametric-anova.html"><a href="sec-nonparametric-anova.html"><i class="fa fa-check"></i><b>24.2</b> Nonparametric ANOVA</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="sec-nonparametric-anova.html"><a href="sec-nonparametric-anova.html#kruskal-wallis-test-one-way-nonparametric-anova"><i class="fa fa-check"></i><b>24.2.1</b> Kruskal-Wallis Test (One-Way Nonparametric ANOVA)</a></li>
<li class="chapter" data-level="24.2.2" data-path="sec-nonparametric-anova.html"><a href="sec-nonparametric-anova.html#friedman-test-nonparametric-two-way-anova"><i class="fa fa-check"></i><b>24.2.2</b> Friedman Test (Nonparametric Two-Way ANOVA)</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="sec-randomized-block-designs.html"><a href="sec-randomized-block-designs.html"><i class="fa fa-check"></i><b>24.3</b> Randomized Block Designs</a></li>
<li class="chapter" data-level="24.4" data-path="nested-designs.html"><a href="nested-designs.html"><i class="fa fa-check"></i><b>24.4</b> Nested Designs</a>
<ul>
<li class="chapter" data-level="24.4.1" data-path="nested-designs.html"><a href="nested-designs.html#two-factor-nested-design"><i class="fa fa-check"></i><b>24.4.1</b> Two-Factor Nested Design</a></li>
<li class="chapter" data-level="24.4.2" data-path="nested-designs.html"><a href="nested-designs.html#unbalanced-nested-two-factor-designs"><i class="fa fa-check"></i><b>24.4.2</b> Unbalanced Nested Two-Factor Designs</a></li>
<li class="chapter" data-level="24.4.3" data-path="nested-designs.html"><a href="nested-designs.html#random-factor-effects"><i class="fa fa-check"></i><b>24.4.3</b> Random Factor Effects</a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html"><i class="fa fa-check"></i><b>24.5</b> Sample Size Planning for ANOVA</a>
<ul>
<li class="chapter" data-level="24.5.1" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#balanced-designs"><i class="fa fa-check"></i><b>24.5.1</b> Balanced Designs</a></li>
<li class="chapter" data-level="24.5.2" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#single-factor-studies"><i class="fa fa-check"></i><b>24.5.2</b> Single Factor Studies</a></li>
<li class="chapter" data-level="24.5.3" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#multi-factor-studies"><i class="fa fa-check"></i><b>24.5.3</b> Multi-Factor Studies</a></li>
<li class="chapter" data-level="24.5.4" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#procedure-for-sample-size-selection"><i class="fa fa-check"></i><b>24.5.4</b> Procedure for Sample Size Selection</a></li>
<li class="chapter" data-level="24.5.5" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#randomized-block-experiments"><i class="fa fa-check"></i><b>24.5.5</b> Randomized Block Experiments</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html"><i class="fa fa-check"></i><b>24.6</b> Single Factor Covariance Model</a>
<ul>
<li class="chapter" data-level="24.6.1" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html#statistical-inference-for-treatment-effects"><i class="fa fa-check"></i><b>24.6.1</b> Statistical Inference for Treatment Effects</a></li>
<li class="chapter" data-level="24.6.2" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html#testing-for-parallel-slopes"><i class="fa fa-check"></i><b>24.6.2</b> Testing for Parallel Slopes</a></li>
<li class="chapter" data-level="24.6.3" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html#adjusted-means"><i class="fa fa-check"></i><b>24.6.3</b> Adjusted Means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="sec-multivariate-methods.html"><a href="sec-multivariate-methods.html"><i class="fa fa-check"></i><b>25</b> Multivariate Methods</a>
<ul>
<li class="chapter" data-level="25.1" data-path="basic-understanding.html"><a href="basic-understanding.html"><i class="fa fa-check"></i><b>25.1</b> Basic Understanding</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="basic-understanding.html"><a href="basic-understanding.html#multivariate-random-vectors"><i class="fa fa-check"></i><b>25.1.1</b> Multivariate Random Vectors</a></li>
<li class="chapter" data-level="25.1.2" data-path="basic-understanding.html"><a href="basic-understanding.html#sec-covariance-matrix-multivariate"><i class="fa fa-check"></i><b>25.1.2</b> Covariance Matrix</a></li>
<li class="chapter" data-level="25.1.3" data-path="basic-understanding.html"><a href="basic-understanding.html#equalities-in-expectation-and-variance"><i class="fa fa-check"></i><b>25.1.3</b> Equalities in Expectation and Variance</a></li>
<li class="chapter" data-level="25.1.4" data-path="basic-understanding.html"><a href="basic-understanding.html#multivariate-normal-distribution-1"><i class="fa fa-check"></i><b>25.1.4</b> Multivariate Normal Distribution</a></li>
<li class="chapter" data-level="25.1.5" data-path="basic-understanding.html"><a href="basic-understanding.html#test-of-multivariate-normality"><i class="fa fa-check"></i><b>25.1.5</b> Test of Multivariate Normality</a></li>
<li class="chapter" data-level="25.1.6" data-path="basic-understanding.html"><a href="basic-understanding.html#mean-vector-inference"><i class="fa fa-check"></i><b>25.1.6</b> Mean Vector Inference</a></li>
<li class="chapter" data-level="25.1.7" data-path="basic-understanding.html"><a href="basic-understanding.html#general-hypothesis-testing"><i class="fa fa-check"></i><b>25.1.7</b> General Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="sec-multivariate-analysis-of-variance.html"><a href="sec-multivariate-analysis-of-variance.html"><i class="fa fa-check"></i><b>25.2</b> Multivariate Analysis of Variance</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="sec-multivariate-analysis-of-variance.html"><a href="sec-multivariate-analysis-of-variance.html#one-way-manova"><i class="fa fa-check"></i><b>25.2.1</b> One-Way MANOVA</a></li>
<li class="chapter" data-level="25.2.2" data-path="sec-multivariate-analysis-of-variance.html"><a href="sec-multivariate-analysis-of-variance.html#sec-profile-analysis"><i class="fa fa-check"></i><b>25.2.2</b> Profile Analysis</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="statistical-test-selection-for-comparing-means.html"><a href="statistical-test-selection-for-comparing-means.html"><i class="fa fa-check"></i><b>25.3</b> Statistical Test Selection for Comparing Means</a></li>
</ul></li>
<li class="part"><span><b>B. QUASI-EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="26" data-path="sec-quasi-experimental.html"><a href="sec-quasi-experimental.html"><i class="fa fa-check"></i><b>26</b> Quasi-Experimental Methods</a>
<ul>
<li class="chapter" data-level="26.1" data-path="identification-strategy-in-quasi-experiments.html"><a href="identification-strategy-in-quasi-experiments.html"><i class="fa fa-check"></i><b>26.1</b> Identification Strategy in Quasi-Experiments</a></li>
<li class="chapter" data-level="26.2" data-path="robustness-checks.html"><a href="robustness-checks.html"><i class="fa fa-check"></i><b>26.2</b> Robustness Checks</a></li>
<li class="chapter" data-level="26.3" data-path="establishing-mechanisms.html"><a href="establishing-mechanisms.html"><i class="fa fa-check"></i><b>26.3</b> Establishing Mechanisms</a></li>
<li class="chapter" data-level="26.4" data-path="limitations-of-quasi-experiments.html"><a href="limitations-of-quasi-experiments.html"><i class="fa fa-check"></i><b>26.4</b> Limitations of Quasi-Experiments</a></li>
<li class="chapter" data-level="26.5" data-path="assumptions-for-identifying-treatment-effects.html"><a href="assumptions-for-identifying-treatment-effects.html"><i class="fa fa-check"></i><b>26.5</b> Assumptions for Identifying Treatment Effects</a>
<ul>
<li class="chapter" data-level="26.5.1" data-path="assumptions-for-identifying-treatment-effects.html"><a href="assumptions-for-identifying-treatment-effects.html#sec-sutva"><i class="fa fa-check"></i><b>26.5.1</b> Stable Unit Treatment Value Assumption</a></li>
<li class="chapter" data-level="26.5.2" data-path="assumptions-for-identifying-treatment-effects.html"><a href="assumptions-for-identifying-treatment-effects.html#sec-conditional-ignorability-assumption"><i class="fa fa-check"></i><b>26.5.2</b> Conditional Ignorability Assumption</a></li>
<li class="chapter" data-level="26.5.3" data-path="assumptions-for-identifying-treatment-effects.html"><a href="assumptions-for-identifying-treatment-effects.html#sec-overlap-positivity-assumption"><i class="fa fa-check"></i><b>26.5.3</b> Overlap (Positivity) Assumption</a></li>
</ul></li>
<li class="chapter" data-level="26.6" data-path="sec-natural-experiments.html"><a href="sec-natural-experiments.html"><i class="fa fa-check"></i><b>26.6</b> Natural Experiments</a>
<ul>
<li class="chapter" data-level="26.6.1" data-path="sec-natural-experiments.html"><a href="sec-natural-experiments.html#the-problem-of-reusing-natural-experiments"><i class="fa fa-check"></i><b>26.6.1</b> The Problem of Reusing Natural Experiments</a></li>
<li class="chapter" data-level="26.6.2" data-path="sec-natural-experiments.html"><a href="sec-natural-experiments.html#statistical-challenges-in-reusing-natural-experiments"><i class="fa fa-check"></i><b>26.6.2</b> Statistical Challenges in Reusing Natural Experiments</a></li>
<li class="chapter" data-level="26.6.3" data-path="sec-natural-experiments.html"><a href="sec-natural-experiments.html#solutions-multiple-testing-corrections"><i class="fa fa-check"></i><b>26.6.3</b> Solutions: Multiple Testing Corrections</a></li>
</ul></li>
<li class="chapter" data-level="26.7" data-path="design-vs.-model-based-approaches.html"><a href="design-vs.-model-based-approaches.html"><i class="fa fa-check"></i><b>26.7</b> Design vs.¬†Model-Based Approaches</a>
<ul>
<li class="chapter" data-level="26.7.1" data-path="design-vs.-model-based-approaches.html"><a href="design-vs.-model-based-approaches.html#sec-design-based"><i class="fa fa-check"></i><b>26.7.1</b> Design-Based Perspective</a></li>
<li class="chapter" data-level="26.7.2" data-path="design-vs.-model-based-approaches.html"><a href="design-vs.-model-based-approaches.html#sec-model-based-perspective"><i class="fa fa-check"></i><b>26.7.2</b> Model-Based Perspective</a></li>
<li class="chapter" data-level="26.7.3" data-path="design-vs.-model-based-approaches.html"><a href="design-vs.-model-based-approaches.html#placing-methods-along-a-spectrum"><i class="fa fa-check"></i><b>26.7.3</b> Placing Methods Along a Spectrum</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="sec-regression-discontinuity.html"><a href="sec-regression-discontinuity.html"><i class="fa fa-check"></i><b>27</b> Regression Discontinuity</a>
<ul>
<li class="chapter" data-level="27.1" data-path="conceptual-framework.html"><a href="conceptual-framework.html"><i class="fa fa-check"></i><b>27.1</b> Conceptual Framework</a>
<ul>
<li class="chapter" data-level="27.1.1" data-path="conceptual-framework.html"><a href="conceptual-framework.html#types-of-regression-discontinuity-designs"><i class="fa fa-check"></i><b>27.1.1</b> Types of Regression Discontinuity Designs</a></li>
<li class="chapter" data-level="27.1.2" data-path="conceptual-framework.html"><a href="conceptual-framework.html#assumptions-for-rd-validity"><i class="fa fa-check"></i><b>27.1.2</b> Assumptions for RD Validity</a></li>
<li class="chapter" data-level="27.1.3" data-path="conceptual-framework.html"><a href="conceptual-framework.html#threats-to-rd-validity"><i class="fa fa-check"></i><b>27.1.3</b> Threats to RD Validity</a></li>
</ul></li>
<li class="chapter" data-level="27.2" data-path="model-estimation-strategies.html"><a href="model-estimation-strategies.html"><i class="fa fa-check"></i><b>27.2</b> Model Estimation Strategies</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="model-estimation-strategies.html"><a href="model-estimation-strategies.html#parametric-models-polynomial-regression"><i class="fa fa-check"></i><b>27.2.1</b> Parametric Models: Polynomial Regression</a></li>
<li class="chapter" data-level="27.2.2" data-path="model-estimation-strategies.html"><a href="model-estimation-strategies.html#nonparametric-models-local-regression"><i class="fa fa-check"></i><b>27.2.2</b> Nonparametric Models: Local Regression</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="formal-definition.html"><a href="formal-definition.html"><i class="fa fa-check"></i><b>27.3</b> Formal Definition</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="formal-definition.html"><a href="formal-definition.html#identification-assumptions"><i class="fa fa-check"></i><b>27.3.1</b> Identification Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="estimation-and-inference.html"><a href="estimation-and-inference.html"><i class="fa fa-check"></i><b>27.4</b> Estimation and Inference</a>
<ul>
<li class="chapter" data-level="27.4.1" data-path="estimation-and-inference.html"><a href="estimation-and-inference.html#local-randomization-based-approach"><i class="fa fa-check"></i><b>27.4.1</b> Local Randomization-Based Approach</a></li>
<li class="chapter" data-level="27.4.2" data-path="estimation-and-inference.html"><a href="estimation-and-inference.html#sec-continuity-based-approach"><i class="fa fa-check"></i><b>27.4.2</b> Continuity-Based Approach</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="specification-checks.html"><a href="specification-checks.html"><i class="fa fa-check"></i><b>27.5</b> Specification Checks</a>
<ul>
<li class="chapter" data-level="27.5.1" data-path="specification-checks.html"><a href="specification-checks.html#sec-balance-checks"><i class="fa fa-check"></i><b>27.5.1</b> Balance Checks</a></li>
<li class="chapter" data-level="27.5.2" data-path="specification-checks.html"><a href="specification-checks.html#sec-sorting-bunching-and-manipulation"><i class="fa fa-check"></i><b>27.5.2</b> Sorting, Bunching, and Manipulation</a></li>
<li class="chapter" data-level="27.5.3" data-path="specification-checks.html"><a href="specification-checks.html#placebo-tests"><i class="fa fa-check"></i><b>27.5.3</b> Placebo Tests</a></li>
<li class="chapter" data-level="27.5.4" data-path="specification-checks.html"><a href="specification-checks.html#sensitivity-to-bandwidth-choice"><i class="fa fa-check"></i><b>27.5.4</b> Sensitivity to Bandwidth Choice</a></li>
<li class="chapter" data-level="27.5.5" data-path="specification-checks.html"><a href="specification-checks.html#assessing-sensitivity"><i class="fa fa-check"></i><b>27.5.5</b> Assessing Sensitivity</a></li>
<li class="chapter" data-level="27.5.6" data-path="specification-checks.html"><a href="specification-checks.html#manipulation-robust-regression-discontinuity-bounds"><i class="fa fa-check"></i><b>27.5.6</b> Manipulation-Robust Regression Discontinuity Bounds</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html"><i class="fa fa-check"></i><b>27.6</b> Fuzzy Regression Discontinuity Design</a>
<ul>
<li class="chapter" data-level="27.6.1" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html#compliance-types"><i class="fa fa-check"></i><b>27.6.1</b> Compliance Types</a></li>
<li class="chapter" data-level="27.6.2" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html#estimating-the-local-average-treatment-effect"><i class="fa fa-check"></i><b>27.6.2</b> Estimating the Local Average Treatment Effect</a></li>
<li class="chapter" data-level="27.6.3" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html#equivalent-representation-using-expectations"><i class="fa fa-check"></i><b>27.6.3</b> Equivalent Representation Using Expectations</a></li>
<li class="chapter" data-level="27.6.4" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html#estimation-strategies"><i class="fa fa-check"></i><b>27.6.4</b> Estimation Strategies</a></li>
<li class="chapter" data-level="27.6.5" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html#practical-considerations-6"><i class="fa fa-check"></i><b>27.6.5</b> Practical Considerations</a></li>
<li class="chapter" data-level="27.6.6" data-path="sec-fuzzy-regression-discontinuity-design.html"><a href="sec-fuzzy-regression-discontinuity-design.html#steps-for-fuzzy-rd"><i class="fa fa-check"></i><b>27.6.6</b> Steps for Fuzzy RD</a></li>
</ul></li>
<li class="chapter" data-level="27.7" data-path="sec-sharp-regression-discontinuity-design.html"><a href="sec-sharp-regression-discontinuity-design.html"><i class="fa fa-check"></i><b>27.7</b> Sharp Regression Discontinuity Design</a>
<ul>
<li class="chapter" data-level="27.7.1" data-path="sec-sharp-regression-discontinuity-design.html"><a href="sec-sharp-regression-discontinuity-design.html#assumptions-for-identification"><i class="fa fa-check"></i><b>27.7.1</b> Assumptions for Identification</a></li>
<li class="chapter" data-level="27.7.2" data-path="sec-sharp-regression-discontinuity-design.html"><a href="sec-sharp-regression-discontinuity-design.html#estimating-the-local-average-treatment-effect-1"><i class="fa fa-check"></i><b>27.7.2</b> Estimating the Local Average Treatment Effect</a></li>
<li class="chapter" data-level="27.7.3" data-path="sec-sharp-regression-discontinuity-design.html"><a href="sec-sharp-regression-discontinuity-design.html#estimation-methods"><i class="fa fa-check"></i><b>27.7.3</b> Estimation Methods</a></li>
<li class="chapter" data-level="27.7.4" data-path="sec-sharp-regression-discontinuity-design.html"><a href="sec-sharp-regression-discontinuity-design.html#steps-for-sharp-rd"><i class="fa fa-check"></i><b>27.7.4</b> Steps for Sharp RD</a></li>
</ul></li>
<li class="chapter" data-level="27.8" data-path="sec-regression-kink-design.html"><a href="sec-regression-kink-design.html"><i class="fa fa-check"></i><b>27.8</b> Regression Kink Design</a>
<ul>
<li class="chapter" data-level="27.8.1" data-path="sec-regression-kink-design.html"><a href="sec-regression-kink-design.html#sec-identification-in-sharp-regression-kink-design"><i class="fa fa-check"></i><b>27.8.1</b> Identification in Sharp Regression Kink Design</a></li>
<li class="chapter" data-level="27.8.2" data-path="sec-regression-kink-design.html"><a href="sec-regression-kink-design.html#sec-identification-in-fuzzy-regression-kink-design"><i class="fa fa-check"></i><b>27.8.2</b> Identification in Fuzzy Regression Kink Design</a></li>
<li class="chapter" data-level="27.8.3" data-path="sec-regression-kink-design.html"><a href="sec-regression-kink-design.html#estimation-of-rkd-effects"><i class="fa fa-check"></i><b>27.8.3</b> Estimation of RKD Effects</a></li>
<li class="chapter" data-level="27.8.4" data-path="sec-regression-kink-design.html"><a href="sec-regression-kink-design.html#robustness-checks-1"><i class="fa fa-check"></i><b>27.8.4</b> Robustness Checks</a></li>
</ul></li>
<li class="chapter" data-level="27.9" data-path="sec-multi-cutoff-regression-discontinuity-design.html"><a href="sec-multi-cutoff-regression-discontinuity-design.html"><i class="fa fa-check"></i><b>27.9</b> Multi-Cutoff Regression Discontinuity Design</a>
<ul>
<li class="chapter" data-level="27.9.1" data-path="sec-multi-cutoff-regression-discontinuity-design.html"><a href="sec-multi-cutoff-regression-discontinuity-design.html#identification"><i class="fa fa-check"></i><b>27.9.1</b> Identification</a></li>
<li class="chapter" data-level="27.9.2" data-path="sec-multi-cutoff-regression-discontinuity-design.html"><a href="sec-multi-cutoff-regression-discontinuity-design.html#key-assumptions-1"><i class="fa fa-check"></i><b>27.9.2</b> Key Assumptions</a></li>
<li class="chapter" data-level="27.9.3" data-path="sec-multi-cutoff-regression-discontinuity-design.html"><a href="sec-multi-cutoff-regression-discontinuity-design.html#estimation-approaches"><i class="fa fa-check"></i><b>27.9.3</b> Estimation Approaches</a></li>
<li class="chapter" data-level="27.9.4" data-path="sec-multi-cutoff-regression-discontinuity-design.html"><a href="sec-multi-cutoff-regression-discontinuity-design.html#robustness-checks-2"><i class="fa fa-check"></i><b>27.9.4</b> Robustness Checks</a></li>
</ul></li>
<li class="chapter" data-level="27.10" data-path="sec-multi-score-regression-discontinuity-design.html"><a href="sec-multi-score-regression-discontinuity-design.html"><i class="fa fa-check"></i><b>27.10</b> Multi-Score Regression Discontinuity Design</a>
<ul>
<li class="chapter" data-level="27.10.1" data-path="sec-multi-score-regression-discontinuity-design.html"><a href="sec-multi-score-regression-discontinuity-design.html#general-framework"><i class="fa fa-check"></i><b>27.10.1</b> General Framework</a></li>
<li class="chapter" data-level="27.10.2" data-path="sec-multi-score-regression-discontinuity-design.html"><a href="sec-multi-score-regression-discontinuity-design.html#identification-1"><i class="fa fa-check"></i><b>27.10.2</b> Identification</a></li>
<li class="chapter" data-level="27.10.3" data-path="sec-multi-score-regression-discontinuity-design.html"><a href="sec-multi-score-regression-discontinuity-design.html#key-assumptions-2"><i class="fa fa-check"></i><b>27.10.3</b> Key Assumptions</a></li>
<li class="chapter" data-level="27.10.4" data-path="sec-multi-score-regression-discontinuity-design.html"><a href="sec-multi-score-regression-discontinuity-design.html#estimation-approaches-1"><i class="fa fa-check"></i><b>27.10.4</b> Estimation Approaches</a></li>
<li class="chapter" data-level="27.10.5" data-path="sec-multi-score-regression-discontinuity-design.html"><a href="sec-multi-score-regression-discontinuity-design.html#robustness-checks-3"><i class="fa fa-check"></i><b>27.10.5</b> Robustness Checks</a></li>
</ul></li>
<li class="chapter" data-level="27.11" data-path="evaluation-of-a-regression-discontinuity-design.html"><a href="evaluation-of-a-regression-discontinuity-design.html"><i class="fa fa-check"></i><b>27.11</b> Evaluation of a Regression Discontinuity Design</a>
<ul>
<li class="chapter" data-level="27.11.1" data-path="evaluation-of-a-regression-discontinuity-design.html"><a href="evaluation-of-a-regression-discontinuity-design.html#graphical-and-formal-evidence"><i class="fa fa-check"></i><b>27.11.1</b> Graphical and Formal Evidence</a></li>
<li class="chapter" data-level="27.11.2" data-path="evaluation-of-a-regression-discontinuity-design.html"><a href="evaluation-of-a-regression-discontinuity-design.html#functional-form-of-the-running-variable"><i class="fa fa-check"></i><b>27.11.2</b> Functional Form of the Running Variable</a></li>
<li class="chapter" data-level="27.11.3" data-path="evaluation-of-a-regression-discontinuity-design.html"><a href="evaluation-of-a-regression-discontinuity-design.html#bandwidth-selection-2"><i class="fa fa-check"></i><b>27.11.3</b> Bandwidth Selection</a></li>
<li class="chapter" data-level="27.11.4" data-path="evaluation-of-a-regression-discontinuity-design.html"><a href="evaluation-of-a-regression-discontinuity-design.html#addressing-potential-confounders"><i class="fa fa-check"></i><b>27.11.4</b> Addressing Potential Confounders</a></li>
<li class="chapter" data-level="27.11.5" data-path="evaluation-of-a-regression-discontinuity-design.html"><a href="evaluation-of-a-regression-discontinuity-design.html#external-validity-in-rd"><i class="fa fa-check"></i><b>27.11.5</b> External Validity in RD</a></li>
</ul></li>
<li class="chapter" data-level="27.12" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html"><i class="fa fa-check"></i><b>27.12</b> Applications of RD Designs</a>
<ul>
<li class="chapter" data-level="27.12.1" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html#applications-in-marketing"><i class="fa fa-check"></i><b>27.12.1</b> Applications in Marketing</a></li>
<li class="chapter" data-level="27.12.2" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html#r-packages-for-rd-estimation"><i class="fa fa-check"></i><b>27.12.2</b> R Packages for RD Estimation</a></li>
<li class="chapter" data-level="27.12.3" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html#example-of-regression-discontinuity-in-education"><i class="fa fa-check"></i><b>27.12.3</b> Example of Regression Discontinuity in Education</a></li>
<li class="chapter" data-level="27.12.4" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html#example-of-occupational-licensing-and-market-efficiency"><i class="fa fa-check"></i><b>27.12.4</b> Example of Occupational Licensing and Market Efficiency</a></li>
<li class="chapter" data-level="27.12.5" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html#replicating-carpenter2009effect"><i class="fa fa-check"></i><b>27.12.5</b> Replicating <span class="citation">(Carpenter and Dobkin 2009)</span></a></li>
<li class="chapter" data-level="27.12.6" data-path="applications-of-rd-designs.html"><a href="applications-of-rd-designs.html#additional-rd-applications"><i class="fa fa-check"></i><b>27.12.6</b> Additional RD Applications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="temporal-discontinuity-designs.html"><a href="temporal-discontinuity-designs.html"><i class="fa fa-check"></i><b>28</b> Temporal Discontinuity Designs</a>
<ul>
<li class="chapter" data-level="28.1" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html"><i class="fa fa-check"></i><b>28.1</b> Regression Discontinuity in Time</a>
<ul>
<li class="chapter" data-level="28.1.1" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html#estimation-and-model-selection"><i class="fa fa-check"></i><b>28.1.1</b> Estimation and Model Selection</a></li>
<li class="chapter" data-level="28.1.2" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html#strengths-of-rdit"><i class="fa fa-check"></i><b>28.1.2</b> Strengths of RDiT</a></li>
<li class="chapter" data-level="28.1.3" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html#limitations-and-challenges-of-rdit"><i class="fa fa-check"></i><b>28.1.3</b> Limitations and Challenges of RDiT</a></li>
<li class="chapter" data-level="28.1.4" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html#recommendations-for-robustness-checks"><i class="fa fa-check"></i><b>28.1.4</b> Recommendations for Robustness Checks</a></li>
<li class="chapter" data-level="28.1.5" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html#applications-of-rdit"><i class="fa fa-check"></i><b>28.1.5</b> Applications of RDiT</a></li>
<li class="chapter" data-level="28.1.6" data-path="sec-regression-discontinuity-in-time.html"><a href="sec-regression-discontinuity-in-time.html#empirical-example"><i class="fa fa-check"></i><b>28.1.6</b> Empirical Example</a></li>
</ul></li>
<li class="chapter" data-level="28.2" data-path="sec-interrupted-time-series.html"><a href="sec-interrupted-time-series.html"><i class="fa fa-check"></i><b>28.2</b> Interrupted Time Series</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="sec-interrupted-time-series.html"><a href="sec-interrupted-time-series.html#advantages-of-its"><i class="fa fa-check"></i><b>28.2.1</b> Advantages of ITS</a></li>
<li class="chapter" data-level="28.2.2" data-path="sec-interrupted-time-series.html"><a href="sec-interrupted-time-series.html#limitations-of-its"><i class="fa fa-check"></i><b>28.2.2</b> Limitations of ITS</a></li>
<li class="chapter" data-level="28.2.3" data-path="sec-interrupted-time-series.html"><a href="sec-interrupted-time-series.html#empirical-example-1"><i class="fa fa-check"></i><b>28.2.3</b> Empirical Example</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="combining-both-rdit-and-its.html"><a href="combining-both-rdit-and-its.html"><i class="fa fa-check"></i><b>28.3</b> Combining both RDiT and ITS</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="combining-both-rdit-and-its.html"><a href="combining-both-rdit-and-its.html#augment-an-its-model-with-a-local-discontinuity-term"><i class="fa fa-check"></i><b>28.3.1</b> Augment an ITS Model with a Local Discontinuity Term</a></li>
<li class="chapter" data-level="28.3.2" data-path="combining-both-rdit-and-its.html"><a href="combining-both-rdit-and-its.html#two-stage-or-multi-stage-modeling"><i class="fa fa-check"></i><b>28.3.2</b> Two-Stage (or Multi-Stage) Modeling</a></li>
<li class="chapter" data-level="28.3.3" data-path="combining-both-rdit-and-its.html"><a href="combining-both-rdit-and-its.html#hierarchical-or-multi-level-modeling"><i class="fa fa-check"></i><b>28.3.3</b> Hierarchical or Multi-Level Modeling</a></li>
<li class="chapter" data-level="28.3.4" data-path="combining-both-rdit-and-its.html"><a href="combining-both-rdit-and-its.html#empirical-example-2"><i class="fa fa-check"></i><b>28.3.4</b> Empirical Example</a></li>
<li class="chapter" data-level="28.3.5" data-path="combining-both-rdit-and-its.html"><a href="combining-both-rdit-and-its.html#practical-guidance"><i class="fa fa-check"></i><b>28.3.5</b> Practical Guidance</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="case-crossover-study-design.html"><a href="case-crossover-study-design.html"><i class="fa fa-check"></i><b>28.4</b> Case-Crossover Study Design</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="case-crossover-study-design.html"><a href="case-crossover-study-design.html#mathematical-foundations"><i class="fa fa-check"></i><b>28.4.1</b> Mathematical Foundations</a></li>
<li class="chapter" data-level="28.4.2" data-path="case-crossover-study-design.html"><a href="case-crossover-study-design.html#selection-of-control-periods"><i class="fa fa-check"></i><b>28.4.2</b> Selection of Control Periods</a></li>
<li class="chapter" data-level="28.4.3" data-path="case-crossover-study-design.html"><a href="case-crossover-study-design.html#assumptions-1"><i class="fa fa-check"></i><b>28.4.3</b> Assumptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="sec-synthetic-difference-in-differences.html"><a href="sec-synthetic-difference-in-differences.html"><i class="fa fa-check"></i><b>29</b> Synthetic Difference-in-Differences</a>
<ul>
<li class="chapter" data-level="29.1" data-path="understanding.html"><a href="understanding.html"><i class="fa fa-check"></i><b>29.1</b> Understanding</a>
<ul>
<li class="chapter" data-level="29.1.1" data-path="understanding.html"><a href="understanding.html#steps-in-sdid-estimation"><i class="fa fa-check"></i><b>29.1.1</b> Steps in SDID Estimation</a></li>
<li class="chapter" data-level="29.1.2" data-path="understanding.html"><a href="understanding.html#comparison-of-methods-1"><i class="fa fa-check"></i><b>29.1.2</b> Comparison of Methods</a></li>
<li class="chapter" data-level="29.1.3" data-path="understanding.html"><a href="understanding.html#why-use-weights"><i class="fa fa-check"></i><b>29.1.3</b> <strong>Why Use Weights?</strong></a></li>
<li class="chapter" data-level="29.1.4" data-path="understanding.html"><a href="understanding.html#benefits-of-localization-in-sdid"><i class="fa fa-check"></i><b>29.1.4</b> <strong>Benefits of Localization in SDID</strong></a></li>
<li class="chapter" data-level="29.1.5" data-path="understanding.html"><a href="understanding.html#designing-sdid-weights"><i class="fa fa-check"></i><b>29.1.5</b> <strong>Designing SDID Weights</strong></a></li>
<li class="chapter" data-level="29.1.6" data-path="understanding.html"><a href="understanding.html#how-sdid-enhances-dids-plausibility"><i class="fa fa-check"></i><b>29.1.6</b> <strong>How SDID Enhances DID‚Äôs Plausibility</strong></a></li>
<li class="chapter" data-level="29.1.7" data-path="understanding.html"><a href="understanding.html#choosing-sdid-weights"><i class="fa fa-check"></i><b>29.1.7</b> <strong>Choosing SDID Weights</strong></a></li>
<li class="chapter" data-level="29.1.8" data-path="understanding.html"><a href="understanding.html#accounting-for-time-varying-covariates-in-weight-estimation"><i class="fa fa-check"></i><b>29.1.8</b> <strong>Accounting for Time-Varying Covariates in Weight Estimation</strong></a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="application-3.html"><a href="application-3.html"><i class="fa fa-check"></i><b>29.2</b> Application</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="application-3.html"><a href="application-3.html#block-treatment"><i class="fa fa-check"></i><b>29.2.1</b> Block Treatment</a></li>
<li class="chapter" data-level="29.2.2" data-path="application-3.html"><a href="application-3.html#staggered-adoption"><i class="fa fa-check"></i><b>29.2.2</b> Staggered Adoption</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="sec-difference-in-differences.html"><a href="sec-difference-in-differences.html"><i class="fa fa-check"></i><b>30</b> Difference-in-Differences</a>
<ul>
<li class="chapter" data-level="30.1" data-path="empirical-studies.html"><a href="empirical-studies.html"><i class="fa fa-check"></i><b>30.1</b> Empirical Studies</a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="empirical-studies.html"><a href="empirical-studies.html#applications-of-did-in-marketing"><i class="fa fa-check"></i><b>30.1.1</b> Applications of DID in Marketing</a></li>
<li class="chapter" data-level="30.1.2" data-path="empirical-studies.html"><a href="empirical-studies.html#applications-of-did-in-economics"><i class="fa fa-check"></i><b>30.1.2</b> Applications of DID in Economics</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="sec-visualization-did.html"><a href="sec-visualization-did.html"><i class="fa fa-check"></i><b>30.2</b> Visualization</a></li>
<li class="chapter" data-level="30.3" data-path="sec-simple-difference-in-differences.html"><a href="sec-simple-difference-in-differences.html"><i class="fa fa-check"></i><b>30.3</b> Simple Difference-in-Differences</a>
<ul>
<li class="chapter" data-level="30.3.1" data-path="sec-simple-difference-in-differences.html"><a href="sec-simple-difference-in-differences.html#basic-setup-of-did"><i class="fa fa-check"></i><b>30.3.1</b> Basic Setup of DID</a></li>
<li class="chapter" data-level="30.3.2" data-path="sec-simple-difference-in-differences.html"><a href="sec-simple-difference-in-differences.html#extensions-of-did"><i class="fa fa-check"></i><b>30.3.2</b> Extensions of DID</a></li>
<li class="chapter" data-level="30.3.3" data-path="sec-simple-difference-in-differences.html"><a href="sec-simple-difference-in-differences.html#goals-of-did"><i class="fa fa-check"></i><b>30.3.3</b> Goals of DID</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="empirical-research-walkthrough.html"><a href="empirical-research-walkthrough.html"><i class="fa fa-check"></i><b>30.4</b> Empirical Research Walkthrough</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="empirical-research-walkthrough.html"><a href="empirical-research-walkthrough.html#example-the-unintended-consequences-of-ban-the-box-policies"><i class="fa fa-check"></i><b>30.4.1</b> Example: The Unintended Consequences of ‚ÄúBan the Box‚Äù Policies</a></li>
<li class="chapter" data-level="30.4.2" data-path="empirical-research-walkthrough.html"><a href="empirical-research-walkthrough.html#example-minimum-wage-and-employment"><i class="fa fa-check"></i><b>30.4.2</b> Example: Minimum Wage and Employment</a></li>
<li class="chapter" data-level="30.4.3" data-path="empirical-research-walkthrough.html"><a href="empirical-research-walkthrough.html#example-the-effects-of-grade-policies-on-major-choice"><i class="fa fa-check"></i><b>30.4.3</b> Example: The Effects of Grade Policies on Major Choice</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="one-difference.html"><a href="one-difference.html"><i class="fa fa-check"></i><b>30.5</b> One Difference</a></li>
<li class="chapter" data-level="30.6" data-path="sec-two-way-fixed-effects.html"><a href="sec-two-way-fixed-effects.html"><i class="fa fa-check"></i><b>30.6</b> Two-Way Fixed Effects</a>
<ul>
<li class="chapter" data-level="30.6.1" data-path="sec-two-way-fixed-effects.html"><a href="sec-two-way-fixed-effects.html#canonical-twfe-model"><i class="fa fa-check"></i><b>30.6.1</b> Canonical TWFE Model</a></li>
<li class="chapter" data-level="30.6.2" data-path="sec-two-way-fixed-effects.html"><a href="sec-two-way-fixed-effects.html#limitations-of-twfe"><i class="fa fa-check"></i><b>30.6.2</b> Limitations of TWFE</a></li>
<li class="chapter" data-level="30.6.3" data-path="sec-two-way-fixed-effects.html"><a href="sec-two-way-fixed-effects.html#diagnosing-and-addressing-bias-in-twfe"><i class="fa fa-check"></i><b>30.6.3</b> Diagnosing and Addressing Bias in TWFE</a></li>
<li class="chapter" data-level="30.6.4" data-path="sec-two-way-fixed-effects.html"><a href="sec-two-way-fixed-effects.html#remedies-for-twfes-shortcomings"><i class="fa fa-check"></i><b>30.6.4</b> Remedies for TWFE‚Äôs Shortcomings</a></li>
<li class="chapter" data-level="30.6.5" data-path="sec-two-way-fixed-effects.html"><a href="sec-two-way-fixed-effects.html#best-practices-and-recommendations"><i class="fa fa-check"></i><b>30.6.5</b> Best Practices and Recommendations</a></li>
</ul></li>
<li class="chapter" data-level="30.7" data-path="sec-multiple-periods-and-variation-in-treatment-timing.html"><a href="sec-multiple-periods-and-variation-in-treatment-timing.html"><i class="fa fa-check"></i><b>30.7</b> Multiple Periods and Variation in Treatment Timing</a>
<ul>
<li class="chapter" data-level="30.7.1" data-path="sec-multiple-periods-and-variation-in-treatment-timing.html"><a href="sec-multiple-periods-and-variation-in-treatment-timing.html#sec-staggered-difference-in-differences"><i class="fa fa-check"></i><b>30.7.1</b> Staggered Difference-in-Differences</a></li>
</ul></li>
<li class="chapter" data-level="30.8" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html"><i class="fa fa-check"></i><b>30.8</b> Modern Estimators for Staggered Adoption</a>
<ul>
<li class="chapter" data-level="30.8.1" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-group-time-average-treatment-effects-callaway2021difference"><i class="fa fa-check"></i><b>30.8.1</b> Group-Time Average Treatment Effects <span class="citation">(Callaway and Sant‚ÄôAnna 2021)</span></a></li>
<li class="chapter" data-level="30.8.2" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-cohort-average-treatment-effects-sun2021estimating"><i class="fa fa-check"></i><b>30.8.2</b> Cohort Average Treatment Effects <span class="citation">(L. Sun and Abraham 2021)</span></a></li>
<li class="chapter" data-level="30.8.3" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-stacked-difference-in-differences"><i class="fa fa-check"></i><b>30.8.3</b> Stacked Difference-in-Differences</a></li>
<li class="chapter" data-level="30.8.4" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-panel-match-did-estimator-with-in-and-out-treatment-conditions"><i class="fa fa-check"></i><b>30.8.4</b> Panel Match DiD Estimator with In-and-Out Treatment Conditions</a></li>
<li class="chapter" data-level="30.8.5" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#counterfactual-estimators"><i class="fa fa-check"></i><b>30.8.5</b> Counterfactual Estimators</a></li>
<li class="chapter" data-level="30.8.6" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-matrix-completion-estimator"><i class="fa fa-check"></i><b>30.8.6</b> Matrix Completion Estimator</a></li>
<li class="chapter" data-level="30.8.7" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-reshaped-inverse-probability-weighting-twfe-estimator"><i class="fa fa-check"></i><b>30.8.7</b> Reshaped Inverse Probability Weighting - TWFE Estimator</a></li>
<li class="chapter" data-level="30.8.8" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#gardner2022two-and-borusyak2024revisiting"><i class="fa fa-check"></i><b>30.8.8</b> <span class="citation">Gardner (2022)</span> and <span class="citation">Borusyak, Jaravel, and Spiess (2024)</span></a></li>
<li class="chapter" data-level="30.8.9" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#dynamic-treatment-effect-estimation-with-interactive-fixed-effects-and-short-panels"><i class="fa fa-check"></i><b>30.8.9</b> Dynamic Treatment Effect Estimation with Interactive Fixed Effects and Short Panels</a></li>
<li class="chapter" data-level="30.8.10" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#sec-switching-difference-in-differences-estimator-de2020two"><i class="fa fa-check"></i><b>30.8.10</b> Switching Difference-in-Differences Estimator <span class="citation">(Cl√©ment De Chaisemartin and d‚ÄôHaultfoeuille 2020)</span></a></li>
<li class="chapter" data-level="30.8.11" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#augmentedforward-did"><i class="fa fa-check"></i><b>30.8.11</b> Augmented/Forward DID</a></li>
<li class="chapter" data-level="30.8.12" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#doubly-robust-difference-in-differences-estimators"><i class="fa fa-check"></i><b>30.8.12</b> Doubly Robust Difference-in-Differences Estimators</a></li>
<li class="chapter" data-level="30.8.13" data-path="sec-modern-estimators-for-staggered-adoption.html"><a href="sec-modern-estimators-for-staggered-adoption.html#nonlinear-difference-in-differences"><i class="fa fa-check"></i><b>30.8.13</b> Nonlinear Difference-in-Differences</a></li>
</ul></li>
<li class="chapter" data-level="30.9" data-path="multiple-treatments.html"><a href="multiple-treatments.html"><i class="fa fa-check"></i><b>30.9</b> Multiple Treatments</a>
<ul>
<li class="chapter" data-level="30.9.1" data-path="multiple-treatments.html"><a href="multiple-treatments.html#multiple-treatment-groups-model-specification"><i class="fa fa-check"></i><b>30.9.1</b> Multiple Treatment Groups: Model Specification</a></li>
<li class="chapter" data-level="30.9.2" data-path="multiple-treatments.html"><a href="multiple-treatments.html#understanding-the-control-group-in-multiple-treatment-did"><i class="fa fa-check"></i><b>30.9.2</b> Understanding the Control Group in Multiple Treatment DiD</a></li>
<li class="chapter" data-level="30.9.3" data-path="multiple-treatments.html"><a href="multiple-treatments.html#alternative-approaches-separate-regressions-vs.-one-model"><i class="fa fa-check"></i><b>30.9.3</b> Alternative Approaches: Separate Regressions vs.¬†One Model</a></li>
<li class="chapter" data-level="30.9.4" data-path="multiple-treatments.html"><a href="multiple-treatments.html#handling-treatment-intensity"><i class="fa fa-check"></i><b>30.9.4</b> Handling Treatment Intensity</a></li>
<li class="chapter" data-level="30.9.5" data-path="multiple-treatments.html"><a href="multiple-treatments.html#considerations-when-individuals-can-move-between-treatment-groups"><i class="fa fa-check"></i><b>30.9.5</b> Considerations When Individuals Can Move Between Treatment Groups</a></li>
<li class="chapter" data-level="30.9.6" data-path="multiple-treatments.html"><a href="multiple-treatments.html#parallel-trends-assumption-in-multiple-treatment-did"><i class="fa fa-check"></i><b>30.9.6</b> Parallel Trends Assumption in Multiple-Treatment DiD</a></li>
</ul></li>
<li class="chapter" data-level="30.10" data-path="mediation-under-did.html"><a href="mediation-under-did.html"><i class="fa fa-check"></i><b>30.10</b> Mediation Under DiD</a>
<ul>
<li class="chapter" data-level="30.10.1" data-path="mediation-under-did.html"><a href="mediation-under-did.html#mediation-model-in-did"><i class="fa fa-check"></i><b>30.10.1</b> Mediation Model in DiD</a></li>
<li class="chapter" data-level="30.10.2" data-path="mediation-under-did.html"><a href="mediation-under-did.html#interpreting-the-results"><i class="fa fa-check"></i><b>30.10.2</b> Interpreting the Results</a></li>
<li class="chapter" data-level="30.10.3" data-path="mediation-under-did.html"><a href="mediation-under-did.html#challenges-in-mediation-analysis-for-did"><i class="fa fa-check"></i><b>30.10.3</b> Challenges in Mediation Analysis for DiD</a></li>
<li class="chapter" data-level="30.10.4" data-path="mediation-under-did.html"><a href="mediation-under-did.html#alternative-approach-instrumental-variables-for-mediation"><i class="fa fa-check"></i><b>30.10.4</b> Alternative Approach: Instrumental Variables for Mediation</a></li>
</ul></li>
<li class="chapter" data-level="30.11" data-path="assumptions-3.html"><a href="assumptions-3.html"><i class="fa fa-check"></i><b>30.11</b> Assumptions</a>
<ul>
<li class="chapter" data-level="30.11.1" data-path="assumptions-3.html"><a href="assumptions-3.html#prior-parallel-trends-test"><i class="fa fa-check"></i><b>30.11.1</b> Prior Parallel Trends Test</a></li>
<li class="chapter" data-level="30.11.2" data-path="assumptions-3.html"><a href="assumptions-3.html#sec-placebo-test-did"><i class="fa fa-check"></i><b>30.11.2</b> Placebo Test</a></li>
</ul></li>
<li class="chapter" data-level="30.12" data-path="robustness-checks-4.html"><a href="robustness-checks-4.html"><i class="fa fa-check"></i><b>30.12</b> Robustness Checks</a>
<ul>
<li class="chapter" data-level="30.12.1" data-path="robustness-checks-4.html"><a href="robustness-checks-4.html#robustness-checks-to-strengthen-causal-interpretation"><i class="fa fa-check"></i><b>30.12.1</b> Robustness Checks to Strengthen Causal Interpretation</a></li>
<li class="chapter" data-level="30.12.2" data-path="robustness-checks-4.html"><a href="robustness-checks-4.html#best-practices-for-reliable-did-implementation"><i class="fa fa-check"></i><b>30.12.2</b> Best Practices for Reliable DiD Implementation</a></li>
</ul></li>
<li class="chapter" data-level="30.13" data-path="concerns-in-did.html"><a href="concerns-in-did.html"><i class="fa fa-check"></i><b>30.13</b> Concerns in DID</a>
<ul>
<li class="chapter" data-level="30.13.1" data-path="concerns-in-did.html"><a href="concerns-in-did.html#matching-methods-in-did"><i class="fa fa-check"></i><b>30.13.1</b> Matching Methods in DID</a></li>
<li class="chapter" data-level="30.13.2" data-path="concerns-in-did.html"><a href="concerns-in-did.html#control-variables-in-did"><i class="fa fa-check"></i><b>30.13.2</b> Control Variables in DID</a></li>
<li class="chapter" data-level="30.13.3" data-path="concerns-in-did.html"><a href="concerns-in-did.html#did-for-count-data-fixed-effects-poisson-model"><i class="fa fa-check"></i><b>30.13.3</b> DID for Count Data: Fixed-Effects Poisson Model</a></li>
<li class="chapter" data-level="30.13.4" data-path="concerns-in-did.html"><a href="concerns-in-did.html#handling-zero-valued-outcomes-in-did"><i class="fa fa-check"></i><b>30.13.4</b> Handling Zero-Valued Outcomes in DID</a></li>
<li class="chapter" data-level="30.13.5" data-path="concerns-in-did.html"><a href="concerns-in-did.html#standard-errors-1"><i class="fa fa-check"></i><b>30.13.5</b> Standard Errors</a></li>
<li class="chapter" data-level="30.13.6" data-path="concerns-in-did.html"><a href="concerns-in-did.html#sec-partial-identification-did"><i class="fa fa-check"></i><b>30.13.6</b> Partial Identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="sec-changes-in-changes.html"><a href="sec-changes-in-changes.html"><i class="fa fa-check"></i><b>31</b> Changes-in-Changes</a>
<ul>
<li class="chapter" data-level="31.1" data-path="key-concepts.html"><a href="key-concepts.html"><i class="fa fa-check"></i><b>31.1</b> Key Concepts</a></li>
<li class="chapter" data-level="31.2" data-path="estimating-qtt-with-cic.html"><a href="estimating-qtt-with-cic.html"><i class="fa fa-check"></i><b>31.2</b> Estimating QTT with CiC</a></li>
<li class="chapter" data-level="31.3" data-path="application-4.html"><a href="application-4.html"><i class="fa fa-check"></i><b>31.3</b> Application</a>
<ul>
<li class="chapter" data-level="31.3.1" data-path="application-4.html"><a href="application-4.html#ecic-package"><i class="fa fa-check"></i><b>31.3.1</b> ECIC package</a></li>
<li class="chapter" data-level="31.3.2" data-path="application-4.html"><a href="application-4.html#qte-package"><i class="fa fa-check"></i><b>31.3.2</b> QTE package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="32" data-path="sec-synthetic-control.html"><a href="sec-synthetic-control.html"><i class="fa fa-check"></i><b>32</b> Synthetic Control</a>
<ul>
<li class="chapter" data-level="32.1" data-path="marketing-applications.html"><a href="marketing-applications.html"><i class="fa fa-check"></i><b>32.1</b> Marketing Applications</a></li>
<li class="chapter" data-level="32.2" data-path="key-features-of-scm.html"><a href="key-features-of-scm.html"><i class="fa fa-check"></i><b>32.2</b> Key Features of SCM</a></li>
<li class="chapter" data-level="32.3" data-path="advantages-of-scm.html"><a href="advantages-of-scm.html"><i class="fa fa-check"></i><b>32.3</b> Advantages of SCM</a>
<ul>
<li class="chapter" data-level="32.3.1" data-path="advantages-of-scm.html"><a href="advantages-of-scm.html#compared-to-did"><i class="fa fa-check"></i><b>32.3.1</b> Compared to DiD</a></li>
<li class="chapter" data-level="32.3.2" data-path="advantages-of-scm.html"><a href="advantages-of-scm.html#compared-to-linear-regression"><i class="fa fa-check"></i><b>32.3.2</b> Compared to Linear Regression</a></li>
<li class="chapter" data-level="32.3.3" data-path="advantages-of-scm.html"><a href="advantages-of-scm.html#additional-advantages"><i class="fa fa-check"></i><b>32.3.3</b> Additional Advantages</a></li>
</ul></li>
<li class="chapter" data-level="32.4" data-path="disadvantages-of-scm.html"><a href="disadvantages-of-scm.html"><i class="fa fa-check"></i><b>32.4</b> Disadvantages of SCM</a></li>
<li class="chapter" data-level="32.5" data-path="assumptions-4.html"><a href="assumptions-4.html"><i class="fa fa-check"></i><b>32.5</b> Assumptions</a></li>
<li class="chapter" data-level="32.6" data-path="estimation-3.html"><a href="estimation-3.html"><i class="fa fa-check"></i><b>32.6</b> Estimation</a>
<ul>
<li class="chapter" data-level="32.6.1" data-path="estimation-3.html"><a href="estimation-3.html#constructing-the-synthetic-control"><i class="fa fa-check"></i><b>32.6.1</b> Constructing the Synthetic Control</a></li>
<li class="chapter" data-level="32.6.2" data-path="estimation-3.html"><a href="estimation-3.html#penalized-synthetic-control"><i class="fa fa-check"></i><b>32.6.2</b> Penalized Synthetic Control</a></li>
</ul></li>
<li class="chapter" data-level="32.7" data-path="theoretical-considerations.html"><a href="theoretical-considerations.html"><i class="fa fa-check"></i><b>32.7</b> Theoretical Considerations</a></li>
<li class="chapter" data-level="32.8" data-path="inference-in-scm.html"><a href="inference-in-scm.html"><i class="fa fa-check"></i><b>32.8</b> Inference in SCM</a>
<ul>
<li class="chapter" data-level="32.8.1" data-path="inference-in-scm.html"><a href="inference-in-scm.html#permutation-placebo-inference"><i class="fa fa-check"></i><b>32.8.1</b> Permutation (Placebo) Inference</a></li>
<li class="chapter" data-level="32.8.2" data-path="inference-in-scm.html"><a href="inference-in-scm.html#one-sided-inference"><i class="fa fa-check"></i><b>32.8.2</b> One-Sided Inference</a></li>
</ul></li>
<li class="chapter" data-level="32.9" data-path="sec-augmented-synthetic-control.html"><a href="sec-augmented-synthetic-control.html"><i class="fa fa-check"></i><b>32.9</b> Augmented Synthetic Control Method</a></li>
<li class="chapter" data-level="32.10" data-path="synthetic-control-with-staggered-adoption.html"><a href="synthetic-control-with-staggered-adoption.html"><i class="fa fa-check"></i><b>32.10</b> Synthetic Control with Staggered Adoption</a>
<ul>
<li class="chapter" data-level="32.10.1" data-path="synthetic-control-with-staggered-adoption.html"><a href="synthetic-control-with-staggered-adoption.html#partially-pooled-synthetic-control"><i class="fa fa-check"></i><b>32.10.1</b> Partially Pooled Synthetic Control</a></li>
</ul></li>
<li class="chapter" data-level="32.11" data-path="generalized-synthetic-control.html"><a href="generalized-synthetic-control.html"><i class="fa fa-check"></i><b>32.11</b> Generalized Synthetic Control</a>
<ul>
<li class="chapter" data-level="32.11.1" data-path="generalized-synthetic-control.html"><a href="generalized-synthetic-control.html#the-problem-with-traditional-methods"><i class="fa fa-check"></i><b>32.11.1</b> The Problem with Traditional Methods</a></li>
<li class="chapter" data-level="32.11.2" data-path="generalized-synthetic-control.html"><a href="generalized-synthetic-control.html#generalized-synthetic-control-model"><i class="fa fa-check"></i><b>32.11.2</b> Generalized Synthetic Control Model</a></li>
<li class="chapter" data-level="32.11.3" data-path="generalized-synthetic-control.html"><a href="generalized-synthetic-control.html#identification-and-estimation"><i class="fa fa-check"></i><b>32.11.3</b> Identification and Estimation</a></li>
<li class="chapter" data-level="32.11.4" data-path="generalized-synthetic-control.html"><a href="generalized-synthetic-control.html#bootstrap-procedure-for-standard-errors"><i class="fa fa-check"></i><b>32.11.4</b> Bootstrap Procedure for Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="32.12" data-path="bayesian-synthetic-control.html"><a href="bayesian-synthetic-control.html"><i class="fa fa-check"></i><b>32.12</b> Bayesian Synthetic Control</a>
<ul>
<li class="chapter" data-level="32.12.1" data-path="bayesian-synthetic-control.html"><a href="bayesian-synthetic-control.html#bayesian-causal-inference-framework"><i class="fa fa-check"></i><b>32.12.1</b> Bayesian Causal Inference Framework</a></li>
<li class="chapter" data-level="32.12.2" data-path="bayesian-synthetic-control.html"><a href="bayesian-synthetic-control.html#bayesian-dynamic-multilevel-factor-model"><i class="fa fa-check"></i><b>32.12.2</b> Bayesian Dynamic Multilevel Factor Model</a></li>
<li class="chapter" data-level="32.12.3" data-path="bayesian-synthetic-control.html"><a href="bayesian-synthetic-control.html#bayesian-sparse-synthetic-control"><i class="fa fa-check"></i><b>32.12.3</b> Bayesian Sparse Synthetic Control</a></li>
<li class="chapter" data-level="32.12.4" data-path="bayesian-synthetic-control.html"><a href="bayesian-synthetic-control.html#bayesian-inference-and-mcmc-estimation"><i class="fa fa-check"></i><b>32.12.4</b> Bayesian Inference and MCMC Estimation</a></li>
</ul></li>
<li class="chapter" data-level="32.13" data-path="using-multiple-outcomes-to-improve-the-synthetic-control-method.html"><a href="using-multiple-outcomes-to-improve-the-synthetic-control-method.html"><i class="fa fa-check"></i><b>32.13</b> Using Multiple Outcomes to Improve the Synthetic Control Method</a>
<ul>
<li class="chapter" data-level="32.13.1" data-path="using-multiple-outcomes-to-improve-the-synthetic-control-method.html"><a href="using-multiple-outcomes-to-improve-the-synthetic-control-method.html#standard-synthetic-control-method"><i class="fa fa-check"></i><b>32.13.1</b> Standard Synthetic Control Method</a></li>
<li class="chapter" data-level="32.13.2" data-path="using-multiple-outcomes-to-improve-the-synthetic-control-method.html"><a href="using-multiple-outcomes-to-improve-the-synthetic-control-method.html#using-multiple-outcomes-for-bias-reduction"><i class="fa fa-check"></i><b>32.13.2</b> Using Multiple Outcomes for Bias Reduction</a></li>
<li class="chapter" data-level="32.13.3" data-path="using-multiple-outcomes-to-improve-the-synthetic-control-method.html"><a href="using-multiple-outcomes-to-improve-the-synthetic-control-method.html#estimation-methods-1"><i class="fa fa-check"></i><b>32.13.3</b> Estimation Methods</a></li>
<li class="chapter" data-level="32.13.4" data-path="using-multiple-outcomes-to-improve-the-synthetic-control-method.html"><a href="using-multiple-outcomes-to-improve-the-synthetic-control-method.html#empirical-application-flint-water-crisis"><i class="fa fa-check"></i><b>32.13.4</b> Empirical Application: Flint Water Crisis</a></li>
</ul></li>
<li class="chapter" data-level="32.14" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>32.14</b> Applications</a>
<ul>
<li class="chapter" data-level="32.14.1" data-path="applications.html"><a href="applications.html#synthetic-control-estimation"><i class="fa fa-check"></i><b>32.14.1</b> Synthetic Control Estimation</a></li>
<li class="chapter" data-level="32.14.2" data-path="applications.html"><a href="applications.html#the-basque-country-policy-change"><i class="fa fa-check"></i><b>32.14.2</b> The Basque Country Policy Change</a></li>
<li class="chapter" data-level="32.14.3" data-path="applications.html"><a href="applications.html#micro-synthetic-control-with-microsynth"><i class="fa fa-check"></i><b>32.14.3</b> Micro-Synthetic Control with <code>microsynth</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="33" data-path="sec-event-studies.html"><a href="sec-event-studies.html"><i class="fa fa-check"></i><b>33</b> Event Studies</a>
<ul>
<li class="chapter" data-level="33.1" data-path="review-of-event-studies-across-disciplines.html"><a href="review-of-event-studies-across-disciplines.html"><i class="fa fa-check"></i><b>33.1</b> Review of Event Studies Across Disciplines</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="review-of-event-studies-across-disciplines.html"><a href="review-of-event-studies-across-disciplines.html#finance-applications"><i class="fa fa-check"></i><b>33.1.1</b> Finance Applications</a></li>
<li class="chapter" data-level="33.1.2" data-path="review-of-event-studies-across-disciplines.html"><a href="review-of-event-studies-across-disciplines.html#management-applications"><i class="fa fa-check"></i><b>33.1.2</b> Management Applications</a></li>
<li class="chapter" data-level="33.1.3" data-path="review-of-event-studies-across-disciplines.html"><a href="review-of-event-studies-across-disciplines.html#marketing-applications-1"><i class="fa fa-check"></i><b>33.1.3</b> Marketing Applications</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="key-assumptions-3.html"><a href="key-assumptions-3.html"><i class="fa fa-check"></i><b>33.2</b> Key Assumptions</a></li>
<li class="chapter" data-level="33.3" data-path="steps-for-conducting-an-event-study.html"><a href="steps-for-conducting-an-event-study.html"><i class="fa fa-check"></i><b>33.3</b> Steps for Conducting an Event Study</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="steps-for-conducting-an-event-study.html"><a href="steps-for-conducting-an-event-study.html#step-1-event-identification"><i class="fa fa-check"></i><b>33.3.1</b> Step 1: Event Identification</a></li>
<li class="chapter" data-level="33.3.2" data-path="steps-for-conducting-an-event-study.html"><a href="steps-for-conducting-an-event-study.html#step-2-define-the-event-and-estimation-windows"><i class="fa fa-check"></i><b>33.3.2</b> Step 2: Define the Event and Estimation Windows</a></li>
<li class="chapter" data-level="33.3.3" data-path="steps-for-conducting-an-event-study.html"><a href="steps-for-conducting-an-event-study.html#step-3-compute-normal-vs.-abnormal-returns"><i class="fa fa-check"></i><b>33.3.3</b> Step 3: Compute Normal vs.¬†Abnormal Returns</a></li>
<li class="chapter" data-level="33.3.4" data-path="steps-for-conducting-an-event-study.html"><a href="steps-for-conducting-an-event-study.html#step-4-compute-cumulative-abnormal-returns"><i class="fa fa-check"></i><b>33.3.4</b> Step 4: Compute Cumulative Abnormal Returns</a></li>
<li class="chapter" data-level="33.3.5" data-path="steps-for-conducting-an-event-study.html"><a href="steps-for-conducting-an-event-study.html#step-5-statistical-tests-for-significance"><i class="fa fa-check"></i><b>33.3.5</b> Step 5: Statistical Tests for Significance</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="event-studies-in-marketing.html"><a href="event-studies-in-marketing.html"><i class="fa fa-check"></i><b>33.4</b> Event Studies in Marketing</a>
<ul>
<li class="chapter" data-level="33.4.1" data-path="event-studies-in-marketing.html"><a href="event-studies-in-marketing.html#definition"><i class="fa fa-check"></i><b>33.4.1</b> Definition</a></li>
<li class="chapter" data-level="33.4.2" data-path="event-studies-in-marketing.html"><a href="event-studies-in-marketing.html#when-can-marketing-events-affect-non-operating-assets-or-debt"><i class="fa fa-check"></i><b>33.4.2</b> When Can Marketing Events Affect Non-Operating Assets or Debt?</a></li>
<li class="chapter" data-level="33.4.3" data-path="event-studies-in-marketing.html"><a href="event-studies-in-marketing.html#calculating-the-leverage-effect"><i class="fa fa-check"></i><b>33.4.3</b> Calculating the Leverage Effect</a></li>
<li class="chapter" data-level="33.4.4" data-path="event-studies-in-marketing.html"><a href="event-studies-in-marketing.html#computing-leverage-effect-from-compustat-data"><i class="fa fa-check"></i><b>33.4.4</b> Computing Leverage Effect from Compustat Data</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="economic-significance.html"><a href="economic-significance.html"><i class="fa fa-check"></i><b>33.5</b> Economic Significance</a></li>
<li class="chapter" data-level="33.6" data-path="testing-in-event-studies.html"><a href="testing-in-event-studies.html"><i class="fa fa-check"></i><b>33.6</b> Testing in Event Studies</a>
<ul>
<li class="chapter" data-level="33.6.1" data-path="testing-in-event-studies.html"><a href="testing-in-event-studies.html#statistical-power-in-event-studies"><i class="fa fa-check"></i><b>33.6.1</b> Statistical Power in Event Studies</a></li>
<li class="chapter" data-level="33.6.2" data-path="testing-in-event-studies.html"><a href="testing-in-event-studies.html#parametric-tests"><i class="fa fa-check"></i><b>33.6.2</b> Parametric Tests</a></li>
<li class="chapter" data-level="33.6.3" data-path="testing-in-event-studies.html"><a href="testing-in-event-studies.html#non-parametric-tests-1"><i class="fa fa-check"></i><b>33.6.3</b> Non-Parametric Tests</a></li>
</ul></li>
<li class="chapter" data-level="33.7" data-path="sample-in-event-studies.html"><a href="sample-in-event-studies.html"><i class="fa fa-check"></i><b>33.7</b> Sample in Event Studies</a></li>
<li class="chapter" data-level="33.8" data-path="confounders-in-event-studies.html"><a href="confounders-in-event-studies.html"><i class="fa fa-check"></i><b>33.8</b> Confounders in Event Studies</a>
<ul>
<li class="chapter" data-level="33.8.1" data-path="confounders-in-event-studies.html"><a href="confounders-in-event-studies.html#types-of-confounding-events"><i class="fa fa-check"></i><b>33.8.1</b> Types of Confounding Events</a></li>
<li class="chapter" data-level="33.8.2" data-path="confounders-in-event-studies.html"><a href="confounders-in-event-studies.html#should-we-exclude-confounded-observations"><i class="fa fa-check"></i><b>33.8.2</b> Should We Exclude Confounded Observations?</a></li>
<li class="chapter" data-level="33.8.3" data-path="confounders-in-event-studies.html"><a href="confounders-in-event-studies.html#simulation-study-should-we-exclude-correlated-and-uncorrelated-events"><i class="fa fa-check"></i><b>33.8.3</b> Simulation Study: Should We Exclude Correlated and Uncorrelated Events?</a></li>
</ul></li>
<li class="chapter" data-level="33.9" data-path="biases-in-event-studies.html"><a href="biases-in-event-studies.html"><i class="fa fa-check"></i><b>33.9</b> Biases in Event Studies</a>
<ul>
<li class="chapter" data-level="33.9.1" data-path="biases-in-event-studies.html"><a href="biases-in-event-studies.html#timing-bias-different-market-closing-times"><i class="fa fa-check"></i><b>33.9.1</b> Timing Bias: Different Market Closing Times</a></li>
<li class="chapter" data-level="33.9.2" data-path="biases-in-event-studies.html"><a href="biases-in-event-studies.html#upward-bias-in-cumulative-abnormal-returns"><i class="fa fa-check"></i><b>33.9.2</b> Upward Bias in Cumulative Abnormal Returns</a></li>
<li class="chapter" data-level="33.9.3" data-path="biases-in-event-studies.html"><a href="biases-in-event-studies.html#cross-sectional-dependence-bias"><i class="fa fa-check"></i><b>33.9.3</b> Cross-Sectional Dependence Bias</a></li>
<li class="chapter" data-level="33.9.4" data-path="biases-in-event-studies.html"><a href="biases-in-event-studies.html#sample-selection-bias"><i class="fa fa-check"></i><b>33.9.4</b> Sample Selection Bias</a></li>
<li class="chapter" data-level="33.9.5" data-path="biases-in-event-studies.html"><a href="biases-in-event-studies.html#corrections-for-sample-selection-bias"><i class="fa fa-check"></i><b>33.9.5</b> Corrections for Sample Selection Bias</a></li>
</ul></li>
<li class="chapter" data-level="33.10" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html"><i class="fa fa-check"></i><b>33.10</b> Long-run Event Studies</a>
<ul>
<li class="chapter" data-level="33.10.1" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html#sec-buy-and-hold-abnormal-returns-bhar"><i class="fa fa-check"></i><b>33.10.1</b> Buy-and-Hold Abnormal Returns (BHAR)</a></li>
<li class="chapter" data-level="33.10.2" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html#long-term-cumulative-abnormal-returns-lcars"><i class="fa fa-check"></i><b>33.10.2</b> Long-term Cumulative Abnormal Returns (LCARs)</a></li>
<li class="chapter" data-level="33.10.3" data-path="long-run-event-studies.html"><a href="long-run-event-studies.html#calendar-time-portfolio-abnormal-returns-ctars"><i class="fa fa-check"></i><b>33.10.3</b> Calendar-time Portfolio Abnormal Returns (CTARs)</a></li>
</ul></li>
<li class="chapter" data-level="33.11" data-path="aggregation.html"><a href="aggregation.html"><i class="fa fa-check"></i><b>33.11</b> Aggregation</a>
<ul>
<li class="chapter" data-level="33.11.1" data-path="aggregation.html"><a href="aggregation.html#over-time"><i class="fa fa-check"></i><b>33.11.1</b> Over Time</a></li>
<li class="chapter" data-level="33.11.2" data-path="aggregation.html"><a href="aggregation.html#across-firms-and-over-time"><i class="fa fa-check"></i><b>33.11.2</b> Across Firms and Over Time</a></li>
<li class="chapter" data-level="33.11.3" data-path="aggregation.html"><a href="aggregation.html#statistical-tests-1"><i class="fa fa-check"></i><b>33.11.3</b> Statistical Tests</a></li>
</ul></li>
<li class="chapter" data-level="33.12" data-path="heterogeneity-in-the-event-effect.html"><a href="heterogeneity-in-the-event-effect.html"><i class="fa fa-check"></i><b>33.12</b> Heterogeneity in the Event Effect</a>
<ul>
<li class="chapter" data-level="33.12.1" data-path="heterogeneity-in-the-event-effect.html"><a href="heterogeneity-in-the-event-effect.html#common-variables-affecting-car-in-marketing-and-finance"><i class="fa fa-check"></i><b>33.12.1</b> Common Variables Affecting CAR in Marketing and Finance</a></li>
</ul></li>
<li class="chapter" data-level="33.13" data-path="expected-return-calculation.html"><a href="expected-return-calculation.html"><i class="fa fa-check"></i><b>33.13</b> Expected Return Calculation</a>
<ul>
<li class="chapter" data-level="33.13.1" data-path="expected-return-calculation.html"><a href="expected-return-calculation.html#statistical-models-for-expected-returns"><i class="fa fa-check"></i><b>33.13.1</b> <strong>Statistical Models for Expected Returns</strong></a></li>
<li class="chapter" data-level="33.13.2" data-path="expected-return-calculation.html"><a href="expected-return-calculation.html#economic-models-for-expected-returns"><i class="fa fa-check"></i><b>33.13.2</b> <strong>Economic Models for Expected Returns</strong></a></li>
</ul></li>
<li class="chapter" data-level="33.14" data-path="application-of-event-study.html"><a href="application-of-event-study.html"><i class="fa fa-check"></i><b>33.14</b> Application of Event Study</a>
<ul>
<li class="chapter" data-level="33.14.1" data-path="application-of-event-study.html"><a href="application-of-event-study.html#sorting-portfolios-for-expected-returns"><i class="fa fa-check"></i><b>33.14.1</b> <strong>Sorting Portfolios for Expected Returns</strong></a></li>
<li class="chapter" data-level="33.14.2" data-path="application-of-event-study.html"><a href="application-of-event-study.html#erer-package"><i class="fa fa-check"></i><b>33.14.2</b> <strong><code>erer</code> Package</strong></a></li>
<li class="chapter" data-level="33.14.3" data-path="application-of-event-study.html"><a href="application-of-event-study.html#eventus"><i class="fa fa-check"></i><b>33.14.3</b> Eventus</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="sec-instrumental-variables.html"><a href="sec-instrumental-variables.html"><i class="fa fa-check"></i><b>34</b> Instrumental Variables</a>
<ul>
<li class="chapter" data-level="34.1" data-path="challenges-with-instrumental-variables.html"><a href="challenges-with-instrumental-variables.html"><i class="fa fa-check"></i><b>34.1</b> Challenges with Instrumental Variables</a></li>
<li class="chapter" data-level="34.2" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html"><i class="fa fa-check"></i><b>34.2</b> Framework for Instrumental Variables</a>
<ul>
<li class="chapter" data-level="34.2.1" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html#constant-treatment-effect-model"><i class="fa fa-check"></i><b>34.2.1</b> Constant-Treatment-Effect Model</a></li>
<li class="chapter" data-level="34.2.2" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html#instrumental-variable-solution"><i class="fa fa-check"></i><b>34.2.2</b> Instrumental Variable Solution</a></li>
<li class="chapter" data-level="34.2.3" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html#heterogeneous-treatment-effects-and-the-late-framework"><i class="fa fa-check"></i><b>34.2.3</b> Heterogeneous Treatment Effects and the LATE Framework</a></li>
<li class="chapter" data-level="34.2.4" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html#assumptions-for-late-identification"><i class="fa fa-check"></i><b>34.2.4</b> Assumptions for LATE Identification</a></li>
<li class="chapter" data-level="34.2.5" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html#local-average-treatment-effect-theorem"><i class="fa fa-check"></i><b>34.2.5</b> Local Average Treatment Effect Theorem</a></li>
<li class="chapter" data-level="34.2.6" data-path="framework-for-instrumental-variables.html"><a href="framework-for-instrumental-variables.html#iv-in-randomized-trials-noncompliance"><i class="fa fa-check"></i><b>34.2.6</b> IV in Randomized Trials (Noncompliance)</a></li>
</ul></li>
<li class="chapter" data-level="34.3" data-path="sec-estimation.html"><a href="sec-estimation.html"><i class="fa fa-check"></i><b>34.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="34.3.1" data-path="sec-estimation.html"><a href="sec-estimation.html#sec-two-stage-least-squares-estimation"><i class="fa fa-check"></i><b>34.3.1</b> Two-Stage Least Squares Estimation</a></li>
<li class="chapter" data-level="34.3.2" data-path="sec-estimation.html"><a href="sec-estimation.html#iv-gmm"><i class="fa fa-check"></i><b>34.3.2</b> IV-GMM</a></li>
<li class="chapter" data-level="34.3.3" data-path="sec-estimation.html"><a href="sec-estimation.html#limited-information-maximum-likelihood"><i class="fa fa-check"></i><b>34.3.3</b> Limited Information Maximum Likelihood</a></li>
<li class="chapter" data-level="34.3.4" data-path="sec-estimation.html"><a href="sec-estimation.html#jackknife-iv"><i class="fa fa-check"></i><b>34.3.4</b> Jackknife IV</a></li>
<li class="chapter" data-level="34.3.5" data-path="sec-estimation.html"><a href="sec-estimation.html#sec-control-function-approach"><i class="fa fa-check"></i><b>34.3.5</b> Control Function Approach</a></li>
<li class="chapter" data-level="34.3.6" data-path="sec-estimation.html"><a href="sec-estimation.html#fuller-and-bias-reduced-iv"><i class="fa fa-check"></i><b>34.3.6</b> Fuller and Bias-Reduced IV</a></li>
</ul></li>
<li class="chapter" data-level="34.4" data-path="asymptotic-properties-of-the-iv-estimator.html"><a href="asymptotic-properties-of-the-iv-estimator.html"><i class="fa fa-check"></i><b>34.4</b> Asymptotic Properties of the IV Estimator</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="asymptotic-properties-of-the-iv-estimator.html"><a href="asymptotic-properties-of-the-iv-estimator.html#sec-consistency-iv"><i class="fa fa-check"></i><b>34.4.1</b> Consistency</a></li>
<li class="chapter" data-level="34.4.2" data-path="asymptotic-properties-of-the-iv-estimator.html"><a href="asymptotic-properties-of-the-iv-estimator.html#asymptotic-normality-1"><i class="fa fa-check"></i><b>34.4.2</b> Asymptotic Normality</a></li>
<li class="chapter" data-level="34.4.3" data-path="asymptotic-properties-of-the-iv-estimator.html"><a href="asymptotic-properties-of-the-iv-estimator.html#asymptotic-efficiency-1"><i class="fa fa-check"></i><b>34.4.3</b> Asymptotic Efficiency</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="sec-inference-iv.html"><a href="sec-inference-iv.html"><i class="fa fa-check"></i><b>34.5</b> Inference</a>
<ul>
<li class="chapter" data-level="34.5.1" data-path="sec-inference-iv.html"><a href="sec-inference-iv.html#sec-weak-instruments-problem"><i class="fa fa-check"></i><b>34.5.1</b> Weak Instruments Problem</a></li>
<li class="chapter" data-level="34.5.2" data-path="sec-inference-iv.html"><a href="sec-inference-iv.html#solutions-and-approaches-for-valid-inference"><i class="fa fa-check"></i><b>34.5.2</b> Solutions and Approaches for Valid Inference</a></li>
<li class="chapter" data-level="34.5.3" data-path="sec-inference-iv.html"><a href="sec-inference-iv.html#sec-anderson-rubin-approach"><i class="fa fa-check"></i><b>34.5.3</b> Anderson-Rubin Approach</a></li>
<li class="chapter" data-level="34.5.4" data-path="sec-inference-iv.html"><a href="sec-inference-iv.html#sec-tf-procedure"><i class="fa fa-check"></i><b>34.5.4</b> tF Procedure</a></li>
<li class="chapter" data-level="34.5.5" data-path="sec-inference-iv.html"><a href="sec-inference-iv.html#sec-ak-approach"><i class="fa fa-check"></i><b>34.5.5</b> AK Approach</a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="testing-assumptions.html"><a href="testing-assumptions.html"><i class="fa fa-check"></i><b>34.6</b> Testing Assumptions</a>
<ul>
<li class="chapter" data-level="34.6.1" data-path="testing-assumptions.html"><a href="testing-assumptions.html#sec-relevance-assumption"><i class="fa fa-check"></i><b>34.6.1</b> Relevance Assumption</a></li>
<li class="chapter" data-level="34.6.2" data-path="testing-assumptions.html"><a href="testing-assumptions.html#independence-unconfoundedness"><i class="fa fa-check"></i><b>34.6.2</b> Independence (Unconfoundedness)</a></li>
<li class="chapter" data-level="34.6.3" data-path="testing-assumptions.html"><a href="testing-assumptions.html#sec-monotonicity-assumption"><i class="fa fa-check"></i><b>34.6.3</b> Monotonicity Assumption</a></li>
<li class="chapter" data-level="34.6.4" data-path="testing-assumptions.html"><a href="testing-assumptions.html#homogeneous-treatment-effects-optional"><i class="fa fa-check"></i><b>34.6.4</b> Homogeneous Treatment Effects (Optional)</a></li>
<li class="chapter" data-level="34.6.5" data-path="testing-assumptions.html"><a href="testing-assumptions.html#sec-linearity-and-additivity"><i class="fa fa-check"></i><b>34.6.5</b> Linearity and Additivity</a></li>
<li class="chapter" data-level="34.6.6" data-path="testing-assumptions.html"><a href="testing-assumptions.html#instrument-exogeneity-exclusion-restriction"><i class="fa fa-check"></i><b>34.6.6</b> Instrument Exogeneity (Exclusion Restriction)</a></li>
<li class="chapter" data-level="34.6.7" data-path="testing-assumptions.html"><a href="testing-assumptions.html#sec-exogeneity-assumption"><i class="fa fa-check"></i><b>34.6.7</b> Exogeneity Assumption</a></li>
</ul></li>
<li class="chapter" data-level="34.7" data-path="cautions-in-iv.html"><a href="cautions-in-iv.html"><i class="fa fa-check"></i><b>34.7</b> Cautions in IV</a>
<ul>
<li class="chapter" data-level="34.7.1" data-path="cautions-in-iv.html"><a href="cautions-in-iv.html#negative-r2-in-iv"><i class="fa fa-check"></i><b>34.7.1</b> Negative <span class="math inline">\(R^2\)</span> in IV</a></li>
<li class="chapter" data-level="34.7.2" data-path="cautions-in-iv.html"><a href="cautions-in-iv.html#sec-many-instruments-bias"><i class="fa fa-check"></i><b>34.7.2</b> Many-Instruments Bias</a></li>
<li class="chapter" data-level="34.7.3" data-path="cautions-in-iv.html"><a href="cautions-in-iv.html#heterogeneous-effects-in-iv-estimation"><i class="fa fa-check"></i><b>34.7.3</b> Heterogeneous Effects in IV Estimation</a></li>
<li class="chapter" data-level="34.7.4" data-path="cautions-in-iv.html"><a href="cautions-in-iv.html#zero-valued-outcomes"><i class="fa fa-check"></i><b>34.7.4</b> Zero-Valued Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="34.8" data-path="types-of-iv.html"><a href="types-of-iv.html"><i class="fa fa-check"></i><b>34.8</b> Types of IV</a>
<ul>
<li class="chapter" data-level="34.8.1" data-path="types-of-iv.html"><a href="types-of-iv.html#treatment-intensity"><i class="fa fa-check"></i><b>34.8.1</b> Treatment Intensity</a></li>
<li class="chapter" data-level="34.8.2" data-path="types-of-iv.html"><a href="types-of-iv.html#decision-maker-iv"><i class="fa fa-check"></i><b>34.8.2</b> Decision-Maker IV</a></li>
<li class="chapter" data-level="34.8.3" data-path="types-of-iv.html"><a href="types-of-iv.html#sec-proxy-variables"><i class="fa fa-check"></i><b>34.8.3</b> Proxy Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="sec-matching-methods.html"><a href="sec-matching-methods.html"><i class="fa fa-check"></i><b>35</b> Matching Methods</a>
<ul>
<li class="chapter" data-level="35.1" data-path="introduction-and-motivation.html"><a href="introduction-and-motivation.html"><i class="fa fa-check"></i><b>35.1</b> Introduction and Motivation</a>
<ul>
<li class="chapter" data-level="35.1.1" data-path="introduction-and-motivation.html"><a href="introduction-and-motivation.html#why-match"><i class="fa fa-check"></i><b>35.1.1</b> Why Match?</a></li>
<li class="chapter" data-level="35.1.2" data-path="introduction-and-motivation.html"><a href="introduction-and-motivation.html#matching-as-pruning"><i class="fa fa-check"></i><b>35.1.2</b> Matching as ‚ÄúPruning‚Äù</a></li>
<li class="chapter" data-level="35.1.3" data-path="introduction-and-motivation.html"><a href="introduction-and-motivation.html#matching-with-did"><i class="fa fa-check"></i><b>35.1.3</b> Matching with DiD</a></li>
</ul></li>
<li class="chapter" data-level="35.2" data-path="key-assumptions-4.html"><a href="key-assumptions-4.html"><i class="fa fa-check"></i><b>35.2</b> Key Assumptions</a></li>
<li class="chapter" data-level="35.3" data-path="framework-for-generalization.html"><a href="framework-for-generalization.html"><i class="fa fa-check"></i><b>35.3</b> Framework for Generalization</a></li>
<li class="chapter" data-level="35.4" data-path="steps-for-matching.html"><a href="steps-for-matching.html"><i class="fa fa-check"></i><b>35.4</b> Steps for Matching</a>
<ul>
<li class="chapter" data-level="35.4.1" data-path="steps-for-matching.html"><a href="steps-for-matching.html#step-1-define-closeness-distance-metrics"><i class="fa fa-check"></i><b>35.4.1</b> Step 1: Define ‚ÄúCloseness‚Äù (Distance Metrics)</a></li>
<li class="chapter" data-level="35.4.2" data-path="steps-for-matching.html"><a href="steps-for-matching.html#step-2-matching-algorithms"><i class="fa fa-check"></i><b>35.4.2</b> Step 2: Matching Algorithms</a></li>
<li class="chapter" data-level="35.4.3" data-path="steps-for-matching.html"><a href="steps-for-matching.html#step-3-diagnosing-match-quality"><i class="fa fa-check"></i><b>35.4.3</b> Step 3: Diagnosing Match Quality</a></li>
<li class="chapter" data-level="35.4.4" data-path="steps-for-matching.html"><a href="steps-for-matching.html#step-4-estimating-treatment-effects"><i class="fa fa-check"></i><b>35.4.4</b> Step 4: Estimating Treatment Effects</a></li>
</ul></li>
<li class="chapter" data-level="35.5" data-path="special-considerations.html"><a href="special-considerations.html"><i class="fa fa-check"></i><b>35.5</b> Special Considerations</a></li>
<li class="chapter" data-level="35.6" data-path="choosing-a-matching-strategy.html"><a href="choosing-a-matching-strategy.html"><i class="fa fa-check"></i><b>35.6</b> Choosing a Matching Strategy</a>
<ul>
<li class="chapter" data-level="35.6.1" data-path="choosing-a-matching-strategy.html"><a href="choosing-a-matching-strategy.html#based-on-estimand"><i class="fa fa-check"></i><b>35.6.1</b> Based on Estimand</a></li>
<li class="chapter" data-level="35.6.2" data-path="choosing-a-matching-strategy.html"><a href="choosing-a-matching-strategy.html#based-on-diagnostics"><i class="fa fa-check"></i><b>35.6.2</b> Based on Diagnostics</a></li>
<li class="chapter" data-level="35.6.3" data-path="choosing-a-matching-strategy.html"><a href="choosing-a-matching-strategy.html#selection-criteria"><i class="fa fa-check"></i><b>35.6.3</b> Selection Criteria</a></li>
</ul></li>
<li class="chapter" data-level="35.7" data-path="matching-vs.-regression.html"><a href="matching-vs.-regression.html"><i class="fa fa-check"></i><b>35.7</b> Matching vs.¬†Regression</a>
<ul>
<li class="chapter" data-level="35.7.1" data-path="matching-vs.-regression.html"><a href="matching-vs.-regression.html#matching-estimand"><i class="fa fa-check"></i><b>35.7.1</b> Matching Estimand</a></li>
<li class="chapter" data-level="35.7.2" data-path="matching-vs.-regression.html"><a href="matching-vs.-regression.html#regression-estimand"><i class="fa fa-check"></i><b>35.7.2</b> Regression Estimand</a></li>
<li class="chapter" data-level="35.7.3" data-path="matching-vs.-regression.html"><a href="matching-vs.-regression.html#interpretation-weighting-differences"><i class="fa fa-check"></i><b>35.7.3</b> Interpretation: Weighting Differences</a></li>
</ul></li>
<li class="chapter" data-level="35.8" data-path="software-and-practical-implementation.html"><a href="software-and-practical-implementation.html"><i class="fa fa-check"></i><b>35.8</b> Software and Practical Implementation</a></li>
<li class="chapter" data-level="35.9" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html"><i class="fa fa-check"></i><b>35.9</b> Selection on Observables</a>
<ul>
<li class="chapter" data-level="35.9.1" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#matching-with-matchit"><i class="fa fa-check"></i><b>35.9.1</b> Matching with <code>MatchIt</code></a></li>
<li class="chapter" data-level="35.9.2" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#reporting-standards"><i class="fa fa-check"></i><b>35.9.2</b> Reporting Standards</a></li>
<li class="chapter" data-level="35.9.3" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#optimization-based-matching-via-designmatch"><i class="fa fa-check"></i><b>35.9.3</b> Optimization-Based Matching via <code>designmatch</code></a></li>
<li class="chapter" data-level="35.9.4" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#matchingfrontier"><i class="fa fa-check"></i><b>35.9.4</b> MatchingFrontier</a></li>
<li class="chapter" data-level="35.9.5" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#sec-propensity-scores"><i class="fa fa-check"></i><b>35.9.5</b> Propensity Scores</a></li>
<li class="chapter" data-level="35.9.6" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#sec-mahalanobis"><i class="fa fa-check"></i><b>35.9.6</b> Mahalanobis Distance Matching</a></li>
<li class="chapter" data-level="35.9.7" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#sec-cem"><i class="fa fa-check"></i><b>35.9.7</b> Coarsened Exact Matching (CEM)</a></li>
<li class="chapter" data-level="35.9.8" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#sec-genetic-matching"><i class="fa fa-check"></i><b>35.9.8</b> Genetic Matching</a></li>
<li class="chapter" data-level="35.9.9" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#entropy-balancing"><i class="fa fa-check"></i><b>35.9.9</b> Entropy Balancing</a></li>
<li class="chapter" data-level="35.9.10" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#matching-for-high-dimensional-data"><i class="fa fa-check"></i><b>35.9.10</b> Matching for High-Dimensional Data</a></li>
<li class="chapter" data-level="35.9.11" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#matching-for-multiple-treatments"><i class="fa fa-check"></i><b>35.9.11</b> Matching for Multiple Treatments</a></li>
<li class="chapter" data-level="35.9.12" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#matching-for-multi-level-treatments"><i class="fa fa-check"></i><b>35.9.12</b> Matching for Multi-Level Treatments</a></li>
<li class="chapter" data-level="35.9.13" data-path="sec-selection-on-observables.html"><a href="sec-selection-on-observables.html#matching-for-repeated-treatments-time-varying-treatments"><i class="fa fa-check"></i><b>35.9.13</b> Matching for Repeated Treatments (Time-Varying Treatments)</a></li>
</ul></li>
<li class="chapter" data-level="35.10" data-path="sec-selection-on-unobservables.html"><a href="sec-selection-on-unobservables.html"><i class="fa fa-check"></i><b>35.10</b> Selection on Unobservables</a>
<ul>
<li class="chapter" data-level="35.10.1" data-path="sec-selection-on-unobservables.html"><a href="sec-selection-on-unobservables.html#sec-rosenbaum-bounds"><i class="fa fa-check"></i><b>35.10.1</b> Rosenbaum Bounds</a></li>
<li class="chapter" data-level="35.10.2" data-path="sec-selection-on-unobservables.html"><a href="sec-selection-on-unobservables.html#sec-relative-correlation-restrictions"><i class="fa fa-check"></i><b>35.10.2</b> Relative Correlation Restrictions</a></li>
<li class="chapter" data-level="35.10.3" data-path="sec-selection-on-unobservables.html"><a href="sec-selection-on-unobservables.html#sec-coefficient-stability-bounds"><i class="fa fa-check"></i><b>35.10.3</b> Coefficient-Stability Bounds</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>C. OTHER CONCERNS</b></span></li>
<li class="chapter" data-level="36" data-path="sec-endogeneity.html"><a href="sec-endogeneity.html"><i class="fa fa-check"></i><b>36</b> Endogeneity</a>
<ul>
<li class="chapter" data-level="36.1" data-path="sec-endogenous-treatment.html"><a href="sec-endogenous-treatment.html"><i class="fa fa-check"></i><b>36.1</b> Endogenous Treatment</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="sec-endogenous-treatment.html"><a href="sec-endogenous-treatment.html#sec-measurement-error"><i class="fa fa-check"></i><b>36.1.1</b> Measurement Errors</a></li>
<li class="chapter" data-level="36.1.2" data-path="sec-endogenous-treatment.html"><a href="sec-endogenous-treatment.html#sec-simultaneity"><i class="fa fa-check"></i><b>36.1.2</b> Simultaneity</a></li>
<li class="chapter" data-level="36.1.3" data-path="sec-endogenous-treatment.html"><a href="sec-endogenous-treatment.html#sec-reverse-causality"><i class="fa fa-check"></i><b>36.1.3</b> Reverse Causality</a></li>
<li class="chapter" data-level="36.1.4" data-path="sec-endogenous-treatment.html"><a href="sec-endogenous-treatment.html#sec-omitted-variable-bias"><i class="fa fa-check"></i><b>36.1.4</b> Omitted Variable Bias</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html"><i class="fa fa-check"></i><b>36.2</b> Endogenous Sample Selection</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html#unifying-model-frameworks"><i class="fa fa-check"></i><b>36.2.1</b> Unifying Model Frameworks</a></li>
<li class="chapter" data-level="36.2.2" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html#estimation-methods-2"><i class="fa fa-check"></i><b>36.2.2</b> Estimation Methods</a></li>
<li class="chapter" data-level="36.2.3" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html#theoretical-connections"><i class="fa fa-check"></i><b>36.2.3</b> Theoretical Connections</a></li>
<li class="chapter" data-level="36.2.4" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html#tobit-2-heckmans-sample-selection-model"><i class="fa fa-check"></i><b>36.2.4</b> Tobit-2: Heckman‚Äôs Sample Selection Model</a></li>
<li class="chapter" data-level="36.2.5" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html#tobit-5-switching-regression-model"><i class="fa fa-check"></i><b>36.2.5</b> Tobit-5: Switching Regression Model</a></li>
<li class="chapter" data-level="36.2.6" data-path="sec-endogenous-sample-selection.html"><a href="sec-endogenous-sample-selection.html#sec-pattern-mixture-models"><i class="fa fa-check"></i><b>36.2.6</b> Pattern-Mixture Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="other-biases.html"><a href="other-biases.html"><i class="fa fa-check"></i><b>37</b> Other Biases</a>
<ul>
<li class="chapter" data-level="37.1" data-path="sec-aggregation-bias.html"><a href="sec-aggregation-bias.html"><i class="fa fa-check"></i><b>37.1</b> Aggregation Bias</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="sec-aggregation-bias.html"><a href="sec-aggregation-bias.html#simpsons-paradox-1"><i class="fa fa-check"></i><b>37.1.1</b> Simpson‚Äôs Paradox</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="sec-contamination-bias.html"><a href="sec-contamination-bias.html"><i class="fa fa-check"></i><b>37.2</b> Contamination Bias</a></li>
<li class="chapter" data-level="37.3" data-path="sec-survivorship-bias.html"><a href="sec-survivorship-bias.html"><i class="fa fa-check"></i><b>37.3</b> Survivorship Bias</a></li>
<li class="chapter" data-level="37.4" data-path="sec-publication-bias.html"><a href="sec-publication-bias.html"><i class="fa fa-check"></i><b>37.4</b> Publication Bias</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="sec-directed-acyclic-graphs.html"><a href="sec-directed-acyclic-graphs.html"><i class="fa fa-check"></i><b>38</b> Directed Acyclic Graphs</a>
<ul>
<li class="chapter" data-level="38.1" data-path="basic-notation-and-graph-structures.html"><a href="basic-notation-and-graph-structures.html"><i class="fa fa-check"></i><b>38.1</b> Basic Notation and Graph Structures</a></li>
<li class="chapter" data-level="38.2" data-path="rule-of-thumb-for-causal-inference.html"><a href="rule-of-thumb-for-causal-inference.html"><i class="fa fa-check"></i><b>38.2</b> Rule of Thumb for Causal Inference</a></li>
<li class="chapter" data-level="38.3" data-path="example-dag.html"><a href="example-dag.html"><i class="fa fa-check"></i><b>38.3</b> Example DAG</a></li>
<li class="chapter" data-level="38.4" data-path="causal-discovery.html"><a href="causal-discovery.html"><i class="fa fa-check"></i><b>38.4</b> Causal Discovery</a></li>
<li class="chapter" data-level="38.5" data-path="section.html"><a href="section.html"><i class="fa fa-check"></i><b>38.5</b> </a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="sec-controls.html"><a href="sec-controls.html"><i class="fa fa-check"></i><b>39</b> Controls</a>
<ul>
<li class="chapter" data-level="39.1" data-path="bad-controls.html"><a href="bad-controls.html"><i class="fa fa-check"></i><b>39.1</b> Bad Controls</a>
<ul>
<li class="chapter" data-level="39.1.1" data-path="bad-controls.html"><a href="bad-controls.html#m-bias"><i class="fa fa-check"></i><b>39.1.1</b> M-bias</a></li>
<li class="chapter" data-level="39.1.2" data-path="bad-controls.html"><a href="bad-controls.html#bias-amplification-1"><i class="fa fa-check"></i><b>39.1.2</b> Bias Amplification</a></li>
<li class="chapter" data-level="39.1.3" data-path="bad-controls.html"><a href="bad-controls.html#sec-overcontrol-bias"><i class="fa fa-check"></i><b>39.1.3</b> Overcontrol Bias</a></li>
<li class="chapter" data-level="39.1.4" data-path="bad-controls.html"><a href="bad-controls.html#selection-bias"><i class="fa fa-check"></i><b>39.1.4</b> Selection Bias</a></li>
<li class="chapter" data-level="39.1.5" data-path="bad-controls.html"><a href="bad-controls.html#case-control-bias"><i class="fa fa-check"></i><b>39.1.5</b> Case-Control Bias</a></li>
<li class="chapter" data-level="39.1.6" data-path="bad-controls.html"><a href="bad-controls.html#summary-3"><i class="fa fa-check"></i><b>39.1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="good-controls.html"><a href="good-controls.html"><i class="fa fa-check"></i><b>39.2</b> Good Controls</a>
<ul>
<li class="chapter" data-level="39.2.1" data-path="good-controls.html"><a href="good-controls.html#omitted-variable-bias-correction"><i class="fa fa-check"></i><b>39.2.1</b> Omitted Variable Bias Correction</a></li>
<li class="chapter" data-level="39.2.2" data-path="good-controls.html"><a href="good-controls.html#omitted-variable-bias-in-mediation-correction"><i class="fa fa-check"></i><b>39.2.2</b> Omitted Variable Bias in Mediation Correction</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="neutral-controls.html"><a href="neutral-controls.html"><i class="fa fa-check"></i><b>39.3</b> Neutral Controls</a>
<ul>
<li class="chapter" data-level="39.3.1" data-path="neutral-controls.html"><a href="neutral-controls.html#good-predictive-controls"><i class="fa fa-check"></i><b>39.3.1</b> Good Predictive Controls</a></li>
<li class="chapter" data-level="39.3.2" data-path="neutral-controls.html"><a href="neutral-controls.html#good-selection-bias"><i class="fa fa-check"></i><b>39.3.2</b> Good Selection Bias</a></li>
<li class="chapter" data-level="39.3.3" data-path="neutral-controls.html"><a href="neutral-controls.html#bad-predictive-controls"><i class="fa fa-check"></i><b>39.3.3</b> Bad Predictive Controls</a></li>
<li class="chapter" data-level="39.3.4" data-path="neutral-controls.html"><a href="neutral-controls.html#bad-selection-bias"><i class="fa fa-check"></i><b>39.3.4</b> Bad Selection Bias</a></li>
<li class="chapter" data-level="39.3.5" data-path="neutral-controls.html"><a href="neutral-controls.html#summary-table-predictive-vs.-causal-utility-of-controls"><i class="fa fa-check"></i><b>39.3.5</b> Summary Table: Predictive vs.¬†Causal Utility of Controls</a></li>
</ul></li>
<li class="chapter" data-level="39.4" data-path="choosing-controls.html"><a href="choosing-controls.html"><i class="fa fa-check"></i><b>39.4</b> Choosing Controls</a>
<ul>
<li class="chapter" data-level="39.4.1" data-path="choosing-controls.html"><a href="choosing-controls.html#step-1-use-a-causal-diagram-dag"><i class="fa fa-check"></i><b>39.4.1</b> Step 1: Use a Causal Diagram (DAG)</a></li>
<li class="chapter" data-level="39.4.2" data-path="choosing-controls.html"><a href="choosing-controls.html#step-2-use-algorithmic-tools"><i class="fa fa-check"></i><b>39.4.2</b> Step 2: Use Algorithmic Tools</a></li>
<li class="chapter" data-level="39.4.3" data-path="choosing-controls.html"><a href="choosing-controls.html#step-3-theoretical-principles"><i class="fa fa-check"></i><b>39.4.3</b> Step 3: Theoretical Principles</a></li>
<li class="chapter" data-level="39.4.4" data-path="choosing-controls.html"><a href="choosing-controls.html#step-4-consider-sensitivity-analysis"><i class="fa fa-check"></i><b>39.4.4</b> Step 4: Consider Sensitivity Analysis</a></li>
<li class="chapter" data-level="39.4.5" data-path="choosing-controls.html"><a href="choosing-controls.html#step-5-know-when-not-to-control"><i class="fa fa-check"></i><b>39.4.5</b> Step 5: Know When Not to Control</a></li>
<li class="chapter" data-level="39.4.6" data-path="choosing-controls.html"><a href="choosing-controls.html#summary-control-selection-pipeline"><i class="fa fa-check"></i><b>39.4.6</b> Summary: Control Selection Pipeline</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V. MISCELLANEOUS</b></span></li>
<li class="chapter" data-level="40" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>40</b> Report</a>
<ul>
<li class="chapter" data-level="40.1" data-path="one-summary-table.html"><a href="one-summary-table.html"><i class="fa fa-check"></i><b>40.1</b> One summary table</a></li>
<li class="chapter" data-level="40.2" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>40.2</b> Model Comparison</a></li>
<li class="chapter" data-level="40.3" data-path="changes-in-an-estimate.html"><a href="changes-in-an-estimate.html"><i class="fa fa-check"></i><b>40.3</b> Changes in an estimate</a></li>
<li class="chapter" data-level="40.4" data-path="standard-errors-2.html"><a href="standard-errors-2.html"><i class="fa fa-check"></i><b>40.4</b> Standard Errors</a></li>
<li class="chapter" data-level="40.5" data-path="coefficient-uncertainty-and-distribution.html"><a href="coefficient-uncertainty-and-distribution.html"><i class="fa fa-check"></i><b>40.5</b> Coefficient Uncertainty and Distribution</a></li>
<li class="chapter" data-level="40.6" data-path="descriptive-tables.html"><a href="descriptive-tables.html"><i class="fa fa-check"></i><b>40.6</b> Descriptive Tables</a></li>
<li class="chapter" data-level="40.7" data-path="visualizations-and-plots.html"><a href="visualizations-and-plots.html"><i class="fa fa-check"></i><b>40.7</b> Visualizations and Plots</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>41</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="42" data-path="sensitivity-analysis-robustness-check.html"><a href="sensitivity-analysis-robustness-check.html"><i class="fa fa-check"></i><b>42</b> Sensitivity Analysis/ Robustness Check</a>
<ul>
<li class="chapter" data-level="42.1" data-path="specification-curve.html"><a href="specification-curve.html"><i class="fa fa-check"></i><b>42.1</b> Specification curve</a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="specification-curve.html"><a href="specification-curve.html#starbility"><i class="fa fa-check"></i><b>42.1.1</b> starbility</a></li>
<li class="chapter" data-level="42.1.2" data-path="specification-curve.html"><a href="specification-curve.html#rdfanalysis"><i class="fa fa-check"></i><b>42.1.2</b> rdfanalysis</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="coefficient-stability.html"><a href="coefficient-stability.html"><i class="fa fa-check"></i><b>42.2</b> Coefficient stability</a></li>
<li class="chapter" data-level="42.3" data-path="omitted-variable-bias-quantification.html"><a href="omitted-variable-bias-quantification.html"><i class="fa fa-check"></i><b>42.3</b> Omitted Variable Bias Quantification</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="replication-and-synthetic-data.html"><a href="replication-and-synthetic-data.html"><i class="fa fa-check"></i><b>43</b> Replication and Synthetic Data</a>
<ul>
<li class="chapter" data-level="43.1" data-path="the-replication-standard.html"><a href="the-replication-standard.html"><i class="fa fa-check"></i><b>43.1</b> The Replication Standard</a>
<ul>
<li class="chapter" data-level="43.1.1" data-path="the-replication-standard.html"><a href="the-replication-standard.html#solutions-for-empirical-replication"><i class="fa fa-check"></i><b>43.1.1</b> Solutions for Empirical Replication</a></li>
<li class="chapter" data-level="43.1.2" data-path="the-replication-standard.html"><a href="the-replication-standard.html#free-data-repositories"><i class="fa fa-check"></i><b>43.1.2</b> Free Data Repositories</a></li>
<li class="chapter" data-level="43.1.3" data-path="the-replication-standard.html"><a href="the-replication-standard.html#exceptions-to-replication"><i class="fa fa-check"></i><b>43.1.3</b> Exceptions to Replication</a></li>
<li class="chapter" data-level="43.1.4" data-path="the-replication-standard.html"><a href="the-replication-standard.html#replication-landscape"><i class="fa fa-check"></i><b>43.1.4</b> Replication Landscape</a></li>
</ul></li>
<li class="chapter" data-level="43.2" data-path="synthetic-data.html"><a href="synthetic-data.html"><i class="fa fa-check"></i><b>43.2</b> Synthetic Data</a>
<ul>
<li class="chapter" data-level="43.2.1" data-path="synthetic-data.html"><a href="synthetic-data.html#benefits-of-synthetic-data"><i class="fa fa-check"></i><b>43.2.1</b> Benefits of Synthetic Data</a></li>
<li class="chapter" data-level="43.2.2" data-path="synthetic-data.html"><a href="synthetic-data.html#concerns-and-limitations"><i class="fa fa-check"></i><b>43.2.2</b> Concerns and Limitations</a></li>
<li class="chapter" data-level="43.2.3" data-path="synthetic-data.html"><a href="synthetic-data.html#further-insights-on-synthetic-data"><i class="fa fa-check"></i><b>43.2.3</b> Further Insights on Synthetic Data</a></li>
<li class="chapter" data-level="43.2.4" data-path="synthetic-data.html"><a href="synthetic-data.html#generating-synthetic-data"><i class="fa fa-check"></i><b>43.2.4</b> Generating Synthetic Data</a></li>
</ul></li>
<li class="chapter" data-level="43.3" data-path="application-5.html"><a href="application-5.html"><i class="fa fa-check"></i><b>43.3</b> Application</a>
<ul>
<li class="chapter" data-level="43.3.1" data-path="application-5.html"><a href="application-5.html#original-dataset"><i class="fa fa-check"></i><b>43.3.1</b> Original Dataset</a></li>
<li class="chapter" data-level="43.3.2" data-path="application-5.html"><a href="application-5.html#restricted-dataset"><i class="fa fa-check"></i><b>43.3.2</b> Restricted Dataset</a></li>
<li class="chapter" data-level="43.3.3" data-path="application-5.html"><a href="application-5.html#synthpop"><i class="fa fa-check"></i><b>43.3.3</b> Synthpop</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path="high-performance-computing.html"><a href="high-performance-computing.html"><i class="fa fa-check"></i><b>44</b> High-Performance Computing</a>
<ul>
<li class="chapter" data-level="44.1" data-path="best-practices-for-hpc-in-data-analysis.html"><a href="best-practices-for-hpc-in-data-analysis.html"><i class="fa fa-check"></i><b>44.1</b> Best Practices for HPC in Data Analysis</a></li>
<li class="chapter" data-level="44.2" data-path="example-workflow-in-r.html"><a href="example-workflow-in-r.html"><i class="fa fa-check"></i><b>44.2</b> Example Workflow in R</a></li>
<li class="chapter" data-level="44.3" data-path="recommendations.html"><a href="recommendations.html"><i class="fa fa-check"></i><b>44.3</b> Recommendations</a></li>
<li class="chapter" data-level="44.4" data-path="demonstration.html"><a href="demonstration.html"><i class="fa fa-check"></i><b>44.4</b> Demonstration</a></li>
</ul></li>
<li class="appendix"><span><b>APPENDIX</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a>
<ul>
<li class="chapter" data-level="A.1" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>A.1</b> Git</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="git.html"><a href="git.html#basic-setup-1"><i class="fa fa-check"></i><b>A.1.1</b> Basic Setup</a></li>
<li class="chapter" data-level="A.1.2" data-path="git.html"><a href="git.html#creating-a-repository"><i class="fa fa-check"></i><b>A.1.2</b> Creating a Repository</a></li>
<li class="chapter" data-level="A.1.3" data-path="git.html"><a href="git.html#tracking-changes"><i class="fa fa-check"></i><b>A.1.3</b> Tracking Changes</a></li>
<li class="chapter" data-level="A.1.4" data-path="git.html"><a href="git.html#viewing-history-and-changes"><i class="fa fa-check"></i><b>A.1.4</b> Viewing History and Changes</a></li>
<li class="chapter" data-level="A.1.5" data-path="git.html"><a href="git.html#ignoring-files"><i class="fa fa-check"></i><b>A.1.5</b> Ignoring Files</a></li>
<li class="chapter" data-level="A.1.6" data-path="git.html"><a href="git.html#remote-repositories"><i class="fa fa-check"></i><b>A.1.6</b> Remote Repositories</a></li>
<li class="chapter" data-level="A.1.7" data-path="git.html"><a href="git.html#collaboration"><i class="fa fa-check"></i><b>A.1.7</b> Collaboration</a></li>
<li class="chapter" data-level="A.1.8" data-path="git.html"><a href="git.html#branching-and-merging"><i class="fa fa-check"></i><b>A.1.8</b> Branching and Merging</a></li>
<li class="chapter" data-level="A.1.9" data-path="git.html"><a href="git.html#handling-conflicts"><i class="fa fa-check"></i><b>A.1.9</b> Handling Conflicts</a></li>
<li class="chapter" data-level="A.1.10" data-path="git.html"><a href="git.html#licensing"><i class="fa fa-check"></i><b>A.1.10</b> Licensing</a></li>
<li class="chapter" data-level="A.1.11" data-path="git.html"><a href="git.html#citing-repositories"><i class="fa fa-check"></i><b>A.1.11</b> Citing Repositories</a></li>
<li class="chapter" data-level="A.1.12" data-path="git.html"><a href="git.html#hosting-and-legal-considerations"><i class="fa fa-check"></i><b>A.1.12</b> Hosting and Legal Considerations</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="short-cut.html"><a href="short-cut.html"><i class="fa fa-check"></i><b>A.2</b> Short-cut</a></li>
<li class="chapter" data-level="A.3" data-path="function-short-cut.html"><a href="function-short-cut.html"><i class="fa fa-check"></i><b>A.3</b> Function short-cut</a></li>
<li class="chapter" data-level="A.4" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>A.4</b> Citation</a></li>
<li class="chapter" data-level="A.5" data-path="install-all-necessary-packages-on-your-local-machine.html"><a href="install-all-necessary-packages-on-your-local-machine.html"><i class="fa fa-check"></i><b>A.5</b> Install All Necessary Packages on Your Local Machine</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="install-all-necessary-packages-on-your-local-machine.html"><a href="install-all-necessary-packages-on-your-local-machine.html#step-1-export-installed-packages-from-your-current-session"><i class="fa fa-check"></i><b>A.5.1</b> Step 1: Export Installed Packages from Your Current Session</a></li>
<li class="chapter" data-level="A.5.2" data-path="install-all-necessary-packages-on-your-local-machine.html"><a href="install-all-necessary-packages-on-your-local-machine.html#step-2-install-packages-on-a-new-machine"><i class="fa fa-check"></i><b>A.5.2</b> Step 2: Install Packages on a New Machine</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bookdown-cheat-sheet.html"><a href="bookdown-cheat-sheet.html"><i class="fa fa-check"></i><b>B</b> Bookdown cheat sheet</a>
<ul>
<li class="chapter" data-level="B.1" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>B.1</b> Operation</a></li>
<li class="chapter" data-level="B.2" data-path="math-expression-syntax.html"><a href="math-expression-syntax.html"><i class="fa fa-check"></i><b>B.2</b> Math Expression/ Syntax</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="math-expression-syntax.html"><a href="math-expression-syntax.html#statistics-notation"><i class="fa fa-check"></i><b>B.2.1</b> Statistics Notation</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="table.html"><a href="table.html"><i class="fa fa-check"></i><b>B.3</b> Table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="references.html"><a href="references.html#cluster-randomization"><i class="fa fa-check"></i><b>B.3.1</b> Cluster Randomization</a></li>
<li class="chapter" data-level="B.4" data-path="methodological-blueprint-for-applied-researchers.html"><a href="methodological-blueprint-for-applied-researchers.html"><i class="fa fa-check"></i><b>B.4</b> 5 Methodological Blueprint for Applied Researchers</a>
<ul>
<li class="chapter" data-level="B.4.1" data-path="methodological-blueprint-for-applied-researchers.html"><a href="methodological-blueprint-for-applied-researchers.html#diagnosing-interference"><i class="fa fa-check"></i><b>B.4.1</b> 5.1 Diagnosing Interference</a></li>
<li class="chapter" data-level="B.4.2" data-path="methodological-blueprint-for-applied-researchers.html"><a href="methodological-blueprint-for-applied-researchers.html#cluster-construction-algorithm"><i class="fa fa-check"></i><b>B.4.2</b> 5.2 Cluster Construction Algorithm</a></li>
<li class="chapter" data-level="B.4.3" data-path="methodological-blueprint-for-applied-researchers.html"><a href="methodological-blueprint-for-applied-researchers.html#analysis-plan"><i class="fa fa-check"></i><b>B.4.3</b> 5.3 Analysis Plan</a></li>
<li class="chapter" data-level="B.4.4" data-path="methodological-blueprint-for-applied-researchers.html"><a href="methodological-blueprint-for-applied-researchers.html#practical-considerations-9"><i class="fa fa-check"></i><b>B.4.4</b> 5.4 Practical Considerations</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="extensions-and-research-opportunities.html"><a href="extensions-and-research-opportunities.html"><i class="fa fa-check"></i><b>B.5</b> 6 Extensions and Research Opportunities</a></li>
<li class="chapter" data-level="B.6" data-path="pre-experiment-checklist.html"><a href="pre-experiment-checklist.html"><i class="fa fa-check"></i><b>B.6</b> 7 Pre-Experiment Checklist</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="chapter-cluster-randomization-and-interference-bias.html"><a href="chapter-cluster-randomization-and-interference-bias.html"><i class="fa fa-check"></i><b>C</b> Chapter: Cluster Randomization and Interference Bias</a>
<ul>
<li class="chapter" data-level="C.1" data-path="implementation-practical-guidelines.html"><a href="implementation-practical-guidelines.html"><i class="fa fa-check"></i><b>C.1</b> 6. Implementation: Practical Guidelines</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="implementation-practical-guidelines.html"><a href="implementation-practical-guidelines.html#constructing-clusters"><i class="fa fa-check"></i><b>C.1.1</b> 6.1 Constructing Clusters</a></li>
<li class="chapter" data-level="C.1.2" data-path="implementation-practical-guidelines.html"><a href="implementation-practical-guidelines.html#evaluating-cluster-quality"><i class="fa fa-check"></i><b>C.1.2</b> 6.2 Evaluating Cluster Quality</a></li>
<li class="chapter" data-level="C.1.3" data-path="implementation-practical-guidelines.html"><a href="implementation-practical-guidelines.html#trade-offs"><i class="fa fa-check"></i><b>C.1.3</b> 6.3 Trade-offs</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="limitations-and-open-questions.html"><a href="limitations-and-open-questions.html"><i class="fa fa-check"></i><b>C.2</b> 8. Limitations and Open Questions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sec-selection-on-observables" class="section level2 hasAnchor" number="35.9">
<h2><span class="header-section-number">35.9</span> Selection on Observables<a href="sec-selection-on-observables.html#sec-selection-on-observables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In observational studies, treatment assignment is typically not randomized. This poses a challenge when estimating causal effects, as treated and control groups may differ systematically. A central assumption that allows us to estimate causal effects from such data is <strong>selection on observables</strong>, also known as <strong>unconfoundedness</strong> or <strong>conditional independence</strong>.</p>
<p>Suppose we observe a binary treatment indicator <span class="math inline">\(T_i \in \{0, 1\}\)</span> and an outcome <span class="math inline">\(Y_i\)</span>. Each unit <span class="math inline">\(i\)</span> has two potential outcomes:</p>
<ul>
<li><span class="math inline">\(Y_i(1)\)</span>: outcome if treated</li>
<li><span class="math inline">\(Y_i(0)\)</span>: outcome if untreated</li>
</ul>
<p>However, only one of these outcomes is observed for each unit. The average treatment effect on the treated (ATT) is:</p>
<p><span class="math display">\[
\text{ATT} = \mathbb{E}[Y(1) - Y(0) \mid T = 1]
\]</span></p>
<p>To identify this from data, we invoke the <strong>conditional independence assumption</strong>:</p>
<p><span class="math display">\[
(Y(0), Y(1)) \perp T \mid X
\]</span></p>
<p>This assumption means that after controlling for covariates <span class="math inline">\(X\)</span>, treatment is as good as randomly assigned. A secondary assumption is <strong>overlap</strong>:</p>
<p><span class="math display">\[
0 &lt; \mathbb{P}(T = 1 \mid X = x) &lt; 1 \quad \text{for all } x
\]</span></p>
<p>This ensures that for every covariate profile, there is a positive probability of being both treated and untreated.</p>
<p>Matching attempts to approximate the conditions of a randomized experiment by creating a comparison group that is similar to the treated group in terms of observed covariates. Instead of relying solely on model-based adjustment (e.g., regression), matching balances the covariate distribution across treatment groups before estimation.</p>
<hr />
<div id="matching-with-matchit" class="section level3 hasAnchor" number="35.9.1">
<h3><span class="header-section-number">35.9.1</span> Matching with <code>MatchIt</code><a href="sec-selection-on-observables.html#matching-with-matchit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We demonstrate the matching procedure using the <code>lalonde</code> dataset, a classic example in the causal inference literature, which investigates the effect of job training on subsequent earnings.</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="sec-selection-on-observables.html#cb927-1" tabindex="-1"></a><span class="fu">library</span>(MatchIt)</span>
<span id="cb927-2"><a href="sec-selection-on-observables.html#cb927-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;lalonde&quot;</span>)</span></code></pre></div>
<p>We focus on estimating the effect of the treatment (<code>treat</code>) on earnings in 1978 (<code>re78</code>), conditional on covariates.</p>
<hr />
<p><strong>Step 1: Planning the Analysis</strong></p>
<p>Before conducting matching, several strategic decisions must be made:</p>
<ul>
<li><p><strong>Estimand</strong>: Do you want ATT (effect on treated), ATE (effect in population), or ATC (effect on controls)? Matching typically targets the ATT.</p></li>
<li><p><strong>Covariate Selection</strong>: Only include <strong>pre-treatment variables</strong> that are potential confounders‚Äîi.e., affect both the treatment assignment and the outcome <span class="citation">(<a href="#ref-austin2011optimal">Austin 2011</a>; <a href="#ref-vanderweele2019principles">T. J. VanderWeele 2019</a>)</span>.</p></li>
<li><p><strong>Distance Measure</strong>: Choose how to quantify similarity between units (e.g., propensity score, Mahalanobis distance).</p></li>
<li><p><strong>Matching Method</strong>: Determine the method (e.g., nearest neighbor, full matching, genetic matching).</p></li>
</ul>
<p>For our demonstration, we focus on ATT using <strong>propensity score matching</strong>.</p>
<hr />
<p><strong>Step 2: Assessing Initial Imbalance</strong></p>
<p>We first assess imbalance between treatment and control groups before matching.</p>
<div class="sourceCode" id="cb928"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb928-1"><a href="sec-selection-on-observables.html#cb928-1" tabindex="-1"></a><span class="co"># Estimate propensity scores with logistic regression</span></span>
<span id="cb928-2"><a href="sec-selection-on-observables.html#cb928-2" tabindex="-1"></a>m.out0 <span class="ot">&lt;-</span> <span class="fu">matchit</span>(</span>
<span id="cb928-3"><a href="sec-selection-on-observables.html#cb928-3" tabindex="-1"></a>  treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb928-4"><a href="sec-selection-on-observables.html#cb928-4" tabindex="-1"></a>  <span class="at">data =</span> MatchIt<span class="sc">::</span>lalonde,</span>
<span id="cb928-5"><a href="sec-selection-on-observables.html#cb928-5" tabindex="-1"></a>  <span class="at">method =</span> <span class="cn">NULL</span>,     <span class="co"># no matching, only estimates propensity scores</span></span>
<span id="cb928-6"><a href="sec-selection-on-observables.html#cb928-6" tabindex="-1"></a>  <span class="at">distance =</span> <span class="st">&quot;glm&quot;</span></span>
<span id="cb928-7"><a href="sec-selection-on-observables.html#cb928-7" tabindex="-1"></a>)</span>
<span id="cb928-8"><a href="sec-selection-on-observables.html#cb928-8" tabindex="-1"></a></span>
<span id="cb928-9"><a href="sec-selection-on-observables.html#cb928-9" tabindex="-1"></a><span class="co"># Summary of balance statistics before matching</span></span>
<span id="cb928-10"><a href="sec-selection-on-observables.html#cb928-10" tabindex="-1"></a><span class="fu">summary</span>(m.out0)</span>
<span id="cb928-11"><a href="sec-selection-on-observables.html#cb928-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb928-12"><a href="sec-selection-on-observables.html#cb928-12" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb928-13"><a href="sec-selection-on-observables.html#cb928-13" tabindex="-1"></a><span class="co">#&gt; matchit(formula = treat ~ age + educ + race + married + nodegree + </span></span>
<span id="cb928-14"><a href="sec-selection-on-observables.html#cb928-14" tabindex="-1"></a><span class="co">#&gt;     re74 + re75, data = MatchIt::lalonde, method = NULL, distance = &quot;glm&quot;)</span></span>
<span id="cb928-15"><a href="sec-selection-on-observables.html#cb928-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb928-16"><a href="sec-selection-on-observables.html#cb928-16" tabindex="-1"></a><span class="co">#&gt; Summary of Balance for All Data:</span></span>
<span id="cb928-17"><a href="sec-selection-on-observables.html#cb928-17" tabindex="-1"></a><span class="co">#&gt;            Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span id="cb928-18"><a href="sec-selection-on-observables.html#cb928-18" tabindex="-1"></a><span class="co">#&gt; distance          0.5774        0.1822          1.7941     0.9211    0.3774</span></span>
<span id="cb928-19"><a href="sec-selection-on-observables.html#cb928-19" tabindex="-1"></a><span class="co">#&gt; age              25.8162       28.0303         -0.3094     0.4400    0.0813</span></span>
<span id="cb928-20"><a href="sec-selection-on-observables.html#cb928-20" tabindex="-1"></a><span class="co">#&gt; educ             10.3459       10.2354          0.0550     0.4959    0.0347</span></span>
<span id="cb928-21"><a href="sec-selection-on-observables.html#cb928-21" tabindex="-1"></a><span class="co">#&gt; raceblack         0.8432        0.2028          1.7615          .    0.6404</span></span>
<span id="cb928-22"><a href="sec-selection-on-observables.html#cb928-22" tabindex="-1"></a><span class="co">#&gt; racehispan        0.0595        0.1422         -0.3498          .    0.0827</span></span>
<span id="cb928-23"><a href="sec-selection-on-observables.html#cb928-23" tabindex="-1"></a><span class="co">#&gt; racewhite         0.0973        0.6550         -1.8819          .    0.5577</span></span>
<span id="cb928-24"><a href="sec-selection-on-observables.html#cb928-24" tabindex="-1"></a><span class="co">#&gt; married           0.1892        0.5128         -0.8263          .    0.3236</span></span>
<span id="cb928-25"><a href="sec-selection-on-observables.html#cb928-25" tabindex="-1"></a><span class="co">#&gt; nodegree          0.7081        0.5967          0.2450          .    0.1114</span></span>
<span id="cb928-26"><a href="sec-selection-on-observables.html#cb928-26" tabindex="-1"></a><span class="co">#&gt; re74           2095.5737     5619.2365         -0.7211     0.5181    0.2248</span></span>
<span id="cb928-27"><a href="sec-selection-on-observables.html#cb928-27" tabindex="-1"></a><span class="co">#&gt; re75           1532.0553     2466.4844         -0.2903     0.9563    0.1342</span></span>
<span id="cb928-28"><a href="sec-selection-on-observables.html#cb928-28" tabindex="-1"></a><span class="co">#&gt;            eCDF Max</span></span>
<span id="cb928-29"><a href="sec-selection-on-observables.html#cb928-29" tabindex="-1"></a><span class="co">#&gt; distance     0.6444</span></span>
<span id="cb928-30"><a href="sec-selection-on-observables.html#cb928-30" tabindex="-1"></a><span class="co">#&gt; age          0.1577</span></span>
<span id="cb928-31"><a href="sec-selection-on-observables.html#cb928-31" tabindex="-1"></a><span class="co">#&gt; educ         0.1114</span></span>
<span id="cb928-32"><a href="sec-selection-on-observables.html#cb928-32" tabindex="-1"></a><span class="co">#&gt; raceblack    0.6404</span></span>
<span id="cb928-33"><a href="sec-selection-on-observables.html#cb928-33" tabindex="-1"></a><span class="co">#&gt; racehispan   0.0827</span></span>
<span id="cb928-34"><a href="sec-selection-on-observables.html#cb928-34" tabindex="-1"></a><span class="co">#&gt; racewhite    0.5577</span></span>
<span id="cb928-35"><a href="sec-selection-on-observables.html#cb928-35" tabindex="-1"></a><span class="co">#&gt; married      0.3236</span></span>
<span id="cb928-36"><a href="sec-selection-on-observables.html#cb928-36" tabindex="-1"></a><span class="co">#&gt; nodegree     0.1114</span></span>
<span id="cb928-37"><a href="sec-selection-on-observables.html#cb928-37" tabindex="-1"></a><span class="co">#&gt; re74         0.4470</span></span>
<span id="cb928-38"><a href="sec-selection-on-observables.html#cb928-38" tabindex="-1"></a><span class="co">#&gt; re75         0.2876</span></span>
<span id="cb928-39"><a href="sec-selection-on-observables.html#cb928-39" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb928-40"><a href="sec-selection-on-observables.html#cb928-40" tabindex="-1"></a><span class="co">#&gt; Sample Sizes:</span></span>
<span id="cb928-41"><a href="sec-selection-on-observables.html#cb928-41" tabindex="-1"></a><span class="co">#&gt;           Control Treated</span></span>
<span id="cb928-42"><a href="sec-selection-on-observables.html#cb928-42" tabindex="-1"></a><span class="co">#&gt; All           429     185</span></span>
<span id="cb928-43"><a href="sec-selection-on-observables.html#cb928-43" tabindex="-1"></a><span class="co">#&gt; Matched       429     185</span></span>
<span id="cb928-44"><a href="sec-selection-on-observables.html#cb928-44" tabindex="-1"></a><span class="co">#&gt; Unmatched       0       0</span></span>
<span id="cb928-45"><a href="sec-selection-on-observables.html#cb928-45" tabindex="-1"></a><span class="co">#&gt; Discarded       0       0</span></span></code></pre></div>
<p>This summary provides:</p>
<ul>
<li><p>Standardized mean differences</p></li>
<li><p>Variance ratios</p></li>
<li><p>Propensity score distributions</p></li>
</ul>
<p>These diagnostics help us understand the extent of covariate imbalance.</p>
<hr />
<p><strong>Step 3: Implementing Matching</strong></p>
<ol style="list-style-type: decimal">
<li>Nearest Neighbor Matching (1:1 without Replacement)</li>
</ol>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb929-1"><a href="sec-selection-on-observables.html#cb929-1" tabindex="-1"></a>m.out1 <span class="ot">&lt;-</span> <span class="fu">matchit</span>(</span>
<span id="cb929-2"><a href="sec-selection-on-observables.html#cb929-2" tabindex="-1"></a>  treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb929-3"><a href="sec-selection-on-observables.html#cb929-3" tabindex="-1"></a>  <span class="at">data =</span> MatchIt<span class="sc">::</span>lalonde,</span>
<span id="cb929-4"><a href="sec-selection-on-observables.html#cb929-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;nearest&quot;</span>,</span>
<span id="cb929-5"><a href="sec-selection-on-observables.html#cb929-5" tabindex="-1"></a>  <span class="at">distance =</span> <span class="st">&quot;glm&quot;</span></span>
<span id="cb929-6"><a href="sec-selection-on-observables.html#cb929-6" tabindex="-1"></a>)</span></code></pre></div>
<p>Matching is based on estimated propensity scores. Each treated unit is matched to the closest control unit.</p>
<p>Assess Balance After Matching</p>
<div class="sourceCode" id="cb930"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb930-1"><a href="sec-selection-on-observables.html#cb930-1" tabindex="-1"></a><span class="fu">summary</span>(m.out1, <span class="at">un =</span> <span class="cn">FALSE</span>)  <span class="co"># only show post-matching stats</span></span>
<span id="cb930-2"><a href="sec-selection-on-observables.html#cb930-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb930-3"><a href="sec-selection-on-observables.html#cb930-3" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb930-4"><a href="sec-selection-on-observables.html#cb930-4" tabindex="-1"></a><span class="co">#&gt; matchit(formula = treat ~ age + educ + race + married + nodegree + </span></span>
<span id="cb930-5"><a href="sec-selection-on-observables.html#cb930-5" tabindex="-1"></a><span class="co">#&gt;     re74 + re75, data = MatchIt::lalonde, method = &quot;nearest&quot;, </span></span>
<span id="cb930-6"><a href="sec-selection-on-observables.html#cb930-6" tabindex="-1"></a><span class="co">#&gt;     distance = &quot;glm&quot;)</span></span>
<span id="cb930-7"><a href="sec-selection-on-observables.html#cb930-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb930-8"><a href="sec-selection-on-observables.html#cb930-8" tabindex="-1"></a><span class="co">#&gt; Summary of Balance for Matched Data:</span></span>
<span id="cb930-9"><a href="sec-selection-on-observables.html#cb930-9" tabindex="-1"></a><span class="co">#&gt;            Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span id="cb930-10"><a href="sec-selection-on-observables.html#cb930-10" tabindex="-1"></a><span class="co">#&gt; distance          0.5774        0.3629          0.9739     0.7566    0.1321</span></span>
<span id="cb930-11"><a href="sec-selection-on-observables.html#cb930-11" tabindex="-1"></a><span class="co">#&gt; age              25.8162       25.3027          0.0718     0.4568    0.0847</span></span>
<span id="cb930-12"><a href="sec-selection-on-observables.html#cb930-12" tabindex="-1"></a><span class="co">#&gt; educ             10.3459       10.6054         -0.1290     0.5721    0.0239</span></span>
<span id="cb930-13"><a href="sec-selection-on-observables.html#cb930-13" tabindex="-1"></a><span class="co">#&gt; raceblack         0.8432        0.4703          1.0259          .    0.3730</span></span>
<span id="cb930-14"><a href="sec-selection-on-observables.html#cb930-14" tabindex="-1"></a><span class="co">#&gt; racehispan        0.0595        0.2162         -0.6629          .    0.1568</span></span>
<span id="cb930-15"><a href="sec-selection-on-observables.html#cb930-15" tabindex="-1"></a><span class="co">#&gt; racewhite         0.0973        0.3135         -0.7296          .    0.2162</span></span>
<span id="cb930-16"><a href="sec-selection-on-observables.html#cb930-16" tabindex="-1"></a><span class="co">#&gt; married           0.1892        0.2108         -0.0552          .    0.0216</span></span>
<span id="cb930-17"><a href="sec-selection-on-observables.html#cb930-17" tabindex="-1"></a><span class="co">#&gt; nodegree          0.7081        0.6378          0.1546          .    0.0703</span></span>
<span id="cb930-18"><a href="sec-selection-on-observables.html#cb930-18" tabindex="-1"></a><span class="co">#&gt; re74           2095.5737     2342.1076         -0.0505     1.3289    0.0469</span></span>
<span id="cb930-19"><a href="sec-selection-on-observables.html#cb930-19" tabindex="-1"></a><span class="co">#&gt; re75           1532.0553     1614.7451         -0.0257     1.4956    0.0452</span></span>
<span id="cb930-20"><a href="sec-selection-on-observables.html#cb930-20" tabindex="-1"></a><span class="co">#&gt;            eCDF Max Std. Pair Dist.</span></span>
<span id="cb930-21"><a href="sec-selection-on-observables.html#cb930-21" tabindex="-1"></a><span class="co">#&gt; distance     0.4216          0.9740</span></span>
<span id="cb930-22"><a href="sec-selection-on-observables.html#cb930-22" tabindex="-1"></a><span class="co">#&gt; age          0.2541          1.3938</span></span>
<span id="cb930-23"><a href="sec-selection-on-observables.html#cb930-23" tabindex="-1"></a><span class="co">#&gt; educ         0.0757          1.2474</span></span>
<span id="cb930-24"><a href="sec-selection-on-observables.html#cb930-24" tabindex="-1"></a><span class="co">#&gt; raceblack    0.3730          1.0259</span></span>
<span id="cb930-25"><a href="sec-selection-on-observables.html#cb930-25" tabindex="-1"></a><span class="co">#&gt; racehispan   0.1568          1.0743</span></span>
<span id="cb930-26"><a href="sec-selection-on-observables.html#cb930-26" tabindex="-1"></a><span class="co">#&gt; racewhite    0.2162          0.8390</span></span>
<span id="cb930-27"><a href="sec-selection-on-observables.html#cb930-27" tabindex="-1"></a><span class="co">#&gt; married      0.0216          0.8281</span></span>
<span id="cb930-28"><a href="sec-selection-on-observables.html#cb930-28" tabindex="-1"></a><span class="co">#&gt; nodegree     0.0703          1.0106</span></span>
<span id="cb930-29"><a href="sec-selection-on-observables.html#cb930-29" tabindex="-1"></a><span class="co">#&gt; re74         0.2757          0.7965</span></span>
<span id="cb930-30"><a href="sec-selection-on-observables.html#cb930-30" tabindex="-1"></a><span class="co">#&gt; re75         0.2054          0.7381</span></span>
<span id="cb930-31"><a href="sec-selection-on-observables.html#cb930-31" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb930-32"><a href="sec-selection-on-observables.html#cb930-32" tabindex="-1"></a><span class="co">#&gt; Sample Sizes:</span></span>
<span id="cb930-33"><a href="sec-selection-on-observables.html#cb930-33" tabindex="-1"></a><span class="co">#&gt;           Control Treated</span></span>
<span id="cb930-34"><a href="sec-selection-on-observables.html#cb930-34" tabindex="-1"></a><span class="co">#&gt; All           429     185</span></span>
<span id="cb930-35"><a href="sec-selection-on-observables.html#cb930-35" tabindex="-1"></a><span class="co">#&gt; Matched       185     185</span></span>
<span id="cb930-36"><a href="sec-selection-on-observables.html#cb930-36" tabindex="-1"></a><span class="co">#&gt; Unmatched     244       0</span></span>
<span id="cb930-37"><a href="sec-selection-on-observables.html#cb930-37" tabindex="-1"></a><span class="co">#&gt; Discarded       0       0</span></span>
<span id="cb930-38"><a href="sec-selection-on-observables.html#cb930-38" tabindex="-1"></a></span>
<span id="cb930-39"><a href="sec-selection-on-observables.html#cb930-39" tabindex="-1"></a><span class="co"># Visual diagnostic: jitter plot of propensity scores</span></span>
<span id="cb930-40"><a href="sec-selection-on-observables.html#cb930-40" tabindex="-1"></a><span class="fu">plot</span>(m.out1, <span class="at">type =</span> <span class="st">&quot;jitter&quot;</span>, <span class="at">interactive =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="35-matching-methods_files/figure-html/unnamed-chunk-4-1.png" width="90%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb931-1"><a href="sec-selection-on-observables.html#cb931-1" tabindex="-1"></a></span>
<span id="cb931-2"><a href="sec-selection-on-observables.html#cb931-2" tabindex="-1"></a><span class="co"># QQ plot for individual covariates</span></span>
<span id="cb931-3"><a href="sec-selection-on-observables.html#cb931-3" tabindex="-1"></a><span class="fu">plot</span>(m.out1, <span class="at">type =</span> <span class="st">&quot;qq&quot;</span>, <span class="at">which.xs =</span> <span class="fu">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;re74&quot;</span>))</span></code></pre></div>
<p><img src="35-matching-methods_files/figure-html/unnamed-chunk-4-2.png" width="90%" style="display: block; margin: auto;" /></p>
<p><strong>Interpretation</strong>: Good matches will show overlapping distributions of covariates across groups, and standardized differences should be below 0.1 in absolute value.</p>
<ol start="2" style="list-style-type: decimal">
<li>Full Matching</li>
</ol>
<p>Allows many-to-one or one-to-many matches, minimizing overall distance.</p>
<div class="sourceCode" id="cb932"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb932-1"><a href="sec-selection-on-observables.html#cb932-1" tabindex="-1"></a>m.out2 <span class="ot">&lt;-</span> <span class="fu">matchit</span>(</span>
<span id="cb932-2"><a href="sec-selection-on-observables.html#cb932-2" tabindex="-1"></a>  treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb932-3"><a href="sec-selection-on-observables.html#cb932-3" tabindex="-1"></a>  <span class="at">data =</span> MatchIt<span class="sc">::</span>lalonde,</span>
<span id="cb932-4"><a href="sec-selection-on-observables.html#cb932-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;full&quot;</span>,</span>
<span id="cb932-5"><a href="sec-selection-on-observables.html#cb932-5" tabindex="-1"></a>  <span class="at">distance =</span> <span class="st">&quot;glm&quot;</span>,</span>
<span id="cb932-6"><a href="sec-selection-on-observables.html#cb932-6" tabindex="-1"></a>  <span class="at">link =</span> <span class="st">&quot;probit&quot;</span></span>
<span id="cb932-7"><a href="sec-selection-on-observables.html#cb932-7" tabindex="-1"></a>)</span>
<span id="cb932-8"><a href="sec-selection-on-observables.html#cb932-8" tabindex="-1"></a></span>
<span id="cb932-9"><a href="sec-selection-on-observables.html#cb932-9" tabindex="-1"></a><span class="fu">summary</span>(m.out2, <span class="at">un =</span> <span class="cn">FALSE</span>)</span>
<span id="cb932-10"><a href="sec-selection-on-observables.html#cb932-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb932-11"><a href="sec-selection-on-observables.html#cb932-11" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb932-12"><a href="sec-selection-on-observables.html#cb932-12" tabindex="-1"></a><span class="co">#&gt; matchit(formula = treat ~ age + educ + race + married + nodegree + </span></span>
<span id="cb932-13"><a href="sec-selection-on-observables.html#cb932-13" tabindex="-1"></a><span class="co">#&gt;     re74 + re75, data = MatchIt::lalonde, method = &quot;full&quot;, distance = &quot;glm&quot;, </span></span>
<span id="cb932-14"><a href="sec-selection-on-observables.html#cb932-14" tabindex="-1"></a><span class="co">#&gt;     link = &quot;probit&quot;)</span></span>
<span id="cb932-15"><a href="sec-selection-on-observables.html#cb932-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb932-16"><a href="sec-selection-on-observables.html#cb932-16" tabindex="-1"></a><span class="co">#&gt; Summary of Balance for Matched Data:</span></span>
<span id="cb932-17"><a href="sec-selection-on-observables.html#cb932-17" tabindex="-1"></a><span class="co">#&gt;            Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean</span></span>
<span id="cb932-18"><a href="sec-selection-on-observables.html#cb932-18" tabindex="-1"></a><span class="co">#&gt; distance          0.5773        0.5764          0.0045     0.9949    0.0043</span></span>
<span id="cb932-19"><a href="sec-selection-on-observables.html#cb932-19" tabindex="-1"></a><span class="co">#&gt; age              25.8162       25.5347          0.0393     0.4790    0.0787</span></span>
<span id="cb932-20"><a href="sec-selection-on-observables.html#cb932-20" tabindex="-1"></a><span class="co">#&gt; educ             10.3459       10.5381         -0.0956     0.6192    0.0253</span></span>
<span id="cb932-21"><a href="sec-selection-on-observables.html#cb932-21" tabindex="-1"></a><span class="co">#&gt; raceblack         0.8432        0.8389          0.0119          .    0.0043</span></span>
<span id="cb932-22"><a href="sec-selection-on-observables.html#cb932-22" tabindex="-1"></a><span class="co">#&gt; racehispan        0.0595        0.0492          0.0435          .    0.0103</span></span>
<span id="cb932-23"><a href="sec-selection-on-observables.html#cb932-23" tabindex="-1"></a><span class="co">#&gt; racewhite         0.0973        0.1119         -0.0493          .    0.0146</span></span>
<span id="cb932-24"><a href="sec-selection-on-observables.html#cb932-24" tabindex="-1"></a><span class="co">#&gt; married           0.1892        0.1633          0.0660          .    0.0259</span></span>
<span id="cb932-25"><a href="sec-selection-on-observables.html#cb932-25" tabindex="-1"></a><span class="co">#&gt; nodegree          0.7081        0.6577          0.1110          .    0.0504</span></span>
<span id="cb932-26"><a href="sec-selection-on-observables.html#cb932-26" tabindex="-1"></a><span class="co">#&gt; re74           2095.5737     2100.2150         -0.0009     1.3467    0.0314</span></span>
<span id="cb932-27"><a href="sec-selection-on-observables.html#cb932-27" tabindex="-1"></a><span class="co">#&gt; re75           1532.0553     1561.4420         -0.0091     1.5906    0.0536</span></span>
<span id="cb932-28"><a href="sec-selection-on-observables.html#cb932-28" tabindex="-1"></a><span class="co">#&gt;            eCDF Max Std. Pair Dist.</span></span>
<span id="cb932-29"><a href="sec-selection-on-observables.html#cb932-29" tabindex="-1"></a><span class="co">#&gt; distance     0.0486          0.0198</span></span>
<span id="cb932-30"><a href="sec-selection-on-observables.html#cb932-30" tabindex="-1"></a><span class="co">#&gt; age          0.2742          1.2843</span></span>
<span id="cb932-31"><a href="sec-selection-on-observables.html#cb932-31" tabindex="-1"></a><span class="co">#&gt; educ         0.0730          1.2179</span></span>
<span id="cb932-32"><a href="sec-selection-on-observables.html#cb932-32" tabindex="-1"></a><span class="co">#&gt; raceblack    0.0043          0.0162</span></span>
<span id="cb932-33"><a href="sec-selection-on-observables.html#cb932-33" tabindex="-1"></a><span class="co">#&gt; racehispan   0.0103          0.4412</span></span>
<span id="cb932-34"><a href="sec-selection-on-observables.html#cb932-34" tabindex="-1"></a><span class="co">#&gt; racewhite    0.0146          0.3454</span></span>
<span id="cb932-35"><a href="sec-selection-on-observables.html#cb932-35" tabindex="-1"></a><span class="co">#&gt; married      0.0259          0.4473</span></span>
<span id="cb932-36"><a href="sec-selection-on-observables.html#cb932-36" tabindex="-1"></a><span class="co">#&gt; nodegree     0.0504          0.9872</span></span>
<span id="cb932-37"><a href="sec-selection-on-observables.html#cb932-37" tabindex="-1"></a><span class="co">#&gt; re74         0.1881          0.8387</span></span>
<span id="cb932-38"><a href="sec-selection-on-observables.html#cb932-38" tabindex="-1"></a><span class="co">#&gt; re75         0.1984          0.8240</span></span>
<span id="cb932-39"><a href="sec-selection-on-observables.html#cb932-39" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb932-40"><a href="sec-selection-on-observables.html#cb932-40" tabindex="-1"></a><span class="co">#&gt; Sample Sizes:</span></span>
<span id="cb932-41"><a href="sec-selection-on-observables.html#cb932-41" tabindex="-1"></a><span class="co">#&gt;               Control Treated</span></span>
<span id="cb932-42"><a href="sec-selection-on-observables.html#cb932-42" tabindex="-1"></a><span class="co">#&gt; All            429.       185</span></span>
<span id="cb932-43"><a href="sec-selection-on-observables.html#cb932-43" tabindex="-1"></a><span class="co">#&gt; Matched (ESS)   50.76     185</span></span>
<span id="cb932-44"><a href="sec-selection-on-observables.html#cb932-44" tabindex="-1"></a><span class="co">#&gt; Matched        429.       185</span></span>
<span id="cb932-45"><a href="sec-selection-on-observables.html#cb932-45" tabindex="-1"></a><span class="co">#&gt; Unmatched        0.         0</span></span>
<span id="cb932-46"><a href="sec-selection-on-observables.html#cb932-46" tabindex="-1"></a><span class="co">#&gt; Discarded        0.         0</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Exact Matching</li>
</ol>
<p>Only matches units with exactly the same covariate values (usually categorical):</p>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb933-1"><a href="sec-selection-on-observables.html#cb933-1" tabindex="-1"></a>m.out3 <span class="ot">&lt;-</span> <span class="fu">matchit</span>(</span>
<span id="cb933-2"><a href="sec-selection-on-observables.html#cb933-2" tabindex="-1"></a>  treat <span class="sc">~</span> race <span class="sc">+</span> nodegree,</span>
<span id="cb933-3"><a href="sec-selection-on-observables.html#cb933-3" tabindex="-1"></a>  <span class="at">data =</span> MatchIt<span class="sc">::</span>lalonde,</span>
<span id="cb933-4"><a href="sec-selection-on-observables.html#cb933-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;exact&quot;</span></span>
<span id="cb933-5"><a href="sec-selection-on-observables.html#cb933-5" tabindex="-1"></a>)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Optimal Matching</li>
</ol>
<p>Minimizes the total distance between matched units across the sample.</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb934-1"><a href="sec-selection-on-observables.html#cb934-1" tabindex="-1"></a>m.out4 <span class="ot">&lt;-</span> <span class="fu">matchit</span>(</span>
<span id="cb934-2"><a href="sec-selection-on-observables.html#cb934-2" tabindex="-1"></a>  treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb934-3"><a href="sec-selection-on-observables.html#cb934-3" tabindex="-1"></a>  <span class="at">data =</span> MatchIt<span class="sc">::</span>lalonde,</span>
<span id="cb934-4"><a href="sec-selection-on-observables.html#cb934-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;optimal&quot;</span>,</span>
<span id="cb934-5"><a href="sec-selection-on-observables.html#cb934-5" tabindex="-1"></a>  <span class="at">ratio =</span> <span class="dv">2</span></span>
<span id="cb934-6"><a href="sec-selection-on-observables.html#cb934-6" tabindex="-1"></a>)</span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li>Genetic Matching</li>
</ol>
<p>Searches over weights assigned to covariates to optimize balance.</p>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb935-1"><a href="sec-selection-on-observables.html#cb935-1" tabindex="-1"></a>m.out5 <span class="ot">&lt;-</span> <span class="fu">matchit</span>(</span>
<span id="cb935-2"><a href="sec-selection-on-observables.html#cb935-2" tabindex="-1"></a>  treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb935-3"><a href="sec-selection-on-observables.html#cb935-3" tabindex="-1"></a>  <span class="at">data =</span> MatchIt<span class="sc">::</span>lalonde,</span>
<span id="cb935-4"><a href="sec-selection-on-observables.html#cb935-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;genetic&quot;</span></span>
<span id="cb935-5"><a href="sec-selection-on-observables.html#cb935-5" tabindex="-1"></a>)</span></code></pre></div>
<hr />
<p><strong>Step 4: Estimating Treatment Effects</strong></p>
<p>Once matching is complete, we use the matched data to estimate treatment effects.</p>
<div class="sourceCode" id="cb936"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb936-1"><a href="sec-selection-on-observables.html#cb936-1" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb936-2"><a href="sec-selection-on-observables.html#cb936-2" tabindex="-1"></a><span class="fu">library</span>(sandwich)</span>
<span id="cb936-3"><a href="sec-selection-on-observables.html#cb936-3" tabindex="-1"></a></span>
<span id="cb936-4"><a href="sec-selection-on-observables.html#cb936-4" tabindex="-1"></a><span class="co"># Extract matched data</span></span>
<span id="cb936-5"><a href="sec-selection-on-observables.html#cb936-5" tabindex="-1"></a>matched_data <span class="ot">&lt;-</span> <span class="fu">match.data</span>(m.out1)</span>
<span id="cb936-6"><a href="sec-selection-on-observables.html#cb936-6" tabindex="-1"></a></span>
<span id="cb936-7"><a href="sec-selection-on-observables.html#cb936-7" tabindex="-1"></a><span class="co"># Estimate ATT with robust standard errors</span></span>
<span id="cb936-8"><a href="sec-selection-on-observables.html#cb936-8" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(re78 <span class="sc">~</span> treat <span class="sc">+</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb936-9"><a href="sec-selection-on-observables.html#cb936-9" tabindex="-1"></a>            <span class="at">data =</span> matched_data,</span>
<span id="cb936-10"><a href="sec-selection-on-observables.html#cb936-10" tabindex="-1"></a>            <span class="at">weights =</span> weights)</span>
<span id="cb936-11"><a href="sec-selection-on-observables.html#cb936-11" tabindex="-1"></a></span>
<span id="cb936-12"><a href="sec-selection-on-observables.html#cb936-12" tabindex="-1"></a><span class="fu">coeftest</span>(model, <span class="at">vcov. =</span> vcovCL, <span class="at">cluster =</span> <span class="sc">~</span>subclass)</span>
<span id="cb936-13"><a href="sec-selection-on-observables.html#cb936-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb936-14"><a href="sec-selection-on-observables.html#cb936-14" tabindex="-1"></a><span class="co">#&gt; t test of coefficients:</span></span>
<span id="cb936-15"><a href="sec-selection-on-observables.html#cb936-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb936-16"><a href="sec-selection-on-observables.html#cb936-16" tabindex="-1"></a><span class="co">#&gt;                Estimate  Std. Error t value Pr(&gt;|t|)   </span></span>
<span id="cb936-17"><a href="sec-selection-on-observables.html#cb936-17" tabindex="-1"></a><span class="co">#&gt; (Intercept) -437.664937 1912.759171 -0.2288 0.819143   </span></span>
<span id="cb936-18"><a href="sec-selection-on-observables.html#cb936-18" tabindex="-1"></a><span class="co">#&gt; treat       1398.134870  723.745751  1.9318 0.054164 . </span></span>
<span id="cb936-19"><a href="sec-selection-on-observables.html#cb936-19" tabindex="-1"></a><span class="co">#&gt; age           -0.343085   39.256789 -0.0087 0.993032   </span></span>
<span id="cb936-20"><a href="sec-selection-on-observables.html#cb936-20" tabindex="-1"></a><span class="co">#&gt; educ         470.767350  147.892765  3.1832 0.001583 **</span></span>
<span id="cb936-21"><a href="sec-selection-on-observables.html#cb936-21" tabindex="-1"></a><span class="co">#&gt; racehispan  1518.303924 1035.083141  1.4668 0.143287   </span></span>
<span id="cb936-22"><a href="sec-selection-on-observables.html#cb936-22" tabindex="-1"></a><span class="co">#&gt; racewhite    557.295853  897.121013  0.6212 0.534856   </span></span>
<span id="cb936-23"><a href="sec-selection-on-observables.html#cb936-23" tabindex="-1"></a><span class="co">#&gt; re74           0.017244    0.166298  0.1037 0.917470   </span></span>
<span id="cb936-24"><a href="sec-selection-on-observables.html#cb936-24" tabindex="-1"></a><span class="co">#&gt; re75           0.226076    0.165722  1.3642 0.173357   </span></span>
<span id="cb936-25"><a href="sec-selection-on-observables.html#cb936-25" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb936-26"><a href="sec-selection-on-observables.html#cb936-26" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>The coefficient on <code>treat</code> is our estimate of the ATT. The weights and subclass clustering account for the matched design.</p>
</div>
<div id="reporting-standards" class="section level3 hasAnchor" number="35.9.2">
<h3><span class="header-section-number">35.9.2</span> Reporting Standards<a href="sec-selection-on-observables.html#reporting-standards" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To ensure transparency and reproducibility, always report the following:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Matching method</strong> (e.g., nearest neighbor, genetic)</p></li>
<li><p><strong>Distance metric</strong> (e.g., propensity score via logistic regression)</p></li>
<li><p><strong>Covariates matched on</strong> and justification for their inclusion</p></li>
<li><p><strong>Balance statistics</strong> (e.g., standardized mean differences before/after)</p></li>
<li><p><strong>Sample sizes</strong>: total, matched, unmatched, discarded</p></li>
<li><p><strong>Estimation model</strong>: whether treatment effects are estimated using regression adjustment, with or without weights</p></li>
<li><p><strong>Assumptions</strong>: especially unconfoundedness and overlap</p></li>
</ol>
<hr />
</div>
<div id="optimization-based-matching-via-designmatch" class="section level3 hasAnchor" number="35.9.3">
<h3><span class="header-section-number">35.9.3</span> Optimization-Based Matching via <code>designmatch</code><a href="sec-selection-on-observables.html#optimization-based-matching-via-designmatch" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For more advanced applications, the <code>designmatch</code> package provides matching methods based on combinatorial optimization.</p>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb937-1"><a href="sec-selection-on-observables.html#cb937-1" tabindex="-1"></a><span class="fu">library</span>(designmatch)</span></code></pre></div>
<p>Notable methods:</p>
<ul>
<li><p><code>distmatch()</code>: Distance-based matching with custom constraints</p></li>
<li><p><code>bmatch()</code>: Bipartite matching using linear programming</p></li>
<li><p><code>cardmatch()</code>: Cardinality matching for maximum matched sample size with balance constraints</p></li>
<li><p><code>profmatch()</code>: Profile matching for stratified treatment allocation</p></li>
<li><p><code>nmatch()</code>: Non-bipartite matching (e.g., in interference settings)</p></li>
</ul>
<hr />
</div>
<div id="matchingfrontier" class="section level3 hasAnchor" number="35.9.4">
<h3><span class="header-section-number">35.9.4</span> MatchingFrontier<a href="sec-selection-on-observables.html#matchingfrontier" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As mentioned in <code>MatchIt</code>, you have to make trade-off (also known as bias-variance trade-off) between balance and sample size. An automated procedure to optimize this trade-off is implemented in <code>MatchingFrontier</code> <span class="citation">(<a href="#ref-king2017balance">G. King, Lucas, and Nielsen 2017</a>)</span>, which solves this joint optimization problem.</p>
<p>Following <code>MatchingFrontier</code> <a href="https://projects.iq.harvard.edu/files/frontier/files/using_matchingfrontier.pdf">guide</a></p>
<div class="sourceCode" id="cb938"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb938-1"><a href="sec-selection-on-observables.html#cb938-1" tabindex="-1"></a><span class="co"># library(devtools)</span></span>
<span id="cb938-2"><a href="sec-selection-on-observables.html#cb938-2" tabindex="-1"></a><span class="co"># install_github(&#39;ChristopherLucas/MatchingFrontier&#39;)</span></span>
<span id="cb938-3"><a href="sec-selection-on-observables.html#cb938-3" tabindex="-1"></a><span class="fu">library</span>(MatchingFrontier)</span>
<span id="cb938-4"><a href="sec-selection-on-observables.html#cb938-4" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="at">package =</span> <span class="st">&quot;MatchIt&quot;</span>)</span>
<span id="cb938-5"><a href="sec-selection-on-observables.html#cb938-5" tabindex="-1"></a><span class="co"># choose var to match on</span></span>
<span id="cb938-6"><a href="sec-selection-on-observables.html#cb938-6" tabindex="-1"></a>match.on <span class="ot">&lt;-</span></span>
<span id="cb938-7"><a href="sec-selection-on-observables.html#cb938-7" tabindex="-1"></a>    <span class="fu">colnames</span>(lalonde)[<span class="sc">!</span>(<span class="fu">colnames</span>(lalonde) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&#39;re78&#39;</span>, <span class="st">&#39;treat&#39;</span>))]</span>
<span id="cb938-8"><a href="sec-selection-on-observables.html#cb938-8" tabindex="-1"></a>match.on</span>
<span id="cb938-9"><a href="sec-selection-on-observables.html#cb938-9" tabindex="-1"></a></span>
<span id="cb938-10"><a href="sec-selection-on-observables.html#cb938-10" tabindex="-1"></a><span class="co"># Mahanlanobis frontier (default)</span></span>
<span id="cb938-11"><a href="sec-selection-on-observables.html#cb938-11" tabindex="-1"></a>mahal.frontier <span class="ot">&lt;-</span></span>
<span id="cb938-12"><a href="sec-selection-on-observables.html#cb938-12" tabindex="-1"></a>    <span class="fu">makeFrontier</span>(</span>
<span id="cb938-13"><a href="sec-selection-on-observables.html#cb938-13" tabindex="-1"></a>        <span class="at">dataset =</span> lalonde,</span>
<span id="cb938-14"><a href="sec-selection-on-observables.html#cb938-14" tabindex="-1"></a>        <span class="at">treatment =</span> <span class="st">&quot;treat&quot;</span>,</span>
<span id="cb938-15"><a href="sec-selection-on-observables.html#cb938-15" tabindex="-1"></a>        <span class="at">match.on =</span> match.on</span>
<span id="cb938-16"><a href="sec-selection-on-observables.html#cb938-16" tabindex="-1"></a>    )</span>
<span id="cb938-17"><a href="sec-selection-on-observables.html#cb938-17" tabindex="-1"></a>mahal.frontier</span>
<span id="cb938-18"><a href="sec-selection-on-observables.html#cb938-18" tabindex="-1"></a></span>
<span id="cb938-19"><a href="sec-selection-on-observables.html#cb938-19" tabindex="-1"></a><span class="co"># L1 frontier</span></span>
<span id="cb938-20"><a href="sec-selection-on-observables.html#cb938-20" tabindex="-1"></a>L1.frontier <span class="ot">&lt;-</span></span>
<span id="cb938-21"><a href="sec-selection-on-observables.html#cb938-21" tabindex="-1"></a>    <span class="fu">makeFrontier</span>(</span>
<span id="cb938-22"><a href="sec-selection-on-observables.html#cb938-22" tabindex="-1"></a>        <span class="at">dataset =</span> lalonde,</span>
<span id="cb938-23"><a href="sec-selection-on-observables.html#cb938-23" tabindex="-1"></a>        <span class="at">treatment =</span> <span class="st">&#39;treat&#39;</span>,</span>
<span id="cb938-24"><a href="sec-selection-on-observables.html#cb938-24" tabindex="-1"></a>        <span class="at">match.on =</span> match.on,</span>
<span id="cb938-25"><a href="sec-selection-on-observables.html#cb938-25" tabindex="-1"></a>        <span class="at">QOI =</span> <span class="st">&#39;SATT&#39;</span>,</span>
<span id="cb938-26"><a href="sec-selection-on-observables.html#cb938-26" tabindex="-1"></a>        <span class="at">metric =</span> <span class="st">&#39;L1&#39;</span>,</span>
<span id="cb938-27"><a href="sec-selection-on-observables.html#cb938-27" tabindex="-1"></a>        <span class="at">ratio =</span> <span class="st">&#39;fixed&#39;</span></span>
<span id="cb938-28"><a href="sec-selection-on-observables.html#cb938-28" tabindex="-1"></a>    )</span>
<span id="cb938-29"><a href="sec-selection-on-observables.html#cb938-29" tabindex="-1"></a>L1.frontier</span>
<span id="cb938-30"><a href="sec-selection-on-observables.html#cb938-30" tabindex="-1"></a></span>
<span id="cb938-31"><a href="sec-selection-on-observables.html#cb938-31" tabindex="-1"></a><span class="co"># estimate effects along the frontier</span></span>
<span id="cb938-32"><a href="sec-selection-on-observables.html#cb938-32" tabindex="-1"></a></span>
<span id="cb938-33"><a href="sec-selection-on-observables.html#cb938-33" tabindex="-1"></a><span class="co"># Set base form</span></span>
<span id="cb938-34"><a href="sec-selection-on-observables.html#cb938-34" tabindex="-1"></a>my.form <span class="ot">&lt;-</span></span>
<span id="cb938-35"><a href="sec-selection-on-observables.html#cb938-35" tabindex="-1"></a>    <span class="fu">as.formula</span>(re78 <span class="sc">~</span> treat <span class="sc">+</span> age <span class="sc">+</span> black <span class="sc">+</span> education </span>
<span id="cb938-36"><a href="sec-selection-on-observables.html#cb938-36" tabindex="-1"></a>               <span class="sc">+</span> hispanic <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75)</span>
<span id="cb938-37"><a href="sec-selection-on-observables.html#cb938-37" tabindex="-1"></a></span>
<span id="cb938-38"><a href="sec-selection-on-observables.html#cb938-38" tabindex="-1"></a><span class="co"># Estimate effects for the mahalanobis frontier</span></span>
<span id="cb938-39"><a href="sec-selection-on-observables.html#cb938-39" tabindex="-1"></a>mahal.estimates <span class="ot">&lt;-</span></span>
<span id="cb938-40"><a href="sec-selection-on-observables.html#cb938-40" tabindex="-1"></a>    <span class="fu">estimateEffects</span>(</span>
<span id="cb938-41"><a href="sec-selection-on-observables.html#cb938-41" tabindex="-1"></a>        mahal.frontier,</span>
<span id="cb938-42"><a href="sec-selection-on-observables.html#cb938-42" tabindex="-1"></a>        <span class="st">&#39;re78 ~ treat&#39;</span>,</span>
<span id="cb938-43"><a href="sec-selection-on-observables.html#cb938-43" tabindex="-1"></a>        <span class="at">mod.dependence.formula =</span> my.form,</span>
<span id="cb938-44"><a href="sec-selection-on-observables.html#cb938-44" tabindex="-1"></a>        <span class="at">continuous.vars =</span> <span class="fu">c</span>(<span class="st">&#39;age&#39;</span>, <span class="st">&#39;education&#39;</span>, <span class="st">&#39;re74&#39;</span>, <span class="st">&#39;re75&#39;</span>),</span>
<span id="cb938-45"><a href="sec-selection-on-observables.html#cb938-45" tabindex="-1"></a>        <span class="at">prop.estimated =</span> .<span class="dv">1</span>,</span>
<span id="cb938-46"><a href="sec-selection-on-observables.html#cb938-46" tabindex="-1"></a>        <span class="at">means.as.cutpoints =</span> <span class="cn">TRUE</span></span>
<span id="cb938-47"><a href="sec-selection-on-observables.html#cb938-47" tabindex="-1"></a>    )</span>
<span id="cb938-48"><a href="sec-selection-on-observables.html#cb938-48" tabindex="-1"></a></span>
<span id="cb938-49"><a href="sec-selection-on-observables.html#cb938-49" tabindex="-1"></a><span class="co"># Estimate effects for the L1 frontier</span></span>
<span id="cb938-50"><a href="sec-selection-on-observables.html#cb938-50" tabindex="-1"></a>L1.estimates <span class="ot">&lt;-</span></span>
<span id="cb938-51"><a href="sec-selection-on-observables.html#cb938-51" tabindex="-1"></a>    <span class="fu">estimateEffects</span>(</span>
<span id="cb938-52"><a href="sec-selection-on-observables.html#cb938-52" tabindex="-1"></a>        L1.frontier,</span>
<span id="cb938-53"><a href="sec-selection-on-observables.html#cb938-53" tabindex="-1"></a>        <span class="st">&#39;re78 ~ treat&#39;</span>,</span>
<span id="cb938-54"><a href="sec-selection-on-observables.html#cb938-54" tabindex="-1"></a>        <span class="at">mod.dependence.formula =</span> my.form,</span>
<span id="cb938-55"><a href="sec-selection-on-observables.html#cb938-55" tabindex="-1"></a>        <span class="at">continuous.vars =</span> <span class="fu">c</span>(<span class="st">&#39;age&#39;</span>, <span class="st">&#39;education&#39;</span>, <span class="st">&#39;re74&#39;</span>, <span class="st">&#39;re75&#39;</span>),</span>
<span id="cb938-56"><a href="sec-selection-on-observables.html#cb938-56" tabindex="-1"></a>        <span class="at">prop.estimated =</span> .<span class="dv">1</span>,</span>
<span id="cb938-57"><a href="sec-selection-on-observables.html#cb938-57" tabindex="-1"></a>        <span class="at">means.as.cutpoints =</span> <span class="cn">TRUE</span></span>
<span id="cb938-58"><a href="sec-selection-on-observables.html#cb938-58" tabindex="-1"></a>    )</span>
<span id="cb938-59"><a href="sec-selection-on-observables.html#cb938-59" tabindex="-1"></a></span>
<span id="cb938-60"><a href="sec-selection-on-observables.html#cb938-60" tabindex="-1"></a><span class="co"># Plot covariates means </span></span>
<span id="cb938-61"><a href="sec-selection-on-observables.html#cb938-61" tabindex="-1"></a><span class="co"># plotPrunedMeans()</span></span>
<span id="cb938-62"><a href="sec-selection-on-observables.html#cb938-62" tabindex="-1"></a></span>
<span id="cb938-63"><a href="sec-selection-on-observables.html#cb938-63" tabindex="-1"></a></span>
<span id="cb938-64"><a href="sec-selection-on-observables.html#cb938-64" tabindex="-1"></a><span class="co"># Plot estimates (deprecated)</span></span>
<span id="cb938-65"><a href="sec-selection-on-observables.html#cb938-65" tabindex="-1"></a><span class="co"># plotEstimates(</span></span>
<span id="cb938-66"><a href="sec-selection-on-observables.html#cb938-66" tabindex="-1"></a><span class="co">#     L1.estimates,</span></span>
<span id="cb938-67"><a href="sec-selection-on-observables.html#cb938-67" tabindex="-1"></a><span class="co">#     ylim = c(-10000, 3000),</span></span>
<span id="cb938-68"><a href="sec-selection-on-observables.html#cb938-68" tabindex="-1"></a><span class="co">#     cex.lab = 1.4,</span></span>
<span id="cb938-69"><a href="sec-selection-on-observables.html#cb938-69" tabindex="-1"></a><span class="co">#     cex.axis = 1.4,</span></span>
<span id="cb938-70"><a href="sec-selection-on-observables.html#cb938-70" tabindex="-1"></a><span class="co">#     panel.first = grid(NULL, NULL, lwd = 2,)</span></span>
<span id="cb938-71"><a href="sec-selection-on-observables.html#cb938-71" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb938-72"><a href="sec-selection-on-observables.html#cb938-72" tabindex="-1"></a></span>
<span id="cb938-73"><a href="sec-selection-on-observables.html#cb938-73" tabindex="-1"></a><span class="co"># Plot estimates</span></span>
<span id="cb938-74"><a href="sec-selection-on-observables.html#cb938-74" tabindex="-1"></a><span class="fu">plotMeans</span>(L1.frontier)</span>
<span id="cb938-75"><a href="sec-selection-on-observables.html#cb938-75" tabindex="-1"></a></span>
<span id="cb938-76"><a href="sec-selection-on-observables.html#cb938-76" tabindex="-1"></a></span>
<span id="cb938-77"><a href="sec-selection-on-observables.html#cb938-77" tabindex="-1"></a><span class="co"># parallel plot</span></span>
<span id="cb938-78"><a href="sec-selection-on-observables.html#cb938-78" tabindex="-1"></a><span class="fu">parallelPlot</span>(</span>
<span id="cb938-79"><a href="sec-selection-on-observables.html#cb938-79" tabindex="-1"></a>    L1.frontier,</span>
<span id="cb938-80"><a href="sec-selection-on-observables.html#cb938-80" tabindex="-1"></a>    <span class="at">N =</span> <span class="dv">400</span>,</span>
<span id="cb938-81"><a href="sec-selection-on-observables.html#cb938-81" tabindex="-1"></a>    <span class="at">variables =</span> <span class="fu">c</span>(<span class="st">&#39;age&#39;</span>, <span class="st">&#39;re74&#39;</span>, <span class="st">&#39;re75&#39;</span>, <span class="st">&#39;black&#39;</span>),</span>
<span id="cb938-82"><a href="sec-selection-on-observables.html#cb938-82" tabindex="-1"></a>    <span class="at">treated.col =</span> <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb938-83"><a href="sec-selection-on-observables.html#cb938-83" tabindex="-1"></a>    <span class="at">control.col =</span> <span class="st">&#39;gray&#39;</span></span>
<span id="cb938-84"><a href="sec-selection-on-observables.html#cb938-84" tabindex="-1"></a>)</span>
<span id="cb938-85"><a href="sec-selection-on-observables.html#cb938-85" tabindex="-1"></a></span>
<span id="cb938-86"><a href="sec-selection-on-observables.html#cb938-86" tabindex="-1"></a><span class="co"># export matched dataset</span></span>
<span id="cb938-87"><a href="sec-selection-on-observables.html#cb938-87" tabindex="-1"></a><span class="co"># take 400 units</span></span>
<span id="cb938-88"><a href="sec-selection-on-observables.html#cb938-88" tabindex="-1"></a>matched.data <span class="ot">&lt;-</span> <span class="fu">generateDataset</span>(L1.frontier, <span class="at">N =</span> <span class="dv">400</span>) </span></code></pre></div>
<hr />
</div>
<div id="sec-propensity-scores" class="section level3 hasAnchor" number="35.9.5">
<h3><span class="header-section-number">35.9.5</span> Propensity Scores<a href="sec-selection-on-observables.html#sec-propensity-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Propensity score methods are widely used for estimating causal effects in observational studies, where random assignment to treatment and control groups is not feasible. The core idea is to mimic a randomized experiment by adjusting for confounding variables that predict treatment assignment. Formally, the <strong>propensity score</strong> is defined as the probability of assignment to treatment conditional on observed covariates <span class="citation">(<a href="#ref-rosenbaum1983central">Rosenbaum and Rubin 1983</a>, <a href="#ref-rosenbaum1985bias">1985</a>)</span>:</p>
<p><span class="math display">\[
e_i(X_i) = P(T_i = 1 \mid X_i)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(T_i \in \{0, 1\}\)</span> is the binary treatment indicator for unit <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(X_i\)</span> is a vector of observed pre-treatment covariates for unit <span class="math inline">\(i\)</span>.</li>
</ul>
<p>The key insight from <span class="citation">Rosenbaum and Rubin (<a href="#ref-rosenbaum1983central">1983</a>)</span> is that conditioning on the propensity score is sufficient to remove bias due to confounding from observed covariates, under certain assumptions.</p>
<hr />
<div id="assumptions-for-identification-1" class="section level4 hasAnchor" number="35.9.5.1">
<h4><span class="header-section-number">35.9.5.1</span> Assumptions for Identification<a href="sec-selection-on-observables.html#assumptions-for-identification-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To identify causal effects using propensity scores, the following assumptions must hold:</p>
<ul>
<li><strong>Unconfoundedness / Conditional Independence Assumption (CIA):</strong></li>
</ul>
<p><span class="math display">\[
(Y_i(0), Y_i(1)) \perp T_i \mid X_i
\]</span></p>
<ul>
<li><strong>Positivity (Overlap):</strong></li>
</ul>
<p><span class="math display">\[
0 &lt; P(T_i = 1 \mid X_i) &lt; 1 \quad \text{for all } i
\]</span></p>
<p>These assumptions ensure that for each unit, we can observe comparable treated and untreated units in the sample. Violations of positivity, especially in high-dimensional covariate spaces, are a critical weakness of propensity score matching.</p>
<hr />
</div>
<div id="why-psm-is-not-recommended-anymore" class="section level4 hasAnchor" number="35.9.5.2">
<h4><span class="header-section-number">35.9.5.2</span> Why PSM Is Not Recommended Anymore<a href="sec-selection-on-observables.html#why-psm-is-not-recommended-anymore" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Despite its intuitive appeal, recent literature has strongly cautioned against using propensity score matching for causal inference <span class="citation">(<a href="#ref-king2019propensity">G. King and Nielsen 2019</a>)</span>. The main criticisms are as follows:</p>
<ul>
<li><strong>Imbalance</strong>: PSM often fails to achieve covariate balance better than simpler techniques like covariate adjustment via regression or exact matching. Matching on the propensity score is a <em>scalar reduction</em> of a multivariate distribution, and this reduction can distort multivariate relationships.</li>
<li><strong>Inefficiency</strong>: Discarding unmatched units reduces statistical efficiency, especially when better estimators (e.g., inverse probability weighting or doubly robust estimators) can use all data.</li>
<li><strong>Model dependence</strong>: Small changes in the specification of the propensity score model can lead to large changes in matches and estimated treatment effects.</li>
<li><strong>Bias</strong>: Poor matches and irrelevant covariates can introduce additional bias rather than reduce it.</li>
</ul>
<p><span class="citation">Abadie and Imbens (<a href="#ref-abadie2016matching">2016</a>)</span> show that the asymptotic distribution of treatment effect estimators is sensitive to the estimation of the propensity score itself:</p>
<ul>
<li>The estimated propensity score can improve efficiency over using the true propensity score when estimating the <a href="types-of-treatment-effects.html#sec-average-treatment-effect">ATE</a>. Formally, the adjustment to the asymptotic variance is non-positive.</li>
<li>However, for the <a href="types-of-treatment-effects.html#sec-average-treatment-effect-on-the-treated">ATT</a>, the sign of the adjustment is data-dependent. Estimation error in the propensity score can lead to misestimated confidence intervals: they may be too wide or too narrow.</li>
</ul>
<p>This result suggests that even in large samples, failure to account for the estimation uncertainty in the propensity score can produce misleading inference.</p>
<p>A fundamental flaw in PSM is the <strong>asymmetry of match quality</strong>:</p>
<ul>
<li>If <span class="math inline">\(X_c = X_t\)</span>, then it must be that <span class="math inline">\(e(X_c) = e(X_t)\)</span>.</li>
<li>However, the converse <strong>does not hold</strong>:<br />
<span class="math inline">\(e(X_c) = e(X_t) \nRightarrow X_c = X_t\)</span></li>
</ul>
<p>Therefore, two units with identical propensity scores may still differ substantially in covariate space. This undermines the matching goal of achieving similarity across all covariates.</p>
<hr />
</div>
<div id="estimating-the-propensity-score" class="section level4 hasAnchor" number="35.9.5.3">
<h4><span class="header-section-number">35.9.5.3</span> Estimating the Propensity Score<a href="sec-selection-on-observables.html#estimating-the-propensity-score" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Estimation of the propensity score is typically carried out using:</p>
<ul>
<li><strong>Parametric models</strong>:
<ul>
<li>Logistic regression:<br />
<span class="math display">\[
\hat{e}_i = \frac{1}{1 + \exp(-X_i^\top \hat{\beta})}
\]</span></li>
</ul></li>
<li><strong>Nonparametric / machine learning methods</strong>:
<ul>
<li>Generalized Boosted Models (GBM)</li>
<li>Boosted Classification and Regression Trees (CART)</li>
<li>Random forests or Bayesian Additive Regression Trees (BART)</li>
</ul></li>
</ul>
<p>These machine learning approaches often yield better balance due to flexible functional forms, but they also complicate interpretation and inference.</p>
<hr />
</div>
<div id="matching-algorithms" class="section level4 hasAnchor" number="35.9.5.4">
<h4><span class="header-section-number">35.9.5.4</span> Matching Algorithms<a href="sec-selection-on-observables.html#matching-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Reduce</strong> the high-dimensional vector <span class="math inline">\(X_i\)</span> to the scalar <span class="math inline">\(\hat{e}_i\)</span>.</li>
<li><strong>Calculate distances</strong> between treated and control units based on <span class="math inline">\(\hat{e}_i\)</span>: <span class="math display">\[
d(i, j) = |\hat{e}_i - \hat{e}_j|
\]</span></li>
<li><strong>Match</strong> each treated unit <span class="math inline">\(i\)</span> to the control unit <span class="math inline">\(j\)</span> with the closest propensity score.</li>
<li><strong>Prune</strong>:
<ul>
<li>Control units not used in any match are discarded.</li>
<li>Matches exceeding a caliper (maximum distance threshold) are also discarded.</li>
</ul></li>
<li><strong>No replacement</strong> is typically assumed ‚Äî each control unit is matched at most once.</li>
</ol>
<p>Let <span class="math inline">\(c &gt; 0\)</span> be a caliper. Then a treated unit <span class="math inline">\(i\)</span> is matched to control unit <span class="math inline">\(j\)</span> only if:</p>
<p><span class="math display">\[
|\hat{e}_i - \hat{e}_j| &lt; c
\]</span></p>
<p>Caliper matching helps reduce poor matches, but may result in <em>random pruning</em>, further reducing balance and efficiency.</p>
<hr />
</div>
<div id="practical-recommendations" class="section level4 hasAnchor" number="35.9.5.5">
<h4><span class="header-section-number">35.9.5.5</span> Practical Recommendations<a href="sec-selection-on-observables.html#practical-recommendations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Do not include irrelevant covariates</strong>: Including variables that are unrelated to the outcome can increase the variability of the estimated propensity score and reduce matching quality.</li>
<li><strong>Avoid instrumental variables</strong> <span class="citation">(<a href="#ref-bhattacharya2007instrumental">Bhattacharya and Vogt 2007</a>)</span>: Including IVs in the propensity score model can <strong>inflate bias</strong> by introducing variation in treatment assignment unrelated to potential outcomes.</li>
<li>Focus on <strong>covariates that are confounders</strong>, i.e., those that affect both treatment and outcome.</li>
</ul>
<p>What remains <strong>after pruning</strong> is more consequential than the initial covariate set. Matching can discard a large portion of the sample, which distorts representativeness and increases variance.</p>
<hr />
</div>
<div id="diagnostics-and-evaluation" class="section level4 hasAnchor" number="35.9.5.6">
<h4><span class="header-section-number">35.9.5.6</span> Diagnostics and Evaluation<a href="sec-selection-on-observables.html#diagnostics-and-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>After matching, the primary diagnostic tool is covariate balance. Key diagnostics include:</p>
<ul>
<li><strong>Standardized mean differences (SMD)</strong> between treatment groups before and after matching</li>
<li><strong>Variance ratios</strong></li>
<li><strong>Visual inspection</strong> via Love plots or density plots</li>
</ul>
<p>Statistical model fit criteria (e.g., AIC, BIC, c-statistics) are <strong>not valid</strong> for evaluating propensity score models, since the goal is <em>not prediction</em>, but achieving balance.</p>
<p>There is <strong>no need to worry about collinearity</strong> in the covariates when estimating propensity scores ‚Äî unlike in outcome regression models, where multicollinearity can inflate standard errors.</p>
<hr />
</div>
<div id="applications-in-business-and-finance" class="section level4 hasAnchor" number="35.9.5.7">
<h4><span class="header-section-number">35.9.5.7</span> Applications in Business and Finance<a href="sec-selection-on-observables.html#applications-in-business-and-finance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Propensity score methods have been used in empirical finance and marketing, though increasingly replaced by more robust approaches. One illustrative application is found in <span class="citation">Hirtle, Kovner, and Plosser (<a href="#ref-hirtle2020impact">2020</a>)</span>, which investigates the causal effect of regulatory bank supervision on firm-level outcomes:</p>
<ul>
<li><strong>Treatment</strong>: Degree of supervisory attention.</li>
<li><strong>Outcomes</strong>: Loan risk, profitability, volatility, and firm growth.</li>
<li><strong>Method</strong>: Propensity score matching to construct treated and control groups of banks with comparable observed characteristics.</li>
</ul>
<p>Their matched sample analysis reveals that <strong>intensified supervision</strong> leads to:</p>
<ul>
<li>Lower risk (more conservative loan portfolios)</li>
<li>Reduced volatility</li>
<li>No significant loss in profitability or growth</li>
</ul>
<hr />
</div>
<div id="conclusion-1" class="section level4 hasAnchor" number="35.9.5.8">
<h4><span class="header-section-number">35.9.5.8</span> Conclusion<a href="sec-selection-on-observables.html#conclusion-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>While the theoretical motivation behind propensity scores remains sound, their application via naive matching methods is no longer considered best practice. The statistical community increasingly favors alternatives such as:</p>
<ul>
<li><strong>Covariate adjustment via regression</strong></li>
<li><strong>Inverse probability weighting (IPW)</strong></li>
<li><strong>Doubly robust estimators</strong></li>
<li><strong>Targeted Maximum Likelihood Estimation (TMLE)</strong></li>
</ul>
<p>These approaches better utilize the full dataset, yield more efficient estimators, and offer more transparent diagnostics. Matching on estimated propensity scores may still be useful for illustration or sensitivity analysis, but should not be the primary method for causal inference in applied research.</p>
<hr />
</div>
<div id="look-ahead-propensity-score-matching" class="section level4 hasAnchor" number="35.9.5.9">
<h4><span class="header-section-number">35.9.5.9</span> Look-Ahead Propensity Score Matching<a href="sec-selection-on-observables.html#look-ahead-propensity-score-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In observational data, estimating <strong>causal effects</strong> is complicated by <strong>self-selection bias</strong>: individuals who receive a treatment may differ systematically from those who do not. Standard <strong>PSM</strong> methods attempt to control for such biases by matching treated and untreated units on observable characteristics.</p>
<p>However, when <strong>unobservable</strong> or <strong>latent traits</strong> influence both treatment assignment and outcomes, traditional PSM may produce biased estimates. <span class="citation">Bapna, Ramaprasad, and Umyarov (<a href="#ref-bapna2018monetizing">2018</a>)</span> introduce <strong>Look-Ahead Propensity Score Matching (LA-PSM)</strong>, a novel technique that leverages <strong>future behavior</strong> to correct for <strong>time-invariant unobserved confounding</strong>, particularly useful in rare-event economic decisions.</p>
<p>In the study of <span class="citation">Bapna, Ramaprasad, and Umyarov (<a href="#ref-bapna2018monetizing">2018</a>)</span>:</p>
<ul>
<li>Treatment: user pays for a premium subscription.</li>
<li>Outcome: social engagement (songs listened, playlists created, friends made).</li>
<li>Problem: users choosing to subscribe are systematically different (e.g., more engaged).</li>
</ul>
<p><strong>LA-PSM Implementation:</strong></p>
<ul>
<li><p>Treated group: users subscribing between Sept 2011 - June 2012.</p></li>
<li><p>Control group: users who will subscribe later (June 2012 - Jan 2015).</p></li>
<li><p>Matching on: observed demographics, past behavior.</p></li>
<li><p>Analysis: <a href="sec-difference-in-differences.html#sec-difference-in-differences">Difference-in-Differences</a> estimation.</p></li>
</ul>
<p><strong>Results:</strong> Premium adoption increases:</p>
<ul>
<li>Songs listened: +287.2%</li>
<li>Playlists created: +1.92%</li>
<li>Forum posts: +2.01%</li>
<li>Friends added: +15.77%</li>
</ul>
<hr />
<p>In standard PSM:</p>
<ul>
<li>Match individuals who received treatment with individuals who did not, based on observed covariates.</li>
<li>Assume selection into treatment is <strong>strongly ignorable</strong>, conditional on covariates.</li>
</ul>
<p>Problem:</p>
<ul>
<li><p>Unobserved factors (e.g., ambition, risk tolerance) may bias both treatment and outcome.</p></li>
<li><p>Standard PSM cannot correct for this.</p></li>
</ul>
<p><strong>Solution: Look-Ahead PSM</strong></p>
<ul>
<li><p>Match treated units with <strong>future-treated</strong> units: those who haven‚Äôt yet received treatment but will in the future.</p></li>
<li><p>Future-treated units share unobservable traits with current-treated units.</p></li>
</ul>
<p>Thus, LA-PSM controls for <strong>time-invariant unobserved confounders</strong>.</p>
<hr />
<p>Let:</p>
<ul>
<li><p><span class="math inline">\(i \in \{1, \ldots, N\}\)</span> index individuals.</p></li>
<li><p><span class="math inline">\(D_i(t)\)</span> = 1 if individual <span class="math inline">\(i\)</span> is treated at time <span class="math inline">\(t\)</span>, 0 otherwise.</p></li>
<li><p><span class="math inline">\(X_i\)</span> = observed covariates.</p></li>
<li><p><span class="math inline">\(U_i\)</span> = unobserved time-invariant confounders.</p></li>
<li><p><span class="math inline">\(Y_i(t)\)</span> = outcome at time <span class="math inline">\(t\)</span>.</p></li>
</ul>
<p>In standard PSM:</p>
<ul>
<li>Match on <span class="math inline">\(\mathbb{P}(D_i(t) = 1 \mid X_i)\)</span>.</li>
</ul>
<p>In LA-PSM:</p>
<ul>
<li><p>Match <strong>current treated</strong> individuals with <strong>future treated</strong> individuals based on: <span class="math display">\[ \mathbb{P}(D_i(t) = 1 \mid X_i) \]</span></p></li>
<li><p>and require: <span class="math display">\[ \exists \, s &gt; t \quad \text{such that} \quad D_i(s) = 1 \]</span></p></li>
</ul>
<p>Formally, define:</p>
<ul>
<li><p>Treatment group: <span class="math display">\[ T = \{ i \mid D_i(t) = 1 \} \]</span></p></li>
<li><p>Control group: <span class="math display">\[ C = \{ j \mid D_j(t) = 0 \quad \text{and} \quad \exists \, s&gt;t : D_j(s) = 1 \} \]</span></p></li>
</ul>
<p>Thus, both treatment and control groups are ‚Äúeventual adopters,‚Äù just at different times.</p>
<hr />
<p><strong>Proposition:</strong><br />
If <span class="math inline">\(U_i\)</span> is <strong>time-invariant</strong> and <strong>affects both treatment assignment and outcomes</strong>, then LA-PSM produces unbiased causal estimates under weaker assumptions than standard PSM.</p>
<ol style="list-style-type: decimal">
<li>In regular PSM, matching on <span class="math inline">\(X_i\)</span> cannot adjust for <span class="math inline">\(U_i\)</span>.</li>
<li>In LA-PSM, by restricting controls to <strong>future adopters</strong>, we select units that share latent traits <span class="math inline">\(U_i\)</span> driving adoption.</li>
<li>Thus, <span class="math inline">\(U_i\)</span> is balanced across treatment and control, eliminating bias from <span class="math inline">\(U_i\)</span>.</li>
<li>Remaining bias is due only to differences in <span class="math inline">\(X_i\)</span>, which are adjusted for via matching.</li>
</ol>
<hr />
<p><strong>Practical Implementation Steps</strong></p>
<ol style="list-style-type: decimal">
<li>In <strong>Static Look-Ahead PSM</strong>, we:</li>
</ol>
<ul>
<li>Fix a single matching window at a given time <span class="math inline">\(t\)</span>.</li>
<li>Define:
<ul>
<li><strong>Treatment Group</strong>: Individuals who receive treatment at time <span class="math inline">\(t\)</span>.</li>
<li><strong>Control Group</strong>: Individuals who are not yet treated at <span class="math inline">\(t\)</span> but will receive treatment at a later time <span class="math inline">\(t&#39;&gt;t\)</span>.</li>
</ul></li>
<li>Estimate propensity scores based only on observed covariates <span class="math inline">\(X\)</span>.</li>
<li>Match treated and (future-treated) control units based on their propensity scores.</li>
</ul>
<p>This ensures treated and control individuals have similar observed <span class="math inline">\(X\)</span> and similar unobserved <span class="math inline">\(U\)</span>, assuming <span class="math inline">\(U\)</span> is time-invariant.</p>
<p>How to implement Static LA-PSM:</p>
<ol style="list-style-type: decimal">
<li>Identify individuals <strong>treated now</strong> (treatment group) and <strong>future adopters</strong> (control group).</li>
<li>Estimate propensity scores <span class="math inline">\(\mathbb{P}(D=1 \mid X)\)</span>.</li>
<li>Match treated and control units using nearest-neighbor matching.</li>
<li>Estimate treatment effects via a regression on the matched sample.</li>
</ol>
<p><strong>Important:</strong></p>
<ul>
<li><p>Drop individuals who are never treated from the analysis.</p></li>
<li><p>Only compare current-treated and future-treated!</p></li>
</ul>
<hr />
<ol start="2" style="list-style-type: decimal">
<li>In <strong>Dynamic Look-Ahead PSM</strong>, we:</li>
</ol>
<ul>
<li>Allow time to move forward (<span class="math inline">\(t=1,2,3,\dots\)</span>).</li>
<li>At each time <span class="math inline">\(t\)</span>:
<ul>
<li>Define treated individuals (those who receive treatment at <span class="math inline">\(t\)</span>).</li>
<li>Define control individuals (those untreated at <span class="math inline">\(t\)</span> but who will adopt later).</li>
</ul></li>
<li>Repeat matching separately for each <span class="math inline">\(t\)</span>.</li>
<li>Aggregate results across different <span class="math inline">\(t\)</span> periods to estimate the overall effect.</li>
</ul>
<p>Dynamic LA-PSM is more flexible:</p>
<ul>
<li><p>It updates control groups over time.</p></li>
<li><p>Better handles situations where treatment adoption spreads gradually over time.</p></li>
</ul>
<p>How to implement Dynamic LA-PSM:</p>
<ol style="list-style-type: decimal">
<li>For each time period <span class="math inline">\(t\)</span>:
<ul>
<li>Define treated-now = individuals treated at <span class="math inline">\(t\)</span>.</li>
<li>Define control = individuals untreated at <span class="math inline">\(t\)</span> but who adopt later.</li>
</ul></li>
<li>Estimate propensity scores <span class="math inline">\(\mathbb{P}(D=1 \mid X)\)</span> within that time window.</li>
<li>Match treated and controls at each <span class="math inline">\(t\)</span> separately.</li>
<li>Pool matched samples from all <span class="math inline">\(t\)</span> together.</li>
<li>Estimate treatment effects using the pooled sample.</li>
</ol>
<p><strong>Important:</strong></p>
<ul>
<li><p>Keep track of time ‚Äî matching is done separately each period.</p></li>
<li><p>Aggregate the treatment effect estimates carefully (either by averaging or pooling matched data).</p></li>
</ul>
<hr />
<table>
<colgroup>
<col width="20%" />
<col width="36%" />
<col width="44%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Feature</th>
<th align="left">Static Look-Ahead PSM</th>
<th align="left">Dynamic Look-Ahead PSM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Matching Window</td>
<td align="left">Single, fixed window (e.g., <span class="math inline">\(t=5\)</span>)</td>
<td align="left">Rolling window at each time <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td align="left">Treated Group</td>
<td align="left">Treated at <span class="math inline">\(t\)</span></td>
<td align="left">Treated at <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td align="left">Control Group</td>
<td align="left">Future treated (after <span class="math inline">\(t\)</span>)</td>
<td align="left">Future treated relative to each <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td align="left">Updates over time?</td>
<td align="left">No</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">Suitable for</td>
<td align="left">Simple adoption settings</td>
<td align="left">Gradual adoption / time-sensitive settings</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Challenge:</strong><br />
Simulate your own dataset with hidden confounding and implement both Static and Dynamic Look-Ahead PSM.<br />
Compare bias against Standard PSM and Randomized Assignment.</p>
</blockquote>
<hr />
</div>
</div>
<div id="sec-mahalanobis" class="section level3 hasAnchor" number="35.9.6">
<h3><span class="header-section-number">35.9.6</span> Mahalanobis Distance Matching<a href="sec-selection-on-observables.html#sec-mahalanobis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mahalanobis Distance Matching is a method for matching units in observational studies based on the <strong>multivariate similarity</strong> of covariates. Unlike propensity score matching, which reduces the covariate space to a single scalar, Mahalanobis distance operates in the full multivariate space. As a result, Mahalanobis matching can be interpreted as approximating a <strong>fully blocked design</strong>, where each treated unit is paired with a control unit that has nearly identical covariate values.</p>
<ul>
<li>In the ideal case: <span class="math inline">\(X_t = X_c\)</span>, implying a perfect match.</li>
<li>In practice, Mahalanobis distance allows for ‚Äúnear-exact‚Äù matches in high-dimensional space.</li>
</ul>
<p>Because it preserves the multivariate structure of the covariates, Mahalanobis matching more faithfully emulates randomization within <strong>covariate strata</strong>, making it more robust to specification error than propensity score matching.</p>
<p>This method is particularly appealing when the number of covariates is relatively small and when these covariates are continuous and well-measured.</p>
<hr />
<p>Given a set of <span class="math inline">\(p\)</span> covariates <span class="math inline">\(X_i \in \mathbb{R}^p\)</span> for unit <span class="math inline">\(i\)</span>, the <strong>Mahalanobis distance</strong> between a treated unit <span class="math inline">\(t\)</span> and a control unit <span class="math inline">\(c\)</span> is defined as:</p>
<p><span class="math display">\[
D_M(X_t, X_c) = \sqrt{(X_t - X_c)^\top S^{-1}(X_t - X_c)}
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_c\)</span> are the <span class="math inline">\(p\)</span>-dimensional vectors of covariates for treated and control units, respectively,</li>
<li><span class="math inline">\(S\)</span> is the sample covariance matrix of the covariates across all units (treated and control),</li>
<li><span class="math inline">\(S^{-1}\)</span> serves to standardize and decorrelate the covariate space, accounting for both scale and correlation among covariates.</li>
</ul>
<hr />
<p><strong>Why Not Use Euclidean Distance?</strong></p>
<p>The Euclidean distance:</p>
<p><span class="math display">\[
D_E(X_t, X_c) = \sqrt{(X_t - X_c)^\top (X_t - X_c)}
\]</span></p>
<p>does <strong>not adjust for different variances</strong> among covariates or for <strong>correlation</strong> between them. Mahalanobis distance corrects for this by incorporating the inverse covariance matrix <span class="math inline">\(S^{-1}\)</span>, effectively transforming the data to a space where the covariates are <strong>standardized and orthogonal</strong>.</p>
<p>This makes the Mahalanobis distance <strong>scale-invariant</strong>, i.e., invariant under affine transformations of the data, which is essential when matching on variables of different units (e.g., income in dollars and age in years).</p>
<hr />
<div id="mahalanobis-matching-algorithm" class="section level4 hasAnchor" number="35.9.6.1">
<h4><span class="header-section-number">35.9.6.1</span> Mahalanobis Matching Algorithm<a href="sec-selection-on-observables.html#mahalanobis-matching-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let <span class="math inline">\(\mathcal{T}\)</span> be the set of treated units and <span class="math inline">\(\mathcal{C}\)</span> the set of control units. The procedure for Mahalanobis matching can be described as follows:</p>
<ol style="list-style-type: decimal">
<li><strong>Compute the covariance matrix</strong> <span class="math inline">\(S\)</span> of the covariates <span class="math inline">\(X\)</span> across all units.</li>
<li><strong>For each treated unit</strong> <span class="math inline">\(i \in \mathcal{T}\)</span>, compute <span class="math inline">\(D_M(X_i, X_j)\)</span> for all <span class="math inline">\(j \in \mathcal{C}\)</span>.</li>
<li><strong>Match</strong> treated unit <span class="math inline">\(i\)</span> to the control unit <span class="math inline">\(j\)</span> with the smallest Mahalanobis distance.</li>
<li><strong>Prune</strong>:
<ul>
<li>Control units not used in any match are discarded.</li>
<li>Matches where <span class="math inline">\(D_M &gt; \delta\)</span> (a caliper threshold) are also discarded.</li>
</ul></li>
</ol>
<p>A caliper <span class="math inline">\(\delta\)</span> is used to enforce a maximum allowable distance. That is, a match is made between <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> only if:</p>
<p><span class="math display">\[
D_M(X_i, X_j) &lt; \delta
\]</span></p>
<p>This prevents poor-quality matches and helps ensure that treated and control units are meaningfully similar. If no match falls within the caliper for a given treated unit, that unit is left unmatched, and potentially discarded from the analysis.</p>
<hr />
</div>
<div id="properties" class="section level4 hasAnchor" number="35.9.6.2">
<h4><span class="header-section-number">35.9.6.2</span> Properties<a href="sec-selection-on-observables.html#properties" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Scale-invariant</strong>: Standardizes variables using <span class="math inline">\(S^{-1}\)</span>, ensuring that variables with large scales do not dominate the distance metric.</li>
<li><strong>Correlation-adjusted</strong>: Accounts for linear relationships among covariates, which is critical in multivariate contexts.</li>
<li><strong>Non-parametric</strong>: No model for treatment assignment is estimated; purely based on observed covariates.</li>
</ul>
<hr />
</div>
<div id="limitations" class="section level4 hasAnchor" number="35.9.6.3">
<h4><span class="header-section-number">35.9.6.3</span> Limitations<a href="sec-selection-on-observables.html#limitations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Sensitive to multicollinearity</strong>: If the covariates are highly collinear, the covariance matrix <span class="math inline">\(S\)</span> may be nearly singular, making <span class="math inline">\(S^{-1}\)</span> unstable or non-invertible. Regularization techniques may be required.</li>
<li><strong>Not suitable for high-dimensional covariate spaces</strong>: As <span class="math inline">\(p\)</span> increases, exact or even near-exact matches become harder to find. Dimensionality reduction techniques (e.g., PCA) may help.</li>
<li><strong>Inefficient with categorical variables</strong>: Since Mahalanobis distance is based on continuous covariates and assumes multivariate normality (implicitly), it‚Äôs less effective when most covariates are categorical or binary.</li>
</ul>
<hr />
</div>
<div id="hybrid-approaches" class="section level4 hasAnchor" number="35.9.6.4">
<h4><span class="header-section-number">35.9.6.4</span> Hybrid Approaches<a href="sec-selection-on-observables.html#hybrid-approaches" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Mahalanobis matching can be <strong>combined with propensity scores</strong> for improved performance:</p>
<ul>
<li><strong>Within propensity score calipers</strong>: Match using Mahalanobis distance only within groups of units that fall within a specified caliper of each other in propensity score space.</li>
<li><strong>Stratified matching</strong>: Divide the sample into strata based on propensity scores and apply Mahalanobis matching within each stratum.</li>
</ul>
<p>These hybrid methods aim to preserve the robustness of Mahalanobis matching while mitigating its weaknesses in high dimensions.</p>
<hr />
</div>
<div id="practical-considerations-7" class="section level4 hasAnchor" number="35.9.6.5">
<h4><span class="header-section-number">35.9.6.5</span> Practical Considerations<a href="sec-selection-on-observables.html#practical-considerations-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Estimate <span class="math inline">\(S\)</span> from the pooled sample (treated + control) to ensure consistency.</li>
<li>Standardize all covariates before applying Mahalanobis distance to ensure comparability and numerical stability.</li>
<li>Use diagnostic plots (e.g., QQ plots or multivariate distance histograms) to assess match quality.</li>
</ul>
<hr />
</div>
</div>
<div id="sec-cem" class="section level3 hasAnchor" number="35.9.7">
<h3><span class="header-section-number">35.9.7</span> Coarsened Exact Matching (CEM)<a href="sec-selection-on-observables.html#sec-cem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Coarsened Exact Matching (CEM) is a <strong>monotonic imbalance bounding</strong> matching method designed to improve covariate balance between treated and control units in observational studies. CEM operates by <strong>coarsening</strong> continuous or high-cardinality covariates into discrete bins and then applying <strong>exact matching</strong> on this coarsened space. The result is a non-parametric method that prioritizes covariate balance and robustness over modeling assumptions.</p>
<p>Introduced and formalized in <span class="citation">Iacus, King, and Porro (<a href="#ref-iacus2012causal">2012</a>)</span>, CEM is well-suited for causal inference when covariates are noisy or when traditional modeling-based approaches (e.g., propensity scores) are unstable or hard to interpret.</p>
<hr />
<p>The central idea is to <strong>discretize covariates</strong> into meaningful bins (either automatically or manually), then sort observations into <strong>strata</strong> or subclasses based on the <strong>unique combinations</strong> of these binned covariate values. Exact matching is applied within each stratum.</p>
<p>Let <span class="math inline">\(X_i \in \mathbb{R}^p\)</span> be the <span class="math inline">\(p\)</span>-dimensional covariate vector for unit <span class="math inline">\(i\)</span>. Define <span class="math inline">\(C(X_i)\)</span> to be a coarsened version of <span class="math inline">\(X_i\)</span>, where:</p>
<ul>
<li>Continuous variables are binned into intervals (e.g., age 20‚Äì29, 30‚Äì39, etc.)</li>
<li>Categorical variables may be grouped (e.g., Likert scales aggregated into fewer categories)</li>
</ul>
<p>Then, matching proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>Temporarily coarsen the covariate space <span class="math inline">\(X \to C(X)\)</span>.</li>
<li>Sort observations into strata defined by unique values of <span class="math inline">\(C(X)\)</span>.</li>
<li>Prune any stratum that contains only treated or only control units.</li>
<li>Retain all original (uncoarsened) units in matched strata for analysis.</li>
</ol>
<p>This process produces a matched sample in which each stratum includes at least one treated and one control unit, improving internal validity by design.</p>
<p>As with other matching methods, CEM requires the <strong>ignorability assumption</strong> (also known as unconfoundedness or selection on observables):</p>
<p><span class="math display">\[ (Y_i(0), Y_i(1)) \perp T_i \mid X_i \]</span></p>
<p>Under this assumption and sufficient overlap in the coarsened strata, CEM yields unbiased estimates of causal effects within the matched sample.</p>
<hr />
<div id="mathematical-properties" class="section level4 hasAnchor" number="35.9.7.1">
<h4><span class="header-section-number">35.9.7.1</span> Mathematical Properties<a href="sec-selection-on-observables.html#mathematical-properties" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Monotonic Imbalance Bounding</strong></li>
</ol>
<p>CEM is a Monotonic Imbalance Bounding method, meaning that the user can pre-specify the maximum level of imbalance allowed on each covariate. The imbalance measure is guaranteed to be weakly decreasing as coarsening becomes finer. This provides:</p>
<ul>
<li><strong>Transparency</strong>: The imbalance tradeoff is determined <em>ex ante</em> by the user.</li>
<li><strong>Control</strong>: Users can make a direct decision about how much imbalance is tolerable.</li>
</ul>
<p>Formally, let <span class="math inline">\(\mathcal{L}(C(X))\)</span> denote a measure of imbalance under coarsened covariates. Then, for any refinements of <span class="math inline">\(C(X)\)</span>:</p>
<p><span class="math display">\[
\text{if } C_1(X) \preceq C_2(X), \text{ then } \mathcal{L}(C_1(X)) \leq \mathcal{L}(C_2(X))
\]</span></p>
<p>That is, finer coarsenings (more bins) cannot increase imbalance.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Congruence Principle</strong></li>
</ol>
<p>CEM respects the congruence principle, which asserts that analysis should not be more precise than the data allow. By coarsening, CEM protects against overfitting and artificial precision, especially when measurement error is present.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Robustness</strong></li>
</ol>
<ul>
<li><strong>Robust to measurement error</strong>: Discretization makes matching less sensitive to noise in covariates.</li>
<li><strong>Works with missing data</strong>: The <code>cem</code> R package supports partial handling of missingness.</li>
<li><strong>Multiple imputation</strong>: CEM can be applied within imputation routines to preserve matching structure across imputed datasets.</li>
<li><strong>Supports multi-valued treatments</strong>: Matching can be extended to treatments beyond binary <span class="math inline">\(T \in \{0, 1\}\)</span>.</li>
</ul>
<hr />
<ol style="list-style-type: decimal">
<li>Load and Prepare Data</li>
</ol>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb939-1"><a href="sec-selection-on-observables.html#cb939-1" tabindex="-1"></a><span class="fu">library</span>(cem)</span>
<span id="cb939-2"><a href="sec-selection-on-observables.html#cb939-2" tabindex="-1"></a><span class="fu">data</span>(LeLonde)</span>
<span id="cb939-3"><a href="sec-selection-on-observables.html#cb939-3" tabindex="-1"></a></span>
<span id="cb939-4"><a href="sec-selection-on-observables.html#cb939-4" tabindex="-1"></a><span class="co"># Remove missing values</span></span>
<span id="cb939-5"><a href="sec-selection-on-observables.html#cb939-5" tabindex="-1"></a>Le <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(LeLonde)</span>
<span id="cb939-6"><a href="sec-selection-on-observables.html#cb939-6" tabindex="-1"></a></span>
<span id="cb939-7"><a href="sec-selection-on-observables.html#cb939-7" tabindex="-1"></a><span class="co"># Treatment and control indices</span></span>
<span id="cb939-8"><a href="sec-selection-on-observables.html#cb939-8" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="fu">which</span>(Le<span class="sc">$</span>treated <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb939-9"><a href="sec-selection-on-observables.html#cb939-9" tabindex="-1"></a>ct <span class="ot">&lt;-</span> <span class="fu">which</span>(Le<span class="sc">$</span>treated <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb939-10"><a href="sec-selection-on-observables.html#cb939-10" tabindex="-1"></a>ntr <span class="ot">&lt;-</span> <span class="fu">length</span>(tr)</span>
<span id="cb939-11"><a href="sec-selection-on-observables.html#cb939-11" tabindex="-1"></a>nct <span class="ot">&lt;-</span> <span class="fu">length</span>(ct)</span>
<span id="cb939-12"><a href="sec-selection-on-observables.html#cb939-12" tabindex="-1"></a></span>
<span id="cb939-13"><a href="sec-selection-on-observables.html#cb939-13" tabindex="-1"></a><span class="co"># Unadjusted bias (na√Øve difference in means)</span></span>
<span id="cb939-14"><a href="sec-selection-on-observables.html#cb939-14" tabindex="-1"></a><span class="fu">mean</span>(Le<span class="sc">$</span>re78[tr]) <span class="sc">-</span> <span class="fu">mean</span>(Le<span class="sc">$</span>re78[ct])</span>
<span id="cb939-15"><a href="sec-selection-on-observables.html#cb939-15" tabindex="-1"></a><span class="co">#&gt; [1] 759.0479</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Define Pre-Treatment Covariates</li>
</ol>
<div class="sourceCode" id="cb940"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb940-1"><a href="sec-selection-on-observables.html#cb940-1" tabindex="-1"></a>vars <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb940-2"><a href="sec-selection-on-observables.html#cb940-2" tabindex="-1"></a>    <span class="st">&quot;age&quot;</span>, <span class="st">&quot;education&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="st">&quot;married&quot;</span>, <span class="st">&quot;nodegree&quot;</span>,</span>
<span id="cb940-3"><a href="sec-selection-on-observables.html#cb940-3" tabindex="-1"></a>    <span class="st">&quot;re74&quot;</span>, <span class="st">&quot;re75&quot;</span>, <span class="st">&quot;hispanic&quot;</span>, <span class="st">&quot;u74&quot;</span>, <span class="st">&quot;u75&quot;</span>, <span class="st">&quot;q1&quot;</span></span>
<span id="cb940-4"><a href="sec-selection-on-observables.html#cb940-4" tabindex="-1"></a>)</span>
<span id="cb940-5"><a href="sec-selection-on-observables.html#cb940-5" tabindex="-1"></a></span>
<span id="cb940-6"><a href="sec-selection-on-observables.html#cb940-6" tabindex="-1"></a><span class="co"># Pre-treatment imbalance</span></span>
<span id="cb940-7"><a href="sec-selection-on-observables.html#cb940-7" tabindex="-1"></a><span class="fu">imbalance</span>(<span class="at">group =</span> Le<span class="sc">$</span>treated, <span class="at">data =</span> Le[vars]) <span class="co"># L1 imbalance = 0.902</span></span>
<span id="cb940-8"><a href="sec-selection-on-observables.html#cb940-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb940-9"><a href="sec-selection-on-observables.html#cb940-9" tabindex="-1"></a><span class="co">#&gt; Multivariate Imbalance Measure: L1=0.902</span></span>
<span id="cb940-10"><a href="sec-selection-on-observables.html#cb940-10" tabindex="-1"></a><span class="co">#&gt; Percentage of local common support: LCS=5.8%</span></span>
<span id="cb940-11"><a href="sec-selection-on-observables.html#cb940-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb940-12"><a href="sec-selection-on-observables.html#cb940-12" tabindex="-1"></a><span class="co">#&gt; Univariate Imbalance Measures:</span></span>
<span id="cb940-13"><a href="sec-selection-on-observables.html#cb940-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb940-14"><a href="sec-selection-on-observables.html#cb940-14" tabindex="-1"></a><span class="co">#&gt;               statistic   type           L1 min 25%      50%       75%</span></span>
<span id="cb940-15"><a href="sec-selection-on-observables.html#cb940-15" tabindex="-1"></a><span class="co">#&gt; age        -0.252373042 (diff) 5.102041e-03   0   0   0.0000   -1.0000</span></span>
<span id="cb940-16"><a href="sec-selection-on-observables.html#cb940-16" tabindex="-1"></a><span class="co">#&gt; education   0.153634710 (diff) 8.463851e-02   1   0   1.0000    1.0000</span></span>
<span id="cb940-17"><a href="sec-selection-on-observables.html#cb940-17" tabindex="-1"></a><span class="co">#&gt; black      -0.010322734 (diff) 1.032273e-02   0   0   0.0000    0.0000</span></span>
<span id="cb940-18"><a href="sec-selection-on-observables.html#cb940-18" tabindex="-1"></a><span class="co">#&gt; married    -0.009551495 (diff) 9.551495e-03   0   0   0.0000    0.0000</span></span>
<span id="cb940-19"><a href="sec-selection-on-observables.html#cb940-19" tabindex="-1"></a><span class="co">#&gt; nodegree   -0.081217371 (diff) 8.121737e-02   0  -1   0.0000    0.0000</span></span>
<span id="cb940-20"><a href="sec-selection-on-observables.html#cb940-20" tabindex="-1"></a><span class="co">#&gt; re74      -18.160446880 (diff) 5.551115e-17   0   0 284.0715  806.3452</span></span>
<span id="cb940-21"><a href="sec-selection-on-observables.html#cb940-21" tabindex="-1"></a><span class="co">#&gt; re75      101.501761679 (diff) 5.551115e-17   0   0 485.6310 1238.4114</span></span>
<span id="cb940-22"><a href="sec-selection-on-observables.html#cb940-22" tabindex="-1"></a><span class="co">#&gt; hispanic   -0.010144756 (diff) 1.014476e-02   0   0   0.0000    0.0000</span></span>
<span id="cb940-23"><a href="sec-selection-on-observables.html#cb940-23" tabindex="-1"></a><span class="co">#&gt; u74        -0.045582186 (diff) 4.558219e-02   0   0   0.0000    0.0000</span></span>
<span id="cb940-24"><a href="sec-selection-on-observables.html#cb940-24" tabindex="-1"></a><span class="co">#&gt; u75        -0.065555292 (diff) 6.555529e-02   0   0   0.0000    0.0000</span></span>
<span id="cb940-25"><a href="sec-selection-on-observables.html#cb940-25" tabindex="-1"></a><span class="co">#&gt; q1          7.494021189 (Chi2) 1.067078e-01  NA  NA       NA        NA</span></span>
<span id="cb940-26"><a href="sec-selection-on-observables.html#cb940-26" tabindex="-1"></a><span class="co">#&gt;                  max</span></span>
<span id="cb940-27"><a href="sec-selection-on-observables.html#cb940-27" tabindex="-1"></a><span class="co">#&gt; age          -6.0000</span></span>
<span id="cb940-28"><a href="sec-selection-on-observables.html#cb940-28" tabindex="-1"></a><span class="co">#&gt; education     1.0000</span></span>
<span id="cb940-29"><a href="sec-selection-on-observables.html#cb940-29" tabindex="-1"></a><span class="co">#&gt; black         0.0000</span></span>
<span id="cb940-30"><a href="sec-selection-on-observables.html#cb940-30" tabindex="-1"></a><span class="co">#&gt; married       0.0000</span></span>
<span id="cb940-31"><a href="sec-selection-on-observables.html#cb940-31" tabindex="-1"></a><span class="co">#&gt; nodegree      0.0000</span></span>
<span id="cb940-32"><a href="sec-selection-on-observables.html#cb940-32" tabindex="-1"></a><span class="co">#&gt; re74      -2139.0195</span></span>
<span id="cb940-33"><a href="sec-selection-on-observables.html#cb940-33" tabindex="-1"></a><span class="co">#&gt; re75        490.3945</span></span>
<span id="cb940-34"><a href="sec-selection-on-observables.html#cb940-34" tabindex="-1"></a><span class="co">#&gt; hispanic      0.0000</span></span>
<span id="cb940-35"><a href="sec-selection-on-observables.html#cb940-35" tabindex="-1"></a><span class="co">#&gt; u74           0.0000</span></span>
<span id="cb940-36"><a href="sec-selection-on-observables.html#cb940-36" tabindex="-1"></a><span class="co">#&gt; u75           0.0000</span></span>
<span id="cb940-37"><a href="sec-selection-on-observables.html#cb940-37" tabindex="-1"></a><span class="co">#&gt; q1                NA</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Automatically Coarsen and Match</li>
</ol>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb941-1"><a href="sec-selection-on-observables.html#cb941-1" tabindex="-1"></a>mat <span class="ot">&lt;-</span> <span class="fu">cem</span>(</span>
<span id="cb941-2"><a href="sec-selection-on-observables.html#cb941-2" tabindex="-1"></a>    <span class="at">treatment =</span> <span class="st">&quot;treated&quot;</span>,</span>
<span id="cb941-3"><a href="sec-selection-on-observables.html#cb941-3" tabindex="-1"></a>    <span class="at">data =</span> Le,</span>
<span id="cb941-4"><a href="sec-selection-on-observables.html#cb941-4" tabindex="-1"></a>    <span class="at">drop =</span> <span class="st">&quot;re78&quot;</span>,     <span class="co"># outcome variable</span></span>
<span id="cb941-5"><a href="sec-selection-on-observables.html#cb941-5" tabindex="-1"></a>    <span class="at">keep.all =</span> <span class="cn">TRUE</span>    <span class="co"># retain unmatched units in output</span></span>
<span id="cb941-6"><a href="sec-selection-on-observables.html#cb941-6" tabindex="-1"></a>)</span>
<span id="cb941-7"><a href="sec-selection-on-observables.html#cb941-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb941-8"><a href="sec-selection-on-observables.html#cb941-8" tabindex="-1"></a><span class="co">#&gt; Using &#39;treated&#39;=&#39;1&#39; as baseline group</span></span>
<span id="cb941-9"><a href="sec-selection-on-observables.html#cb941-9" tabindex="-1"></a>mat</span>
<span id="cb941-10"><a href="sec-selection-on-observables.html#cb941-10" tabindex="-1"></a><span class="co">#&gt;            G0  G1</span></span>
<span id="cb941-11"><a href="sec-selection-on-observables.html#cb941-11" tabindex="-1"></a><span class="co">#&gt; All       392 258</span></span>
<span id="cb941-12"><a href="sec-selection-on-observables.html#cb941-12" tabindex="-1"></a><span class="co">#&gt; Matched    95  84</span></span>
<span id="cb941-13"><a href="sec-selection-on-observables.html#cb941-13" tabindex="-1"></a><span class="co">#&gt; Unmatched 297 174</span></span></code></pre></div>
<ul>
<li><p><code>mat$w</code> contains <strong>weights</strong> for matched units.</p></li>
<li><p>Summary of matched strata and units retained.</p></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Manual Coarsening (User-Controlled)</li>
</ol>
<p>Users may coarsen variables explicitly based on theoretical knowledge or data distribution.</p>
<p>Example: Grouped Categorical and Binned Continuous Covariates</p>
<div class="sourceCode" id="cb942"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb942-1"><a href="sec-selection-on-observables.html#cb942-1" tabindex="-1"></a><span class="co"># Inspect levels for grouping</span></span>
<span id="cb942-2"><a href="sec-selection-on-observables.html#cb942-2" tabindex="-1"></a><span class="fu">levels</span>(Le<span class="sc">$</span>q1)</span>
<span id="cb942-3"><a href="sec-selection-on-observables.html#cb942-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;agree&quot;             &quot;disagree&quot;          &quot;neutral&quot;          </span></span>
<span id="cb942-4"><a href="sec-selection-on-observables.html#cb942-4" tabindex="-1"></a><span class="co">#&gt; [4] &quot;no opinion&quot;        &quot;strongly agree&quot;    &quot;strongly disagree&quot;</span></span>
<span id="cb942-5"><a href="sec-selection-on-observables.html#cb942-5" tabindex="-1"></a></span>
<span id="cb942-6"><a href="sec-selection-on-observables.html#cb942-6" tabindex="-1"></a><span class="co"># Group Likert responses</span></span>
<span id="cb942-7"><a href="sec-selection-on-observables.html#cb942-7" tabindex="-1"></a>q1.grp <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb942-8"><a href="sec-selection-on-observables.html#cb942-8" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">&quot;strongly agree&quot;</span>, <span class="st">&quot;agree&quot;</span>),</span>
<span id="cb942-9"><a href="sec-selection-on-observables.html#cb942-9" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">&quot;neutral&quot;</span>, <span class="st">&quot;no opinion&quot;</span>),</span>
<span id="cb942-10"><a href="sec-selection-on-observables.html#cb942-10" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">&quot;strongly disagree&quot;</span>, <span class="st">&quot;disagree&quot;</span>)</span>
<span id="cb942-11"><a href="sec-selection-on-observables.html#cb942-11" tabindex="-1"></a>)</span>
<span id="cb942-12"><a href="sec-selection-on-observables.html#cb942-12" tabindex="-1"></a></span>
<span id="cb942-13"><a href="sec-selection-on-observables.html#cb942-13" tabindex="-1"></a><span class="co"># Custom cutpoints for education</span></span>
<span id="cb942-14"><a href="sec-selection-on-observables.html#cb942-14" tabindex="-1"></a><span class="fu">table</span>(Le<span class="sc">$</span>education)</span>
<span id="cb942-15"><a href="sec-selection-on-observables.html#cb942-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb942-16"><a href="sec-selection-on-observables.html#cb942-16" tabindex="-1"></a><span class="co">#&gt;   3   4   5   6   7   8   9  10  11  12  13  14  15 </span></span>
<span id="cb942-17"><a href="sec-selection-on-observables.html#cb942-17" tabindex="-1"></a><span class="co">#&gt;   1   5   4   6  12  55 106 146 173 113  19   9   1</span></span>
<span id="cb942-18"><a href="sec-selection-on-observables.html#cb942-18" tabindex="-1"></a>educut <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">6.5</span>, <span class="fl">8.5</span>, <span class="fl">12.5</span>, <span class="dv">17</span>)</span>
<span id="cb942-19"><a href="sec-selection-on-observables.html#cb942-19" tabindex="-1"></a></span>
<span id="cb942-20"><a href="sec-selection-on-observables.html#cb942-20" tabindex="-1"></a><span class="co"># Run CEM with manual coarsening</span></span>
<span id="cb942-21"><a href="sec-selection-on-observables.html#cb942-21" tabindex="-1"></a>mat1 <span class="ot">&lt;-</span> <span class="fu">cem</span>(</span>
<span id="cb942-22"><a href="sec-selection-on-observables.html#cb942-22" tabindex="-1"></a>    <span class="at">treatment =</span> <span class="st">&quot;treated&quot;</span>,</span>
<span id="cb942-23"><a href="sec-selection-on-observables.html#cb942-23" tabindex="-1"></a>    <span class="at">data =</span> Le,</span>
<span id="cb942-24"><a href="sec-selection-on-observables.html#cb942-24" tabindex="-1"></a>    <span class="at">drop =</span> <span class="st">&quot;re78&quot;</span>,</span>
<span id="cb942-25"><a href="sec-selection-on-observables.html#cb942-25" tabindex="-1"></a>    <span class="at">cutpoints =</span> <span class="fu">list</span>(<span class="at">education =</span> educut),</span>
<span id="cb942-26"><a href="sec-selection-on-observables.html#cb942-26" tabindex="-1"></a>    <span class="at">grouping =</span> <span class="fu">list</span>(<span class="at">q1 =</span> q1.grp)</span>
<span id="cb942-27"><a href="sec-selection-on-observables.html#cb942-27" tabindex="-1"></a>)</span>
<span id="cb942-28"><a href="sec-selection-on-observables.html#cb942-28" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb942-29"><a href="sec-selection-on-observables.html#cb942-29" tabindex="-1"></a><span class="co">#&gt; Using &#39;treated&#39;=&#39;1&#39; as baseline group</span></span>
<span id="cb942-30"><a href="sec-selection-on-observables.html#cb942-30" tabindex="-1"></a>mat1</span>
<span id="cb942-31"><a href="sec-selection-on-observables.html#cb942-31" tabindex="-1"></a><span class="co">#&gt;            G0  G1</span></span>
<span id="cb942-32"><a href="sec-selection-on-observables.html#cb942-32" tabindex="-1"></a><span class="co">#&gt; All       392 258</span></span>
<span id="cb942-33"><a href="sec-selection-on-observables.html#cb942-33" tabindex="-1"></a><span class="co">#&gt; Matched   158 115</span></span>
<span id="cb942-34"><a href="sec-selection-on-observables.html#cb942-34" tabindex="-1"></a><span class="co">#&gt; Unmatched 234 143</span></span></code></pre></div>
<p>This allows for <strong>domain-specific discretion</strong> and enhances interpretability.</p>
</div>
<div id="progressive-coarsening" class="section level4 hasAnchor" number="35.9.7.2">
<h4><span class="header-section-number">35.9.7.2</span> Progressive Coarsening<a href="sec-selection-on-observables.html#progressive-coarsening" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>CEM supports <strong>progressive coarsening</strong>, where matching is attempted with fine coarsening first. If insufficient matches are found, coarsening is gradually relaxed until a suitable number of matched units is retained.</p>
<p>This strategy balances:</p>
<ul>
<li><p><strong>Precision</strong> (finer bins)</p></li>
<li><p><strong>Sample size retention</strong> (coarser bins)</p></li>
</ul>
</div>
<div id="summary-2" class="section level4 hasAnchor" number="35.9.7.3">
<h4><span class="header-section-number">35.9.7.3</span> Summary<a href="sec-selection-on-observables.html#summary-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Strengths</p>
<ul>
<li><p>Transparent and tunable matching procedure</p></li>
<li><p>Non-parametric: Does not require estimation of a treatment assignment model</p></li>
<li><p>Robust to measurement error and model misspecification</p></li>
<li><p>Supports multi-valued treatments and partial missingness</p></li>
<li><p>Theoretically grounded via monotonic imbalance bounding</p></li>
</ul>
<p>Limitations</p>
<ul>
<li><p>Loss of information due to coarsening</p></li>
<li><p>Arbitrary binning may influence results if not theoretically motivated</p></li>
<li><p>Not designed for high-dimensional settings without careful variable selection</p></li>
<li><p>Cannot account for unobserved confounding</p></li>
</ul>
<p>Coarsened Exact Matching offers a powerful, transparent, and theoretically principled method for preprocessing observational data before estimating causal effects. It overcomes several limitations of traditional matching approaches, particularly propensity score matching, by giving researchers direct control over the quality of matches and by anchoring inference in empirical balance rather than model-dependent estimates.</p>
<hr />
</div>
</div>
<div id="sec-genetic-matching" class="section level3 hasAnchor" number="35.9.8">
<h3><span class="header-section-number">35.9.8</span> Genetic Matching<a href="sec-selection-on-observables.html#sec-genetic-matching" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Genetic Matching (GM) is a generalization of <a href="sec-selection-on-observables.html#sec-propensity-scores">propensity score</a> and <a href="sec-selection-on-observables.html#sec-mahalanobis">Mahalanobis distance matching</a>, leveraging a search algorithm inspired by evolutionary biology to optimize covariate balance. Unlike classical matching techniques, which rely on pre-specified distance metrics, Genetic Matching <em>learns</em> an optimal distance metric through an iterative process aimed at minimizing imbalance between treated and control groups.</p>
<p>Genetic Matching was introduced by <span class="citation">Diamond and Sekhon (<a href="#ref-diamond2013genetic">2013</a>)</span> and is designed to improve balance on observed covariates by selecting optimal weights for each covariate. The core idea is to define a generalized Mahalanobis distance metric, where the weights used in the distance calculation are chosen by a <strong>genetic search algorithm</strong>. This process adaptively explores the space of possible weighting matrices and evolves toward a set of weights that result in optimal covariate balance across treatment groups.</p>
<p>The method combines two components:</p>
<ul>
<li><a href="sec-selection-on-observables.html#sec-propensity-scores"><strong>Propensity Score Matching</strong></a>: Balances on the estimated probability of treatment assignment given covariates.</li>
<li><a href="sec-selection-on-observables.html#sec-mahalanobis"><strong>Mahalanobis Distance Matching</strong></a>: Accounts for correlations among covariates and ensures geometric proximity in multivariate space.</li>
</ul>
<p>The Genetic Matching approach treats the selection of covariate weights as an optimization problem, solved using techniques inspired by natural selection‚Äîmutation, crossover, and survival of the fittest.</p>
<p>Compared to traditional matching methods such as:</p>
<ul>
<li><strong>Nearest Neighbor Matching</strong>: May result in poor balance in high-dimensional or imbalanced datasets.</li>
<li><strong>Full Matching</strong>: More efficient but not always feasible with severe imbalance.</li>
</ul>
<p>Genetic Matching is particularly powerful in situations where traditional distance metrics are insufficient to achieve balance. It adaptively searches the weight space to ensure better covariate overlap, which is crucial for unbiased causal inference.</p>
<p>In empirical settings, this often results in superior balance on observed covariates and more credible estimates of treatment effects.</p>
<hr />
<p>Let:</p>
<ul>
<li><p><span class="math inline">\(T_i \in \{0, 1\}\)</span> be the binary treatment indicator for unit <span class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^p\)</span> be the covariate vector for unit <span class="math inline">\(i\)</span>, where <span class="math inline">\(p\)</span> is the number of observed covariates.</p></li>
<li><p><span class="math inline">\(\mathbf{W}\)</span> be a <span class="math inline">\(p \times p\)</span> positive definite weight matrix optimized by the algorithm.</p></li>
</ul>
<p>The <strong>generalized Mahalanobis distance</strong> between unit <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is defined as:</p>
<p><span class="math display">\[
D_{ij} = \sqrt{(\mathbf{X}_i - \mathbf{X}_j)^\top \mathbf{W} (\mathbf{X}_i - \mathbf{X}_j)}
\]</span></p>
<p>Here, <span class="math inline">\(\mathbf{W}\)</span> is not necessarily the inverse of the covariance matrix (as in standard Mahalanobis distance), but a data-driven weighting matrix found by Genetic Matching to optimize covariate balance.</p>
<p>The genetic algorithm optimizes the weights in <span class="math inline">\(\mathbf{W}\)</span> to minimize a global imbalance metric <span class="math inline">\(\mathcal{B}\)</span> across all covariates. This can involve different balance criteria:</p>
<ul>
<li>Paired <span class="math inline">\(t\)</span>-tests for continuous or dichotomous variables</li>
<li>Kolmogorov‚ÄìSmirnov (K‚ÄìS) test statistics for distributional similarity</li>
<li>Standardized mean differences</li>
</ul>
<p>Let <span class="math inline">\(b_k\)</span> denote the balance metric for the <span class="math inline">\(k\)</span>th covariate. Then the total imbalance could be:</p>
<p><span class="math display">\[
\mathcal{B} = \sum_{k=1}^{p} w_k b_k^2
\]</span></p>
<p>The optimization objective becomes finding <span class="math inline">\(\mathbf{W}\)</span> that minimizes <span class="math inline">\(\mathcal{B}\)</span>.</p>
<hr />
<p>Genetic Matching is implemented in the <code>Matching</code> package in R via the <code>GenMatch()</code> function. This function:</p>
<ul>
<li>Accepts a treatment indicator (<code>Tr</code>) and a matrix of covariates (<code>X</code>).</li>
<li>Optionally takes a <strong>Balance Matrix</strong> (<code>BalanceMatrix</code>) that specifies which variables should be balanced.</li>
<li>Uses a genetic search to find the weight matrix that best achieves balance on the specified variables.</li>
</ul>
<p>Balance is assessed via:</p>
<ul>
<li>Paired <span class="math inline">\(t\)</span>-tests for dichotomous or continuous variables</li>
<li>Kolmogorov-Smirnov (K‚ÄìS) tests for distributional differences</li>
</ul>
<p>Matching can be performed:</p>
<ul>
<li><strong>With or without replacement</strong> (with replacement often improves match quality at the cost of increased variance).</li>
<li>For different estimands: <a href="types-of-treatment-effects.html#sec-average-treatment-effect">Average Treatment Effect</a>, <a href="types-of-treatment-effects.html#sec-average-treatment-effect-on-the-treated">Average Treatment Effect on the Treated</a>, or <a href="types-of-treatment-effects.html#sec-average-treatment-effect-on-the-control">Average Treatment Effect on the Control</a>.</li>
</ul>
<hr />
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb943-1"><a href="sec-selection-on-observables.html#cb943-1" tabindex="-1"></a><span class="fu">library</span>(Matching)</span>
<span id="cb943-2"><a href="sec-selection-on-observables.html#cb943-2" tabindex="-1"></a><span class="fu">data</span>(lalonde, <span class="at">package =</span> <span class="st">&quot;MatchIt&quot;</span>)</span>
<span id="cb943-3"><a href="sec-selection-on-observables.html#cb943-3" tabindex="-1"></a><span class="fu">attach</span>(lalonde)</span>
<span id="cb943-4"><a href="sec-selection-on-observables.html#cb943-4" tabindex="-1"></a></span>
<span id="cb943-5"><a href="sec-selection-on-observables.html#cb943-5" tabindex="-1"></a><span class="co"># Define the covariates to match on</span></span>
<span id="cb943-6"><a href="sec-selection-on-observables.html#cb943-6" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(age, educ, black, hisp, married, nodegr, u74, u75, re75, re74)</span>
<span id="cb943-7"><a href="sec-selection-on-observables.html#cb943-7" tabindex="-1"></a></span>
<span id="cb943-8"><a href="sec-selection-on-observables.html#cb943-8" tabindex="-1"></a><span class="co"># Define the covariates to balance on</span></span>
<span id="cb943-9"><a href="sec-selection-on-observables.html#cb943-9" tabindex="-1"></a>BalanceMat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb943-10"><a href="sec-selection-on-observables.html#cb943-10" tabindex="-1"></a>  age, educ, black, hisp, married, nodegr,</span>
<span id="cb943-11"><a href="sec-selection-on-observables.html#cb943-11" tabindex="-1"></a>  u74, u75, re75, re74,</span>
<span id="cb943-12"><a href="sec-selection-on-observables.html#cb943-12" tabindex="-1"></a>  <span class="fu">I</span>(re74 <span class="sc">*</span> re75) <span class="co"># Include interaction term</span></span>
<span id="cb943-13"><a href="sec-selection-on-observables.html#cb943-13" tabindex="-1"></a>)</span>
<span id="cb943-14"><a href="sec-selection-on-observables.html#cb943-14" tabindex="-1"></a></span>
<span id="cb943-15"><a href="sec-selection-on-observables.html#cb943-15" tabindex="-1"></a><span class="co"># Genetic Matching to optimize covariate balance</span></span>
<span id="cb943-16"><a href="sec-selection-on-observables.html#cb943-16" tabindex="-1"></a><span class="co"># Note: pop.size = 16 is too small for real applications</span></span>
<span id="cb943-17"><a href="sec-selection-on-observables.html#cb943-17" tabindex="-1"></a>genout <span class="ot">&lt;-</span> <span class="fu">GenMatch</span>(</span>
<span id="cb943-18"><a href="sec-selection-on-observables.html#cb943-18" tabindex="-1"></a>  <span class="at">Tr =</span> treat,</span>
<span id="cb943-19"><a href="sec-selection-on-observables.html#cb943-19" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb943-20"><a href="sec-selection-on-observables.html#cb943-20" tabindex="-1"></a>  <span class="at">BalanceMatrix =</span> BalanceMat,</span>
<span id="cb943-21"><a href="sec-selection-on-observables.html#cb943-21" tabindex="-1"></a>  <span class="at">estimand =</span> <span class="st">&quot;ATE&quot;</span>,</span>
<span id="cb943-22"><a href="sec-selection-on-observables.html#cb943-22" tabindex="-1"></a>  <span class="at">M =</span> <span class="dv">1</span>,</span>
<span id="cb943-23"><a href="sec-selection-on-observables.html#cb943-23" tabindex="-1"></a>  <span class="at">pop.size =</span> <span class="dv">16</span>,</span>
<span id="cb943-24"><a href="sec-selection-on-observables.html#cb943-24" tabindex="-1"></a>  <span class="at">max.generations =</span> <span class="dv">10</span>,</span>
<span id="cb943-25"><a href="sec-selection-on-observables.html#cb943-25" tabindex="-1"></a>  <span class="at">wait.generations =</span> <span class="dv">1</span></span>
<span id="cb943-26"><a href="sec-selection-on-observables.html#cb943-26" tabindex="-1"></a>)</span>
<span id="cb943-27"><a href="sec-selection-on-observables.html#cb943-27" tabindex="-1"></a></span>
<span id="cb943-28"><a href="sec-selection-on-observables.html#cb943-28" tabindex="-1"></a><span class="co"># Define the outcome variable</span></span>
<span id="cb943-29"><a href="sec-selection-on-observables.html#cb943-29" tabindex="-1"></a>Y <span class="ot">&lt;-</span> re78 <span class="sc">/</span> <span class="dv">1000</span></span>
<span id="cb943-30"><a href="sec-selection-on-observables.html#cb943-30" tabindex="-1"></a></span>
<span id="cb943-31"><a href="sec-selection-on-observables.html#cb943-31" tabindex="-1"></a><span class="co"># Perform matching with the optimized weights</span></span>
<span id="cb943-32"><a href="sec-selection-on-observables.html#cb943-32" tabindex="-1"></a>mout <span class="ot">&lt;-</span> <span class="fu">Match</span>(</span>
<span id="cb943-33"><a href="sec-selection-on-observables.html#cb943-33" tabindex="-1"></a>  <span class="at">Y =</span> Y,</span>
<span id="cb943-34"><a href="sec-selection-on-observables.html#cb943-34" tabindex="-1"></a>  <span class="at">Tr =</span> treat,</span>
<span id="cb943-35"><a href="sec-selection-on-observables.html#cb943-35" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb943-36"><a href="sec-selection-on-observables.html#cb943-36" tabindex="-1"></a>  <span class="at">estimand =</span> <span class="st">&quot;ATE&quot;</span>,</span>
<span id="cb943-37"><a href="sec-selection-on-observables.html#cb943-37" tabindex="-1"></a>  <span class="at">Weight.matrix =</span> genout</span>
<span id="cb943-38"><a href="sec-selection-on-observables.html#cb943-38" tabindex="-1"></a>)</span>
<span id="cb943-39"><a href="sec-selection-on-observables.html#cb943-39" tabindex="-1"></a></span>
<span id="cb943-40"><a href="sec-selection-on-observables.html#cb943-40" tabindex="-1"></a><span class="co"># Summarize the treatment effect estimates</span></span>
<span id="cb943-41"><a href="sec-selection-on-observables.html#cb943-41" tabindex="-1"></a><span class="fu">summary</span>(mout)</span>
<span id="cb943-42"><a href="sec-selection-on-observables.html#cb943-42" tabindex="-1"></a></span>
<span id="cb943-43"><a href="sec-selection-on-observables.html#cb943-43" tabindex="-1"></a><span class="co"># Assess post-matching balance</span></span>
<span id="cb943-44"><a href="sec-selection-on-observables.html#cb943-44" tabindex="-1"></a>mb <span class="ot">&lt;-</span> <span class="fu">MatchBalance</span>(</span>
<span id="cb943-45"><a href="sec-selection-on-observables.html#cb943-45" tabindex="-1"></a>  treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> black <span class="sc">+</span> hisp <span class="sc">+</span> married <span class="sc">+</span> nodegr <span class="sc">+</span></span>
<span id="cb943-46"><a href="sec-selection-on-observables.html#cb943-46" tabindex="-1"></a>    u74 <span class="sc">+</span> u75 <span class="sc">+</span> re75 <span class="sc">+</span> re74 <span class="sc">+</span> <span class="fu">I</span>(re74 <span class="sc">*</span> re75),</span>
<span id="cb943-47"><a href="sec-selection-on-observables.html#cb943-47" tabindex="-1"></a>  <span class="at">match.out =</span> mout,</span>
<span id="cb943-48"><a href="sec-selection-on-observables.html#cb943-48" tabindex="-1"></a>  <span class="at">nboots =</span> <span class="dv">500</span></span>
<span id="cb943-49"><a href="sec-selection-on-observables.html#cb943-49" tabindex="-1"></a>)</span></code></pre></div>
<p><strong>Extensions and Considerations</strong></p>
<ul>
<li><p>The method can be extended to multinomial treatments (via generalized entropy balancing).</p></li>
<li><p>For longitudinal or panel data, entropy balancing can be adapted to match across time points.</p></li>
<li><p>One should avoid balancing on post-treatment variables, which would bias estimates.</p></li>
</ul>
<p>Entropy balancing fits naturally into modern workflows for causal inference, and is especially valuable when researchers want to prioritize design over modeling.</p>
<hr />
</div>
<div id="entropy-balancing" class="section level3 hasAnchor" number="35.9.9">
<h3><span class="header-section-number">35.9.9</span> Entropy Balancing<a href="sec-selection-on-observables.html#entropy-balancing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Entropy balancing is a data preprocessing technique for causal inference in observational studies. Introduced by <span class="citation">Hainmueller (<a href="#ref-hainmueller2012entropy">2012</a>)</span>, it is particularly useful in settings with binary treatments where covariate imbalance between treated and control groups threatens the validity of causal estimates.</p>
<p>The method applies a <strong>maximum entropy reweighting</strong> scheme to assign <strong>unit weights</strong> to control group observations such that the <strong>reweighted covariate distribution</strong> in the control group matches the <strong>sample moments</strong> (e.g., means, variances) of the treated group.</p>
<p>Entropy balancing directly targets covariate balance and avoids the trial-and-error of iterative propensity score or matching methods. It also reduces reliance on outcome models by ensuring pre-treatment covariates are aligned between groups.</p>
<ul>
<li><strong>Goal</strong>: Create a set of weights for the control group such that its covariate distribution matches that of the treated group.</li>
<li><strong>Approach</strong>: Solve a constrained optimization problem that minimizes information loss (measured via Shannon entropy) subject to <strong>balance constraints</strong> on covariates.</li>
</ul>
<p>Entropy balancing:</p>
<ul>
<li><p>Achieves exact balance on the specified covariate moments (e.g., means, variances).</p></li>
<li><p>Produces unique, data-driven weights without the need for iterative matching.</p></li>
<li><p>Is compatible with any outcome model in the second stage (e.g., weighted regression, IPW, DID, etc.).</p></li>
</ul>
<p><strong>Advantages of Entropy Balancing</strong></p>
<ul>
<li><strong>Exact balance</strong>: Guarantees moment balance without iterative diagnostics.</li>
<li><strong>Flexibility</strong>: Can balance on higher moments, interactions, or non-linear transformations.</li>
<li><strong>Model independence</strong>: Reduces reliance on correct specification of the outcome model.</li>
<li><strong>Stability</strong>: The optimization procedure is smooth and produces stable, interpretable weights.</li>
</ul>
<p>Entropy balancing is especially useful in high-dimensional settings or when working with small treated groups, where matching can perform poorly or fail entirely.</p>
<hr />
<p>Suppose we have <span class="math inline">\(n_1\)</span> treated units and <span class="math inline">\(n_0\)</span> control units, with covariates <span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^p\)</span> for each unit <span class="math inline">\(i\)</span>. Let <span class="math inline">\(T_i \in \{0,1\}\)</span> be the treatment indicator.</p>
<p>Let the treatment group‚Äôs sample moment vector be:</p>
<p><span class="math display">\[
\bar{\mathbf{X}}_T = \frac{1}{n_1} \sum_{i: T_i=1} \mathbf{X}_i
\]</span></p>
<p>We seek a set of weights <span class="math inline">\(\{w_i\}_{i: T_i=0}\)</span> for control units such that:</p>
<ol style="list-style-type: decimal">
<li><strong>Covariate balancing constraints</strong> (e.g., mean balance):</li>
</ol>
<p><span class="math display">\[
\sum_{i: T_i=0} w_i \mathbf{X}_i = \bar{\mathbf{X}}_T
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Minimum entropy divergence</strong> from uniform weights:</li>
</ol>
<p>We minimize the Kullback-Leibler divergence between the new weights <span class="math inline">\(w_i\)</span> and uniform base weights <span class="math inline">\(w_i^{(0)} = \frac{1}{n_0}\)</span>:</p>
<p><span class="math display">\[
\min_{\{w_i\}} \sum_{i: T_i=0} w_i \log \left( \frac{w_i}{w_i^{(0)}} \right)
\]</span></p>
<p>subject to:</p>
<ul>
<li><span class="math inline">\(\sum w_i = 1\)</span> (weights must sum to 1)</li>
<li><span class="math inline">\(\sum w_i \mathbf{X}_i = \bar{\mathbf{X}}_T\)</span></li>
<li>(Optionally) higher-order moments, e.g., variances, skewness, etc.</li>
</ul>
<p>This is a <strong>convex optimization problem</strong>, ensuring a unique global solution.</p>
<hr />
<div class="sourceCode" id="cb944"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb944-1"><a href="sec-selection-on-observables.html#cb944-1" tabindex="-1"></a><span class="co"># Load package</span></span>
<span id="cb944-2"><a href="sec-selection-on-observables.html#cb944-2" tabindex="-1"></a><span class="fu">library</span>(ebal)</span>
<span id="cb944-3"><a href="sec-selection-on-observables.html#cb944-3" tabindex="-1"></a></span>
<span id="cb944-4"><a href="sec-selection-on-observables.html#cb944-4" tabindex="-1"></a><span class="co"># Simulate data</span></span>
<span id="cb944-5"><a href="sec-selection-on-observables.html#cb944-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb944-6"><a href="sec-selection-on-observables.html#cb944-6" tabindex="-1"></a>n_treat <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb944-7"><a href="sec-selection-on-observables.html#cb944-7" tabindex="-1"></a>n_control <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb944-8"><a href="sec-selection-on-observables.html#cb944-8" tabindex="-1"></a></span>
<span id="cb944-9"><a href="sec-selection-on-observables.html#cb944-9" tabindex="-1"></a><span class="co"># Covariates</span></span>
<span id="cb944-10"><a href="sec-selection-on-observables.html#cb944-10" tabindex="-1"></a>X_treat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n_treat <span class="sc">*</span> <span class="dv">3</span>, <span class="at">mean =</span> <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb944-11"><a href="sec-selection-on-observables.html#cb944-11" tabindex="-1"></a>X_control <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n_control <span class="sc">*</span> <span class="dv">3</span>, <span class="at">mean =</span> <span class="dv">0</span>), <span class="at">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb944-12"><a href="sec-selection-on-observables.html#cb944-12" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rbind</span>(X_control, X_treat)  <span class="co"># Order: control first, then treated</span></span>
<span id="cb944-13"><a href="sec-selection-on-observables.html#cb944-13" tabindex="-1"></a></span>
<span id="cb944-14"><a href="sec-selection-on-observables.html#cb944-14" tabindex="-1"></a><span class="co"># Treatment vector: 0 = control, 1 = treated</span></span>
<span id="cb944-15"><a href="sec-selection-on-observables.html#cb944-15" tabindex="-1"></a>treatment <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, n_control), <span class="fu">rep</span>(<span class="dv">1</span>, n_treat))</span>
<span id="cb944-16"><a href="sec-selection-on-observables.html#cb944-16" tabindex="-1"></a></span>
<span id="cb944-17"><a href="sec-selection-on-observables.html#cb944-17" tabindex="-1"></a><span class="co"># Apply entropy balancing</span></span>
<span id="cb944-18"><a href="sec-selection-on-observables.html#cb944-18" tabindex="-1"></a>eb_out <span class="ot">&lt;-</span> <span class="fu">ebalance</span>(<span class="at">Treatment =</span> treatment, <span class="at">X =</span> X)</span>
<span id="cb944-19"><a href="sec-selection-on-observables.html#cb944-19" tabindex="-1"></a></span>
<span id="cb944-20"><a href="sec-selection-on-observables.html#cb944-20" tabindex="-1"></a><span class="co"># Simulate outcome variable</span></span>
<span id="cb944-21"><a href="sec-selection-on-observables.html#cb944-21" tabindex="-1"></a>Y_control <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_control, <span class="at">mean =</span> <span class="dv">1</span>)</span>
<span id="cb944-22"><a href="sec-selection-on-observables.html#cb944-22" tabindex="-1"></a>Y_treat <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_treat, <span class="at">mean =</span> <span class="dv">3</span>)</span>
<span id="cb944-23"><a href="sec-selection-on-observables.html#cb944-23" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">c</span>(Y_control, Y_treat)</span>
<span id="cb944-24"><a href="sec-selection-on-observables.html#cb944-24" tabindex="-1"></a></span>
<span id="cb944-25"><a href="sec-selection-on-observables.html#cb944-25" tabindex="-1"></a><span class="co"># Construct weights: treated get weight 1, control get weights from ebalance</span></span>
<span id="cb944-26"><a href="sec-selection-on-observables.html#cb944-26" tabindex="-1"></a>weights <span class="ot">&lt;-</span> <span class="fu">c</span>(eb_out<span class="sc">$</span>w, <span class="fu">rep</span>(<span class="dv">1</span>, n_treat))</span>
<span id="cb944-27"><a href="sec-selection-on-observables.html#cb944-27" tabindex="-1"></a></span>
<span id="cb944-28"><a href="sec-selection-on-observables.html#cb944-28" tabindex="-1"></a><span class="co"># Estimate ATE using weighted linear regression</span></span>
<span id="cb944-29"><a href="sec-selection-on-observables.html#cb944-29" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Y =</span> Y, <span class="at">treat =</span> treatment, <span class="at">weights =</span> weights)</span>
<span id="cb944-30"><a href="sec-selection-on-observables.html#cb944-30" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> treat, <span class="at">data =</span> df, <span class="at">weights =</span> weights)</span>
<span id="cb944-31"><a href="sec-selection-on-observables.html#cb944-31" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<hr />
</div>
<div id="matching-for-high-dimensional-data" class="section level3 hasAnchor" number="35.9.10">
<h3><span class="header-section-number">35.9.10</span> Matching for High-Dimensional Data<a href="sec-selection-on-observables.html#matching-for-high-dimensional-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As the dimensionality of covariates increases, traditional matching methods (such as nearest neighbor matching using propensity scores or Mahalanobis distance) become increasingly unreliable. This issue, often referred to as the <strong>curse of dimensionality</strong>, undermines the ability to find good matches because distances between points become less informative in high-dimensional space.</p>
<p>In high-dimensional settings, where the number of covariates is large (potentially exceeding the number of observations), careful preprocessing is necessary to reduce dimensionality before matching can be effectively applied. The following approaches are commonly used to mitigate these challenges by reducing the feature space while preserving meaningful structure relevant to treatment assignment and outcomes.</p>
<div id="dimensionality-reduction-techniques" class="section level4 hasAnchor" number="35.9.10.1">
<h4><span class="header-section-number">35.9.10.1</span> Dimensionality Reduction Techniques<a href="sec-selection-on-observables.html#dimensionality-reduction-techniques" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A variety of dimensionality reduction techniques can be employed prior to matching. Each method has distinct assumptions and use cases:</p>
<ul>
<li><p><strong>Lasso Regression (Least Absolute Shrinkage and Selection Operator)</strong><br />
Lasso imposes an <span class="math inline">\(L_1\)</span> penalty on the regression coefficients, effectively shrinking some coefficients to zero. This property is particularly useful in high-dimensional settings, as it performs both regularization and variable selection.<br />
Lasso can be used to identify a smaller set of covariates that are most predictive of treatment assignment or outcome, which can then be used in matching procedures <span class="citation">(<a href="#ref-gordon2019comparison">Gordon et al. 2019</a>)</span>.</p></li>
<li><p><strong>Penalized Logistic Regression</strong><br />
When the treatment is binary, penalized logistic regression (e.g., using an <span class="math inline">\(L_1\)</span> or <span class="math inline">\(L_2\)</span> penalty) can be employed to estimate propensity scores while avoiding overfitting in high-dimensional spaces. These penalized models provide more stable estimates of the propensity score, which is essential for reliable matching <span class="citation">(<a href="#ref-eckles2021bias">Eckles and Bakshy 2021</a>)</span>.</p></li>
<li><p><strong>Principal Component Analysis (PCA)</strong><br />
PCA is an unsupervised linear transformation that projects the original features into a lower-dimensional space by retaining the directions of maximum variance. While PCA does not consider treatment assignment directly, it is effective for denoising and compressing data, particularly when covariates are highly correlated.<br />
The principal components can then be used as inputs to standard matching methods.</p></li>
<li><p><strong>Locality Preserving Projections (LPP)</strong><br />
LPP is a linear dimensionality reduction technique that, unlike PCA, preserves local neighborhood structures. It constructs a similarity graph and projects data into a lower-dimensional space such that nearby points remain close. This locality-preserving property is beneficial for matching, as it helps maintain the integrity of local relationships within the data <span class="citation">(<a href="#ref-li2016matching">S. Li et al. 2016</a>)</span>.</p></li>
<li><p><strong>Random Projection</strong><br />
Random projection reduces dimensionality by projecting data onto a lower-dimensional subspace using a random matrix. It is computationally efficient and has theoretical guarantees (e.g., Johnson‚ÄìLindenstrauss lemma) that distances between points are approximately preserved. This makes it a viable option for extremely high-dimensional data where exact structure preservation is less critical.</p></li>
<li><p><strong>Autoencoders</strong><br />
Autoencoders are neural network architectures designed to learn efficient, nonlinear representations (encodings) of data. An autoencoder consists of an encoder that compresses the input and a decoder that attempts to reconstruct the original input from this compressed representation.<br />
Autoencoders are particularly effective in capturing complex, nonlinear relationships among features, which may be missed by linear methods like PCA. The latent representation obtained from the encoder can then be used for matching <span class="citation">(<a href="#ref-ramachandra2018deep">Ramachandra 2018</a>)</span>.</p></li>
</ul>
</div>
<div id="joint-dimensionality-reduction-and-distribution-balancing" class="section level4 hasAnchor" number="35.9.10.2">
<h4><span class="header-section-number">35.9.10.2</span> Joint Dimensionality Reduction and Distribution Balancing<a href="sec-selection-on-observables.html#joint-dimensionality-reduction-and-distribution-balancing" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Rather than performing dimensionality reduction and matching as separate steps, an emerging strategy is to jointly learn representations that simultaneously:</p>
<ol style="list-style-type: decimal">
<li>Reduce dimensionality, and</li>
<li>Balance the covariate distributions between treated and control groups.</li>
</ol>
<p>This is exemplified by <em>representation learning for causal inference</em> approaches. One such method, proposed by <span class="citation">Yao et al. (<a href="#ref-yao2018representation">2018</a>)</span>, integrates neural networks with matching objectives to learn latent representations of covariates that are both low-dimensional and balanced. These representations are optimized such that the distributions of treated and control units in the latent space are similar (e.g., using maximum mean discrepancy or other balancing metrics), thereby improving the quality of matches and robustness of treatment effect estimates.</p>
</div>
<div id="summary-of-approaches" class="section level4 hasAnchor" number="35.9.10.3">
<h4><span class="header-section-number">35.9.10.3</span> Summary of Approaches<a href="sec-selection-on-observables.html#summary-of-approaches" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<table>
<colgroup>
<col width="22%" />
<col width="12%" />
<col width="9%" />
<col width="36%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Type</th>
<th>Supervised?</th>
<th>Key Feature</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Lasso</td>
<td>Linear, sparse</td>
<td>Yes</td>
<td>Variable selection via <span class="math inline">\(L_1\)</span> penalty</td>
<td><span class="citation">(<a href="#ref-gordon2019comparison">Gordon et al. 2019</a>)</span></td>
</tr>
<tr class="even">
<td>Penalized logistic regression</td>
<td>Linear</td>
<td>Yes</td>
<td>Regularized propensity score estimation</td>
<td><span class="citation">(<a href="#ref-eckles2021bias">Eckles and Bakshy 2021</a>)</span></td>
</tr>
<tr class="odd">
<td>PCA</td>
<td>Linear</td>
<td>No</td>
<td>Projects onto directions of maximal variance</td>
<td>‚Äì</td>
</tr>
<tr class="even">
<td>LPP</td>
<td>Linear</td>
<td>No</td>
<td>Preserves local neighborhood structure</td>
<td><span class="citation">(<a href="#ref-li2016matching">S. Li et al. 2016</a>)</span></td>
</tr>
<tr class="odd">
<td>Random projection</td>
<td>Linear (random)</td>
<td>No</td>
<td>Fast and preserves pairwise distances</td>
<td>‚Äì</td>
</tr>
<tr class="even">
<td>Autoencoders</td>
<td>Nonlinear</td>
<td>Yes</td>
<td>Learns nonlinear representations</td>
<td><span class="citation">(<a href="#ref-ramachandra2018deep">Ramachandra 2018</a>)</span></td>
</tr>
<tr class="odd">
<td>Joint representation learning</td>
<td>Nonlinear</td>
<td>Yes</td>
<td>Learns balanced low-dimensional representations</td>
<td><span class="citation">(<a href="#ref-yao2018representation">Yao et al. 2018</a>)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="practical-considerations-8" class="section level4 hasAnchor" number="35.9.10.4">
<h4><span class="header-section-number">35.9.10.4</span> Practical Considerations<a href="sec-selection-on-observables.html#practical-considerations-8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><strong>Model selection and validation</strong>: When applying dimensionality reduction prior to matching, one must ensure that the reduced representation still contains sufficient information for confounding adjustment. Cross-validation and balance metrics (e.g., standardized mean differences) should be used to assess the adequacy of the transformation.</p></li>
<li><p><strong>Interpretability</strong>: While methods like PCA or autoencoders can be effective, they may obscure the interpretability of matches since the transformed features may not correspond to original covariates. Sparse methods like Lasso retain interpretability by selecting original covariates.</p></li>
<li><p><strong>Computational efficiency</strong>: Techniques such as random projection or penalized regression are computationally efficient and scalable to large datasets, while autoencoders and joint learning approaches may require more extensive training and hyperparameter tuning.</p></li>
</ul>
<hr />
</div>
</div>
<div id="matching-for-multiple-treatments" class="section level3 hasAnchor" number="35.9.11">
<h3><span class="header-section-number">35.9.11</span> Matching for Multiple Treatments<a href="sec-selection-on-observables.html#matching-for-multiple-treatments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In many applied settings, researchers face the challenge of estimating causal effects for <strong>more than two treatment levels</strong>. For example, a marketing campaign may have three variants (e.g., control, light exposure, heavy exposure), or a policy evaluation may involve multiple interventions. Standard binary treatment matching methods fall short in these cases, necessitating methodological extensions.</p>
<p>Suppose a dataset includes <span class="math inline">\(T\)</span> distinct treatment groups: <span class="math inline">\(\mathcal{T} = \{0, 1, ..., T-1\}\)</span>. Here, <span class="math inline">\(T = 0\)</span> typically denotes the control group, and <span class="math inline">\(T \in \{1, ..., T-1\}\)</span> are active treatments. The goal is to estimate the <a href="types-of-treatment-effects.html#sec-average-treatment-effect">Average Treatment Effect</a> or <strong>Pairwise Treatment Effects</strong>, such as <span class="math inline">\(\text{ATE}_{j,k} = \mathbb{E}[Y(j) - Y(k)]\)</span> for any <span class="math inline">\(j, k \in \mathcal{T}\)</span>.</p>
<p>Key challenges in this setting include:</p>
<ul>
<li>Ensuring common support across multiple groups</li>
<li>Adjusting for confounders in a balanced way across all treatment pairs</li>
<li>Managing covariate imbalance and dimensionality as the number of treatments increases</li>
</ul>
<hr />
<div id="matching-approaches-for-multiple-treatments" class="section level4 hasAnchor" number="35.9.11.1">
<h4><span class="header-section-number">35.9.11.1</span> Matching Approaches for Multiple Treatments<a href="sec-selection-on-observables.html#matching-approaches-for-multiple-treatments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Several strategies exist for matching in the presence of multiple treatments:</p>
<ol style="list-style-type: decimal">
<li><strong>Generalized Propensity Scores (GPS)</strong></li>
</ol>
<p>The generalized propensity score is defined as the conditional probability of receiving each treatment level given covariates:</p>
<p><span class="math display">\[
e_t(X) = \mathbb{P}(T = t \mid X), \quad \text{for } t = 0, 1, ..., T-1
\]</span></p>
<p>Estimation is typically done using <strong>multinomial logistic regression</strong>. Once GPS scores are estimated, matching can proceed via:</p>
<ul>
<li><strong>One-vs-all</strong>: For each treatment level, match treated units to all others combined.</li>
<li><strong>Pairwise matching</strong>: Conduct separate pairwise comparisons between all treatment levels.</li>
<li><strong>Full matching</strong>: Attempt to construct a global matched sample covering all treatments, using the GPS vector.</li>
</ul>
<p><span class="citation">(<a href="#ref-mccaffrey2013tutorial">McCaffrey et al. 2013</a>)</span> provides a comprehensive overview of GPS-based methods, including their implementation in the <code>twang</code> package.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Covariate Balancing Propensity Scores (CBPS)</strong> for Multiple Treatments</li>
</ol>
<p><span class="citation">(<a href="#ref-lopez2017estimation">Lopez and Gutman 2017</a>)</span> extend CBPS to the multinomial case. Rather than merely estimating GPS, CBPS directly optimizes covariate balance across treatment groups while estimating GPS parameters. This dual-objective estimation leads to more robust causal estimates in finite samples.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Kernel or Distance-Based Matching on Multinomial Scores</strong></li>
</ol>
<p>Instead of reducing GPS to scalar scores, matching can be performed using the full vector of propensity scores, using distance metrics such as Euclidean or Mahalanobis distance in the GPS space. This approach aligns with <span class="citation">Q.-Y. Zhao et al. (<a href="#ref-zhao2021propensity">2021</a>)</span>, who also consider <strong>continuous treatments</strong> using <strong>Generalized Propensity Score Density Estimation</strong>.</p>
<hr />
</div>
<div id="matching-with-multiple-treatments-using-matchit-and-alternatives" class="section level4 hasAnchor" number="35.9.11.2">
<h4><span class="header-section-number">35.9.11.2</span> Matching with Multiple Treatments Using MatchIt and Alternatives<a href="sec-selection-on-observables.html#matching-with-multiple-treatments-using-matchit-and-alternatives" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>While the <code>MatchIt</code> package in R was originally developed with binary treatment settings in mind, it can be adapted to handle multiple treatment groups through <strong>pairwise matching</strong> and careful design. However, this approach requires manual data preparation and a clear understanding of the causal estimands of interest‚Äîsuch as the ATT, ATC, or ATE.</p>
<ol style="list-style-type: decimal">
<li>Pairwise Matching with a Shared Control Group</li>
</ol>
<p>To estimate the effect of multiple treatments compared to a shared control group, one straightforward method is to perform separate pairwise matchings between the control group and each treatment group:</p>
<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb945-1"><a href="sec-selection-on-observables.html#cb945-1" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb945-2"><a href="sec-selection-on-observables.html#cb945-2" tabindex="-1"></a><span class="fu">library</span>(MatchIt)</span>
<span id="cb945-3"><a href="sec-selection-on-observables.html#cb945-3" tabindex="-1"></a><span class="fu">library</span>(cobalt)  <span class="co"># For balance checking</span></span>
<span id="cb945-4"><a href="sec-selection-on-observables.html#cb945-4" tabindex="-1"></a></span>
<span id="cb945-5"><a href="sec-selection-on-observables.html#cb945-5" tabindex="-1"></a><span class="co"># Example dataset: Simulated</span></span>
<span id="cb945-6"><a href="sec-selection-on-observables.html#cb945-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb945-7"><a href="sec-selection-on-observables.html#cb945-7" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb945-8"><a href="sec-selection-on-observables.html#cb945-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb945-9"><a href="sec-selection-on-observables.html#cb945-9" tabindex="-1"></a>  <span class="at">treat =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>)),</span>
<span id="cb945-10"><a href="sec-selection-on-observables.html#cb945-10" tabindex="-1"></a>  <span class="at">cov1 =</span> <span class="fu">rnorm</span>(n),</span>
<span id="cb945-11"><a href="sec-selection-on-observables.html#cb945-11" tabindex="-1"></a>  <span class="at">cov2 =</span> <span class="fu">runif</span>(n),</span>
<span id="cb945-12"><a href="sec-selection-on-observables.html#cb945-12" tabindex="-1"></a>  <span class="at">cov3 =</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>),</span>
<span id="cb945-13"><a href="sec-selection-on-observables.html#cb945-13" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb945-14"><a href="sec-selection-on-observables.html#cb945-14" tabindex="-1"></a>)</span>
<span id="cb945-15"><a href="sec-selection-on-observables.html#cb945-15" tabindex="-1"></a></span>
<span id="cb945-16"><a href="sec-selection-on-observables.html#cb945-16" tabindex="-1"></a><span class="co"># Define treatment levels</span></span>
<span id="cb945-17"><a href="sec-selection-on-observables.html#cb945-17" tabindex="-1"></a>treatment_levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)</span>
<span id="cb945-18"><a href="sec-selection-on-observables.html#cb945-18" tabindex="-1"></a>control_level <span class="ot">&lt;-</span> <span class="st">&quot;control&quot;</span></span>
<span id="cb945-19"><a href="sec-selection-on-observables.html#cb945-19" tabindex="-1"></a></span>
<span id="cb945-20"><a href="sec-selection-on-observables.html#cb945-20" tabindex="-1"></a><span class="co"># Initialize weight column</span></span>
<span id="cb945-21"><a href="sec-selection-on-observables.html#cb945-21" tabindex="-1"></a>df<span class="sc">$</span>match.weights <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb945-22"><a href="sec-selection-on-observables.html#cb945-22" tabindex="-1"></a></span>
<span id="cb945-23"><a href="sec-selection-on-observables.html#cb945-23" tabindex="-1"></a><span class="co"># Perform pairwise matching of each treatment group vs control</span></span>
<span id="cb945-24"><a href="sec-selection-on-observables.html#cb945-24" tabindex="-1"></a><span class="cf">for</span> (treat <span class="cf">in</span> treatment_levels) {</span>
<span id="cb945-25"><a href="sec-selection-on-observables.html#cb945-25" tabindex="-1"></a>  <span class="co"># Subset to control and current treatment</span></span>
<span id="cb945-26"><a href="sec-selection-on-observables.html#cb945-26" tabindex="-1"></a>  subset_df <span class="ot">&lt;-</span> df[df<span class="sc">$</span>treat <span class="sc">%in%</span> <span class="fu">c</span>(treat, control_level), ]</span>
<span id="cb945-27"><a href="sec-selection-on-observables.html#cb945-27" tabindex="-1"></a>  </span>
<span id="cb945-28"><a href="sec-selection-on-observables.html#cb945-28" tabindex="-1"></a>  <span class="co"># Create a binary treatment variable: 1 for current treatment, 0 for control</span></span>
<span id="cb945-29"><a href="sec-selection-on-observables.html#cb945-29" tabindex="-1"></a>  subset_df<span class="sc">$</span>treat_binary <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(subset_df<span class="sc">$</span>treat <span class="sc">==</span> treat)</span>
<span id="cb945-30"><a href="sec-selection-on-observables.html#cb945-30" tabindex="-1"></a></span>
<span id="cb945-31"><a href="sec-selection-on-observables.html#cb945-31" tabindex="-1"></a>  <span class="co"># Run matching</span></span>
<span id="cb945-32"><a href="sec-selection-on-observables.html#cb945-32" tabindex="-1"></a>  m.out <span class="ot">&lt;-</span> <span class="fu">matchit</span>(treat_binary <span class="sc">~</span> cov1 <span class="sc">+</span> cov2 <span class="sc">+</span> cov3,</span>
<span id="cb945-33"><a href="sec-selection-on-observables.html#cb945-33" tabindex="-1"></a>                   <span class="at">data =</span> subset_df, <span class="at">method =</span> <span class="st">&quot;nearest&quot;</span>)</span>
<span id="cb945-34"><a href="sec-selection-on-observables.html#cb945-34" tabindex="-1"></a></span>
<span id="cb945-35"><a href="sec-selection-on-observables.html#cb945-35" tabindex="-1"></a>  <span class="co"># Assign weights back to the original dataset</span></span>
<span id="cb945-36"><a href="sec-selection-on-observables.html#cb945-36" tabindex="-1"></a>  matched_units <span class="ot">&lt;-</span> <span class="fu">names</span>(m.out<span class="sc">$</span>weights[m.out<span class="sc">$</span>weights <span class="sc">&gt;</span> <span class="dv">0</span>])</span>
<span id="cb945-37"><a href="sec-selection-on-observables.html#cb945-37" tabindex="-1"></a>  df[matched_units, <span class="st">&quot;match.weights&quot;</span>] <span class="ot">&lt;-</span> m.out<span class="sc">$</span>weights[matched_units]</span>
<span id="cb945-38"><a href="sec-selection-on-observables.html#cb945-38" tabindex="-1"></a>}</span>
<span id="cb945-39"><a href="sec-selection-on-observables.html#cb945-39" tabindex="-1"></a></span>
<span id="cb945-40"><a href="sec-selection-on-observables.html#cb945-40" tabindex="-1"></a><span class="co"># Check covariate balance</span></span>
<span id="cb945-41"><a href="sec-selection-on-observables.html#cb945-41" tabindex="-1"></a><span class="fu">bal.tab</span>(treat <span class="sc">~</span> cov1 <span class="sc">+</span> cov2 <span class="sc">+</span> cov3, <span class="at">data =</span> df,</span>
<span id="cb945-42"><a href="sec-selection-on-observables.html#cb945-42" tabindex="-1"></a>        <span class="at">weights =</span> df<span class="sc">$</span>match.weights, <span class="at">method =</span> <span class="st">&quot;matching&quot;</span>)</span>
<span id="cb945-43"><a href="sec-selection-on-observables.html#cb945-43" tabindex="-1"></a><span class="co">#&gt; Balance summary across all treatment pairs</span></span>
<span id="cb945-44"><a href="sec-selection-on-observables.html#cb945-44" tabindex="-1"></a><span class="co">#&gt;         Type Max.Diff.Adj</span></span>
<span id="cb945-45"><a href="sec-selection-on-observables.html#cb945-45" tabindex="-1"></a><span class="co">#&gt; cov1 Contin.       0.2200</span></span>
<span id="cb945-46"><a href="sec-selection-on-observables.html#cb945-46" tabindex="-1"></a><span class="co">#&gt; cov2 Contin.       0.1416</span></span>
<span id="cb945-47"><a href="sec-selection-on-observables.html#cb945-47" tabindex="-1"></a><span class="co">#&gt; cov3  Binary       0.0412</span></span>
<span id="cb945-48"><a href="sec-selection-on-observables.html#cb945-48" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb945-49"><a href="sec-selection-on-observables.html#cb945-49" tabindex="-1"></a><span class="co">#&gt; Sample sizes</span></span>
<span id="cb945-50"><a href="sec-selection-on-observables.html#cb945-50" tabindex="-1"></a><span class="co">#&gt;           A  B  C control</span></span>
<span id="cb945-51"><a href="sec-selection-on-observables.html#cb945-51" tabindex="-1"></a><span class="co">#&gt; All     104 97 85     114</span></span>
<span id="cb945-52"><a href="sec-selection-on-observables.html#cb945-52" tabindex="-1"></a><span class="co">#&gt; Matched 104 97 85     114</span></span>
<span id="cb945-53"><a href="sec-selection-on-observables.html#cb945-53" tabindex="-1"></a></span>
<span id="cb945-54"><a href="sec-selection-on-observables.html#cb945-54" tabindex="-1"></a><span class="co"># Estimate treatment effects using weighted regression</span></span>
<span id="cb945-55"><a href="sec-selection-on-observables.html#cb945-55" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(outcome <span class="sc">~</span> <span class="fu">relevel</span>(treat, <span class="at">ref =</span> <span class="st">&quot;control&quot;</span>),</span>
<span id="cb945-56"><a href="sec-selection-on-observables.html#cb945-56" tabindex="-1"></a>             <span class="at">data =</span> df[df<span class="sc">$</span>match.weights <span class="sc">&gt;</span> <span class="dv">0</span>, ],</span>
<span id="cb945-57"><a href="sec-selection-on-observables.html#cb945-57" tabindex="-1"></a>             <span class="at">weights =</span> match.weights)</span>
<span id="cb945-58"><a href="sec-selection-on-observables.html#cb945-58" tabindex="-1"></a></span>
<span id="cb945-59"><a href="sec-selection-on-observables.html#cb945-59" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb945-60"><a href="sec-selection-on-observables.html#cb945-60" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb945-61"><a href="sec-selection-on-observables.html#cb945-61" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb945-62"><a href="sec-selection-on-observables.html#cb945-62" tabindex="-1"></a><span class="co">#&gt; glm(formula = outcome ~ relevel(treat, ref = &quot;control&quot;), data = df[df$match.weights &gt; </span></span>
<span id="cb945-63"><a href="sec-selection-on-observables.html#cb945-63" tabindex="-1"></a><span class="co">#&gt;     0, ], weights = match.weights)</span></span>
<span id="cb945-64"><a href="sec-selection-on-observables.html#cb945-64" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb945-65"><a href="sec-selection-on-observables.html#cb945-65" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb945-66"><a href="sec-selection-on-observables.html#cb945-66" tabindex="-1"></a><span class="co">#&gt;                                  Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb945-67"><a href="sec-selection-on-observables.html#cb945-67" tabindex="-1"></a><span class="co">#&gt; (Intercept)                      -0.03758    0.09349  -0.402    0.688</span></span>
<span id="cb945-68"><a href="sec-selection-on-observables.html#cb945-68" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)A  0.08584    0.13536   0.634    0.526</span></span>
<span id="cb945-69"><a href="sec-selection-on-observables.html#cb945-69" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)B  0.06877    0.13789   0.499    0.618</span></span>
<span id="cb945-70"><a href="sec-selection-on-observables.html#cb945-70" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)C  0.03806    0.14305   0.266    0.790</span></span>
<span id="cb945-71"><a href="sec-selection-on-observables.html#cb945-71" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb945-72"><a href="sec-selection-on-observables.html#cb945-72" tabindex="-1"></a><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.9964463)</span></span>
<span id="cb945-73"><a href="sec-selection-on-observables.html#cb945-73" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb945-74"><a href="sec-selection-on-observables.html#cb945-74" tabindex="-1"></a><span class="co">#&gt;     Null deviance: 395.05  on 399  degrees of freedom</span></span>
<span id="cb945-75"><a href="sec-selection-on-observables.html#cb945-75" tabindex="-1"></a><span class="co">#&gt; Residual deviance: 394.59  on 396  degrees of freedom</span></span>
<span id="cb945-76"><a href="sec-selection-on-observables.html#cb945-76" tabindex="-1"></a><span class="co">#&gt; AIC: 1139.7</span></span>
<span id="cb945-77"><a href="sec-selection-on-observables.html#cb945-77" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb945-78"><a href="sec-selection-on-observables.html#cb945-78" tabindex="-1"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
<p>This approach estimates the <strong>ATT for each treatment group</strong> relative to the control. That is, for each treated group (e.g., A, B, or C), we ask: <em>what would the outcome have been if those who received treatment had instead received the control?</em></p>
<ol start="2" style="list-style-type: decimal">
<li>Estimating the ATC Using <code>MatchIt</code></li>
</ol>
<p>In some cases, we may wish to estimate the ATC‚Äîi.e., what would have happened to the control group if they had received each of the treatments. To do this, we match <strong>control units to each treated group</strong>, reversing the focal population. Practically, this means keeping the control group intact and separately matching each treatment group to it.</p>
<div class="sourceCode" id="cb946"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb946-1"><a href="sec-selection-on-observables.html#cb946-1" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb946-2"><a href="sec-selection-on-observables.html#cb946-2" tabindex="-1"></a><span class="fu">library</span>(MatchIt)</span>
<span id="cb946-3"><a href="sec-selection-on-observables.html#cb946-3" tabindex="-1"></a><span class="fu">library</span>(cobalt)</span>
<span id="cb946-4"><a href="sec-selection-on-observables.html#cb946-4" tabindex="-1"></a></span>
<span id="cb946-5"><a href="sec-selection-on-observables.html#cb946-5" tabindex="-1"></a><span class="co"># Simulate example data</span></span>
<span id="cb946-6"><a href="sec-selection-on-observables.html#cb946-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb946-7"><a href="sec-selection-on-observables.html#cb946-7" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb946-8"><a href="sec-selection-on-observables.html#cb946-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb946-9"><a href="sec-selection-on-observables.html#cb946-9" tabindex="-1"></a>  <span class="at">treat =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>)),</span>
<span id="cb946-10"><a href="sec-selection-on-observables.html#cb946-10" tabindex="-1"></a>  <span class="at">cov1 =</span> <span class="fu">rnorm</span>(n),</span>
<span id="cb946-11"><a href="sec-selection-on-observables.html#cb946-11" tabindex="-1"></a>  <span class="at">cov2 =</span> <span class="fu">runif</span>(n),</span>
<span id="cb946-12"><a href="sec-selection-on-observables.html#cb946-12" tabindex="-1"></a>  <span class="at">cov3 =</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>),</span>
<span id="cb946-13"><a href="sec-selection-on-observables.html#cb946-13" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb946-14"><a href="sec-selection-on-observables.html#cb946-14" tabindex="-1"></a>)</span>
<span id="cb946-15"><a href="sec-selection-on-observables.html#cb946-15" tabindex="-1"></a></span>
<span id="cb946-16"><a href="sec-selection-on-observables.html#cb946-16" tabindex="-1"></a><span class="co"># Define treatment levels</span></span>
<span id="cb946-17"><a href="sec-selection-on-observables.html#cb946-17" tabindex="-1"></a>treatment_levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>)</span>
<span id="cb946-18"><a href="sec-selection-on-observables.html#cb946-18" tabindex="-1"></a>control_level <span class="ot">&lt;-</span> <span class="st">&quot;control&quot;</span></span>
<span id="cb946-19"><a href="sec-selection-on-observables.html#cb946-19" tabindex="-1"></a></span>
<span id="cb946-20"><a href="sec-selection-on-observables.html#cb946-20" tabindex="-1"></a><span class="co"># Initialize weight column</span></span>
<span id="cb946-21"><a href="sec-selection-on-observables.html#cb946-21" tabindex="-1"></a>df<span class="sc">$</span>match.weights <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb946-22"><a href="sec-selection-on-observables.html#cb946-22" tabindex="-1"></a></span>
<span id="cb946-23"><a href="sec-selection-on-observables.html#cb946-23" tabindex="-1"></a><span class="co"># Estimate ATC by matching treated units to the control group</span></span>
<span id="cb946-24"><a href="sec-selection-on-observables.html#cb946-24" tabindex="-1"></a><span class="cf">for</span> (treat <span class="cf">in</span> treatment_levels) {</span>
<span id="cb946-25"><a href="sec-selection-on-observables.html#cb946-25" tabindex="-1"></a>  <span class="co"># Subset to current treatment and control</span></span>
<span id="cb946-26"><a href="sec-selection-on-observables.html#cb946-26" tabindex="-1"></a>  subset_df <span class="ot">&lt;-</span> df[df<span class="sc">$</span>treat <span class="sc">%in%</span> <span class="fu">c</span>(treat, control_level), ]</span>
<span id="cb946-27"><a href="sec-selection-on-observables.html#cb946-27" tabindex="-1"></a>  </span>
<span id="cb946-28"><a href="sec-selection-on-observables.html#cb946-28" tabindex="-1"></a>  <span class="co"># Binary treatment variable: 0 for treatment group, 1 for control</span></span>
<span id="cb946-29"><a href="sec-selection-on-observables.html#cb946-29" tabindex="-1"></a>  <span class="co"># This reverses the focus, targeting the control as the treated group</span></span>
<span id="cb946-30"><a href="sec-selection-on-observables.html#cb946-30" tabindex="-1"></a>  subset_df<span class="sc">$</span>treat_binary <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(subset_df<span class="sc">$</span>treat <span class="sc">==</span> control_level)</span>
<span id="cb946-31"><a href="sec-selection-on-observables.html#cb946-31" tabindex="-1"></a></span>
<span id="cb946-32"><a href="sec-selection-on-observables.html#cb946-32" tabindex="-1"></a>  <span class="co"># Perform matching</span></span>
<span id="cb946-33"><a href="sec-selection-on-observables.html#cb946-33" tabindex="-1"></a>  m.out <span class="ot">&lt;-</span> <span class="fu">matchit</span>(treat_binary <span class="sc">~</span> cov1 <span class="sc">+</span> cov2 <span class="sc">+</span> cov3,</span>
<span id="cb946-34"><a href="sec-selection-on-observables.html#cb946-34" tabindex="-1"></a>                   <span class="at">data =</span> subset_df, <span class="at">method =</span> <span class="st">&quot;nearest&quot;</span>)</span>
<span id="cb946-35"><a href="sec-selection-on-observables.html#cb946-35" tabindex="-1"></a>  </span>
<span id="cb946-36"><a href="sec-selection-on-observables.html#cb946-36" tabindex="-1"></a>  <span class="co"># Extract matched unit IDs</span></span>
<span id="cb946-37"><a href="sec-selection-on-observables.html#cb946-37" tabindex="-1"></a>  matched_ids <span class="ot">&lt;-</span> <span class="fu">names</span>(m.out<span class="sc">$</span>weights[m.out<span class="sc">$</span>weights <span class="sc">&gt;</span> <span class="dv">0</span>])</span>
<span id="cb946-38"><a href="sec-selection-on-observables.html#cb946-38" tabindex="-1"></a>  </span>
<span id="cb946-39"><a href="sec-selection-on-observables.html#cb946-39" tabindex="-1"></a>  <span class="co"># Assign weights back to original dataset</span></span>
<span id="cb946-40"><a href="sec-selection-on-observables.html#cb946-40" tabindex="-1"></a>  df[matched_ids, <span class="st">&quot;match.weights&quot;</span>] <span class="ot">&lt;-</span> m.out<span class="sc">$</span>weights[matched_ids]</span>
<span id="cb946-41"><a href="sec-selection-on-observables.html#cb946-41" tabindex="-1"></a>}</span>
<span id="cb946-42"><a href="sec-selection-on-observables.html#cb946-42" tabindex="-1"></a></span>
<span id="cb946-43"><a href="sec-selection-on-observables.html#cb946-43" tabindex="-1"></a><span class="co"># Check balance (optional)</span></span>
<span id="cb946-44"><a href="sec-selection-on-observables.html#cb946-44" tabindex="-1"></a><span class="fu">bal.tab</span>(treat <span class="sc">~</span> cov1 <span class="sc">+</span> cov2 <span class="sc">+</span> cov3, <span class="at">data =</span> df,</span>
<span id="cb946-45"><a href="sec-selection-on-observables.html#cb946-45" tabindex="-1"></a>        <span class="at">weights =</span> df<span class="sc">$</span>match.weights, <span class="at">method =</span> <span class="st">&quot;matching&quot;</span>)</span>
<span id="cb946-46"><a href="sec-selection-on-observables.html#cb946-46" tabindex="-1"></a><span class="co">#&gt; Balance summary across all treatment pairs</span></span>
<span id="cb946-47"><a href="sec-selection-on-observables.html#cb946-47" tabindex="-1"></a><span class="co">#&gt;         Type Max.Diff.Adj</span></span>
<span id="cb946-48"><a href="sec-selection-on-observables.html#cb946-48" tabindex="-1"></a><span class="co">#&gt; cov1 Contin.       0.1229</span></span>
<span id="cb946-49"><a href="sec-selection-on-observables.html#cb946-49" tabindex="-1"></a><span class="co">#&gt; cov2 Contin.       0.2695</span></span>
<span id="cb946-50"><a href="sec-selection-on-observables.html#cb946-50" tabindex="-1"></a><span class="co">#&gt; cov3  Binary       0.1985</span></span>
<span id="cb946-51"><a href="sec-selection-on-observables.html#cb946-51" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb946-52"><a href="sec-selection-on-observables.html#cb946-52" tabindex="-1"></a><span class="co">#&gt; Sample sizes</span></span>
<span id="cb946-53"><a href="sec-selection-on-observables.html#cb946-53" tabindex="-1"></a><span class="co">#&gt;            A  B  C control</span></span>
<span id="cb946-54"><a href="sec-selection-on-observables.html#cb946-54" tabindex="-1"></a><span class="co">#&gt; All       99 90 98     113</span></span>
<span id="cb946-55"><a href="sec-selection-on-observables.html#cb946-55" tabindex="-1"></a><span class="co">#&gt; Matched   99 90 98     111</span></span>
<span id="cb946-56"><a href="sec-selection-on-observables.html#cb946-56" tabindex="-1"></a><span class="co">#&gt; Unmatched  0  0  0       2</span></span>
<span id="cb946-57"><a href="sec-selection-on-observables.html#cb946-57" tabindex="-1"></a></span>
<span id="cb946-58"><a href="sec-selection-on-observables.html#cb946-58" tabindex="-1"></a><span class="co"># Estimate ATC via weighted regression</span></span>
<span id="cb946-59"><a href="sec-selection-on-observables.html#cb946-59" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(outcome <span class="sc">~</span> <span class="fu">relevel</span>(treat, <span class="at">ref =</span> <span class="st">&quot;control&quot;</span>),</span>
<span id="cb946-60"><a href="sec-selection-on-observables.html#cb946-60" tabindex="-1"></a>             <span class="at">data =</span> df[df<span class="sc">$</span>match.weights <span class="sc">&gt;</span> <span class="dv">0</span>, ],</span>
<span id="cb946-61"><a href="sec-selection-on-observables.html#cb946-61" tabindex="-1"></a>             <span class="at">weights =</span> match.weights)</span>
<span id="cb946-62"><a href="sec-selection-on-observables.html#cb946-62" tabindex="-1"></a></span>
<span id="cb946-63"><a href="sec-selection-on-observables.html#cb946-63" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb946-64"><a href="sec-selection-on-observables.html#cb946-64" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb946-65"><a href="sec-selection-on-observables.html#cb946-65" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb946-66"><a href="sec-selection-on-observables.html#cb946-66" tabindex="-1"></a><span class="co">#&gt; glm(formula = outcome ~ relevel(treat, ref = &quot;control&quot;), data = df[df$match.weights &gt; </span></span>
<span id="cb946-67"><a href="sec-selection-on-observables.html#cb946-67" tabindex="-1"></a><span class="co">#&gt;     0, ], weights = match.weights)</span></span>
<span id="cb946-68"><a href="sec-selection-on-observables.html#cb946-68" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb946-69"><a href="sec-selection-on-observables.html#cb946-69" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb946-70"><a href="sec-selection-on-observables.html#cb946-70" tabindex="-1"></a><span class="co">#&gt;                                  Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb946-71"><a href="sec-selection-on-observables.html#cb946-71" tabindex="-1"></a><span class="co">#&gt; (Intercept)                       0.06826    0.09176   0.744    0.457</span></span>
<span id="cb946-72"><a href="sec-selection-on-observables.html#cb946-72" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)A -0.05103    0.13364  -0.382    0.703</span></span>
<span id="cb946-73"><a href="sec-selection-on-observables.html#cb946-73" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)B  0.08667    0.13713   0.632    0.528</span></span>
<span id="cb946-74"><a href="sec-selection-on-observables.html#cb946-74" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)C  0.09488    0.13400   0.708    0.479</span></span>
<span id="cb946-75"><a href="sec-selection-on-observables.html#cb946-75" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb946-76"><a href="sec-selection-on-observables.html#cb946-76" tabindex="-1"></a><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.9346181)</span></span>
<span id="cb946-77"><a href="sec-selection-on-observables.html#cb946-77" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb946-78"><a href="sec-selection-on-observables.html#cb946-78" tabindex="-1"></a><span class="co">#&gt;     Null deviance: 369.69  on 397  degrees of freedom</span></span>
<span id="cb946-79"><a href="sec-selection-on-observables.html#cb946-79" tabindex="-1"></a><span class="co">#&gt; Residual deviance: 368.24  on 394  degrees of freedom</span></span>
<span id="cb946-80"><a href="sec-selection-on-observables.html#cb946-80" tabindex="-1"></a><span class="co">#&gt; AIC: 1108.5</span></span>
<span id="cb946-81"><a href="sec-selection-on-observables.html#cb946-81" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb946-82"><a href="sec-selection-on-observables.html#cb946-82" tabindex="-1"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Regression and Effect Estimation</li>
</ol>
<p>After constructing the matched dataset, one can use regression on the matched sample to estimate the treatment effects:</p>
<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb947-1"><a href="sec-selection-on-observables.html#cb947-1" tabindex="-1"></a><span class="co"># Subset the data first</span></span>
<span id="cb947-2"><a href="sec-selection-on-observables.html#cb947-2" tabindex="-1"></a>matched_data <span class="ot">&lt;-</span> df[df<span class="sc">$</span>match.weights <span class="sc">&gt;</span> <span class="dv">0</span>, ]</span>
<span id="cb947-3"><a href="sec-selection-on-observables.html#cb947-3" tabindex="-1"></a></span>
<span id="cb947-4"><a href="sec-selection-on-observables.html#cb947-4" tabindex="-1"></a><span class="co"># Then fit the weighted regression using the weights from the subset</span></span>
<span id="cb947-5"><a href="sec-selection-on-observables.html#cb947-5" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(outcome <span class="sc">~</span> <span class="fu">relevel</span>(treat, <span class="at">ref =</span> <span class="st">&quot;control&quot;</span>),</span>
<span id="cb947-6"><a href="sec-selection-on-observables.html#cb947-6" tabindex="-1"></a>             <span class="at">data =</span> matched_data,</span>
<span id="cb947-7"><a href="sec-selection-on-observables.html#cb947-7" tabindex="-1"></a>             <span class="at">weights =</span> matched_data<span class="sc">$</span>match.weights)</span>
<span id="cb947-8"><a href="sec-selection-on-observables.html#cb947-8" tabindex="-1"></a></span>
<span id="cb947-9"><a href="sec-selection-on-observables.html#cb947-9" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb947-10"><a href="sec-selection-on-observables.html#cb947-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb947-11"><a href="sec-selection-on-observables.html#cb947-11" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb947-12"><a href="sec-selection-on-observables.html#cb947-12" tabindex="-1"></a><span class="co">#&gt; glm(formula = outcome ~ relevel(treat, ref = &quot;control&quot;), data = matched_data, </span></span>
<span id="cb947-13"><a href="sec-selection-on-observables.html#cb947-13" tabindex="-1"></a><span class="co">#&gt;     weights = matched_data$match.weights)</span></span>
<span id="cb947-14"><a href="sec-selection-on-observables.html#cb947-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb947-15"><a href="sec-selection-on-observables.html#cb947-15" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb947-16"><a href="sec-selection-on-observables.html#cb947-16" tabindex="-1"></a><span class="co">#&gt;                                  Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb947-17"><a href="sec-selection-on-observables.html#cb947-17" tabindex="-1"></a><span class="co">#&gt; (Intercept)                       0.06826    0.09176   0.744    0.457</span></span>
<span id="cb947-18"><a href="sec-selection-on-observables.html#cb947-18" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)A -0.05103    0.13364  -0.382    0.703</span></span>
<span id="cb947-19"><a href="sec-selection-on-observables.html#cb947-19" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)B  0.08667    0.13713   0.632    0.528</span></span>
<span id="cb947-20"><a href="sec-selection-on-observables.html#cb947-20" tabindex="-1"></a><span class="co">#&gt; relevel(treat, ref = &quot;control&quot;)C  0.09488    0.13400   0.708    0.479</span></span>
<span id="cb947-21"><a href="sec-selection-on-observables.html#cb947-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb947-22"><a href="sec-selection-on-observables.html#cb947-22" tabindex="-1"></a><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.9346181)</span></span>
<span id="cb947-23"><a href="sec-selection-on-observables.html#cb947-23" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb947-24"><a href="sec-selection-on-observables.html#cb947-24" tabindex="-1"></a><span class="co">#&gt;     Null deviance: 369.69  on 397  degrees of freedom</span></span>
<span id="cb947-25"><a href="sec-selection-on-observables.html#cb947-25" tabindex="-1"></a><span class="co">#&gt; Residual deviance: 368.24  on 394  degrees of freedom</span></span>
<span id="cb947-26"><a href="sec-selection-on-observables.html#cb947-26" tabindex="-1"></a><span class="co">#&gt; AIC: 1108.5</span></span>
<span id="cb947-27"><a href="sec-selection-on-observables.html#cb947-27" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb947-28"><a href="sec-selection-on-observables.html#cb947-28" tabindex="-1"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
<p>Caveats and Limitations</p>
<ul>
<li><p>Matching one treatment group at a time does not preserve global covariate balance across all treatment groups, only pairwise balance with the control.</p></li>
<li><p>Overlap (common support) assumptions should be verified individually for each pairwise comparison.</p></li>
<li><p>Matched samples may vary for each comparison, complicating aggregate inference or joint hypothesis testing.</p></li>
</ul>
<hr />
</div>
<div id="alternative-weighting-for-multiple-treatments-with-weightit" class="section level4 hasAnchor" number="35.9.11.3">
<h4><span class="header-section-number">35.9.11.3</span> Alternative: Weighting for Multiple Treatments with <code>WeightIt</code><a href="sec-selection-on-observables.html#alternative-weighting-for-multiple-treatments-with-weightit" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Matching can be cumbersome in multiple-treatment settings. Weighting approaches offer a more seamless framework, especially when estimating ATE or ATC across all treatment levels simultaneously. The <code>WeightIt</code> package extends propensity score weighting to multi-treatment scenarios with strong support for diagnostics and flexible estimation.</p>
<div class="sourceCode" id="cb948"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb948-1"><a href="sec-selection-on-observables.html#cb948-1" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb948-2"><a href="sec-selection-on-observables.html#cb948-2" tabindex="-1"></a><span class="fu">library</span>(WeightIt)</span>
<span id="cb948-3"><a href="sec-selection-on-observables.html#cb948-3" tabindex="-1"></a><span class="fu">library</span>(cobalt)</span>
<span id="cb948-4"><a href="sec-selection-on-observables.html#cb948-4" tabindex="-1"></a></span>
<span id="cb948-5"><a href="sec-selection-on-observables.html#cb948-5" tabindex="-1"></a><span class="co"># Simulate example data</span></span>
<span id="cb948-6"><a href="sec-selection-on-observables.html#cb948-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb948-7"><a href="sec-selection-on-observables.html#cb948-7" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb948-8"><a href="sec-selection-on-observables.html#cb948-8" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb948-9"><a href="sec-selection-on-observables.html#cb948-9" tabindex="-1"></a>  <span class="at">treat =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), n, <span class="at">replace =</span> <span class="cn">TRUE</span>)),</span>
<span id="cb948-10"><a href="sec-selection-on-observables.html#cb948-10" tabindex="-1"></a>  <span class="at">cov1 =</span> <span class="fu">rnorm</span>(n),</span>
<span id="cb948-11"><a href="sec-selection-on-observables.html#cb948-11" tabindex="-1"></a>  <span class="at">cov2 =</span> <span class="fu">runif</span>(n),</span>
<span id="cb948-12"><a href="sec-selection-on-observables.html#cb948-12" tabindex="-1"></a>  <span class="at">cov3 =</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>),</span>
<span id="cb948-13"><a href="sec-selection-on-observables.html#cb948-13" tabindex="-1"></a>  <span class="at">outcome =</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb948-14"><a href="sec-selection-on-observables.html#cb948-14" tabindex="-1"></a>)</span>
<span id="cb948-15"><a href="sec-selection-on-observables.html#cb948-15" tabindex="-1"></a></span>
<span id="cb948-16"><a href="sec-selection-on-observables.html#cb948-16" tabindex="-1"></a><span class="co"># Estimate weights for ATE across all treatment levels using multinomial logistic regression</span></span>
<span id="cb948-17"><a href="sec-selection-on-observables.html#cb948-17" tabindex="-1"></a>w.out <span class="ot">&lt;-</span> <span class="fu">weightit</span>(</span>
<span id="cb948-18"><a href="sec-selection-on-observables.html#cb948-18" tabindex="-1"></a>  treat <span class="sc">~</span> cov1 <span class="sc">+</span> cov2 <span class="sc">+</span> cov3,</span>
<span id="cb948-19"><a href="sec-selection-on-observables.html#cb948-19" tabindex="-1"></a>  <span class="at">data =</span> df,</span>
<span id="cb948-20"><a href="sec-selection-on-observables.html#cb948-20" tabindex="-1"></a>  <span class="at">estimand =</span> <span class="st">&quot;ATE&quot;</span>,</span>
<span id="cb948-21"><a href="sec-selection-on-observables.html#cb948-21" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>  <span class="co"># multinomial model when treat is a factor with &gt;2 levels</span></span>
<span id="cb948-22"><a href="sec-selection-on-observables.html#cb948-22" tabindex="-1"></a>)</span>
<span id="cb948-23"><a href="sec-selection-on-observables.html#cb948-23" tabindex="-1"></a></span>
<span id="cb948-24"><a href="sec-selection-on-observables.html#cb948-24" tabindex="-1"></a><span class="co"># Check covariate balance</span></span>
<span id="cb948-25"><a href="sec-selection-on-observables.html#cb948-25" tabindex="-1"></a><span class="fu">bal.tab</span>(w.out)</span>
<span id="cb948-26"><a href="sec-selection-on-observables.html#cb948-26" tabindex="-1"></a><span class="co">#&gt; Balance summary across all treatment pairs</span></span>
<span id="cb948-27"><a href="sec-selection-on-observables.html#cb948-27" tabindex="-1"></a><span class="co">#&gt;         Type Max.Diff.Adj</span></span>
<span id="cb948-28"><a href="sec-selection-on-observables.html#cb948-28" tabindex="-1"></a><span class="co">#&gt; cov1 Contin.       0.0309</span></span>
<span id="cb948-29"><a href="sec-selection-on-observables.html#cb948-29" tabindex="-1"></a><span class="co">#&gt; cov2 Contin.       0.0341</span></span>
<span id="cb948-30"><a href="sec-selection-on-observables.html#cb948-30" tabindex="-1"></a><span class="co">#&gt; cov3  Binary       0.0109</span></span>
<span id="cb948-31"><a href="sec-selection-on-observables.html#cb948-31" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-32"><a href="sec-selection-on-observables.html#cb948-32" tabindex="-1"></a><span class="co">#&gt; Effective sample sizes</span></span>
<span id="cb948-33"><a href="sec-selection-on-observables.html#cb948-33" tabindex="-1"></a><span class="co">#&gt;                 A     B      C control</span></span>
<span id="cb948-34"><a href="sec-selection-on-observables.html#cb948-34" tabindex="-1"></a><span class="co">#&gt; Unadjusted 112.   99.   107.     82.  </span></span>
<span id="cb948-35"><a href="sec-selection-on-observables.html#cb948-35" tabindex="-1"></a><span class="co">#&gt; Adjusted   109.59 92.71 100.11   80.73</span></span>
<span id="cb948-36"><a href="sec-selection-on-observables.html#cb948-36" tabindex="-1"></a></span>
<span id="cb948-37"><a href="sec-selection-on-observables.html#cb948-37" tabindex="-1"></a><span class="fu">bal.tab</span>(w.out, <span class="at">which.treat =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>))</span>
<span id="cb948-38"><a href="sec-selection-on-observables.html#cb948-38" tabindex="-1"></a><span class="co">#&gt; Balance by treatment pair</span></span>
<span id="cb948-39"><a href="sec-selection-on-observables.html#cb948-39" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-40"><a href="sec-selection-on-observables.html#cb948-40" tabindex="-1"></a><span class="co">#&gt;  - - - A (0) vs. B (1) - - - </span></span>
<span id="cb948-41"><a href="sec-selection-on-observables.html#cb948-41" tabindex="-1"></a><span class="co">#&gt; Balance Measures</span></span>
<span id="cb948-42"><a href="sec-selection-on-observables.html#cb948-42" tabindex="-1"></a><span class="co">#&gt;         Type Diff.Adj</span></span>
<span id="cb948-43"><a href="sec-selection-on-observables.html#cb948-43" tabindex="-1"></a><span class="co">#&gt; cov1 Contin.  -0.0211</span></span>
<span id="cb948-44"><a href="sec-selection-on-observables.html#cb948-44" tabindex="-1"></a><span class="co">#&gt; cov2 Contin.  -0.0018</span></span>
<span id="cb948-45"><a href="sec-selection-on-observables.html#cb948-45" tabindex="-1"></a><span class="co">#&gt; cov3  Binary   0.0013</span></span>
<span id="cb948-46"><a href="sec-selection-on-observables.html#cb948-46" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-47"><a href="sec-selection-on-observables.html#cb948-47" tabindex="-1"></a><span class="co">#&gt; Effective sample sizes</span></span>
<span id="cb948-48"><a href="sec-selection-on-observables.html#cb948-48" tabindex="-1"></a><span class="co">#&gt;                 A     B</span></span>
<span id="cb948-49"><a href="sec-selection-on-observables.html#cb948-49" tabindex="-1"></a><span class="co">#&gt; Unadjusted 112.   99.  </span></span>
<span id="cb948-50"><a href="sec-selection-on-observables.html#cb948-50" tabindex="-1"></a><span class="co">#&gt; Adjusted   109.59 92.71</span></span>
<span id="cb948-51"><a href="sec-selection-on-observables.html#cb948-51" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-52"><a href="sec-selection-on-observables.html#cb948-52" tabindex="-1"></a><span class="co">#&gt;  - - - A (0) vs. C (1) - - - </span></span>
<span id="cb948-53"><a href="sec-selection-on-observables.html#cb948-53" tabindex="-1"></a><span class="co">#&gt; Balance Measures</span></span>
<span id="cb948-54"><a href="sec-selection-on-observables.html#cb948-54" tabindex="-1"></a><span class="co">#&gt;         Type Diff.Adj</span></span>
<span id="cb948-55"><a href="sec-selection-on-observables.html#cb948-55" tabindex="-1"></a><span class="co">#&gt; cov1 Contin.  -0.0034</span></span>
<span id="cb948-56"><a href="sec-selection-on-observables.html#cb948-56" tabindex="-1"></a><span class="co">#&gt; cov2 Contin.   0.0322</span></span>
<span id="cb948-57"><a href="sec-selection-on-observables.html#cb948-57" tabindex="-1"></a><span class="co">#&gt; cov3  Binary   0.0109</span></span>
<span id="cb948-58"><a href="sec-selection-on-observables.html#cb948-58" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-59"><a href="sec-selection-on-observables.html#cb948-59" tabindex="-1"></a><span class="co">#&gt; Effective sample sizes</span></span>
<span id="cb948-60"><a href="sec-selection-on-observables.html#cb948-60" tabindex="-1"></a><span class="co">#&gt;                 A      C</span></span>
<span id="cb948-61"><a href="sec-selection-on-observables.html#cb948-61" tabindex="-1"></a><span class="co">#&gt; Unadjusted 112.   107.  </span></span>
<span id="cb948-62"><a href="sec-selection-on-observables.html#cb948-62" tabindex="-1"></a><span class="co">#&gt; Adjusted   109.59 100.11</span></span>
<span id="cb948-63"><a href="sec-selection-on-observables.html#cb948-63" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-64"><a href="sec-selection-on-observables.html#cb948-64" tabindex="-1"></a><span class="co">#&gt;  - - - B (0) vs. C (1) - - - </span></span>
<span id="cb948-65"><a href="sec-selection-on-observables.html#cb948-65" tabindex="-1"></a><span class="co">#&gt; Balance Measures</span></span>
<span id="cb948-66"><a href="sec-selection-on-observables.html#cb948-66" tabindex="-1"></a><span class="co">#&gt;         Type Diff.Adj</span></span>
<span id="cb948-67"><a href="sec-selection-on-observables.html#cb948-67" tabindex="-1"></a><span class="co">#&gt; cov1 Contin.   0.0176</span></span>
<span id="cb948-68"><a href="sec-selection-on-observables.html#cb948-68" tabindex="-1"></a><span class="co">#&gt; cov2 Contin.   0.0341</span></span>
<span id="cb948-69"><a href="sec-selection-on-observables.html#cb948-69" tabindex="-1"></a><span class="co">#&gt; cov3  Binary   0.0097</span></span>
<span id="cb948-70"><a href="sec-selection-on-observables.html#cb948-70" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb948-71"><a href="sec-selection-on-observables.html#cb948-71" tabindex="-1"></a><span class="co">#&gt; Effective sample sizes</span></span>
<span id="cb948-72"><a href="sec-selection-on-observables.html#cb948-72" tabindex="-1"></a><span class="co">#&gt;                B      C</span></span>
<span id="cb948-73"><a href="sec-selection-on-observables.html#cb948-73" tabindex="-1"></a><span class="co">#&gt; Unadjusted 99.   107.  </span></span>
<span id="cb948-74"><a href="sec-selection-on-observables.html#cb948-74" tabindex="-1"></a><span class="co">#&gt; Adjusted   92.71 100.11</span></span>
<span id="cb948-75"><a href="sec-selection-on-observables.html#cb948-75" tabindex="-1"></a><span class="co">#&gt;  - - - - - - - - - - - - - - - -</span></span>
<span id="cb948-76"><a href="sec-selection-on-observables.html#cb948-76" tabindex="-1"></a></span>
<span id="cb948-77"><a href="sec-selection-on-observables.html#cb948-77" tabindex="-1"></a></span>
<span id="cb948-78"><a href="sec-selection-on-observables.html#cb948-78" tabindex="-1"></a><span class="co"># Estimate treatment effects with robust SEs</span></span>
<span id="cb948-79"><a href="sec-selection-on-observables.html#cb948-79" tabindex="-1"></a><span class="fu">library</span>(jtools)</span>
<span id="cb948-80"><a href="sec-selection-on-observables.html#cb948-80" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(outcome <span class="sc">~</span> <span class="fu">relevel</span>(treat, <span class="at">ref =</span> <span class="st">&quot;control&quot;</span>),</span>
<span id="cb948-81"><a href="sec-selection-on-observables.html#cb948-81" tabindex="-1"></a>             <span class="at">data =</span> df,</span>
<span id="cb948-82"><a href="sec-selection-on-observables.html#cb948-82" tabindex="-1"></a>             <span class="at">weights =</span> w.out<span class="sc">$</span>weights)</span>
<span id="cb948-83"><a href="sec-selection-on-observables.html#cb948-83" tabindex="-1"></a><span class="fu">summ</span>(model, <span class="at">robust =</span> <span class="st">&quot;HC1&quot;</span>)</span></code></pre></div>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Observations
</td>
<td style="text-align:right;">
400
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Dependent variable
</td>
<td style="text-align:right;">
outcome
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Type
</td>
<td style="text-align:right;">
Linear regression
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
œá¬≤(3)
</td>
<td style="text-align:right;">
33.68
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
p
</td>
<td style="text-align:right;">
0.03
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Pseudo-R¬≤ (Cragg-Uhler)
</td>
<td style="text-align:right;">
0.02
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Pseudo-R¬≤ (McFadden)
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
AIC
</td>
<td style="text-align:right;">
1143.60
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
BIC
</td>
<td style="text-align:right;">
1163.56
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Est.
</th>
<th style="text-align:right;">
S.E.
</th>
<th style="text-align:right;">
t val.
</th>
<th style="text-align:right;">
p
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
(Intercept)
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
-1.93
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
relevel(treat, ref = ‚Äúcontrol‚Äù)A
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
1.74
</td>
<td style="text-align:right;">
0.08
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
relevel(treat, ref = ‚Äúcontrol‚Äù)B
</td>
<td style="text-align:right;">
-0.03
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
0.83
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
relevel(treat, ref = ‚Äúcontrol‚Äù)C
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<sup></sup> Standard errors: Robust, type = HC1
</td>
</tr>
</tfoot>
</table>
<p>Additional Notes:</p>
<ul>
<li><p>To estimate the ATT for a specific treatment (e.g., treatment A), set <code>focal = "A"</code> and <code>estimand = "ATT"</code> in <code>weightit()</code>.</p></li>
<li><p>Setting <code>method = "gbm"</code> in <code>WeightIt</code> will use boosted models, equivalent to the <code>twang</code> package.</p></li>
<li><p>Weighting approaches avoid sample size loss from discarding unmatched units and provide smoother covariate balance optimization.</p></li>
</ul>
</div>
<div id="summary-matching-vs.-weighting-in-multi-treatment-settings" class="section level4 hasAnchor" number="35.9.11.4">
<h4><span class="header-section-number">35.9.11.4</span> Summary: Matching vs.¬†Weighting in Multi-Treatment Settings<a href="sec-selection-on-observables.html#summary-matching-vs.-weighting-in-multi-treatment-settings" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<table>
<colgroup>
<col width="7%" />
<col width="21%" />
<col width="12%" />
<col width="24%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Approach</th>
<th>Estimands Supported</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>MatchIt</code></td>
<td>Pairwise matching (manual)</td>
<td>ATT, ATC</td>
<td>Intuitive; transparent matched pairs</td>
<td>Manual; repeated steps; limited to pairwise comparisons</td>
</tr>
<tr class="even">
<td><code>WeightIt</code></td>
<td>Simultaneous weighting</td>
<td>ATT, ATC, ATE</td>
<td>Flexible; single model; scalable</td>
<td>Requires model diagnostics</td>
</tr>
<tr class="odd">
<td><code>twang</code></td>
<td>Boosted weighting for GPS</td>
<td>ATT, ATE</td>
<td>Automatic tuning; longitudinal support</td>
<td>More complex interface</td>
</tr>
<tr class="even">
<td><code>CBPS</code></td>
<td>Balance-constrained GPS estimation</td>
<td>ATT, ATE</td>
<td>Direct balance optimization</td>
<td>May require customization</td>
</tr>
</tbody>
</table>
<p>In general, weighting is more scalable and coherent for estimating causal effects in multi-treatment contexts, while matching can be useful when interpretability and transparency of individual pairings is important.</p>
<hr />
</div>
</div>
<div id="matching-for-multi-level-treatments" class="section level3 hasAnchor" number="35.9.12">
<h3><span class="header-section-number">35.9.12</span> Matching for Multi-Level Treatments<a href="sec-selection-on-observables.html#matching-for-multi-level-treatments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Some treatments are not just categorical, but <strong>ordinal</strong> (multi-level), such as ‚Äúlow‚Äù, ‚Äúmedium‚Äù, and ‚Äúhigh‚Äù dosage levels. These differ from multinomial treatments in that the levels have a <strong>natural order</strong>. Incorporating this structure can improve both estimation efficiency and interpretability.</p>
<div id="propensity-score-estimation" class="section level4 hasAnchor" number="35.9.12.1">
<h4><span class="header-section-number">35.9.12.1</span> Propensity Score Estimation<a href="sec-selection-on-observables.html#propensity-score-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this context, researchers often use <strong>ordinal logistic regression</strong> to estimate the probability of being in each treatment level:</p>
<p><span class="math display">\[
\text{logit}\left(\mathbb{P}(T \leq t \mid X)\right) = \alpha_t - X^\top \beta
\]</span></p>
<p>This model imposes the <strong>proportional odds assumption</strong>, where the log-odds are linear in covariates but share the same coefficients across cutoffs.</p>
</div>
<div id="matching-strategies" class="section level4 hasAnchor" number="35.9.12.2">
<h4><span class="header-section-number">35.9.12.2</span> Matching Strategies<a href="sec-selection-on-observables.html#matching-strategies" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="citation">Yang et al. (<a href="#ref-yang2016propensity">2016</a>)</span> provide a framework for matching with ordinal treatments, arguing that matching on the <strong>generalized propensity score</strong> derived from an ordinal model helps preserve the order and improves balance. Key considerations include:</p>
<ul>
<li>Matching on estimated ordinal probabilities or cumulative logits</li>
<li>Using Mahalanobis distance in the latent score space</li>
<li>Implementing stratification or subclassification based on predicted scores</li>
</ul>
<p>A custom package, <a href="https://github.com/shuyang1987/multilevelMatching"><code>shuyang1987/multilevelMatching</code></a>, provides tools for this kind of analysis. The package includes:</p>
<ul>
<li>Functions to estimate ordinal GPS</li>
<li>Matching and subclassification routines</li>
<li>Diagnostics to evaluate covariate balance</li>
</ul>
<hr />
</div>
</div>
<div id="matching-for-repeated-treatments-time-varying-treatments" class="section level3 hasAnchor" number="35.9.13">
<h3><span class="header-section-number">35.9.13</span> Matching for Repeated Treatments (Time-Varying Treatments)<a href="sec-selection-on-observables.html#matching-for-repeated-treatments-time-varying-treatments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In longitudinal studies, treatments are often administered at multiple time points. Examples include:</p>
<ul>
<li>A patient receiving a drug in multiple doses over weeks</li>
<li>A user receiving marketing emails over several days</li>
</ul>
<p>This setting raises unique challenges, such as:</p>
<ul>
<li><strong>Time-varying confounding</strong>: Covariates affected by prior treatment may influence future treatment and outcomes</li>
<li><strong>Cumulative dose effects</strong>: Treatment assignment is no longer a one-time event</li>
</ul>
<div id="marginal-structural-models" class="section level4 hasAnchor" number="35.9.13.1">
<h4><span class="header-section-number">35.9.13.1</span> Marginal Structural Models<a href="sec-selection-on-observables.html#marginal-structural-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The most popular framework for analyzing repeated treatments is the <strong>Marginal Structural Model (MSMs)</strong>, which estimates causal effects by weighting each observation using <strong>Inverse Probability of Treatment Weights (IPTW)</strong>.</p>
<p>Let <span class="math inline">\(A_t\)</span> be the treatment at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(X_t\)</span> be time-varying covariates. The IPTW for a trajectory is:</p>
<p><span class="math display">\[
w_i = \prod_{t=1}^{T} \frac{1}{\mathbb{P}(A_{it} \mid \bar{A}_{i,t-1}, \bar{X}_{i,t})}
\]</span></p>
<p>Weights are estimated using logistic regression models at each time point. The outcome model then regresses <span class="math inline">\(Y\)</span> on <span class="math inline">\(\bar{A}_T\)</span> using the weights.</p>
<p>The <a href="https://cran.r-project.org/web/packages/twang/vignettes/iptw.pdf"><code>twang</code></a> package provides tools for:</p>
<ul>
<li>Estimating time-varying propensity scores</li>
<li>Computing IPTWs</li>
<li>Fitting marginal structural models</li>
<li>Checking covariate balance over time</li>
</ul>
<p>Practical Notes</p>
<ul>
<li>Stabilized weights help reduce variance</li>
<li>Trimming or truncating extreme weights is often necessary to maintain robust inference</li>
<li>Dynamic treatment regimes may require further generalizations such as structural nested mean models.</li>
</ul>
<hr />
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-abadie2016matching" class="csl-entry">
Abadie, Alberto, and Guido W Imbens. 2016. <span>‚ÄúMatching on the Estimated Propensity Score.‚Äù</span> <em>Econometrica</em> 84 (2): 781‚Äì807.
</div>
<div id="ref-austin2011optimal" class="csl-entry">
Austin, Peter C. 2011. <span>‚ÄúOptimal Caliper Widths for Propensity-Score Matching When Estimating Differences in Means and Differences in Proportions in Observational Studies.‚Äù</span> <em>Pharmaceutical Statistics</em> 10 (2): 150‚Äì61.
</div>
<div id="ref-bapna2018monetizing" class="csl-entry">
Bapna, Ravi, Jui Ramaprasad, and Akhmed Umyarov. 2018. <span>‚ÄúMonetizing Freemium Communities.‚Äù</span> <em>Mis Quarterly</em> 42 (3): 719‚ÄìA4.
</div>
<div id="ref-bhattacharya2007instrumental" class="csl-entry">
Bhattacharya, Jay, and William B Vogt. 2007. <span>‚ÄúDo Instrumental Variables Belong in Propensity Scores?‚Äù</span> National Bureau of Economic Research.
</div>
<div id="ref-diamond2013genetic" class="csl-entry">
Diamond, Alexis, and Jasjeet S Sekhon. 2013. <span>‚ÄúGenetic Matching for Estimating Causal Effects: A General Multivariate Matching Method for Achieving Balance in Observational Studies.‚Äù</span> <em>Review of Economics and Statistics</em> 95 (3): 932‚Äì45.
</div>
<div id="ref-eckles2021bias" class="csl-entry">
Eckles, Dean, and Eytan Bakshy. 2021. <span>‚ÄúBias and High-Dimensional Adjustment in Observational Studies of Peer Effects.‚Äù</span> <em>Journal of the American Statistical Association</em> 116 (534): 507‚Äì17.
</div>
<div id="ref-gordon2019comparison" class="csl-entry">
Gordon, Brett R, Florian Zettelmeyer, Neha Bhargava, and Dan Chapsky. 2019. <span>‚ÄúA Comparison of Approaches to Advertising Measurement: Evidence from Big Field Experiments at Facebook.‚Äù</span> <em>Marketing Science</em> 38 (2): 193‚Äì225.
</div>
<div id="ref-hainmueller2012entropy" class="csl-entry">
Hainmueller, Jens. 2012. <span>‚ÄúEntropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.‚Äù</span> <em>Political Analysis</em> 20 (1): 25‚Äì46.
</div>
<div id="ref-hirtle2020impact" class="csl-entry">
Hirtle, Beverly, Anna Kovner, and Matthew Plosser. 2020. <span>‚ÄúThe Impact of Supervision on Bank Performance.‚Äù</span> <em>The Journal of Finance</em> 75 (5): 2765‚Äì2808.
</div>
<div id="ref-iacus2012causal" class="csl-entry">
Iacus, Stefano M, Gary King, and Giuseppe Porro. 2012. <span>‚ÄúCausal Inference Without Balance Checking: Coarsened Exact Matching.‚Äù</span> <em>Political Analysis</em> 20 (1): 1‚Äì24.
</div>
<div id="ref-king2017balance" class="csl-entry">
King, Gary, Christopher Lucas, and Richard A Nielsen. 2017. <span>‚ÄúThe Balance-Sample Size Frontier in Matching Methods for Causal Inference.‚Äù</span> <em>American Journal of Political Science</em> 61 (2): 473‚Äì89.
</div>
<div id="ref-king2019propensity" class="csl-entry">
King, Gary, and Richard Nielsen. 2019. <span>‚ÄúWhy Propensity Scores Should Not Be Used for Matching.‚Äù</span> <em>Political Analysis</em> 27 (4): 435‚Äì54.
</div>
<div id="ref-li2016matching" class="csl-entry">
Li, Sheng, Nikos Vlassis, Jaya Kawale, and Yun Fu. 2016. <span>‚ÄúMatching via Dimensionality Reduction for Estimation of Treatment Effects in Digital Marketing Campaigns.‚Äù</span> In <em>IJCAI</em>, 16:3768‚Äì74.
</div>
<div id="ref-lopez2017estimation" class="csl-entry">
Lopez, Michael J, and Roee Gutman. 2017. <span>‚ÄúEstimation of Causal Effects with Multiple Treatments: A Review and New Ideas.‚Äù</span> <em>Statistical Science</em>, 432‚Äì54.
</div>
<div id="ref-mccaffrey2013tutorial" class="csl-entry">
McCaffrey, Daniel F, Beth Ann Griffin, Daniel Almirall, Mary Ellen Slaughter, Rajeev Ramchand, and Lane F Burgette. 2013. <span>‚ÄúA Tutorial on Propensity Score Estimation for Multiple Treatments Using Generalized Boosted Models.‚Äù</span> <em>Statistics in Medicine</em> 32 (19): 3388‚Äì3414.
</div>
<div id="ref-ramachandra2018deep" class="csl-entry">
Ramachandra, Vikas. 2018. <span>‚ÄúDeep Learning for Causal Inference.‚Äù</span> <em>arXiv Preprint arXiv:1803.00149</em>.
</div>
<div id="ref-rosenbaum1983central" class="csl-entry">
Rosenbaum, Paul R, and Donald B Rubin. 1983. <span>‚ÄúThe Central Role of the Propensity Score in Observational Studies for Causal Effects.‚Äù</span> <em>Biometrika</em> 70 (1): 41‚Äì55.
</div>
<div id="ref-rosenbaum1985bias" class="csl-entry">
‚Äî‚Äî‚Äî. 1985. <span>‚ÄúThe Bias Due to Incomplete Matching.‚Äù</span> <em>Biometrics</em>, 103‚Äì16.
</div>
<div id="ref-vanderweele2019principles" class="csl-entry">
VanderWeele, Tyler J. 2019. <span>‚ÄúPrinciples of Confounder Selection.‚Äù</span> <em>European Journal of Epidemiology</em> 34: 211‚Äì19.
</div>
<div id="ref-yang2016propensity" class="csl-entry">
Yang, Shu, Guido W Imbens, Zhanglin Cui, Douglas E Faries, and Zbigniew Kadziola. 2016. <span>‚ÄúPropensity Score Matching and Subclassification in Observational Studies with Multi-Level Treatments.‚Äù</span> <em>Biometrics</em> 72 (4): 1055‚Äì65.
</div>
<div id="ref-yao2018representation" class="csl-entry">
Yao, Liuyi, Sheng Li, Yaliang Li, Mengdi Huai, Jing Gao, and Aidong Zhang. 2018. <span>‚ÄúRepresentation Learning for Treatment Effect Estimation from Observational Data.‚Äù</span> <em>Advances in Neural Information Processing Systems</em> 31.
</div>
<div id="ref-zhao2021propensity" class="csl-entry">
Zhao, Qin-Yu, Jing-Chao Luo, Ying Su, Yi-Jie Zhang, Guo-Wei Tu, and Zhe Luo. 2021. <span>‚ÄúPropensity Score Matching with r: Conventional Methods and New Features.‚Äù</span> <em>Annals of Translational Medicine</em> 9 (9).
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="software-and-practical-implementation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sec-selection-on-unobservables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/mikenguyen13/data_analysis/edit/main/35-matching-methods.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/mikenguyen13/data_analysis/blob/main/35-matching-methods.Rmd",
    "text": null
  },
  "download": ["data_analysis.pdf", "data_analysis.epub", "data_analysis.mobi"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true,
    "sharing": {
      "facebook": true,
      "github": true,
      "twitter": true,
      "linkedin": true
    },
    "info": true,
    "edit": "https://github.com/mikenguyen13/data_analysis/edit/main/%s"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
