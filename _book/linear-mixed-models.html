<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 8 Linear Mixed Models | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="8.1 Dependent Data Forms of dependent data: Multivariate measurements on different individuals: (e.g., a person’s blood pressure, fat, etc are correlated) Clustered measurements: (e.g., blood...">
<meta name="generator" content="bookdown 0.35 with bs4_book()">
<meta property="og:title" content="Chapter 8 Linear Mixed Models | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/linear-mixed-models.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="8.1 Dependent Data Forms of dependent data: Multivariate measurements on different individuals: (e.g., a person’s blood pressure, fat, etc are correlated) Clustered measurements: (e.g., blood...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 8 Linear Mixed Models | A Guide on Data Analysis">
<meta name="twitter:description" content="8.1 Dependent Data Forms of dependent data: Multivariate measurements on different individuals: (e.g., a person’s blood pressure, fat, etc are correlated) Clustered measurements: (e.g., blood...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-stat.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="active" href="linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="model-specification.html"><span class="header-section-number">10</span> Model Specification</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">11</span> Imputation (Missing Data)</a></li>
<li><a class="" href="data.html"><span class="header-section-number">12</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">13</span> Variable Transformation</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">14</span> Hypothesis Testing</a></li>
<li><a class="" href="marginal-effects.html"><span class="header-section-number">15</span> Marginal Effects</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">16</span> Prediction and Estimation</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">17</span> Moderation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="causal-inference.html"><span class="header-section-number">18</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="experimental-design.html"><span class="header-section-number">19</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">20</span> Sampling</a></li>
<li><a class="" href="analysis-of-variance-anova.html"><span class="header-section-number">21</span> Analysis of Variance (ANOVA)</a></li>
<li><a class="" href="multivariate-methods.html"><span class="header-section-number">22</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="quasi-experimental.html"><span class="header-section-number">23</span> Quasi-experimental</a></li>
<li><a class="" href="regression-discontinuity.html"><span class="header-section-number">24</span> Regression Discontinuity</a></li>
<li><a class="" href="difference-in-differences.html"><span class="header-section-number">25</span> Difference-in-differences</a></li>
<li><a class="" href="synthetic-control.html"><span class="header-section-number">26</span> Synthetic Control</a></li>
<li><a class="" href="event-studies.html"><span class="header-section-number">27</span> Event Studies</a></li>
<li><a class="" href="matching-methods.html"><span class="header-section-number">28</span> Matching Methods</a></li>
<li><a class="" href="interrupted-time-series.html"><span class="header-section-number">29</span> Interrupted Time Series</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">30</span> Endogeneity</a></li>
<li><a class="" href="controls.html"><span class="header-section-number">31</span> Controls</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="mediation.html"><span class="header-section-number">32</span> Mediation</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">33</span> Directed Acyclic Graph</a></li>
<li><a class="" href="report.html"><span class="header-section-number">34</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">35</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">36</span> Sensitivity Analysis/ Robustness Check</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="linear-mixed-models" class="section level1" number="8">
<h1>
<span class="header-section-number">8</span> Linear Mixed Models<a class="anchor" aria-label="anchor" href="#linear-mixed-models"><i class="fas fa-link"></i></a>
</h1>
<div id="dependent-data" class="section level2" number="8.1">
<h2>
<span class="header-section-number">8.1</span> Dependent Data<a class="anchor" aria-label="anchor" href="#dependent-data"><i class="fas fa-link"></i></a>
</h2>
<p>Forms of dependent data:</p>
<ul>
<li>Multivariate measurements on different individuals: (e.g., a person’s blood pressure, fat, etc are correlated)</li>
<li>Clustered measurements: (e.g., blood pressure measurements of people in the same family can be correlated).</li>
<li>Repeated measurements: (e.g., measurement of cholesterol over time can be correlated) “If data are collected repeatedly on experimental material to which treatments were applied initially, the data is a repeated measure.” <span class="citation">(<a href="references.html#ref-Schabenberger_2001">Schabenberger and Pierce 2001</a>)</span>
</li>
<li>Longitudinal data: (e.g., individual’s cholesterol tracked over time are correlated): “data collected repeatedly over time in an observational study are termed longitudinal.” <span class="citation">(<a href="references.html#ref-Schabenberger_2001">Schabenberger and Pierce 2001</a>)</span>
</li>
<li>Spatial data: (e.g., measurement of individuals living in the same neighborhood are correlated)</li>
</ul>
<p>Hence, we like to account for these correlations.</p>
<p><strong>Linear Mixed Model</strong> (LMM), also known as <strong>Mixed Linear Model</strong> has 2 components:</p>
<ul>
<li><p><strong>Fixed effect</strong> (e.g, gender, age, diet, time)</p></li>
<li><p><strong>Random effects</strong> representing individual variation or auto correlation/spatial effects that imply <strong>dependent (correlated) errors</strong></p></li>
</ul>
<p>Review <a href="analysis-of-variance-anova.html#two-way-mixed-effects-anova">Two-Way Mixed Effects ANOVA</a></p>
<p>We choose to model the random subject-specific effect instead of including dummy subject covariates in our model because:</p>
<ul>
<li>reduction in the number of parameters to estimate</li>
<li>when you do inference, it would make more sense that you can infer from a population (i.e., random effect).</li>
</ul>
<p><strong>LLM Motivation</strong></p>
<p>In a repeated measurements analysis where <span class="math inline">\(Y_{ij}\)</span> is the response for the <span class="math inline">\(i\)</span>-th individual measured at the <span class="math inline">\(j\)</span>-th time,</p>
<p><span class="math inline">\(i =1,…,N\)</span> ; <span class="math inline">\(j = 1,…,n_i\)</span></p>
<p><span class="math display">\[
\mathbf{Y}_i =
\left(
\begin{array}
{c}
Y_{i1} \\
. \\
.\\
.\\
Y_{in_i}
\end{array}
\right)
\]</span></p>
<p>is all measurements for subject <span class="math inline">\(i\)</span>.</p>
<p><u><em>Stage 1: (Regression Model)</em></u> how the response changes over time for the <span class="math inline">\(i\)</span>-th subject</p>
<p><span class="math display">\[
\mathbf{Y_i = Z_i \beta_i + \epsilon_i}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(Z_i\)</span> is an <span class="math inline">\(n_i \times q\)</span> matrix of known covariates</li>
<li>
<span class="math inline">\(\beta_i\)</span> is an unknown <span class="math inline">\(q \times 1\)</span> vector of subjective -specific coefficients (regression coefficients different for each subject)</li>
<li>
<span class="math inline">\(\epsilon_i\)</span> are the random errors (typically <span class="math inline">\(\sim N(0, \sigma^2 I)\)</span>)</li>
</ul>
<p>We notice that there are two many <span class="math inline">\(\beta\)</span> to estimate here. Hence, this is the motivation for the second stage</p>
<p><u><em>Stage 2: (Parameter Model)</em></u></p>
<p><span class="math display">\[
\mathbf{\beta_i = K_i \beta + b_i}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(K_i\)</span> is a <span class="math inline">\(q \times p\)</span> matrix of known covariates</li>
<li>
<span class="math inline">\(\beta\)</span> is a <span class="math inline">\(p \times 1\)</span> vector of unknown parameter</li>
<li>
<span class="math inline">\(\mathbf{b}_i\)</span> are independent <span class="math inline">\(N(0,D)\)</span> random variables</li>
</ul>
<p>This model explain the observed variability between subjects with respect to the subject-specific regression coefficients, <span class="math inline">\(\beta_i\)</span>. We model our different coefficient (<span class="math inline">\(\beta_i\)</span>) with respect to <span class="math inline">\(\beta\)</span>.</p>
<p>Example:</p>
<p>Stage 1:</p>
<p><span class="math display">\[
Y_{ij} = \beta_{1i} + \beta_{2i}t_{ij} + \epsilon_{ij}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(j = 1,..,n_i\)</span></li>
</ul>
<p>In the matrix notation,</p>
<p><span class="math display">\[
\mathbf{Y_i} =
\left(
\begin{array}
{c}
Y_{i1} \\
.\\
Y_{in_i}
\end{array}
\right); \mathbf{Z}_i =
\left(
\begin{array}
{cc}
1 &amp; t_{i1} \\
. &amp; . \\
1 &amp; t_{in_i}
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
\beta_i =
\left(
\begin{array}
{c}
\beta_{1i} \\
\beta_{2i}
\end{array}
\right); \epsilon_i =
\left(
\begin{array}
{c}
\epsilon_{i1} \\
. \\
\epsilon_{in_i}
\end{array}
\right)
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
\mathbf{Y_i = Z_i \beta_i + \epsilon_i}
\]</span></p>
<p>Stage 2:</p>
<p><span class="math display">\[
\begin{aligned}
\beta_{1i} &amp;= \beta_0 + b_{1i} \\
\beta_{2i} &amp;= \beta_1 L_i + \beta_2 H_i + \beta_3 C_i + b_{2i}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(L_i, H_i, C_i\)</span> are indicator variables defined to 1 as the subject falls into different categories.</p>
<p>Subject specific intercepts do not depend upon treatment, with <span class="math inline">\(\beta_0\)</span> (the average response at the start of treatment), and <span class="math inline">\(\beta_1 , \beta_2, \beta_3\)</span> (the average time effects for each of three treatment groups).</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{K}_i &amp;= \left(
\begin{array}
{cccc}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; L_i &amp; H_i &amp; C_i
\end{array}
\right) \\
\beta &amp;= (\beta_0 , \beta_1, \beta_2, \beta_3)' \\
\mathbf{b}_i &amp;=
\left(
\begin{array}
{c}
b_{1i} \\
b_{2i} \\
\end{array}
\right) \\
\beta_i &amp;= \mathbf{K_i \beta + b_i}
\end{aligned}
\]</span></p>
<p>To get <span class="math inline">\(\hat{\beta}\)</span>, we can fit the model sequentially:</p>
<ol style="list-style-type: decimal">
<li>Estimate <span class="math inline">\(\hat{\beta_i}\)</span> in the first stage</li>
<li>Estimate <span class="math inline">\(\hat{\beta}\)</span> in the second stage by replacing <span class="math inline">\(\beta_i\)</span> with <span class="math inline">\(\hat{\beta}_i\)</span>
</li>
</ol>
<p>However, problems arise from this method:</p>
<ul>
<li>information is lost by summarizing the vector <span class="math inline">\(\mathbf{Y}_i\)</span> solely by <span class="math inline">\(\hat{\beta}_i\)</span>
</li>
<li>we need to account for variability when replacing <span class="math inline">\(\beta_i\)</span> with its estimate</li>
<li>different subjects might have different number of observations.</li>
</ul>
<p>To address these problems, we can use <strong>Linear Mixed Model</strong> <span class="citation">(<a href="references.html#ref-laird1982random">Laird and Ware 1982</a>)</span></p>
<p>Substituting stage 2 into stage 1:</p>
<p><span class="math display">\[
\mathbf{Y}_i = \mathbf{Z}_i \mathbf{K}_i \beta + \mathbf{Z}_i \mathbf{b}_i + \mathbf{\epsilon}_i
\]</span></p>
<p>Let <span class="math inline">\(\mathbf{X}_i = \mathbf{Z}_i \mathbf{K}_i\)</span> be an <span class="math inline">\(n_i \times p\)</span> matrix . Then, the LMM is</p>
<p><span class="math display">\[
\mathbf{Y}_i = \mathbf{X}_i \beta + \mathbf{Z}_i \mathbf{b}_i + \mathbf{\epsilon}_i
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(i = 1,..,N\)</span></li>
<li>
<span class="math inline">\(\beta\)</span> are the fixed effects, which are common to all subjects</li>
<li>
<span class="math inline">\(\mathbf{b}_i\)</span> are the subject specific random effects. <span class="math inline">\(\mathbf{b}_i \sim N_q (\mathbf{0,D})\)</span>
</li>
<li><span class="math inline">\(\mathbf{\epsilon}_i \sim N_{n_i}(\mathbf{0,\Sigma_i})\)</span></li>
<li>
<span class="math inline">\(\mathbf{b}_i\)</span> and <span class="math inline">\(\epsilon_i\)</span> are independent</li>
<li>
<span class="math inline">\(\mathbf{Z}_{i(n_i \times q})\)</span> and <span class="math inline">\(\mathbf{X}_{i(n_i \times p})\)</span> are matrices of known covariates.</li>
</ul>
<p>Equivalently, in the hierarchical form, we call <strong>conditional</strong> or <strong>hierarchical</strong> formulation of the linear mixed model</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_i | \mathbf{b}_i &amp;\sim N(\mathbf{X}_i \beta+ \mathbf{Z}_i \mathbf{b}_i, \mathbf{\Sigma}_i) \\
\mathbf{b}_i &amp;\sim N(\mathbf{0,D})
\end{aligned}
\]</span></p>
<p>for <span class="math inline">\(i = 1,..,N\)</span>. denote the respective functions by <span class="math inline">\(f(\mathbf{Y}_i |\mathbf{b}_i)\)</span> and <span class="math inline">\(f(\mathbf{b}_i)\)</span></p>
<p>In general,</p>
<p><span class="math display">\[
\begin{aligned}
f(A,B) &amp;= f(A|B)f(B) \\
f(A) &amp;= \int f(A,B)dB = \int f(A|B) f(B) dB
\end{aligned}
\]</span></p>
<p>In the LMM, the marginal density of <span class="math inline">\(\mathbf{Y}_i\)</span> is</p>
<p><span class="math display">\[
f(\mathbf{Y}_i) = \int f(\mathbf{Y}_i | \mathbf{b}_i) f(\mathbf{b}_i) d\mathbf{b}_i
\]</span></p>
<p>which can be shown</p>
<p><span class="math display">\[
\mathbf{Y}_i \sim N(\mathbf{X_i \beta, Z_i DZ'_i + \Sigma_i})
\]</span></p>
<p>This is the <strong>marginal</strong> formulation of the linear mixed model</p>
<p>Notes:</p>
<p>We no longer have <span class="math inline">\(Z_i b_i\)</span> in the mean, but add error in the variance (marginal dependence in Y). kinda of averaging out the common effect. Technically, we shouldn’t call it averaging the error b (adding it to the variance covariance matrix), it should be called adding random effect</p>
<p>Continue with our example</p>
<p><span class="math display">\[
Y_{ij} = (\beta_0 + b_{1i}) + (\beta_1L_i + \beta_2 H_i + \beta_3 C_i + b_{2i})t_{ij} + \epsilon_{ij}
\]</span></p>
<p>for each treatment group</p>
<p><span class="math display">\[
Y_{ik}=
\begin{cases}
\beta_0 + b_{1i} + (\beta_1 + \ b_{2i})t_{ij} + \epsilon_{ij} &amp; L \\
\beta_0 + b_{1i} + (\beta_2 + \ b_{2i})t_{ij} + \epsilon_{ij} &amp; H\\
\beta_0 + b_{1i} + (\beta_3 + \ b_{2i})t_{ij} + \epsilon_{ij} &amp; C
\end{cases}
\]</span></p>
<ul>
<li>Intercepts and slopes are all subject specific</li>
<li>Different treatment groups have different slops, but the same intercept.</li>
</ul>
<p><strong>In the hierarchical model form</strong></p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_i | \mathbf{b}_i &amp;\sim N(\mathbf{X}_i \beta + \mathbf{Z}_i \mathbf{b}_i, \mathbf{\Sigma}_i)\\
\mathbf{b}_i &amp;\sim N(\mathbf{0,D})
\end{aligned}
\]</span></p>
<p>X will be in the form of</p>
<p><span class="math display">\[
\beta = (\beta_0, \beta_1, \beta_2, \beta_3)'
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{X}_i &amp;= \mathbf{Z}_i \mathbf{K}_i \\
&amp;=
\left[
\begin{array}
{cc}
1 &amp; t_{i1} \\
1 &amp; t_{i2} \\
. &amp; . \\
1 &amp; t_{in_i}
\end{array}
\right]
\times
\left[
\begin{array}
{cccc}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; L_i &amp; H_i &amp; C_i \\
\end{array}
\right] \\
&amp;=
\left[
\begin{array}
{cccc}
1 &amp; t_{i1}L_i &amp; t_{i1}H_i &amp; T_{i1}C_i \\
1 &amp; t_{i2}L_i &amp; t_{i2}H_i &amp; T_{i2}C_i \\
. &amp;. &amp;. &amp;. \\
1 &amp; t_{in_i}L_i &amp; t_{in_i}H_i &amp; T_{in_i}C_i \\
\end{array}
\right]\end{aligned}
\]</span></p>
<p><span class="math display">\[
\mathbf{b}_i =
\left(
\begin{array}
{c}
b_{1i} \\
b_{2i}
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
D =
\left(
\begin{array}
{cc}
d_{11} &amp; d_{12}\\
d_{12} &amp; d_{22}
\end{array}
\right)
\]</span></p>
<p>Assuming <span class="math inline">\(\mathbf{\Sigma}_i = \sigma^2 \mathbf{I}_{n_i}\)</span>, which is called <strong>conditional independence</strong>, meaning the response on subject i are independent conditional on <span class="math inline">\(\mathbf{b}_i\)</span> and <span class="math inline">\(\beta\)</span></p>
<p><strong>In the marginal model form</strong></p>
<p><span class="math display">\[
Y_{ij} = \beta_0 + \beta_1 L_i t_{ij} + \beta_2 H_i t_{ij} + \beta_3 C_i t_{ij} + \eta_{ij}
\]</span></p>
<p>where <span class="math inline">\(\eta_i \sim N(\mathbf{0},\mathbf{Z}_i\mathbf{DZ}_i'+ \mathbf{\Sigma}_i)\)</span></p>
<p>Equivalently,</p>
<p><span class="math display">\[
\mathbf{Y_i \sim N(X_i \beta, Z_i DZ_i' + \Sigma_i})
\]</span></p>
<p>In this case that <span class="math inline">\(n_i = 2\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Z_iDZ_i'} &amp;=
\left(
\begin{array}
{cc}
1 &amp; t_{i1} \\
1 &amp; t_{i2}
\end{array}
\right)
\left(
\begin{array}
{cc}
d_{11} &amp; d_{12} \\
d_{12} &amp; d_{22}
\end{array}
\right)
\left(
\begin{array}
{cc}
1 &amp; 1 \\
t_{i1} &amp; t_{i2}
\end{array}
\right) \\
&amp;=
\left(
\begin{array}
{cc}
d_{11} + 2d_{12}t_{i1} + d_{22}t_{i1}^2 &amp; d_{11} + d_{12}(t_{i1} + t_{i2}) + d_{22}t_{i1}t_{i2} \\
d_{11} + d_{12}(t_{i1} + t_{i2}) + d_{22} t_{i1} t_{i2} &amp; d_{11} + 2d_{12}t_{i2} + d_{22}t_{i2}^2  
\end{array}
\right)
\end{aligned}
\]</span></p>
<p><span class="math display">\[
var(Y_{i1}) = d_{11} + 2d_{12}t_{i1} + d_{22} t_{i1}^2 + \sigma^2
\]</span></p>
<p>On top of correlation in the errors, the marginal implies that the variance function of the response is quadratic over time, with positive curvature <span class="math inline">\(d_{22}\)</span></p>
<div id="random-intercepts-model" class="section level3" number="8.1.1">
<h3>
<span class="header-section-number">8.1.1</span> Random-Intercepts Model<a class="anchor" aria-label="anchor" href="#random-intercepts-model"><i class="fas fa-link"></i></a>
</h3>
<p>If we remove the random slopes,</p>
<ul>
<li>the assumption is that all variability in subject-specific slopes can be attributed to treatment differences</li>
<li>the model is random-intercepts model. This has subject specific intercepts, but the same slopes within each treatment group.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_i | b_i &amp;\sim N(\mathbf{X}_i \beta + 1 b_i , \Sigma_i) \\
b_i &amp;\sim N(0,d_{11})
\end{aligned}
\]</span></p>
<p>The marginal model is then (<span class="math inline">\(\mathbf{\Sigma}_i = \sigma^2 \mathbf{I}\)</span>)</p>
<p><span class="math display">\[
\mathbf{Y}_i \sim N(\mathbf{X}_i \beta, 11'd_{11} + \sigma^2 \mathbf{I})
\]</span></p>
<p>The marginal covariance matrix is</p>
<p><span class="math display">\[
\begin{aligned}
cov(\mathbf{Y}_i)  &amp;= 11'd_{11} + \sigma^2I \\
&amp;=
\left(
\begin{array}
{cccc}
d_{11}+ \sigma^2 &amp; d_{11} &amp; ... &amp; d_{11} \\
d_{11} &amp; d_{11} + \sigma^2 &amp; d_{11} &amp; ... \\
. &amp; . &amp; . &amp; . \\
d_{11} &amp; ... &amp; ... &amp; d_{11} + \sigma^2
\end{array}
\right)
\end{aligned}
\]</span></p>
<p>the associated correlation matrix is</p>
<p><span class="math display">\[
corr(\mathbf{Y}_i) =
\left(
\begin{array}
{cccc}
1 &amp; \rho &amp; ... &amp; \rho \\
\rho &amp; 1 &amp; \rho &amp; ... \\
. &amp; . &amp; . &amp; . \\
\rho &amp; ... &amp; ... &amp; 1 \\
\end{array}
\right)
\]</span></p>
<p>where <span class="math inline">\(\rho \equiv \frac{d_{11}}{d_{11} + \sigma^2}\)</span></p>
<p>Thu, we have</p>
<ul>
<li>constant variance over time</li>
<li>equal, positive correlation between any two measurements from the same subject</li>
<li>a covariance structure that is called <strong>compound symmetry</strong>, and <span class="math inline">\(\rho\)</span> is called the <strong>intra-class correlation</strong>
</li>
<li>that when <span class="math inline">\(\rho\)</span> is large, the <strong>inter-subject variability</strong> (<span class="math inline">\(d_{11}\)</span>) is large relative to the intra-subject variability (<span class="math inline">\(\sigma^2\)</span>)</li>
</ul>
</div>
<div id="covariance-models" class="section level3" number="8.1.2">
<h3>
<span class="header-section-number">8.1.2</span> Covariance Models<a class="anchor" aria-label="anchor" href="#covariance-models"><i class="fas fa-link"></i></a>
</h3>
<p>If the conditional independence assumption, (<span class="math inline">\(\mathbf{\Sigma_i= \sigma^2 I_{n_i}}\)</span>). Consider, <span class="math inline">\(\epsilon_i = \epsilon_{(1)i} + \epsilon_{(2)i}\)</span>, where</p>
<ul>
<li>
<span class="math inline">\(\epsilon_{(1)i}\)</span> is a “serial correlation” component. That is, part of the individual’s profile is a response to time-varying stochastic processes.</li>
<li>
<span class="math inline">\(\epsilon_{(2)i}\)</span> is the measurement error component, and is independent of <span class="math inline">\(\epsilon_{(1)i}\)</span>
</li>
</ul>
<p>Then</p>
<p><span class="math display">\[
\mathbf{Y_i = X_i \beta + Z_i b_i + \epsilon_{(1)i} + \epsilon_{(2)i}}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(\mathbf{b_i} \sim N(\mathbf{0,D})\)</span></p></li>
<li><p><span class="math inline">\(\epsilon_{(2)i} \sim N(\mathbf{0,\sigma^2 I_{n_i}})\)</span></p></li>
<li><p><span class="math inline">\(\epsilon_{(1)i} \sim N(\mathbf{0,\tau^2H_i})\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{b}_i\)</span> and <span class="math inline">\(\epsilon_i\)</span> are mutually independent</p></li>
</ul>
<p>To model the structure of the <span class="math inline">\(n_i \times n_i\)</span> correlation (or covariance ) matrix <span class="math inline">\(\mathbf{H}_i\)</span>. Let the (j,k)th element of <span class="math inline">\(\mathbf{H}_i\)</span> be <span class="math inline">\(h_{ijk}= g(t_{ij}t_{ik})\)</span>. that is a function of the times <span class="math inline">\(t_{ij}\)</span> and <span class="math inline">\(t_{ik}\)</span> , which is assumed to be some function of the “distance’ between the times.</p>
<p><span class="math display">\[
h_{ijk} = g(|t_{ij}-t_{ik}|)
\]</span></p>
<p>for some decreasing function <span class="math inline">\(g(.)\)</span> with <span class="math inline">\(g(0)=1\)</span> (for correlation matrices).</p>
<p>Examples of this type of function:</p>
<ul>
<li>Exponential function: <span class="math inline">\(g(|t_{ij}-t_{ik}|) = \exp(-\phi|t_{ij} - t_{ik}|)\)</span>
</li>
<li>Gaussian function: <span class="math inline">\(g(|t_{ij} - t_{ik}|) = \exp(-\phi(t_{ij} - t_{ik})^2)\)</span>
</li>
</ul>
<p>Similar structures could also be used for <span class="math inline">\(\mathbf{D}\)</span> matrix (of <span class="math inline">\(\mathbf{b}\)</span>)</p>
<p>Example: Autoregressive Covariance Structure</p>
<p>A first order Autoregressive Model (AR(1)) has the form</p>
<p><span class="math display">\[
\alpha_t = \phi \alpha_{t-1} + \eta_t
\]</span></p>
<p>where <span class="math inline">\(\eta_t \sim iid N (0,\sigma^2_\eta)\)</span></p>
<p>Then, the covariance between two observations is</p>
<p><span class="math display">\[
cov(\alpha_t, \alpha_{t+h}) = \frac{\sigma^2_\eta \phi^{|h|}}{1- \phi^2}
\]</span></p>
<p>for <span class="math inline">\(h = 0, \pm 1, \pm 2, ...; |\phi|&lt;1\)</span></p>
<p>Hence,</p>
<p><span class="math display">\[
corr(\alpha_t, \alpha_{t+h}) = \phi^{|h|}
\]</span></p>
<p>If we let <span class="math inline">\(\alpha_T = (\alpha_1,...\alpha_T)'\)</span>, then</p>
<p><span class="math display">\[
corr(\alpha_T) =
\left[
\begin{array}
{ccccc}
1 &amp; \phi^1 &amp; \phi^2 &amp; ... &amp; \phi^2 \\
\phi^1 &amp; 1 &amp; \phi^1 &amp; ... &amp; \phi^{T-1} \\
\phi^2 &amp; \phi^1 &amp; 1 &amp; ... &amp; \phi^{T-2} \\
. &amp; . &amp; . &amp; . &amp;. \\
\phi^T &amp; \phi^{T-1} &amp; \phi^{T-2} &amp; ... &amp; 1
\end{array}
\right]
\]</span></p>
<p>Notes:</p>
<ul>
<li>The correlation decreases as time lag increases</li>
<li>This matrix structure is known as a <strong>Toeplitz</strong> structure</li>
<li>More complicated covariance structures are possible, which is critical component of spatial random effects models and time series models.</li>
<li>Often, we don’t need both random effects <span class="math inline">\(\mathbf{b}\)</span> and <span class="math inline">\(\epsilon_{(1)i}\)</span>
</li>
</ul>
<p>More in the <a href="data.html#time-series-1">Time Series</a> section</p>
</div>
</div>
<div id="estimation-2" class="section level2" number="8.2">
<h2>
<span class="header-section-number">8.2</span> Estimation<a class="anchor" aria-label="anchor" href="#estimation-2"><i class="fas fa-link"></i></a>
</h2>
<p><span class="math display">\[
\mathbf{Y}_i = \mathbf{X}_i \beta + \mathbf{Z}_i \mathbf{b}_i + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(\beta, \mathbf{b}_i, \mathbf{D}, \mathbf{\Sigma}_i\)</span> we must obtain estimation from the data</p>
<ul>
<li>
<span class="math inline">\(\mathbf{\beta}, \mathbf{D}, \mathbf{\Sigma}_i\)</span> are unknown, but fixed, parameters, and must be estimated from the data</li>
<li>
<span class="math inline">\(\mathbf{b}_i\)</span> is a random variable. Thus, we can’t estimate these values, but we can predict them. (i.e., you can’t estimate a random thing).</li>
</ul>
<p>If we have</p>
<ul>
<li>
<span class="math inline">\(\hat{\beta}\)</span> as an estimator of <span class="math inline">\(\beta\)</span>
</li>
<li>
<span class="math inline">\(\hat{\mathbf{b}}_i\)</span> as a predictor of <span class="math inline">\(\mathbf{b}_i\)</span>
</li>
</ul>
<p>Then,</p>
<ul>
<li>The population average estimate of <span class="math inline">\(\mathbf{Y}_i\)</span> is <span class="math inline">\(\hat{\mathbf{Y}_i} = \mathbf{X}_i \hat{\beta}\)</span>
</li>
<li>The subject-specific prediction is <span class="math inline">\(\hat{\mathbf{Y}_i} = \mathbf{X}_i \hat{\beta} + \mathbf{Z}_i \hat{b}_i\)</span>
</li>
</ul>
<p>According to <span class="citation">(<a href="references.html#ref-henderson1975best">Henderson 1975</a>)</span>, estimating equations known as the mixed model equations:</p>
<p><span class="math display">\[
\left[
\begin{array}
{c}
\hat{\beta} \\
\hat{\mathbf{b}}
\end{array}
\right]
=
\left[
\begin{array}
{cc}
\mathbf{X'\Sigma^{-1}X} &amp; \mathbf{X'\Sigma^{-1}Z} \\
\mathbf{Z'\Sigma^{-1}X} &amp; \mathbf{Z'\Sigma^{-1}Z +B^{-1}}
\end{array}
\right]
\left[
\begin{array}
{cc}
\mathbf{X'\Sigma^{-1}Y} \\
\mathbf{Z'\Sigma^{-1}Y}
\end{array}
\right]
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}
&amp;=
\left[
\begin{array}
{c}
\mathbf{y}_1 \\
. \\
\mathbf{y}_N
\end{array}
\right] ;
\mathbf{X}
=
\left[
\begin{array}
{c}
\mathbf{X}_1 \\
. \\
\mathbf{X}_N
\end{array}
\right];
\mathbf{b} =
\left[
\begin{array}
{c}
\mathbf{b}_1 \\
. \\
\mathbf{b}_N
\end{array}
\right] ;
\epsilon =
\left[
\begin{array}
{c}
\epsilon_1 \\
. \\
\epsilon_N
\end{array}
\right]
\\
cov(\epsilon) &amp;= \mathbf{\Sigma},
\mathbf{Z} =
\left[
\begin{array}
{cccc}
\mathbf{Z}_1 &amp; 0 &amp;  ... &amp; 0 \\
0 &amp; \mathbf{Z}_2 &amp; ... &amp; 0 \\
. &amp; . &amp; . &amp; . \\
0 &amp; 0 &amp; ... &amp; \mathbf{Z}_n
\end{array}
\right],
\mathbf{B} =
\left[
\begin{array}
{cccc}
\mathbf{D} &amp; 0 &amp; ... &amp; 0 \\
0 &amp; \mathbf{D} &amp; ... &amp; 0 \\
. &amp; . &amp; . &amp; . \\
0 &amp; 0 &amp; ... &amp; \mathbf{D}
\end{array}
\right]
\end{aligned}
\]</span></p>
<p>The model has the form</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y} &amp;= \mathbf{X \beta + Z b + \epsilon} \\
\mathbf{Y} &amp;\sim N(\mathbf{X \beta, ZBZ' + \Sigma})
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(\mathbf{V = ZBZ' + \Sigma}\)</span>, then the solutions to the estimating equations can be</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\beta} &amp;= \mathbf{(X'V^{-1}X)^{-1}X'V^{-1}Y} \\
\hat{\mathbf{b}} &amp;= \mathbf{BZ'V^{-1}(Y-X\hat{\beta}})
\end{aligned}
\]</span></p>
<p>The estimate <span class="math inline">\(\hat{\beta}\)</span> is a generalized least squares estimate.</p>
<p>The predictor, <span class="math inline">\(\hat{\mathbf{b}}\)</span> is the best linear unbiased predictor (BLUP), for <span class="math inline">\(\mathbf{b}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
E(\hat{\beta}) &amp;= \beta \\
var(\hat{\beta}) &amp;= (\mathbf{X'V^{-1}X})^{-1} \\
E(\hat{\mathbf{b}}) &amp;= 0
\end{aligned}
\]</span></p>
<p><span class="math display">\[
var(\mathbf{\hat{b}-b}) = \mathbf{B-BZ'V^{-1}ZB + BZ'V^{-1}X(X'V^{-1}X)^{-1}X'V^{-1}B}
\]</span></p>
<p>The variance here is the variance of the prediction error (mean squared prediction error, MSPE), which is more meaningful than <span class="math inline">\(var(\hat{\mathbf{b}})\)</span>, since MSPE accounts for both variance and bias in the prediction.</p>
<p>To derive the mixed model equations, consider</p>
<p><span class="math display">\[
\mathbf{\epsilon = Y - X\beta - Zb}
\]</span></p>
<p>Let <span class="math inline">\(T = \sum_{i=1}^N n_i\)</span> be the total number of observations (i.e., the length of <span class="math inline">\(\mathbf{Y},\epsilon\)</span>) and <span class="math inline">\(Nq\)</span> the length of <span class="math inline">\(\mathbf{b}\)</span>. The joint distribution of <span class="math inline">\(\mathbf{b, \epsilon}\)</span> is</p>
<p><span class="math display">\[
f(\mathbf{b,\epsilon})= \frac{1}{(2\pi)^{(T+ Nq)/2}}
\left|
\begin{array}
{cc}
\mathbf{B} &amp; 0 \\
0 &amp; \mathbf{\Sigma}
\end{array}
\right| ^{-1/2}
\exp
\left(
-\frac{1}{2}
\left[
\begin{array}
{c}
\mathbf{b} \\
\mathbf{Y - X \beta - Zb}
\end{array}
\right]'
\left[
\begin{array}
{cc}
\mathbf{B} &amp; 0 \\
0 &amp; \mathbf{\Sigma}
\end{array}
\right]^{-1}
\left[
\begin{array}
{c}
\mathbf{b} \\
\mathbf{Y - X \beta - Zb}
\end{array}
\right]
\right)
\]</span></p>
<p>Maximization of <span class="math inline">\(f(\mathbf{b},\epsilon)\)</span> with respect to <span class="math inline">\(\mathbf{b}\)</span> and <span class="math inline">\(\beta\)</span> requires minimization of</p>
<p><span class="math display">\[
\begin{aligned}
Q &amp;=
\left[
\begin{array}
{c}
\mathbf{b} \\
\mathbf{Y - X \beta - Zb}
\end{array}
\right]'
\left[
\begin{array}
{cc}
\mathbf{B} &amp; 0 \\
0 &amp; \mathbf{\Sigma}
\end{array}
\right]^{-1}
\left[
\begin{array}
{c}
\mathbf{b} \\
\mathbf{Y - X \beta - Zb}
\end{array}
\right] \\
&amp;= \mathbf{b'B^{-1}b+(Y-X \beta-Zb)'\Sigma^{-1}(Y-X \beta-Zb)}
\end{aligned}
\]</span></p>
<p>Setting the derivatives of Q with respect to <span class="math inline">\(\mathbf{b}\)</span> and <span class="math inline">\(\mathbf{\beta}\)</span> to zero leads to the system of equations:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{X'\Sigma^{-1}X\beta + X'\Sigma^{-1}Zb} &amp;= \mathbf{X'\Sigma^{-1}Y}\\
\mathbf{(Z'\Sigma^{-1}Z + B^{-1})b + Z'\Sigma^{-1}X\beta} &amp;= \mathbf{Z'\Sigma^{-1}Y}
\end{aligned}
\]</span></p>
<p>Rearranging</p>
<p><span class="math display">\[
\left[
\begin{array}
{cc}
\mathbf{X'\Sigma^{-1}X} &amp; \mathbf{X'\Sigma^{-1}Z} \\
\mathbf{Z'\Sigma^{-1}X} &amp; \mathbf{Z'\Sigma^{-1}Z + B^{-1}}
\end{array}
\right]
\left[
\begin{array}
{c}
\beta \\
\mathbf{b}
\end{array}
\right]
=
\left[
\begin{array}
{c}
\mathbf{X'\Sigma^{-1}Y} \\
\mathbf{Z'\Sigma^{-1}Y}
\end{array}
\right]
\]</span></p>
<p>Thus, the solution to the mixed model equations give:</p>
<p><span class="math display">\[
\left[
\begin{array}
{c}
\hat{\beta} \\
\hat{\mathbf{b}}
\end{array}
\right]
=
\left[
\begin{array}
{cc}
\mathbf{X'\Sigma^{-1}X} &amp; \mathbf{X'\Sigma^{-1}Z} \\
\mathbf{Z'\Sigma^{-1}X} &amp; \mathbf{Z'\Sigma^{-1}Z + B^{-1}}
\end{array}
\right] ^{-1}
\left[
\begin{array}
{c}
\mathbf{X'\Sigma^{-1}Y} \\
\mathbf{Z'\Sigma^{-1}Y}
\end{array}
\right]
\]</span></p>
<p>Equivalently,</p>
<p>Bayes’ theorem</p>
<p><span class="math display">\[
f(\mathbf{b}| \mathbf{Y}) = \frac{f(\mathbf{Y}|\mathbf{b})f(\mathbf{b})}{\int f(\mathbf{Y}|\mathbf{b})f(\mathbf{b}) d\mathbf{b}}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(f(\mathbf{Y}|\mathbf{b})\)</span> is the “likelihood”</li>
<li>
<span class="math inline">\(f(\mathbf{b})\)</span> is the prior</li>
<li>the denominator is the “normalizing constant”</li>
<li>
<span class="math inline">\(f(\mathbf{b}|\mathbf{Y})\)</span> is the posterior distribution</li>
</ul>
<p>In this case</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y} | \mathbf{b} &amp;\sim N(\mathbf{X\beta+Zb,\Sigma}) \\
\mathbf{b} &amp;\sim N(\mathbf{0,B})
\end{aligned}
\]</span></p>
<p>The posterior distribution has the form</p>
<p><span class="math display">\[
\mathbf{b}|\mathbf{Y} \sim N(\mathbf{BZ'V^{-1}(Y-X\beta),(Z'\Sigma^{-1}Z + B^{-1})^{-1}})
\]</span></p>
<p>Hence, the best predictor (based on squared error loss)</p>
<p><span class="math display">\[
E(\mathbf{b}|\mathbf{Y}) = \mathbf{BZ'V^{-1}(Y-X\beta)}
\]</span></p>
<div id="estimating-mathbfv" class="section level3" number="8.2.1">
<h3>
<span class="header-section-number">8.2.1</span> Estimating <span class="math inline">\(\mathbf{V}\)</span><a class="anchor" aria-label="anchor" href="#estimating-mathbfv"><i class="fas fa-link"></i></a>
</h3>
<p>If we have <span class="math inline">\(\tilde{\mathbf{V}}\)</span> (estimate of <span class="math inline">\(\mathbf{V}\)</span>), then we can estimate:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\beta} &amp;= \mathbf{(X'\tilde{V}^{-1}X)^{-1}X'\tilde{V}^{-1}Y} \\
\hat{\mathbf{b}} &amp;= \mathbf{BZ'\tilde{V}^{-1}(Y-X\hat{\beta})}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\({\mathbf{b}}\)</span> is <strong>EBLUP</strong> (estimated BLUP) or <strong>empirical Bayes estimate</strong></p>
<p>Note:</p>
<ul>
<li>
<span class="math inline">\(\hat{var}(\hat{\beta})\)</span> is a consistent estimator of <span class="math inline">\(var(\hat{\beta})\)</span> if <span class="math inline">\(\tilde{\mathbf{V}}\)</span> is a consistent estimator of <span class="math inline">\(\mathbf{V}\)</span>
</li>
<li>However, <span class="math inline">\(\hat{var}(\hat{\beta})\)</span> is biased since the variability arises from estimating <span class="math inline">\(\mathbf{V}\)</span> is not accounted for in the estimate.</li>
<li>Hence, <span class="math inline">\(\hat{var}(\hat{\beta})\)</span> underestimates the true variability</li>
</ul>
<p>Ways to estimate <span class="math inline">\(\mathbf{V}\)</span></p>
<ul>
<li><a href="linear-mixed-models.html#maximum-likelihood-estimation-mle">Maximum Likelihood Estimation (MLE)</a></li>
<li><a href="linear-mixed-models.html#restricted-maximum-likelihood-reml">Restricted Maximum Likelihood (REML)</a></li>
<li><a href="linear-mixed-models.html#estimated-generalized-least-squares">Estimated Generalized Least Squares</a></li>
<li><a href="linear-mixed-models.html#bayesian-hierarchical-models-bhm">Bayesian Hierarchical Models (BHM)</a></li>
</ul>
<div id="maximum-likelihood-estimation-mle" class="section level4" number="8.2.1.1">
<h4>
<span class="header-section-number">8.2.1.1</span> Maximum Likelihood Estimation (MLE)<a class="anchor" aria-label="anchor" href="#maximum-likelihood-estimation-mle"><i class="fas fa-link"></i></a>
</h4>
<p>Grouping unknown parameters in <span class="math inline">\(\Sigma\)</span> and <span class="math inline">\(B\)</span> under a parameter vector <span class="math inline">\(\theta\)</span>. Under MLE, <span class="math inline">\(\hat{\theta}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> maximize the likelihood <span class="math inline">\(\mathbf{y} \sim N(\mathbf{X\beta, V(\theta))}\)</span>. Synonymously, <span class="math inline">\(-2\log L(\mathbf{y;\theta,\beta})\)</span>:</p>
<p><span class="math display">\[
-2l(\mathbf{\beta,\theta,y}) = \log |\mathbf{V(\theta)}| + \mathbf{(y-X\beta)'V(\theta)^{-1}(y-X\beta)} + N \log(2\pi)
\]</span></p>
<ul>
<li>Step 1: Replace <span class="math inline">\(\beta\)</span> with its maximum likelihood (where <span class="math inline">\(\theta\)</span> is known <span class="math inline">\(\hat{\beta}= (\mathbf{X'V(\theta)^{-1}X)^{-1}X'V(\theta)^{-1}y}\)</span>
</li>
<li>Step 2: Minimize the above equation with respect to <span class="math inline">\(\theta\)</span> to get the estimator <span class="math inline">\(\hat{\theta}_{MLE}\)</span>
</li>
<li>Step 3: Substitute <span class="math inline">\(\hat{\theta}_{MLE}\)</span> back to get <span class="math inline">\(\hat{\beta}_{MLE} = (\mathbf{X'V(\theta_{MLE})^{-1}X)^{-1}X'V(\theta_{MLE})^{-1}y}\)</span>
</li>
<li>Step 4: Get <span class="math inline">\(\hat{\mathbf{b}}_{MLE} = \mathbf{B(\hat{\theta}_{MLE})Z'V(\hat{\theta}_{MLE})^{-1}(y-X\hat{\beta}_{MLE})}\)</span>
</li>
</ul>
<p>Note:</p>
<ul>
<li>
<span class="math inline">\(\hat{\theta}\)</span> are typically negatively biased due to unaccounted fixed effects being estimated, which we could try to account for.</li>
</ul>
</div>
<div id="restricted-maximum-likelihood-reml" class="section level4" number="8.2.1.2">
<h4>
<span class="header-section-number">8.2.1.2</span> Restricted Maximum Likelihood (REML)<a class="anchor" aria-label="anchor" href="#restricted-maximum-likelihood-reml"><i class="fas fa-link"></i></a>
</h4>
<p>REML accounts for the number of estimated mean parameters by adjusting the objective function. Specifically, the likelihood of linear combination of the elements of <span class="math inline">\(\mathbf{y}\)</span> is accounted for.</p>
<p>We have <span class="math inline">\(\mathbf{K'y}\)</span>, where <span class="math inline">\(\mathbf{K}\)</span> is any <span class="math inline">\(N \times (N - p)\)</span> full-rank contrast matrix, which has columns orthogonal to the <span class="math inline">\(\mathbf{X}\)</span> matrix (that is <span class="math inline">\(\mathbf{K'X} = 0\)</span>). Then,</p>
<p><span class="math display">\[
\mathbf{K'y} \sim N(0,\mathbf{K'V(\theta)K})
\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is no longer in the distribution</p>
<p>We can proceed to maximize this likelihood for the contrasts to get <span class="math inline">\(\hat{\theta}_{REML}\)</span>, which does not depend on the choice of <span class="math inline">\(\mathbf{K}\)</span>. And <span class="math inline">\(\hat{\beta}\)</span> are based on <span class="math inline">\(\hat{\theta}\)</span></p>
<p>Comparison REML and MLE</p>
<ul>
<li>
<p>Both methods are based upon the likelihood principle, and have desired properties for the estimates:</p>
<ul>
<li><p>consistency</p></li>
<li><p>asymptotic normality</p></li>
<li><p>efficiency</p></li>
</ul>
</li>
<li><p>ML estimation provides estimates for fixed effects, while REML can’t</p></li>
<li><p>In balanced models, REML is identical to ANOVA</p></li>
<li><p>REML accounts for df for the fixed effects int eh model, which is important when <span class="math inline">\(\mathbf{X}\)</span> is large relative to the sample size</p></li>
<li><p>Changing <span class="math inline">\(\mathbf{\beta}\)</span> has no effect on the REML estimates of <span class="math inline">\(\theta\)</span></p></li>
<li><p>REML is less sensitive to outliers than MLE</p></li>
<li><p>MLE is better than REML regarding model comparisons (e.g., AIC or BIC)</p></li>
</ul>
</div>
<div id="estimated-generalized-least-squares" class="section level4" number="8.2.1.3">
<h4>
<span class="header-section-number">8.2.1.3</span> Estimated Generalized Least Squares<a class="anchor" aria-label="anchor" href="#estimated-generalized-least-squares"><i class="fas fa-link"></i></a>
</h4>
<p>MLE and REML rely upon the Gaussian assumption. To overcome this issue, EGLS uses the first and second moments.</p>
<p><span class="math display">\[
\mathbf{Y}_i = \mathbf{X}_i \beta + \mathbf{Z}_i \mathbf{b}_i + \epsilon_i
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\epsilon_i \sim (\mathbf{0,\Sigma_i})\)</span></li>
<li><span class="math inline">\(\mathbf{b}_i \sim (\mathbf{0,D})\)</span></li>
<li><span class="math inline">\(cov(\epsilon_i, \mathbf{b}_i) = 0\)</span></li>
</ul>
<p>Then the EGLS estimator is</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\beta}_{GLS} &amp;= \{\sum_{i=1}^n \mathbf{X'_iV_i(\theta)^{-1}X_i}  \}^{-1} \sum_{i=1}^n \mathbf{X'_iV_i(\theta)^{-1}Y_i} \\
&amp;=\{\mathbf{X'V(\theta)^{-1}X} \}^{-1} \mathbf{X'V(\theta)^{-1}Y}
\end{aligned}
\]</span></p>
<p>depends on the first two moments</p>
<ul>
<li><span class="math inline">\(E(\mathbf{Y}_i) = \mathbf{X}_i \beta\)</span></li>
<li><span class="math inline">\(var(\mathbf{Y}_i)= \mathbf{V}_i\)</span></li>
</ul>
<p>EGLS use <span class="math inline">\(\hat{\mathbf{V}}\)</span> for <span class="math inline">\(\mathbf{V(\theta)}\)</span></p>
<p><span class="math display">\[
\hat{\beta}_{EGLS} = \{ \mathbf{X'\hat{V}^{-1}X} \}^{-1} \mathbf{X'\hat{V}^{-1}Y}
\]</span></p>
<p>Hence, the fixed effects estimators for the MLE, REML, and EGLS are of the same form, except for the estimate of <span class="math inline">\(\mathbf{V}\)</span></p>
<p>In case of non-iterative approach, EGLS can be appealing when <span class="math inline">\(\mathbf{V}\)</span> can be estimated without much computational burden.</p>
</div>
<div id="bayesian-hierarchical-models-bhm" class="section level4" number="8.2.1.4">
<h4>
<span class="header-section-number">8.2.1.4</span> Bayesian Hierarchical Models (BHM)<a class="anchor" aria-label="anchor" href="#bayesian-hierarchical-models-bhm"><i class="fas fa-link"></i></a>
</h4>
<p>Joint distribution cane be decomposed hierarchically in terms of the product of conditional distributions and a marginal distribution</p>
<p><span class="math display">\[
f(A,B,C) = f(A|B,C) f(B|C)f(C)
\]</span></p>
<p>Applying to estimate <span class="math inline">\(\mathbf{V}\)</span></p>
<p><span class="math display">\[
\begin{aligned}
f(\mathbf{Y, \beta, b, \theta}) &amp;= f(\mathbf{Y|\beta,b, \theta})f(\mathbf{b|\theta,\beta})f(\mathbf{\beta|\theta})f(\mathbf{\theta}) &amp; \text{based on probability decomposition} \\
&amp;= f(\mathbf{Y|\beta,b, \theta})f(\mathbf{b|\theta})f(\mathbf{\beta})f(\mathbf{\theta}) &amp; \text{based on simplifying modeling assumptions}
\end{aligned}
\]</span></p>
<p>elaborate on the second equality, if we assume conditional independence (e.g., given <span class="math inline">\(\theta\)</span>, no additional info about <span class="math inline">\(\mathbf{b}\)</span> is given by knowing <span class="math inline">\(\beta\)</span>), then we can simply from the first equality</p>
<p>Using Bayes’ rule</p>
<p><span class="math display">\[
f(\mathbf{\beta, b, \theta|Y}) \propto f(\mathbf{Y|\beta,b, \theta})f(\mathbf{b|\theta})f(\mathbf{\beta})f(\mathbf{\theta})
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y| \beta, b, \theta} &amp;\sim \mathbf{N(X\beta+ Zb, \Sigma(\theta))} \\
\mathbf{b | \theta} &amp;\sim \mathbf{N(0, B(\theta))}
\end{aligned}
\]</span></p>
<p>and we also have to have prior distributions for <span class="math inline">\(f(\beta), f(\theta)\)</span></p>
<p>With normalizing constant, we can obtain the posterior distribution. Typically, we can’t get analytical solution right away. Hence, we can use Markov Chain Monte Carlo (MCMC) to obtain samples from the posterior distribution.</p>
<p>Bayesian Methods:</p>
<ul>
<li>account for the uncertainty in parameters estimates and accommodate the propagation of that uncertainty through the model</li>
<li>can adjust prior information (i.e., priori) in parameters</li>
<li>Can extend beyond Gaussian distributions</li>
<li>but hard to implement algorithms and might have problem converging</li>
</ul>
</div>
</div>
</div>
<div id="inference-3" class="section level2" number="8.3">
<h2>
<span class="header-section-number">8.3</span> Inference<a class="anchor" aria-label="anchor" href="#inference-3"><i class="fas fa-link"></i></a>
</h2>
<div id="parameters-beta" class="section level3" number="8.3.1">
<h3>
<span class="header-section-number">8.3.1</span> Parameters <span class="math inline">\(\beta\)</span><a class="anchor" aria-label="anchor" href="#parameters-beta"><i class="fas fa-link"></i></a>
</h3>
<div id="wald-test-GLMM" class="section level4" number="8.3.1.1">
<h4>
<span class="header-section-number">8.3.1.1</span> Wald test<a class="anchor" aria-label="anchor" href="#wald-test-GLMM"><i class="fas fa-link"></i></a>
</h4>
<p>We have</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{\hat{\beta}(\theta)} &amp;= \mathbf{\{X'V^{-1}(\theta) X\}^{-1}X'V^{-1}(\theta) Y} \\
var(\hat{\beta}(\theta)) &amp;= \mathbf{\{X'V^{-1}(\theta) X\}^{-1}}
\end{aligned}
\]</span></p>
<p>We can use <span class="math inline">\(\hat{\theta}\)</span> in place of <span class="math inline">\(\theta\)</span> to approximate Wald test</p>
<p><span class="math display">\[
H_0: \mathbf{A \beta =d}
\]</span></p>
<p>With</p>
<p><span class="math display">\[
W = \mathbf{(A\hat{\beta} - d)'[A(X'\hat{V}^{-1}X)^{-1}A']^{-1}(A\hat{\beta} - d)}
\]</span></p>
<p>where <span class="math inline">\(W \sim \chi^2_{rank(A)}\)</span> under <span class="math inline">\(H_0\)</span> is true. However, it does not take into account variability from using <span class="math inline">\(\hat{\theta}\)</span> in place of <span class="math inline">\(\theta\)</span>, hence the standard errors are underestimated</p>
</div>
<div id="f-test-1" class="section level4" number="8.3.1.2">
<h4>
<span class="header-section-number">8.3.1.2</span> F-test<a class="anchor" aria-label="anchor" href="#f-test-1"><i class="fas fa-link"></i></a>
</h4>
<p>Alternatively, we can use the modified F-test, suppose we have <span class="math inline">\(var(\mathbf{Y}) = \sigma^2 \mathbf{V}(\theta)\)</span>, then</p>
<p><span class="math display">\[
F^* = \frac{\mathbf{(A\hat{\beta} - d)'[A(X'\hat{V}^{-1}X)^{-1}A']^{-1}(A\hat{\beta} - d)}}{\hat{\sigma}^2 \text{rank}(A)}
\]</span></p>
<p>where <span class="math inline">\(F^* \sim f_{rank(A), den(df)}\)</span> under the null hypothesis. And den(df) needs to be approximated from the data by either:</p>
<ul>
<li>Satterthwaite method</li>
<li>Kenward-Roger approximation</li>
</ul>
<p>Under balanced cases, the Wald and F tests are similar. But for small sample sizes, they can differ in p-values. And both can be reduced to t-test for a single <span class="math inline">\(\beta\)</span></p>
</div>
<div id="likelihood-ratio-test" class="section level4" number="8.3.1.3">
<h4>
<span class="header-section-number">8.3.1.3</span> Likelihood Ratio Test<a class="anchor" aria-label="anchor" href="#likelihood-ratio-test"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[
H_0: \beta \in \Theta_{\beta,0}
\]</span></p>
<p>where <span class="math inline">\(\Theta_{\beta, 0}\)</span> is a subspace of the parameter space, <span class="math inline">\(\Theta_{\beta}\)</span> of the fixed effects <span class="math inline">\(\beta\)</span> . Then</p>
<p><span class="math display">\[
-2\log \lambda_N = -2\log\{\frac{\hat{L}_{ML,0}}{\hat{L}_{ML}}\}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\hat{L}_{ML,0}\)</span> , <span class="math inline">\(\hat{L}_{ML}\)</span> are the maximized likelihood obtained from maximizing over <span class="math inline">\(\Theta_{\beta,0}\)</span> and <span class="math inline">\(\Theta_{\beta}\)</span>
</li>
<li>
<span class="math inline">\(-2 \log \lambda_N \dot{\sim} \chi^2_{df}\)</span> where df is the difference in the dimension (i.e., number of parameters) of <span class="math inline">\(\Theta_{\beta,0}\)</span> and <span class="math inline">\(\Theta_{\beta}\)</span>
</li>
</ul>
<p>This method is not applicable for REML. But REML can still be used to test for covariance parameters between nested models.</p>
</div>
</div>
<div id="variance-components" class="section level3" number="8.3.2">
<h3>
<span class="header-section-number">8.3.2</span> Variance Components<a class="anchor" aria-label="anchor" href="#variance-components"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p>For ML and REML estimator, <span class="math inline">\(\hat{\theta} \sim N(\theta, I(\theta))\)</span> for large samples</p></li>
<li>
<p>Wald test in variance components is analogous to the fixed effects case (see <a href="linear-mixed-models.html#wald-test-GLMM">8.3.1.1</a> )</p>
<ul>
<li><p>However, the normal approximation depends largely on the true value of <span class="math inline">\(\theta\)</span>. It will fail if the true value of <span class="math inline">\(\theta\)</span> is close to the boundary of the parameter space <span class="math inline">\(\Theta_{\theta}\)</span> (i.e., <span class="math inline">\(\sigma^2 \approx 0\)</span>)</p></li>
<li><p>Typically works better for covariance parameter, than variance parameters.</p></li>
</ul>
</li>
<li><p>The likelihood ratio tests can also be used with ML or REML estimates. However, the same problem of parameters</p></li>
</ul>
</div>
</div>
<div id="information-criteria" class="section level2" number="8.4">
<h2>
<span class="header-section-number">8.4</span> Information Criteria<a class="anchor" aria-label="anchor" href="#information-criteria"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>account for the likelihood and the number of parameters to assess model comparison.</li>
</ul>
<div id="akaikes-information-criteria-aic" class="section level3" number="8.4.1">
<h3>
<span class="header-section-number">8.4.1</span> Akaike’s Information Criteria (AIC)<a class="anchor" aria-label="anchor" href="#akaikes-information-criteria-aic"><i class="fas fa-link"></i></a>
</h3>
<p>Derived as an estimator of the expected Kullback discrepancy between the true model and a fitted candidate model</p>
<p><span class="math display">\[
AIC = -2l(\hat{\theta}, \hat{\beta}) + 2q
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(l(\hat{\theta}, \hat{\beta})\)</span> is the log-likelihood</li>
<li>q = the effective number of parameters; total of fixed and those associated with random effects (variance/covariance; those not estimated to be on a boundary constraint)</li>
</ul>
<p>Note:</p>
<ul>
<li>In comparing models that differ in their random effects, this method is not advised to due the inability to get the correct number of effective parameters).</li>
<li>We prefer smaller AIC values.</li>
<li>If your program uses <span class="math inline">\(l-q\)</span> then we prefer larger AIC values (but rarely).</li>
<li>can be used for mixed model section, (e.g., selection of the covariance structure), but the sample size must be very large to have adequate comparison based on the criterion</li>
<li>Can have a large negative bias (e.g., when sample size is small but the number of parameters is large) due to the penalty term can’t approximate the bias adjustment adequately</li>
</ul>
</div>
<div id="corrected-aic-aicc" class="section level3" number="8.4.2">
<h3>
<span class="header-section-number">8.4.2</span> Corrected AIC (AICC)<a class="anchor" aria-label="anchor" href="#corrected-aic-aicc"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>developed by <span class="citation">(<a href="references.html#ref-hurvich1989regression">Hurvich and Tsai 1989</a>)</span>
</li>
<li>correct small-sample adjustment</li>
<li>depends on the candidate model class</li>
<li>Only if you have fixed covariance structure, then AICC is justified, but not general covariance structure</li>
</ul>
</div>
<div id="bayesian-information-criteria-bic" class="section level3" number="8.4.3">
<h3>
<span class="header-section-number">8.4.3</span> Bayesian Information Criteria (BIC)<a class="anchor" aria-label="anchor" href="#bayesian-information-criteria-bic"><i class="fas fa-link"></i></a>
</h3>
<p><span class="math display">\[
BIC = -2l(\hat{\theta}, \hat{\beta}) + q \log n
\]</span></p>
<p>where n = number of observations.</p>
<ul>
<li>we prefer smaller BIC value</li>
<li>BIC and AIC are used for both REML and MLE if we have the same mean structure. Otherwise, in general, we should prefer MLE</li>
</ul>
<p>With our example presented at the beginning of <a href="linear-mixed-models.html#linear-mixed-models">Linear Mixed Models</a>,</p>
<p><span class="math display">\[
Y_{ik}=
\begin{cases}
\beta_0 + b_{1i} + (\beta_1 + \ b_{2i})t_{ij} + \epsilon_{ij} &amp; L \\
\beta_0 + b_{1i} + (\beta_2 + \ b_{2i})t_{ij} + \epsilon_{ij} &amp; H\\
\beta_0 + b_{1i} + (\beta_3 + \ b_{2i})t_{ij} + \epsilon_{ij} &amp; C
\end{cases}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(i = 1,..,N\)</span></li>
<li>
<span class="math inline">\(j = 1,..,n_i\)</span> (measures at time <span class="math inline">\(t_{ij}\)</span>)</li>
</ul>
<p>Note:</p>
<ul>
<li>we have subject-specific intercepts,</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathbf{Y}_i |b_i &amp;\sim N(\mathbf{X}_i \beta + 1 b_i, \sigma^2 \mathbf{I}) \\
b_i &amp;\sim N(0,d_{11})
\end{aligned}
\]</span></p>
<p>here, we want to estimate <span class="math inline">\(\beta, \sigma^2, d_{11}\)</span> and predict <span class="math inline">\(b_i\)</span></p>
</div>
</div>
<div id="split-plot-designs" class="section level2" number="8.5">
<h2>
<span class="header-section-number">8.5</span> Split-Plot Designs<a class="anchor" aria-label="anchor" href="#split-plot-designs"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Typically used in the case that you have two factors where one needs much larger units than the other.</li>
</ul>
<p>Example:</p>
<p>A: 3 levels (large units)</p>
<p>B: 2 levels (small units)</p>
<ul>
<li>A and B levels are randomized into 4 blocks.</li>
<li>But it differs from <a href="analysis-of-variance-anova.html#randomized-block-designs">Randomized Block Designs</a>. In each block, both have one of the 6 (3x2) treatment combinations. But <a href="analysis-of-variance-anova.html#randomized-block-designs">Randomized Block Designs</a> assign in each block randomly, while split-plot does not randomize this step.</li>
<li>Moreover, because A needs to be applied in large units, factor A is applied only once in each block while B can be applied multiple times.</li>
</ul>
<p>Hence, we have our model</p>
<p>If A is our factor of interest</p>
<p><span class="math display">\[
Y_{ij} = \mu + \rho_i + \alpha_j + e_{ij}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(i\)</span> = replication (block or subject)</li>
<li>
<span class="math inline">\(j\)</span> = level of Factor A</li>
<li>
<span class="math inline">\(\mu\)</span> = overall mean</li>
<li>
<span class="math inline">\(\rho_i\)</span> = variation due to the <span class="math inline">\(i\)</span>-th block</li>
<li>
<span class="math inline">\(e_{ij} \sim N(0, \sigma^2_e)\)</span> = whole plot error</li>
</ul>
<p>If B is our factor of interest</p>
<p><span class="math display">\[
Y_{ijk} = \mu + \phi_{ij} + \beta_k + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\phi_{ij}\)</span> = variation due to the <span class="math inline">\(ij\)</span>-th main plot</li>
<li>
<span class="math inline">\(\beta_k\)</span> = Factor B effect</li>
<li>
<span class="math inline">\(\epsilon_{ijk} \sim N(0, \sigma^2_\epsilon)\)</span> = subplot error</li>
<li><span class="math inline">\(\phi_{ij} = \rho_i + \alpha_j + e_{ij}\)</span></li>
</ul>
<p>Together, the split-plot model</p>
<p><span class="math display">\[
Y_{ijk} = \mu + \rho_i + \alpha_j + e_{ij} + \beta_k + (\alpha \beta)_{jk} + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(i\)</span> = replicate (blocks or subjects)</li>
<li>
<span class="math inline">\(j\)</span> = level of factor A</li>
<li>
<span class="math inline">\(k\)</span> = level of factor B</li>
<li>
<span class="math inline">\(\mu\)</span> = overall mean</li>
<li>
<span class="math inline">\(\rho_i\)</span> = effect of the block</li>
<li>
<span class="math inline">\(\alpha_j\)</span> = main effect of factor A (fixed)</li>
<li>
<span class="math inline">\(e_{ij} = (\rho \alpha)_{ij}\)</span> = block by factor A interaction (the whole plot error, random)</li>
<li>
<span class="math inline">\(\beta_k\)</span> = main effect of factor B (fixed)</li>
<li>
<span class="math inline">\((\alpha \beta)_{jk}\)</span> = interaction between factors A and B (fixed)</li>
<li>
<span class="math inline">\(\epsilon_{ijk}\)</span> = subplot error (random)</li>
</ul>
<p>We can approach sub-plot analysis based on</p>
<ul>
<li>
<p>the ANOVA perspective</p>
<ul>
<li>
<p>Whole plot comparisons</p>
<ul>
<li><p>Compare factor A to the whole plot error (i.e., <span class="math inline">\(\alpha_j\)</span> to <span class="math inline">\(e_{ij}\)</span>)</p></li>
<li><p>Compare the block to the whole plot error (i.e., <span class="math inline">\(\rho_i\)</span> to <span class="math inline">\(e_{ij}\)</span>)</p></li>
</ul>
</li>
<li>
<p>Sub-plot comparisons:</p>
<ul>
<li><p>Compare factor B to the subplot error (<span class="math inline">\(\beta\)</span> to <span class="math inline">\(\epsilon_{ijk}\)</span>)</p></li>
<li><p>Compare the AB interaction to the subplot error (<span class="math inline">\((\alpha \beta)_{jk}\)</span> to <span class="math inline">\(\epsilon_{ijk}\)</span>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>the mixed model perspective</p></li>
</ul>
<p><span class="math display">\[
\mathbf{Y = X \beta + Zb + \epsilon}
\]</span></p>
<div id="application-4" class="section level3" number="8.5.1">
<h3>
<span class="header-section-number">8.5.1</span> Application<a class="anchor" aria-label="anchor" href="#application-4"><i class="fas fa-link"></i></a>
</h3>
<div id="example-1" class="section level4" number="8.5.1.1">
<h4>
<span class="header-section-number">8.5.1.1</span> Example 1<a class="anchor" aria-label="anchor" href="#example-1"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[
y_{ijk} = \mu + i_i + v_j + (iv)_{ij} + f_k + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(y_{ijk}\)</span> = observed yield</li>
<li>
<span class="math inline">\(\mu\)</span> = overall average yield</li>
<li>
<span class="math inline">\(i_i\)</span> = irrigation effect</li>
<li>
<span class="math inline">\(v_j\)</span> = variety effect</li>
<li>
<span class="math inline">\((iv)_{ij}\)</span> = irrigation by variety interaction</li>
<li>
<span class="math inline">\(f_k\)</span> = random field (block) effect</li>
<li>
<span class="math inline">\(\epsilon_{ijk}\)</span> = residual</li>
<li>because variety-field combination is only observed once, we can’t have the random interaction effects between variety and field</li>
</ul>
<div class="sourceCode" id="cb167"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">irrigation</span>, package <span class="op">=</span> <span class="st">"faraway"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">irrigation</span><span class="op">)</span></span>
<span><span class="co">#&gt;      field   irrigation variety     yield      </span></span>
<span><span class="co">#&gt;  f1     :2   i1:4       v1:8    Min.   :34.80  </span></span>
<span><span class="co">#&gt;  f2     :2   i2:4       v2:8    1st Qu.:37.60  </span></span>
<span><span class="co">#&gt;  f3     :2   i3:4               Median :40.15  </span></span>
<span><span class="co">#&gt;  f4     :2   i4:4               Mean   :40.23  </span></span>
<span><span class="co">#&gt;  f5     :2                      3rd Qu.:42.73  </span></span>
<span><span class="co">#&gt;  f6     :2                      Max.   :47.60  </span></span>
<span><span class="co">#&gt;  (Other):4</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">irrigation</span>, <span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt;   field irrigation variety yield</span></span>
<span><span class="co">#&gt; 1    f1         i1      v1  35.4</span></span>
<span><span class="co">#&gt; 2    f1         i1      v2  37.9</span></span>
<span><span class="co">#&gt; 3    f2         i2      v1  36.7</span></span>
<span><span class="co">#&gt; 4    f2         i2      v2  38.2</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">irrigation</span>,</span>
<span>       <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span></span>
<span>         x     <span class="op">=</span> <span class="va">field</span>,</span>
<span>         y     <span class="op">=</span> <span class="va">yield</span>,</span>
<span>         shape <span class="op">=</span> <span class="va">irrigation</span>,</span>
<span>         color <span class="op">=</span> <span class="va">variety</span></span>
<span>       <span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="08-linear-mixed-models_files/figure-html/unnamed-chunk-1-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb168"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sp_model</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">lmerTest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">yield</span> <span class="op">~</span> <span class="va">irrigation</span> <span class="op">*</span> <span class="va">variety</span> </span>
<span>                   <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span><span class="va">field</span><span class="op">)</span>, <span class="va">irrigation</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">sp_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [</span></span>
<span><span class="co">#&gt; lmerModLmerTest]</span></span>
<span><span class="co">#&gt; Formula: yield ~ irrigation * variety + (1 | field)</span></span>
<span><span class="co">#&gt;    Data: irrigation</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML criterion at convergence: 45.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -0.7448 -0.5509  0.0000  0.5509  0.7448 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  field    (Intercept) 16.200   4.025   </span></span>
<span><span class="co">#&gt;  Residual              2.107   1.452   </span></span>
<span><span class="co">#&gt; Number of obs: 16, groups:  field, 8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                        Estimate Std. Error     df t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)              38.500      3.026  4.487  12.725 0.000109 ***</span></span>
<span><span class="co">#&gt; irrigationi2              1.200      4.279  4.487   0.280 0.791591    </span></span>
<span><span class="co">#&gt; irrigationi3              0.700      4.279  4.487   0.164 0.877156    </span></span>
<span><span class="co">#&gt; irrigationi4              3.500      4.279  4.487   0.818 0.454584    </span></span>
<span><span class="co">#&gt; varietyv2                 0.600      1.452  4.000   0.413 0.700582    </span></span>
<span><span class="co">#&gt; irrigationi2:varietyv2   -0.400      2.053  4.000  -0.195 0.855020    </span></span>
<span><span class="co">#&gt; irrigationi3:varietyv2   -0.200      2.053  4.000  -0.097 0.927082    </span></span>
<span><span class="co">#&gt; irrigationi4:varietyv2    1.200      2.053  4.000   0.584 0.590265    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;             (Intr) irrgt2 irrgt3 irrgt4 vrtyv2 irr2:2 irr3:2</span></span>
<span><span class="co">#&gt; irrigation2 -0.707                                          </span></span>
<span><span class="co">#&gt; irrigation3 -0.707  0.500                                   </span></span>
<span><span class="co">#&gt; irrigation4 -0.707  0.500  0.500                            </span></span>
<span><span class="co">#&gt; varietyv2   -0.240  0.170  0.170  0.170                     </span></span>
<span><span class="co">#&gt; irrgtn2:vr2  0.170 -0.240 -0.120 -0.120 -0.707              </span></span>
<span><span class="co">#&gt; irrgtn3:vr2  0.170 -0.120 -0.240 -0.120 -0.707  0.500       </span></span>
<span><span class="co">#&gt; irrgtn4:vr2  0.170 -0.120 -0.120 -0.240 -0.707  0.500  0.500</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">sp_model</span>, ddf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Kenward-Roger"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Type III Analysis of Variance Table with Kenward-Roger's method</span></span>
<span><span class="co">#&gt;                    Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F)</span></span>
<span><span class="co">#&gt; irrigation         2.4545 0.81818     3     4  0.3882 0.7685</span></span>
<span><span class="co">#&gt; variety            2.2500 2.25000     1     4  1.0676 0.3599</span></span>
<span><span class="co">#&gt; irrigation:variety 1.5500 0.51667     3     4  0.2452 0.8612</span></span></code></pre></div>
<p>Since p-value of the interaction term is insignificant, we consider fitting without it.</p>
<div class="sourceCode" id="cb169"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span>
<span><span class="va">sp_model_additive</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">yield</span> <span class="op">~</span> <span class="va">irrigation</span> <span class="op">+</span> <span class="va">variety</span> </span>
<span>                          <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">field</span><span class="op">)</span>, <span class="va">irrigation</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">sp_model_additive</span>,<span class="va">sp_model</span>,ddf <span class="op">=</span> <span class="st">"Kenward-Roger"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Data: irrigation</span></span>
<span><span class="co">#&gt; Models:</span></span>
<span><span class="co">#&gt; sp_model_additive: yield ~ irrigation + variety + (1 | field)</span></span>
<span><span class="co">#&gt; sp_model: yield ~ irrigation * variety + (1 | field)</span></span>
<span><span class="co">#&gt;                   npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)</span></span>
<span><span class="co">#&gt; sp_model_additive    7 83.959 89.368 -34.980   69.959                     </span></span>
<span><span class="co">#&gt; sp_model            10 88.609 96.335 -34.305   68.609 1.3503  3     0.7172</span></span></code></pre></div>
<p>Since <span class="math inline">\(p\)</span>-value of <span class="math inline">\(\chi^2\)</span> test is insignificant, we can’t reject the additive model is already sufficient. Looking at AIC and BIC, we can also see that we would prefer the additive model</p>
<p><strong>Random Effect Examination</strong></p>
<p><code>exactRLRT</code> test</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: Var(random effect) (i.e., <span class="math inline">\(\sigma^2\)</span>)= 0</li>
<li>
<span class="math inline">\(H_a\)</span>: Var(random effect) (i.e., <span class="math inline">\(\sigma^2\)</span>) &gt; 0</li>
</ul>
<div class="sourceCode" id="cb170"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sp_model</span> <span class="op">&lt;-</span> <span class="fu">lme4</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">yield</span> <span class="op">~</span> <span class="va">irrigation</span> <span class="op">*</span> <span class="va">variety</span> </span>
<span>                       <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">field</span><span class="op">)</span>, <span class="va">irrigation</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/fabian-s/RLRsim">RLRsim</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/RLRsim/man/exactRLRT.html">exactRLRT</a></span><span class="op">(</span><span class="va">sp_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  simulated finite sample distribution of RLRT.</span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt;  (p-value based on 10000 simulated values)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  </span></span>
<span><span class="co">#&gt; RLRT = 6.1118, p-value = 0.0097</span></span></code></pre></div>
<p>Since the p-value is significant, we reject <span class="math inline">\(H_0\)</span></p>
</div>
</div>
</div>
<div id="repeated-measures-in-mixed-models" class="section level2" number="8.6">
<h2>
<span class="header-section-number">8.6</span> Repeated Measures in Mixed Models<a class="anchor" aria-label="anchor" href="#repeated-measures-in-mixed-models"><i class="fas fa-link"></i></a>
</h2>
<p><span class="math display">\[
Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \delta_{i(k)}+ \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(i\)</span>-th group (fixed)</li>
<li>
<span class="math inline">\(j\)</span>-th (repeated measure) time effect (fixed)</li>
<li>
<span class="math inline">\(k\)</span>-th subject</li>
<li>
<span class="math inline">\(\delta_{i(k)} \sim N(0,\sigma^2_\delta)\)</span> (k-th subject in the <span class="math inline">\(i\)</span>-th group) and <span class="math inline">\(\epsilon_{ijk} \sim N(0,\sigma^2)\)</span> (independent error) are random effects (<span class="math inline">\(i = 1,..,n_A, j = 1,..,n_B, k = 1,...,n_i\)</span>)</li>
</ul>
<p>hence, the variance-covariance matrix of the repeated observations on the k-th subject of the i-th group, <span class="math inline">\(\mathbf{Y}_{ik} = (Y_{i1k},..,Y_{in_Bk})'\)</span>, will be</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{\Sigma}_{subject} &amp;=
\left(
\begin{array}
{cccc}
\sigma^2_\delta + \sigma^2 &amp; \sigma^2_\delta &amp; ... &amp; \sigma^2_\delta \\
\sigma^2_\delta &amp; \sigma^2_\delta +\sigma^2 &amp; ... &amp; \sigma^2_\delta \\
. &amp; . &amp; . &amp; . \\
\sigma^2_\delta &amp; \sigma^2_\delta &amp; ... &amp; \sigma^2_\delta + \sigma^2 \\
\end{array}
\right) \\
&amp;= (\sigma^2_\delta + \sigma^2)
\left(
\begin{array}
{cccc}
1 &amp; \rho &amp; ... &amp; \rho \\
\rho &amp; 1 &amp; ... &amp; \rho \\
. &amp; . &amp; . &amp; . \\
\rho &amp; \rho &amp; ... &amp; 1 \\
\end{array}
\right)
&amp; \text{product of a scalar and a correlation matrix}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\rho = \frac{\sigma^2_\delta}{\sigma^2_\delta + \sigma^2}\)</span>, which is the compound symmetry structure that we discussed in <a href="linear-mixed-models.html#random-intercepts-model">Random-Intercepts Model</a></p>
<p>But if you only have repeated measurements on the subject over time, AR(1) structure might be more appropriate</p>
<p>Mixed model for a repeated measure</p>
<p><span class="math display">\[
Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\epsilon_{ijk}\)</span> combines random error of both the whole and subplots.</li>
</ul>
<p>In general,</p>
<p><span class="math display">\[
\mathbf{Y = X \beta + \epsilon}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\epsilon \sim N(0, \sigma^2 \mathbf{\Sigma})\)</span> where <span class="math inline">\(\mathbf{\Sigma}\)</span> is block diagonal if the random error covariance is the same for each subject</li>
</ul>
<p>The variance covariance matrix with AR(1) structure is</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{subject} =
\sigma^2
\left(
\begin{array}
{ccccc}
1  &amp; \rho &amp; \rho^2 &amp; ... &amp; \rho^{n_B-1} \\
\rho &amp; 1 &amp; \rho &amp; ... &amp; \rho^{n_B-2} \\
. &amp; . &amp; . &amp; . &amp; . \\
\rho^{n_B-1} &amp; \rho^{n_B-2} &amp; \rho^{n_B-3} &amp; ... &amp; 1 \\
\end{array}
\right)
\]</span></p>
<p>Hence, the mixed model for a repeated measure can be written as</p>
<p><span class="math display">\[
Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\epsilon_{ijk}\)</span> = random error of whole and subplots</li>
</ul>
<p>Generally,</p>
<p><span class="math display">\[
\mathbf{Y = X \beta + \epsilon}
\]</span></p>
<p>where <span class="math inline">\(\epsilon \sim N(0, \mathbf{\sigma^2 \Sigma})\)</span> and <span class="math inline">\(\Sigma\)</span> = block diagonal if the random error covariance is the same for each subject.</p>
</div>
<div id="unbalanced-or-unequally-spaced-data" class="section level2" number="8.7">
<h2>
<span class="header-section-number">8.7</span> Unbalanced or Unequally Spaced Data<a class="anchor" aria-label="anchor" href="#unbalanced-or-unequally-spaced-data"><i class="fas fa-link"></i></a>
</h2>
<p>Consider the model</p>
<p><span class="math display">\[
Y_{ikt} = \beta_0 + \beta_{0i} + \beta_{1}t + \beta_{1i}t + \beta_{2} t^2 + \beta_{2i} t^2 + \epsilon_{ikt}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(i = 1,2\)</span> (groups)</li>
<li>
<span class="math inline">\(k = 1,…, n_i\)</span> ( individuals)</li>
<li>
<span class="math inline">\(t = (t_1,t_2,t_3,t_4)\)</span> (times)</li>
<li>
<span class="math inline">\(\beta_{2i}\)</span> = common quadratic term</li>
<li>
<span class="math inline">\(\beta_{1i}\)</span> = common linear time trends</li>
<li>
<span class="math inline">\(\beta_{0i}\)</span> = common intercepts</li>
</ul>
<p>Then, we assume the variance-covariance matrix of the repeated measurements collected on a particular subject over time has the form</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{ik} = \sigma^2
\left(
\begin{array}
{cccc}
1 &amp; \rho^{t_2-t_1} &amp; \rho^{t_3-t_1} &amp; \rho^{t_4-t_1} \\
\rho^{t_2-t_1} &amp; 1 &amp; \rho^{t_3-t_2} &amp; \rho^{t_4-t_2} \\
\rho^{t_3-t_1} &amp; \rho^{t_3-t_2} &amp; 1 &amp; \rho^{t_4-t_3} \\
\rho^{t_4-t_1} &amp; \rho^{t_4-t_2} &amp; \rho^{t_4-t_3} &amp; 1
\end{array}
\right)
\]</span></p>
<p>which is called “power” covariance model</p>
<p>We can consider <span class="math inline">\(\beta_{2i} , \beta_{1i}, \beta_{0i}\)</span> accordingly to see whether these terms are needed in the final model</p>
</div>
<div id="application-5" class="section level2" number="8.8">
<h2>
<span class="header-section-number">8.8</span> Application<a class="anchor" aria-label="anchor" href="#application-5"><i class="fas fa-link"></i></a>
</h2>
<p>R Packages for mixed models</p>
<ul>
<li>
<p><code>nlme</code></p>
<ul>
<li><p>has nested structure</p></li>
<li><p>flexible for complex design</p></li>
<li><p>not user-friendly</p></li>
</ul>
</li>
<li>
<p><code>lme4</code></p>
<ul>
<li><p>computationally efficient</p></li>
<li><p>user-friendly</p></li>
<li><p>can handle non-normal response</p></li>
<li><p>for more detailed application, check <a href="https://arxiv.org/abs/1406.5823">Fitting Linear Mixed-Effects Models Using lme4</a></p></li>
</ul>
</li>
<li>
<p>Others</p>
<ul>
<li><p>Bayesian setting: <code>MCMCglmm</code>, <code>brms</code></p></li>
<li><p>For genetics: <code>ASReml</code></p></li>
</ul>
</li>
</ul>
<div id="example-1-pulps" class="section level3" number="8.8.1">
<h3>
<span class="header-section-number">8.8.1</span> Example 1 (Pulps)<a class="anchor" aria-label="anchor" href="#example-1-pulps"><i class="fas fa-link"></i></a>
</h3>
<p>Model:</p>
<p><span class="math display">\[
y_{ij} = \mu + \alpha_i + \epsilon_{ij}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(i = 1,..,a\)</span> groups for random effect <span class="math inline">\(\alpha_i\)</span>
</li>
<li>
<span class="math inline">\(j = 1,...,n\)</span> individuals in each group</li>
<li>
<span class="math inline">\(\alpha_i \sim N(0, \sigma^2_\alpha)\)</span> is random effects</li>
<li>
<span class="math inline">\(\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)\)</span> is random effects</li>
<li>Imply compound symmetry model where the intraclass correlation coefficient is: <span class="math inline">\(\rho = \frac{\sigma^2_\alpha}{\sigma^2_\alpha + \sigma^2_\epsilon}\)</span>
</li>
<li>If factor <span class="math inline">\(a\)</span> does not explain much variation, low correlation within the levels: <span class="math inline">\(\sigma^2_\alpha \to 0\)</span> then <span class="math inline">\(\rho \to 0\)</span>
</li>
<li>If factor <span class="math inline">\(a\)</span> explain much variation, high correlation within the levels <span class="math inline">\(\sigma^2_\alpha \to \infty\)</span> hence, <span class="math inline">\(\rho \to 1\)</span>
</li>
</ul>
<div class="sourceCode" id="cb171"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">pulp</span>, package <span class="op">=</span> <span class="st">"faraway"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span></span>
<span>    y    <span class="op">=</span> <span class="va">pulp</span><span class="op">$</span><span class="va">bright</span>,</span>
<span>    x    <span class="op">=</span> <span class="va">pulp</span><span class="op">$</span><span class="va">operator</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"Operator"</span>,</span>
<span>    ylab <span class="op">=</span> <span class="st">"Brightness"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="08-linear-mixed-models_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb172"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pulp</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">operator</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span>average <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">bright</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 4 × 2</span></span>
<span><span class="co">#&gt;   operator average</span></span>
<span><span class="co">#&gt;   &lt;fct&gt;      &lt;dbl&gt;</span></span>
<span><span class="co">#&gt; 1 a           60.2</span></span>
<span><span class="co">#&gt; 2 b           60.1</span></span>
<span><span class="co">#&gt; 3 c           60.6</span></span>
<span><span class="co">#&gt; 4 d           60.7</span></span></code></pre></div>
<p><code>lmer</code> application</p>
<div class="sourceCode" id="cb173"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/lme4/lme4/">lme4</a></span><span class="op">)</span></span>
<span><span class="va">mixed_model</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span></span>
<span>        <span class="co"># pipe (i..e, | ) denotes random-effect terms</span></span>
<span>        formula <span class="op">=</span> <span class="va">bright</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span><span class="va">operator</span><span class="op">)</span>, </span>
<span>         data <span class="op">=</span> <span class="va">pulp</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by REML ['lmerMod']</span></span>
<span><span class="co">#&gt; Formula: bright ~ 1 + (1 | operator)</span></span>
<span><span class="co">#&gt;    Data: pulp</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML criterion at convergence: 18.6</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1.4666 -0.7595 -0.1244  0.6281  1.6012 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  operator (Intercept) 0.06808  0.2609  </span></span>
<span><span class="co">#&gt;  Residual             0.10625  0.3260  </span></span>
<span><span class="co">#&gt; Number of obs: 20, groups:  operator, 4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value</span></span>
<span><span class="co">#&gt; (Intercept)  60.4000     0.1494   404.2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; $operator</span></span>
<span><span class="co">#&gt;   (Intercept)</span></span>
<span><span class="co">#&gt; a    60.27806</span></span>
<span><span class="co">#&gt; b    60.14088</span></span>
<span><span class="co">#&gt; c    60.56767</span></span>
<span><span class="co">#&gt; d    60.61340</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attr(,"class")</span></span>
<span><span class="co">#&gt; [1] "coef.mer"</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span>   <span class="co"># fixed effects</span></span>
<span><span class="co">#&gt; (Intercept) </span></span>
<span><span class="co">#&gt;        60.4</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span> <span class="co"># confidence interval</span></span>
<span><span class="co">#&gt;                 2.5 %     97.5 %</span></span>
<span><span class="co">#&gt; .sig01       0.000000  0.6178987</span></span>
<span><span class="co">#&gt; .sigma       0.238912  0.4821845</span></span>
<span><span class="co">#&gt; (Intercept) 60.071299 60.7287012</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span>   <span class="co"># random effects</span></span>
<span><span class="co">#&gt; $operator</span></span>
<span><span class="co">#&gt;   (Intercept)</span></span>
<span><span class="co">#&gt; a  -0.1219403</span></span>
<span><span class="co">#&gt; b  -0.2591231</span></span>
<span><span class="co">#&gt; c   0.1676679</span></span>
<span><span class="co">#&gt; d   0.2133955</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; with conditional variances for "operator"</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/VarCorr.html">VarCorr</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span> <span class="co"># random effects standard deviation</span></span>
<span><span class="co">#&gt;  Groups   Name        Std.Dev.</span></span>
<span><span class="co">#&gt;  operator (Intercept) 0.26093 </span></span>
<span><span class="co">#&gt;  Residual             0.32596</span></span>
<span><span class="va">re_dat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/VarCorr.html">VarCorr</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># rho based on the above formula</span></span>
<span><span class="va">rho</span> <span class="op">=</span> <span class="va">re_dat</span><span class="op">[</span><span class="fl">1</span>, <span class="st">'vcov'</span><span class="op">]</span> <span class="op">/</span> <span class="op">(</span><span class="va">re_dat</span><span class="op">[</span><span class="fl">1</span>, <span class="st">'vcov'</span><span class="op">]</span> <span class="op">+</span> <span class="va">re_dat</span><span class="op">[</span><span class="fl">2</span>, <span class="st">'vcov'</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">rho</span></span>
<span><span class="co">#&gt; [1] 0.3905354</span></span></code></pre></div>
<p>To Satterthwaite approximation for the denominator df, we use <code>lmerTest</code></p>
<div class="sourceCode" id="cb174"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/runehaubo/lmerTestR">lmerTest</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="fu">lmerTest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">bright</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">operator</span><span class="op">)</span>, <span class="va">pulp</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span></span>
<span><span class="co">#&gt;             Estimate Std. Error df  t value     Pr(&gt;|t|)</span></span>
<span><span class="co">#&gt; (Intercept)     60.4  0.1494434  3 404.1664 3.340265e-08</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span>, <span class="op">]</span></span>
<span><span class="co">#&gt;   2.5 %  97.5 % </span></span>
<span><span class="co">#&gt; 60.0713 60.7287</span></span></code></pre></div>
<p>In this example, we can see that the confidence interval computed by <code>confint</code> in <code>lmer</code> package is very close is <code>confint</code> in <code>lmerTest</code> model.</p>
<p><code>MCMglmm</code> application</p>
<p>under the Bayesian framework</p>
<div class="sourceCode" id="cb175"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MCMCglmm</span><span class="op">)</span></span>
<span><span class="va">mixed_model_bayes</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/MCMCglmm/man/MCMCglmm.html">MCMCglmm</a></span><span class="op">(</span></span>
<span>        <span class="va">bright</span> <span class="op">~</span> <span class="fl">1</span>,</span>
<span>        random <span class="op">=</span>  <span class="op">~</span> <span class="va">operator</span>,</span>
<span>        data <span class="op">=</span> <span class="va">pulp</span>,</span>
<span>        verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>    <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mixed_model_bayes</span><span class="op">)</span><span class="op">$</span><span class="va">solutions</span></span>
<span><span class="co">#&gt;             post.mean l-95% CI u-95% CI eff.samp pMCMC</span></span>
<span><span class="co">#&gt; (Intercept)  60.39993 60.06017 60.65108     1000 0.001</span></span></code></pre></div>
<p>this method offers the confidence interval slightly more positive than <code>lmer</code> and <code>lmerTest</code></p>
<div id="prediction" class="section level4" number="8.8.1.1">
<h4>
<span class="header-section-number">8.8.1.1</span> Prediction<a class="anchor" aria-label="anchor" href="#prediction"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb176"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># random effects prediction (BLUPs)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span><span class="op">$</span><span class="va">operator</span></span>
<span><span class="co">#&gt;   (Intercept)</span></span>
<span><span class="co">#&gt; a  -0.1219403</span></span>
<span><span class="co">#&gt; b  -0.2591231</span></span>
<span><span class="co">#&gt; c   0.1676679</span></span>
<span><span class="co">#&gt; d   0.2133955</span></span>
<span></span>
<span><span class="co"># prediction for each categories</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span><span class="op">$</span><span class="va">operator</span> </span>
<span><span class="co">#&gt;   (Intercept)</span></span>
<span><span class="co">#&gt; a    60.27806</span></span>
<span><span class="co">#&gt; b    60.14088</span></span>
<span><span class="co">#&gt; c    60.56767</span></span>
<span><span class="co">#&gt; d    60.61340</span></span>
<span></span>
<span><span class="co"># equivalent to the above method</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mixed_model</span>, newdata <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>operator <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'a'</span>, <span class="st">'b'</span>, <span class="st">'c'</span>, <span class="st">'d'</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co">#&gt;        1        2        3        4 </span></span>
<span><span class="co">#&gt; 60.27806 60.14088 60.56767 60.61340</span></span></code></pre></div>
<p>use <code><a href="https://rdrr.io/pkg/lme4/man/bootMer.html">bootMer()</a></code> to get bootstrap-based confidence intervals for predictions.</p>
<p>Another example using GLMM in the context of blocking</p>
<p>Penicillin data</p>
<div class="sourceCode" id="cb177"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">penicillin</span>, package <span class="op">=</span> <span class="st">"faraway"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">penicillin</span><span class="op">)</span></span>
<span><span class="co">#&gt;  treat    blend       yield   </span></span>
<span><span class="co">#&gt;  A:5   Blend1:4   Min.   :77  </span></span>
<span><span class="co">#&gt;  B:5   Blend2:4   1st Qu.:81  </span></span>
<span><span class="co">#&gt;  C:5   Blend3:4   Median :87  </span></span>
<span><span class="co">#&gt;  D:5   Blend4:4   Mean   :86  </span></span>
<span><span class="co">#&gt;        Blend5:4   3rd Qu.:89  </span></span>
<span><span class="co">#&gt;                   Max.   :97</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">penicillin</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span></span>
<span>    y     <span class="op">=</span> <span class="va">yield</span>,</span>
<span>    x     <span class="op">=</span> <span class="va">treat</span>,</span>
<span>    shape <span class="op">=</span> <span class="va">blend</span>,</span>
<span>    color <span class="op">=</span> <span class="va">blend</span></span>
<span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="co"># treatment = fixed effect</span></span>
<span>    <span class="co"># blend = random effects</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Treatment"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="08-linear-mixed-models_files/figure-html/unnamed-chunk-10-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb178"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/runehaubo/lmerTestR">lmerTest</a></span><span class="op">)</span> <span class="co"># for p-values</span></span>
<span><span class="va">mixed_model</span> <span class="op">&lt;-</span> <span class="fu">lmerTest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">yield</span> <span class="op">~</span> <span class="va">treat</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">blend</span><span class="op">)</span>,</span>
<span>                              data <span class="op">=</span> <span class="va">penicillin</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [</span></span>
<span><span class="co">#&gt; lmerModLmerTest]</span></span>
<span><span class="co">#&gt; Formula: yield ~ treat + (1 | blend)</span></span>
<span><span class="co">#&gt;    Data: penicillin</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML criterion at convergence: 103.8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1.4152 -0.5017 -0.1644  0.6830  1.2836 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  blend    (Intercept) 11.79    3.434   </span></span>
<span><span class="co">#&gt;  Residual             18.83    4.340   </span></span>
<span><span class="co">#&gt; Number of obs: 20, groups:  blend, 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error     df t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)   84.000      2.475 11.075  33.941 1.51e-12 ***</span></span>
<span><span class="co">#&gt; treatB         1.000      2.745 12.000   0.364   0.7219    </span></span>
<span><span class="co">#&gt; treatC         5.000      2.745 12.000   1.822   0.0935 .  </span></span>
<span><span class="co">#&gt; treatD         2.000      2.745 12.000   0.729   0.4802    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;        (Intr) treatB treatC</span></span>
<span><span class="co">#&gt; treatB -0.555              </span></span>
<span><span class="co">#&gt; treatC -0.555  0.500       </span></span>
<span><span class="co">#&gt; treatD -0.555  0.500  0.500</span></span>
<span></span>
<span><span class="co">#The BLUPs for the each blend</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span><span class="op">$</span><span class="va">blend</span></span>
<span><span class="co">#&gt;        (Intercept)</span></span>
<span><span class="co">#&gt; Blend1   4.2878788</span></span>
<span><span class="co">#&gt; Blend2  -2.1439394</span></span>
<span><span class="co">#&gt; Blend3  -0.7146465</span></span>
<span><span class="co">#&gt; Blend4   1.4292929</span></span>
<span><span class="co">#&gt; Blend5  -2.8585859</span></span></code></pre></div>
<p>Examine treatment effect</p>
<div class="sourceCode" id="cb179"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">mixed_model</span><span class="op">)</span> <span class="co"># p-value based on lmerTest</span></span>
<span><span class="co">#&gt; Type III Analysis of Variance Table with Satterthwaite's method</span></span>
<span><span class="co">#&gt;       Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F)</span></span>
<span><span class="co">#&gt; treat     70  23.333     3    12  1.2389 0.3387</span></span></code></pre></div>
<p>Since the p-value is greater than 0.05, we can’t reject the null hypothesis that there is no treatment effect.</p>
<div class="sourceCode" id="cb180"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://people.math.aau.dk/~sorenh/software/pbkrtest/">pbkrtest</a></span><span class="op">)</span></span>
<span><span class="co"># REML is not appropriate for testing fixed effects, it should be ML</span></span>
<span><span class="va">full_model</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">yield</span> <span class="op">~</span> <span class="va">treat</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">blend</span><span class="op">)</span>, </span>
<span>         <span class="va">penicillin</span>, </span>
<span>         REML <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> </span>
<span><span class="va">null_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">yield</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">blend</span><span class="op">)</span>, </span>
<span>                   <span class="va">penicillin</span>, </span>
<span>                   REML <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># use  Kenward-Roger approximation for df</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/pbkrtest/man/kr-modcomp.html">KRmodcomp</a></span><span class="op">(</span><span class="va">full_model</span>, <span class="va">null_model</span><span class="op">)</span> </span>
<span><span class="co">#&gt; large : yield ~ treat + (1 | blend)</span></span>
<span><span class="co">#&gt; small : yield ~ 1 + (1 | blend)</span></span>
<span><span class="co">#&gt;          stat     ndf     ddf F.scaling p.value</span></span>
<span><span class="co">#&gt; Ftest  1.2389  3.0000 12.0000         1  0.3387</span></span></code></pre></div>
<p>Since the p-value is greater than 0.05, and consistent with our previous observation, we conclude that we can’t reject the null hypothesis that there is no treatment effect.</p>
</div>
</div>
<div id="example-2-rats" class="section level3" number="8.8.2">
<h3>
<span class="header-section-number">8.8.2</span> Example 2 (Rats)<a class="anchor" aria-label="anchor" href="#example-2-rats"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb181"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rats</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span></span>
<span>    <span class="st">"images/rats.dat"</span>,</span>
<span>    header <span class="op">=</span> <span class="cn">F</span>,</span>
<span>    sep <span class="op">=</span> <span class="st">' '</span>,</span>
<span>    col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'Treatment'</span>, <span class="st">'rat'</span>, <span class="st">'age'</span>, <span class="st">'y'</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># log transformed age</span></span>
<span><span class="va">rats</span><span class="op">$</span><span class="va">t</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="va">rats</span><span class="op">$</span><span class="va">age</span> <span class="op">-</span> <span class="fl">45</span><span class="op">)</span> <span class="op">/</span> <span class="fl">10</span><span class="op">)</span> </span></code></pre></div>
<p>We are interested in whether treatment effect induces changes over time.</p>
<div class="sourceCode" id="cb182"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rat_model</span> <span class="op">&lt;-</span></span>
<span>    <span class="co"># treatment = fixed effect, rat = random effects</span></span>
<span>    <span class="fu">lmerTest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/lmerTest/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">t</span><span class="op">:</span><span class="va">Treatment</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">rat</span><span class="op">)</span>, </span>
<span>                   data <span class="op">=</span> <span class="va">rats</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">rat_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed model fit by REML. t-tests use Satterthwaite's method [</span></span>
<span><span class="co">#&gt; lmerModLmerTest]</span></span>
<span><span class="co">#&gt; Formula: y ~ t:Treatment + (1 | rat)</span></span>
<span><span class="co">#&gt;    Data: rats</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; REML criterion at convergence: 932.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -2.25574 -0.65898 -0.01163  0.58356  2.88309 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  rat      (Intercept) 3.565    1.888   </span></span>
<span><span class="co">#&gt;  Residual             1.445    1.202   </span></span>
<span><span class="co">#&gt; Number of obs: 252, groups:  rat, 50</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                Estimate Std. Error       df t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)     68.6074     0.3312  89.0275  207.13   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; t:Treatmentcon   7.3138     0.2808 247.2762   26.05   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; t:Treatmenthig   6.8711     0.2276 247.7097   30.19   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; t:Treatmentlow   7.5069     0.2252 247.5196   33.34   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;             (Intr) t:Trtmntc t:Trtmnth</span></span>
<span><span class="co">#&gt; t:Tretmntcn -0.327                    </span></span>
<span><span class="co">#&gt; t:Tretmnthg -0.340  0.111             </span></span>
<span><span class="co">#&gt; t:Tretmntlw -0.351  0.115     0.119</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">rat_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; Type III Analysis of Variance Table with Satterthwaite's method</span></span>
<span><span class="co">#&gt;             Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; t:Treatment 3181.9  1060.6     3 223.21  734.11 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Since the p-value is significant, we can be confident concluding that there is a treatment effect</p>
</div>
<div id="example-3-agridat" class="section level3" number="8.8.3">
<h3>
<span class="header-section-number">8.8.3</span> Example 3 (Agridat)<a class="anchor" aria-label="anchor" href="#example-3-agridat"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb183"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://kwstat.github.io/agridat/">agridat</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://latticeextra.r-forge.r-project.org/">latticeExtra</a></span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="va">harris.wateruse</span></span>
<span><span class="co"># Compare to Schabenberger &amp; Pierce, fig 7.23</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/latticeExtra/man/useOuterStrips.html">useOuterStrips</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/lattice/man/xyplot.html">xyplot</a></span><span class="op">(</span></span>
<span>        <span class="va">water</span> <span class="op">~</span> <span class="va">day</span> <span class="op">|</span> <span class="va">species</span> <span class="op">*</span> <span class="va">age</span>,</span>
<span>        <span class="va">dat</span>,</span>
<span>        as.table <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>        group <span class="op">=</span> <span class="va">tree</span>,</span>
<span>        type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'p'</span>, <span class="st">'smooth'</span><span class="op">)</span>,</span>
<span>        main <span class="op">=</span> <span class="st">"harris.wateruse 2 species, 2 ages (10 trees each)"</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="08-linear-mixed-models_files/figure-html/unnamed-chunk-15-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Remove outliers</p>
<div class="sourceCode" id="cb184"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">day</span><span class="op">!=</span><span class="fl">268</span><span class="op">)</span></span></code></pre></div>
<p>Plot between age and species</p>
<div class="sourceCode" id="cb185"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/lattice/man/xyplot.html">xyplot</a></span><span class="op">(</span></span>
<span>    <span class="va">water</span> <span class="op">~</span> <span class="va">day</span> <span class="op">|</span> <span class="va">tree</span>,</span>
<span>    <span class="va">dat</span>,</span>
<span>    subset   <span class="op">=</span> <span class="va">age</span> <span class="op">==</span> <span class="st">"A2"</span> <span class="op">&amp;</span> <span class="va">species</span> <span class="op">==</span> <span class="st">"S2"</span>,</span>
<span>    as.table <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    type     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'p'</span>, <span class="st">'smooth'</span><span class="op">)</span>,</span>
<span>    ylab     <span class="op">=</span> <span class="st">"Water use profiles of individual trees"</span>,</span>
<span>    main     <span class="op">=</span> <span class="st">"harris.wateruse (Age 2, Species 2)"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="08-linear-mixed-models_files/figure-html/unnamed-chunk-17-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb186"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Rescale day for nicer output, </span></span>
<span><span class="co"># and convergence issues, add quadratic term</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html">transform</a></span><span class="op">(</span><span class="va">dat</span>, ti <span class="op">=</span> <span class="va">day</span> <span class="op">/</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/transform.html">transform</a></span><span class="op">(</span><span class="va">dat</span>, ti2 <span class="op">=</span> <span class="va">ti</span> <span class="op">*</span> <span class="va">ti</span><span class="op">)</span></span>
<span><span class="co"># Start with a subgroup: age 2, species 2</span></span>
<span><span class="va">d22</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">age</span> <span class="op">==</span> <span class="st">"A2"</span> <span class="op">&amp;</span> <span class="va">species</span> <span class="op">==</span> <span class="st">"S2"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><code>lme</code> function from <code>nlme</code> package</p>
<div class="sourceCode" id="cb187"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/nlme/">nlme</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co">## We use pdDiag() to get uncorrelated random effects</span></span>
<span><span class="va">m1n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lme.html">lme</a></span><span class="op">(</span></span>
<span>    <span class="va">water</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">ti</span> <span class="op">+</span> <span class="va">ti2</span>,</span>
<span>    <span class="co">#intercept, time and time-squared = fixed effects</span></span>
<span>    data <span class="op">=</span> <span class="va">d22</span>,</span>
<span>    na.action <span class="op">=</span> <span class="va">na.omit</span>,</span>
<span>    random <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>tree <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/pdDiag.html">pdDiag</a></span><span class="op">(</span><span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">ti</span> <span class="op">+</span> <span class="va">ti2</span><span class="op">)</span><span class="op">)</span> </span>
<span>    <span class="co"># random intercept, time </span></span>
<span>    <span class="co"># and time squared per tree = random effects</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">m1n</span><span class="op">)</span></span>
<span><span class="co">#&gt;     (Intercept)            ti           ti2</span></span>
<span><span class="co">#&gt; T04   0.1985796  1.609864e-09  4.990101e-10</span></span>
<span><span class="co">#&gt; T05   0.3492827  2.487690e-10 -4.845287e-11</span></span>
<span><span class="co">#&gt; T19  -0.1978989 -7.681202e-10 -1.961453e-10</span></span>
<span><span class="co">#&gt; T23   0.4519003 -3.270426e-10 -2.413583e-10</span></span>
<span><span class="co">#&gt; T38  -0.6457494 -1.608770e-09 -3.298010e-10</span></span>
<span><span class="co">#&gt; T40   0.3739432  3.264705e-10 -2.543109e-11</span></span>
<span><span class="co">#&gt; T49   0.8620648  9.021831e-10 -5.402247e-12</span></span>
<span><span class="co">#&gt; T53  -0.5655049 -8.279040e-10 -4.579291e-11</span></span>
<span><span class="co">#&gt; T67  -0.4394623 -3.485113e-10  2.147434e-11</span></span>
<span><span class="co">#&gt; T71  -0.3871552  7.930610e-10  3.718993e-10</span></span></code></pre></div>
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">m1n</span><span class="op">)</span></span>
<span><span class="co">#&gt; (Intercept)          ti         ti2 </span></span>
<span><span class="co">#&gt;  -10.798799   12.346704   -2.838503</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m1n</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed-effects model fit by REML</span></span>
<span><span class="co">#&gt;   Data: d22 </span></span>
<span><span class="co">#&gt;        AIC     BIC    logLik</span></span>
<span><span class="co">#&gt;   276.5142 300.761 -131.2571</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Formula: ~1 + ti + ti2 | tree</span></span>
<span><span class="co">#&gt;  Structure: Diagonal</span></span>
<span><span class="co">#&gt;         (Intercept)           ti          ti2  Residual</span></span>
<span><span class="co">#&gt; StdDev:   0.5187869 1.438333e-05 3.864019e-06 0.3836614</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:  water ~ 1 + ti + ti2 </span></span>
<span><span class="co">#&gt;                  Value Std.Error  DF   t-value p-value</span></span>
<span><span class="co">#&gt; (Intercept) -10.798799 0.8814666 227 -12.25094       0</span></span>
<span><span class="co">#&gt; ti           12.346704 0.7827112 227  15.77428       0</span></span>
<span><span class="co">#&gt; ti2          -2.838503 0.1720614 227 -16.49704       0</span></span>
<span><span class="co">#&gt;  Correlation: </span></span>
<span><span class="co">#&gt;     (Intr) ti    </span></span>
<span><span class="co">#&gt; ti  -0.979       </span></span>
<span><span class="co">#&gt; ti2  0.970 -0.997</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Standardized Within-Group Residuals:</span></span>
<span><span class="co">#&gt;         Min          Q1         Med          Q3         Max </span></span>
<span><span class="co">#&gt; -3.07588246 -0.58531056  0.01210209  0.65402695  3.88777402 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Observations: 239</span></span>
<span><span class="co">#&gt; Number of Groups: 10</span></span></code></pre></div>
<p><code>lmer</code> function from <code>lme4</code> package</p>
<div class="sourceCode" id="cb189"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m1lmer</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">water</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">ti</span> <span class="op">+</span> <span class="va">ti2</span> <span class="op">+</span> <span class="op">(</span><span class="va">ti</span> <span class="op">+</span> <span class="va">ti2</span> <span class="op">||</span></span>
<span>                                     <span class="va">tree</span><span class="op">)</span>,</span>
<span>         data <span class="op">=</span> <span class="va">d22</span>,</span>
<span>         na.action <span class="op">=</span> <span class="va">na.omit</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">m1lmer</span><span class="op">)</span></span>
<span><span class="co">#&gt; $tree</span></span>
<span><span class="co">#&gt;     (Intercept) ti ti2</span></span>
<span><span class="co">#&gt; T04   0.1985796  0   0</span></span>
<span><span class="co">#&gt; T05   0.3492827  0   0</span></span>
<span><span class="co">#&gt; T19  -0.1978989  0   0</span></span>
<span><span class="co">#&gt; T23   0.4519003  0   0</span></span>
<span><span class="co">#&gt; T38  -0.6457494  0   0</span></span>
<span><span class="co">#&gt; T40   0.3739432  0   0</span></span>
<span><span class="co">#&gt; T49   0.8620648  0   0</span></span>
<span><span class="co">#&gt; T53  -0.5655049  0   0</span></span>
<span><span class="co">#&gt; T67  -0.4394623  0   0</span></span>
<span><span class="co">#&gt; T71  -0.3871552  0   0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; with conditional variances for "tree"</span></span></code></pre></div>
<p>Notes:</p>
<ul>
<li><p><code>||</code> double pipes= uncorrelated random effects</p></li>
<li>
<p>To remove the intercept term:</p>
<ul>
<li><p><code>(0+ti|tree)</code></p></li>
<li><p><code>(ti-1|tree)</code></p></li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">m1lmer</span><span class="op">)</span></span>
<span><span class="co">#&gt; (Intercept)          ti         ti2 </span></span>
<span><span class="co">#&gt;  -10.798799   12.346704   -2.838503</span></span>
<span><span class="va">m1l</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span><span class="op">(</span><span class="va">water</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">ti</span> <span class="op">+</span> <span class="va">ti2</span> </span>
<span>         <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">tree</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">ti</span> <span class="op">|</span> <span class="va">tree</span><span class="op">)</span> </span>
<span>         <span class="op">+</span> <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="va">ti2</span> <span class="op">|</span> <span class="va">tree</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">d22</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">m1l</span><span class="op">)</span></span>
<span><span class="co">#&gt; $tree</span></span>
<span><span class="co">#&gt;     (Intercept) ti ti2</span></span>
<span><span class="co">#&gt; T04   0.1985796  0   0</span></span>
<span><span class="co">#&gt; T05   0.3492827  0   0</span></span>
<span><span class="co">#&gt; T19  -0.1978989  0   0</span></span>
<span><span class="co">#&gt; T23   0.4519003  0   0</span></span>
<span><span class="co">#&gt; T38  -0.6457494  0   0</span></span>
<span><span class="co">#&gt; T40   0.3739432  0   0</span></span>
<span><span class="co">#&gt; T49   0.8620648  0   0</span></span>
<span><span class="co">#&gt; T53  -0.5655049  0   0</span></span>
<span><span class="co">#&gt; T67  -0.4394623  0   0</span></span>
<span><span class="co">#&gt; T71  -0.3871552  0   0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; with conditional variances for "tree"</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">m1l</span><span class="op">)</span></span>
<span><span class="co">#&gt; (Intercept)          ti         ti2 </span></span>
<span><span class="co">#&gt;  -10.798799   12.346704   -2.838503</span></span></code></pre></div>
<p>To include structured covariance terms, we can use the following way</p>
<div class="sourceCode" id="cb191"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m2n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/lme.html">lme</a></span><span class="op">(</span></span>
<span>    <span class="va">water</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">ti</span> <span class="op">+</span> <span class="va">ti2</span>,</span>
<span>    data <span class="op">=</span> <span class="va">d22</span>,</span>
<span>    random <span class="op">=</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">|</span> <span class="va">tree</span>,</span>
<span>    cor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/nlme/man/corExp.html">corExp</a></span><span class="op">(</span>form <span class="op">=</span>  <span class="op">~</span> <span class="va">day</span> <span class="op">|</span> <span class="va">tree</span><span class="op">)</span>,</span>
<span>    na.action <span class="op">=</span> <span class="va">na.omit</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/random.effects.html">ranef</a></span><span class="op">(</span><span class="va">m2n</span><span class="op">)</span></span>
<span><span class="co">#&gt;     (Intercept)</span></span>
<span><span class="co">#&gt; T04   0.1929971</span></span>
<span><span class="co">#&gt; T05   0.3424631</span></span>
<span><span class="co">#&gt; T19  -0.1988495</span></span>
<span><span class="co">#&gt; T23   0.4538660</span></span>
<span><span class="co">#&gt; T38  -0.6413664</span></span>
<span><span class="co">#&gt; T40   0.3769378</span></span>
<span><span class="co">#&gt; T49   0.8410043</span></span>
<span><span class="co">#&gt; T53  -0.5528236</span></span>
<span><span class="co">#&gt; T67  -0.4452930</span></span>
<span><span class="co">#&gt; T71  -0.3689358</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/nlme/man/fixed.effects.html">fixef</a></span><span class="op">(</span><span class="va">m2n</span><span class="op">)</span></span>
<span><span class="co">#&gt; (Intercept)          ti         ti2 </span></span>
<span><span class="co">#&gt;  -11.223310   12.712094   -2.913682</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m2n</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed-effects model fit by REML</span></span>
<span><span class="co">#&gt;   Data: d22 </span></span>
<span><span class="co">#&gt;        AIC      BIC   logLik</span></span>
<span><span class="co">#&gt;   263.3081 284.0911 -125.654</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Formula: ~1 | tree</span></span>
<span><span class="co">#&gt;         (Intercept)  Residual</span></span>
<span><span class="co">#&gt; StdDev:   0.5154042 0.3925777</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation Structure: Exponential spatial correlation</span></span>
<span><span class="co">#&gt;  Formula: ~day | tree </span></span>
<span><span class="co">#&gt;  Parameter estimate(s):</span></span>
<span><span class="co">#&gt;    range </span></span>
<span><span class="co">#&gt; 3.794624 </span></span>
<span><span class="co">#&gt; Fixed effects:  water ~ 1 + ti + ti2 </span></span>
<span><span class="co">#&gt;                  Value Std.Error  DF   t-value p-value</span></span>
<span><span class="co">#&gt; (Intercept) -11.223310 1.0988725 227 -10.21348       0</span></span>
<span><span class="co">#&gt; ti           12.712094 0.9794235 227  12.97916       0</span></span>
<span><span class="co">#&gt; ti2          -2.913682 0.2148551 227 -13.56115       0</span></span>
<span><span class="co">#&gt;  Correlation: </span></span>
<span><span class="co">#&gt;     (Intr) ti    </span></span>
<span><span class="co">#&gt; ti  -0.985       </span></span>
<span><span class="co">#&gt; ti2  0.976 -0.997</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Standardized Within-Group Residuals:</span></span>
<span><span class="co">#&gt;         Min          Q1         Med          Q3         Max </span></span>
<span><span class="co">#&gt; -3.04861039 -0.55703950  0.00278101  0.62558762  3.80676991 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Observations: 239</span></span>
<span><span class="co">#&gt; Number of Groups: 10</span></span></code></pre></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></div>
<div class="next"><a href="nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-mixed-models"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li>
<a class="nav-link" href="#dependent-data"><span class="header-section-number">8.1</span> Dependent Data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#random-intercepts-model"><span class="header-section-number">8.1.1</span> Random-Intercepts Model</a></li>
<li><a class="nav-link" href="#covariance-models"><span class="header-section-number">8.1.2</span> Covariance Models</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#estimation-2"><span class="header-section-number">8.2</span> Estimation</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#estimating-mathbfv"><span class="header-section-number">8.2.1</span> Estimating \(\mathbf{V}\)</a></li></ul>
</li>
<li>
<a class="nav-link" href="#inference-3"><span class="header-section-number">8.3</span> Inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#parameters-beta"><span class="header-section-number">8.3.1</span> Parameters \(\beta\)</a></li>
<li><a class="nav-link" href="#variance-components"><span class="header-section-number">8.3.2</span> Variance Components</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#information-criteria"><span class="header-section-number">8.4</span> Information Criteria</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#akaikes-information-criteria-aic"><span class="header-section-number">8.4.1</span> Akaike’s Information Criteria (AIC)</a></li>
<li><a class="nav-link" href="#corrected-aic-aicc"><span class="header-section-number">8.4.2</span> Corrected AIC (AICC)</a></li>
<li><a class="nav-link" href="#bayesian-information-criteria-bic"><span class="header-section-number">8.4.3</span> Bayesian Information Criteria (BIC)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#split-plot-designs"><span class="header-section-number">8.5</span> Split-Plot Designs</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#application-4"><span class="header-section-number">8.5.1</span> Application</a></li></ul>
</li>
<li><a class="nav-link" href="#repeated-measures-in-mixed-models"><span class="header-section-number">8.6</span> Repeated Measures in Mixed Models</a></li>
<li><a class="nav-link" href="#unbalanced-or-unequally-spaced-data"><span class="header-section-number">8.7</span> Unbalanced or Unequally Spaced Data</a></li>
<li>
<a class="nav-link" href="#application-5"><span class="header-section-number">8.8</span> Application</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#example-1-pulps"><span class="header-section-number">8.8.1</span> Example 1 (Pulps)</a></li>
<li><a class="nav-link" href="#example-2-rats"><span class="header-section-number">8.8.2</span> Example 2 (Rats)</a></li>
<li><a class="nav-link" href="#example-3-agridat"><span class="header-section-number">8.8.3</span> Example 3 (Agridat)</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/08-linear-mixed-models.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/08-linear-mixed-models.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2023-08-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
