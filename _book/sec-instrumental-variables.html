<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 34 Instrumental Variables | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="In many empirical settings, we seek to estimate the causal effect of an explanatory variable \(X\) on an outcome variable \(Y\). A common starting point is the Ordinary Least Squares regression:...">
<meta name="generator" content="bookdown 0.35 with bs4_book()">
<meta property="og:title" content="Chapter 34 Instrumental Variables | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/sec-instrumental-variables.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="In many empirical settings, we seek to estimate the causal effect of an explanatory variable \(X\) on an outcome variable \(Y\). A common starting point is the Ordinary Least Squares regression:...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 34 Instrumental Variables | A Guide on Data Analysis">
<meta name="twitter:description" content="In many empirical settings, we seek to estimate the causal effect of an explanatory variable \(X\) on an outcome variable \(Y\). A common starting point is the Ordinary Least Squares regression:...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="active" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="controls.html"><span class="header-section-number">38</span> Controls</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">39</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="sec-instrumental-variables" class="section level1" number="34">
<h1>
<span class="header-section-number">34</span> Instrumental Variables<a class="anchor" aria-label="anchor" href="#sec-instrumental-variables"><i class="fas fa-link"></i></a>
</h1>
<p>In many empirical settings, we seek to estimate the causal effect of an explanatory variable <span class="math inline">\(X\)</span> on an outcome variable <span class="math inline">\(Y\)</span>. A common starting point is the <a href="linear-regression.html#ordinary-least-squares">Ordinary Least Squares</a> regression:</p>
<p><span class="math display">\[ Y = \beta_0 + \beta_1 X + \varepsilon. \]</span></p>
<p>For OLS to provide an unbiased and consistent estimate of <span class="math inline">\(\beta_1\)</span>, the explanatory variable <span class="math inline">\(X\)</span> must satisfy the <em>exogeneity condition</em>:</p>
<p><span class="math display">\[ \mathbb{E}[\varepsilon \mid X] = 0. \]</span></p>
<p>However, when <span class="math inline">\(X\)</span> is correlated with the error term <span class="math inline">\(\varepsilon\)</span>, this assumption is violated, leading to <em>endogeneity</em>. As a result, the OLS estimator is biased and inconsistent. Common causes of endogeneity include:</p>
<ul>
<li>
<strong>Omitted Variable Bias (OVB):</strong> When a relevant variable is omitted from the regression, leading to correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(\varepsilon\)</span>.</li>
<li>
<strong>Simultaneity:</strong> When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are jointly determined, such as in supply-and-demand models.</li>
<li>
<strong>Measurement Error:</strong> Errors in measuring <span class="math inline">\(X\)</span> introduce bias in estimation.
<ul>
<li>
<strong>Attenuation Bias in Errors-in-Variables</strong>: measurement error in the independent variable leads to an underestimate of the true effect (biasing the coefficient toward zero).</li>
</ul>
</li>
</ul>
<p>Instrumental Variables (IV) estimation addresses endogeneity by introducing an instrument <span class="math inline">\(Z\)</span> that affects <span class="math inline">\(Y\)</span> <em>only</em> through <span class="math inline">\(X\)</span>. Similar to <a href="sec-experimental-design.html#sec-experimental-design">RCT</a>, we try to introduce randomization (random assignment to treatment) to our treatment variable by using only variation in the instrument.</p>
<p>Logic of using an instrument:</p>
<ul>
<li><p>Use only exogenous variation to see the variation in treatment (try to exclude all endogenous variation in the treatment)</p></li>
<li><p>Use only exogenous variation to see the variation in outcome (try to exclude all endogenous variation in the outcome)</p></li>
<li><p>See the relationship between treatment and outcome in terms of residual variations that are exogenous to omitted variables.</p></li>
</ul>
<p>For an instrument <span class="math inline">\(Z\)</span> to be valid, it must satisfy two conditions:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Relevance Condition</strong>: The instrument <span class="math inline">\(Z\)</span> must be correlated with the endogenous variable <span class="math inline">\(X\)</span>: <span class="math display">\[ \text{Cov}(Z, X) \neq 0. \]</span></p></li>
<li><p><strong>Exogeneity Condition (Exclusion Restriction)</strong>: The instrument <span class="math inline">\(Z\)</span> must be uncorrelated with the error term <span class="math inline">\(\varepsilon\)</span> and affect <span class="math inline">\(Y\)</span> <em>only</em> through <span class="math inline">\(X\)</span>: <span class="math display">\[ \text{Cov}(Z, \varepsilon) = 0. \]</span></p></li>
</ol>
<p>These conditions ensure that <span class="math inline">\(Z\)</span> provides exogenous variation in <span class="math inline">\(X\)</span>, allowing us to isolate the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>These conditions ensure that <span class="math inline">\(Z\)</span> provides exogenous variation in <span class="math inline">\(X\)</span>, allowing us to estimate the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. <a href="sec-experimental-design.html#sec-the-gold-standard-randomized-controlled-trials">Random assignment</a> of <span class="math inline">\(Z\)</span> helps ensure exogeneity, but we must also confirm that <span class="math inline">\(Z\)</span> influences <span class="math inline">\(Y\)</span> <em>only</em> through <span class="math inline">\(X\)</span> to satisfy the exclusion restriction.</p>
<p>The IV approach dates back to early econometric research in the 1920s and 1930s, with a significant role in Cowles Commission studies on simultaneous equations. Key contributions include:</p>
<ul>
<li>
<span class="citation">Wright (<a href="references.html#ref-wright1928tariff">1928</a>)</span>: One of the earliest applications, studying supply and demand for pig iron.</li>
<li>
<span class="citation">J. Angrist and Imbens (<a href="references.html#ref-angrist1991sources">1991</a>)</span>: Popularized IV methods using quarter-of-birth as an instrument for education.</li>
</ul>
<p>The <em>credibility revolution</em> in econometrics (1990s–2000s) led to widespread use of IVs in applied research, particularly in economics, political science, and epidemiology.</p>
<div id="challenges-with-instrumental-variables" class="section level2" number="34.1">
<h2>
<span class="header-section-number">34.1</span> Challenges with Instrumental Variables<a class="anchor" aria-label="anchor" href="#challenges-with-instrumental-variables"><i class="fas fa-link"></i></a>
</h2>
<p>While IVs can provide a solution to endogeneity, several challenges arise:</p>
<ul>
<li>
<strong>Exclusion Restriction Violations:</strong> If <span class="math inline">\(Z\)</span> affects <span class="math inline">\(Y\)</span> through any channel other than <span class="math inline">\(X\)</span>, the IV estimate is biased.</li>
<li>
<strong>Repeated Use of Instruments:</strong> Common instruments, such as weather or policy changes, may be invalid due to their widespread application across studies <span class="citation">(<a href="references.html#ref-gallen2020broken">Gallen 2020</a>)</span>. One needs to test for invalid instruments (Hausman-like test).
<ul>
<li>A notable example is <span class="citation">Mellon (<a href="references.html#ref-mellon2023rain">2023</a>)</span>, who documents that <em>289 social sciences studies</em> have used weather as an instrument for 195 variables, raising concerns about exclusion violations.</li>
</ul>
</li>
<li>
<strong>Heterogeneous Treatment Effects:</strong> The Local Average Treatment Effect (LATE) estimated by IV applies only to <em>compliers</em>—units whose treatment status is affected by the instrument.</li>
<li>
<strong>Weak Instruments</strong>: Too little correlation with the endogenous regressor yields unstable estimates.</li>
<li>
<strong>Invalid Instruments</strong>: If the instrument violates exogeneity, your results are inconsistent.</li>
<li>
<strong>Interpretation Mistakes</strong>: The IV identifies <em>only</em> the effect for those “marginal” units whose treatment status is driven by the instrument.</li>
</ul>
<hr>
</div>
<div id="framework-for-instrumental-variables" class="section level2" number="34.2">
<h2>
<span class="header-section-number">34.2</span> Framework for Instrumental Variables<a class="anchor" aria-label="anchor" href="#framework-for-instrumental-variables"><i class="fas fa-link"></i></a>
</h2>
<p>We consider a binary treatment framework where:</p>
<ul>
<li><p><span class="math inline">\(D_i \sim Bernoulli(p)\)</span> is a dummy treatment variable.</p></li>
<li><p><span class="math inline">\((Y_{0i}, Y_{1i})\)</span> are the potential outcomes under control and treatment.</p></li>
<li><p>The observed outcome is: <span class="math display">\[ Y_i = Y_{0i} + (Y_{1i} - Y_{0i}) D_i. \]</span></p></li>
<li>
<p>We introduce an instrumental variable <span class="math inline">\(Z_i\)</span> satisfying: <span class="math display">\[ Z_i \perp (Y_{0i}, Y_{1i}, D_{0i}, D_{1i}). \]</span></p>
<ul>
<li>This means <span class="math inline">\(Z_i\)</span> is independent of potential outcomes and potential treatment status.</li>
<li>
<span class="math inline">\(Z_i\)</span> must also be correlated with <span class="math inline">\(D_i\)</span> to satisfy the <strong>relevance condition</strong>.</li>
</ul>
</li>
</ul>
<div id="constant-treatment-effect-model" class="section level3" number="34.2.1">
<h3>
<span class="header-section-number">34.2.1</span> Constant-Treatment-Effect Model<a class="anchor" aria-label="anchor" href="#constant-treatment-effect-model"><i class="fas fa-link"></i></a>
</h3>
<p>Under the constant treatment effect assumption (i.e., the treatment effect is the same for all individuals),</p>
<p><span class="math display">\[
\begin{aligned}
Y_{0i} &amp;= \alpha + \eta_i, \\
Y_{1i} - Y_{0i} &amp;= \rho, \\
Y_i &amp;= Y_{0i} + D_i (Y_{1i} - Y_{0i}) \\
    &amp;= \alpha + \eta_i  + D_i \rho \\
    &amp;= \alpha + \rho D_i + \eta_i.
\end{aligned}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\eta_i\)</span> captures individual-level heterogeneity.</li>
<li>
<span class="math inline">\(\rho\)</span> is the constant treatment effect.</li>
</ul>
<p>The problem with OLS estimation is that <span class="math inline">\(D_i\)</span> may be correlated with <span class="math inline">\(\eta_i\)</span>, leading to <strong>endogeneity bias</strong>.</p>
</div>
<div id="instrumental-variable-solution" class="section level3" number="34.2.2">
<h3>
<span class="header-section-number">34.2.2</span> Instrumental Variable Solution<a class="anchor" aria-label="anchor" href="#instrumental-variable-solution"><i class="fas fa-link"></i></a>
</h3>
<p>A valid instrument <span class="math inline">\(Z_i\)</span> allows us to estimate the causal effect <span class="math inline">\(\rho\)</span> via:</p>
<p><span class="math display">\[
\begin{aligned}
\rho &amp;= \frac{\text{Cov}(Y_i, Z_i)}{\text{Cov}(D_i, Z_i)} \\
     &amp;= \frac{\text{Cov}(Y_i, Z_i) / V(Z_i) }{\text{Cov}(D_i, Z_i) / V(Z_i)} \\
     &amp;= \frac{\text{Reduced form estimate}}{\text{First-stage estimate}} \\
     &amp;= \frac{E[Y_i |Z_i = 1] - E[Y_i | Z_i = 0]}{E[D_i |Z_i = 1] - E[D_i | Z_i = 0 ]}.
\end{aligned}
\]</span></p>
<p>This ratio measures the treatment effect <em>only if</em> <span class="math inline">\(Z_i\)</span> is a valid instrument.</p>
</div>
<div id="heterogeneous-treatment-effects-and-the-late-framework" class="section level3" number="34.2.3">
<h3>
<span class="header-section-number">34.2.3</span> Heterogeneous Treatment Effects and the LATE Framework<a class="anchor" aria-label="anchor" href="#heterogeneous-treatment-effects-and-the-late-framework"><i class="fas fa-link"></i></a>
</h3>
<p>In a more general framework where treatment effects vary across individuals,</p>
<ul>
<li><p>Define <strong>potential outcomes</strong> as: <span class="math display">\[ Y_i(d,z) = \text{outcome for unit } i \text{ given } D_i = d, Z_i = z. \]</span></p></li>
<li>
<p>Define <strong>treatment status</strong> based on <span class="math inline">\(Z_i\)</span>: <span class="math display">\[ D_i = D_{0i} + Z_i (D_{1i} - D_{0i}). \]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(D_{1i}\)</span> is the treatment status when <span class="math inline">\(Z_i = 1\)</span>.</li>
<li>
<span class="math inline">\(D_{0i}\)</span> is the treatment status when <span class="math inline">\(Z_i = 0\)</span>.</li>
<li>
<span class="math inline">\(D_{1i} - D_{0i}\)</span> is the causal effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(D_i\)</span>.</li>
</ul>
</li>
</ul>
</div>
<div id="assumptions-for-late-identification" class="section level3" number="34.2.4">
<h3>
<span class="header-section-number">34.2.4</span> Assumptions for LATE Identification<a class="anchor" aria-label="anchor" href="#assumptions-for-late-identification"><i class="fas fa-link"></i></a>
</h3>
<div id="independence-instrument-randomization" class="section level4" number="34.2.4.1">
<h4>
<span class="header-section-number">34.2.4.1</span> Independence (Instrument Randomization)<a class="anchor" aria-label="anchor" href="#independence-instrument-randomization"><i class="fas fa-link"></i></a>
</h4>
<p>The instrument must be <em>as good as randomly assigned</em>:</p>
<p><span class="math display">\[ [\{Y_i(d,z); \forall d, z \}, D_{1i}, D_{0i} ] \perp Z_i. \]</span></p>
<p>This ensures that <span class="math inline">\(Z_i\)</span> is uncorrelated with potential outcomes and potential treatment status.</p>
<p>This assumption let the <strong>first-stage equation</strong> be the average causal effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(D_i\)</span></p>
<p><span class="math display">\[ \begin{aligned} E[D_i |Z_i = 1] - E[D_i | Z_i = 0] &amp;= E[D_{1i} |Z_i = 1] - E[D_{0i} |Z_i = 0] \\ &amp;= E[D_{1i} - D_{0i}] \end{aligned} \]</span></p>
<p>This assumption also is sufficient for a causal interpretation of the <strong>reduced form</strong>, where we see the effect of the instrument <span class="math inline">\(Z_i\)</span> on the outcome <span class="math inline">\(Y_i\)</span>:</p>
<p><span class="math display">\[ E[Y_i |Z_i = 1 ] - E[Y_i|Z_i = 0] = E[Y_i (D_{1i}, Z_i = 1) - Y_i (D_{0i} , Z_i = 0)] \]</span></p>
</div>
<div id="exclusion-restriction" class="section level4" number="34.2.4.2">
<h4>
<span class="header-section-number">34.2.4.2</span> Exclusion Restriction<a class="anchor" aria-label="anchor" href="#exclusion-restriction"><i class="fas fa-link"></i></a>
</h4>
<p>This is also known as the existence of the instrument assumption <span class="citation">(<a href="references.html#ref-imbens1994identification">G. W. Imbens and Angrist 1994</a>)</span>. The instrument should only affect <span class="math inline">\(Y_i\)</span> through <span class="math inline">\(D_i\)</span> (i.e., the treatment <span class="math inline">\(D_i\)</span> fully mediates the effect of <span class="math inline">\(Z_i\)</span> on <span class="math inline">\(Y_i\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
Y_{1i} &amp;= Y_i (1,1) = Y_i (1,0)\\
Y_{0i} &amp;= Y_i (0,1) = Y_i (0,0)
\end{aligned}
\]</span></p>
<p>Under this assumption (and assume <span class="math inline">\(Y_{1i, Y_{0i}}\)</span> already satisfy the independence assumption), the observed outcome <span class="math inline">\(Y_i\)</span> can be rewritten as:</p>
<p><span class="math display">\[
\begin{aligned}
  Y_i &amp;= Y_i (0, Z_i) + [Y_i (1 , Z_i) - Y_i (0, Z_i)] D_i \\
      &amp;= Y_{0i} + (Y_{1i} - Y_{0i}) D_i.
  \end{aligned}
\]</span></p>
<p>This assumption let us go from reduced-form causal effects to treatment effects <span class="citation">(<a href="references.html#ref-angrist1995two">J. D. Angrist and Imbens 1995</a>)</span>.</p>
</div>
<div id="monotonicity-no-defiers" class="section level4" number="34.2.4.3">
<h4>
<span class="header-section-number">34.2.4.3</span> Monotonicity (No Defiers)<a class="anchor" aria-label="anchor" href="#monotonicity-no-defiers"><i class="fas fa-link"></i></a>
</h4>
<p>We assume that <span class="math inline">\(Z_i\)</span> affects <span class="math inline">\(D_i\)</span> in a <em>monotonic</em> way:</p>
<p><span class="math display">\[ D_{1i} \geq D_{0i}, \quad \forall i. \]</span></p>
<ul>
<li>This assumption lets us assume that there is a first stage, in which we examine the proportion of the population that <span class="math inline">\(D_i\)</span> is driven by <span class="math inline">\(Z_i\)</span>. It implies that <span class="math inline">\(Z_i\)</span> only moves individuals <em>toward</em> treatment, but never away. This rules out “defiers” (i.e., individuals who would have taken the treatment when not assigned but refuse when assigned).</li>
<li>This assumption is used to solve to problem of the shifts between participation status back to non-participation status.
<ul>
<li><p>Alternatively, one can solve the same problem by assuming constant (homogeneous) treatment effect <span class="citation">(<a href="references.html#ref-imbens1994identification">G. W. Imbens and Angrist 1994</a>)</span>, but this is rather restrictive.</p></li>
<li><p>A third solution is the assumption that there exists a value of the instrument, where the probability of participation conditional on that value is 0 <span class="citation">J. Angrist and Imbens (<a href="references.html#ref-angrist1991sources">1991</a>)</span>.</p></li>
</ul>
</li>
</ul>
<p>Under monotonicity,</p>
<p><span class="math display">\[
\begin{aligned}
  E[D_{1i} - D_{0i} ] = P[D_{1i} &gt; D_{0i}].
  \end{aligned}
\]</span></p>
</div>
</div>
<div id="local-average-treatment-effect-theorem" class="section level3" number="34.2.5">
<h3>
<span class="header-section-number">34.2.5</span> Local Average Treatment Effect Theorem<a class="anchor" aria-label="anchor" href="#local-average-treatment-effect-theorem"><i class="fas fa-link"></i></a>
</h3>
<p>Given <strong>Independence</strong>, <strong>Exclusion</strong>, and <strong>Monotonicity</strong>, we obtain the <strong>LATE</strong> result <span class="citation">(<a href="references.html#ref-angrist2009mostly">J. D. Angrist and Pischke 2009, 4.4.1</a>)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{E[Y_i | Z_i = 1] - E[Y_i | Z_i = 0]}{E[D_i |Z_i = 1] - E[D_i |Z_i = 0]} = E[Y_{1i} - Y_{0i} | D_{1i} &gt; D_{0i}].
\end{aligned}
\]</span></p>
<p>This states that the IV estimator recovers the causal effect <em>only for compliers</em>—units whose treatment status changes due to <span class="math inline">\(Z_i\)</span>.</p>
<p>IV only identifies treatment effects for <strong>switchers</strong> (compliers):</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="25%">
<col width="34%">
<col width="40%">
</colgroup>
<thead><tr class="header">
<th>Switcher Type</th>
<th>Compliance Type</th>
<th>Definition</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Switchers</strong></td>
<td><strong>Compliers</strong></td>
<td>
<span class="math inline">\(D_{1i} &gt; D_{0i}\)</span> (take treatment if <span class="math inline">\(Z_i = 1\)</span>, not if <span class="math inline">\(Z_i = 0\)</span>)</td>
</tr>
<tr class="even">
<td><strong>Non-switchers</strong></td>
<td><strong>Always-Takers</strong></td>
<td>
<span class="math inline">\(D_{1i} = D_{0i} = 1\)</span> (always take treatment)</td>
</tr>
<tr class="odd">
<td><strong>Non-switchers</strong></td>
<td><strong>Never-Takers</strong></td>
<td>
<span class="math inline">\(D_{1i} = D_{0i} = 0\)</span> (never take treatment)</td>
</tr>
</tbody>
</table></div>
<ul>
<li>IV estimates nothing for always-takers and never-takers since their treatment status is unaffected by <span class="math inline">\(Z_i\)</span> (Similar to the fixed-effects models).</li>
</ul>
</div>
<div id="iv-in-randomized-trials-noncompliance" class="section level3" number="34.2.6">
<h3>
<span class="header-section-number">34.2.6</span> IV in Randomized Trials (Noncompliance)<a class="anchor" aria-label="anchor" href="#iv-in-randomized-trials-noncompliance"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>In randomized trials, if compliance is imperfect (i.e., compliance is voluntary), where individuals in the treatment group will not always take the treatment (e.g., <strong>selection bias</strong>), intention-to-treat (ITT) estimates are valid but <strong>contaminated by noncompliance</strong>.</li>
<li>IV estimation using <a href="sec-experimental-design.html#sec-the-gold-standard-randomized-controlled-trials">random assignment</a> (<span class="math inline">\(Z_i\)</span>) as an instrument for actual treatment received (<span class="math inline">\(D_i\)</span>) recovers the LATE.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\frac{E[Y_i |Z_i = 1] - E[Y_i |Z_i = 0]}{E[D_i |Z_i = 1]} = \frac{\text{Intent-to-Treat Effect}}{\text{Compliance Rate}} = E[Y_{1i} - Y_{0i} |D_i = 1].
\end{aligned}
\]</span></p>
<p>Under full compliance, <strong>LATE = Treatment Effect on the Treated (TOT)</strong>.</p>
<hr>
</div>
</div>
<div id="sec-estimation" class="section level2" number="34.3">
<h2>
<span class="header-section-number">34.3</span> Estimation<a class="anchor" aria-label="anchor" href="#sec-estimation"><i class="fas fa-link"></i></a>
</h2>
<div id="sec-two-stage-least-squares-estimation" class="section level3" number="34.3.1">
<h3>
<span class="header-section-number">34.3.1</span> Two-Stage Least Squares Estimation<a class="anchor" aria-label="anchor" href="#sec-two-stage-least-squares-estimation"><i class="fas fa-link"></i></a>
</h3>
<p>Two-Stage Least Squares (2SLS) is the most widely used IV estimator It’s a special case of <a href="sec-instrumental-variables.html#iv-gmm">IV-GMM</a>. Consider the structural equation:</p>
<p><span class="math display">\[
Y_i = X_i \beta + \varepsilon_i,
\]</span></p>
<p>where <span class="math inline">\(X_i\)</span> is endogenous. We introduce an <strong>instrument</strong> <span class="math inline">\(Z_i\)</span> satisfying:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Relevance</strong>: <span class="math inline">\(Z_i\)</span> is correlated with <span class="math inline">\(X_i\)</span>.</li>
<li>
<strong>Exogeneity</strong>: <span class="math inline">\(Z_i\)</span> is uncorrelated with <span class="math inline">\(\varepsilon_i\)</span>.</li>
</ol>
<p><strong>2SLS Steps</strong></p>
<ol style="list-style-type: decimal">
<li>
<p><strong>First-Stage Regression:</strong> Predict <span class="math inline">\(X_i\)</span> using the instrument: <span class="math display">\[
X_i = \pi_0 + \pi_1 Z_i + v_i.
\]</span></p>
<ul>
<li>Obtain fitted values <span class="math inline">\(\hat{X}_i = \pi_0 + \pi_1 Z_i\)</span>.</li>
</ul>
</li>
<li>
<p><strong>Second-Stage Regression:</strong> Use <span class="math inline">\(\hat{X}_i\)</span> in place of <span class="math inline">\(X_i\)</span>: <span class="math display">\[
Y_i = \beta_0 + \beta_1 \hat{X}_i + \varepsilon_i.
\]</span></p>
<ul>
<li>The estimated <span class="math inline">\(\hat{\beta}_1\)</span> is our IV estimator.</li>
</ul>
</li>
</ol>
<div class="sourceCode" id="cb882"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lrberge.github.io/fixest/">fixest</a></span><span class="op">)</span></span>
<span><span class="va">base</span> <span class="op">=</span> <span class="va">iris</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">base</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"y"</span>, <span class="st">"x1"</span>, <span class="st">"x_endo_1"</span>, <span class="st">"x_inst_1"</span>, <span class="st">"fe"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">base</span><span class="op">$</span><span class="va">x_inst_2</span> <span class="op">=</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">y</span> <span class="op">+</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">x_endo_1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">150</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">base</span><span class="op">$</span><span class="va">x_endo_2</span> <span class="op">=</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">x_inst_1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">150</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># IV Estimation</span></span>
<span><span class="va">est_iv</span> <span class="op">=</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">|</span> <span class="va">x_endo_1</span> <span class="op">+</span> <span class="va">x_endo_2</span> <span class="op">~</span> <span class="va">x_inst_1</span> <span class="op">+</span> <span class="va">x_inst_2</span>, <span class="va">base</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">est_iv</span><span class="op">)</span></span>
<span><span class="co">#&gt; TSLS estimation - Dep. Var.: y</span></span>
<span><span class="co">#&gt;                   Endo.    : x_endo_1, x_endo_2</span></span>
<span><span class="co">#&gt;                   Instr.   : x_inst_1, x_inst_2</span></span>
<span><span class="co">#&gt; Second stage: Dep. Var.: y</span></span>
<span><span class="co">#&gt; Observations: 150</span></span>
<span><span class="co">#&gt; Standard-errors: IID </span></span>
<span><span class="co">#&gt;              Estimate Std. Error  t value   Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  1.831380   0.411435  4.45121 1.6844e-05 ***</span></span>
<span><span class="co">#&gt; fit_x_endo_1 0.444982   0.022086 20.14744  &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; fit_x_endo_2 0.639916   0.307376  2.08186 3.9100e-02 *  </span></span>
<span><span class="co">#&gt; x1           0.565095   0.084715  6.67051 4.9180e-10 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; RMSE: 0.398842   Adj. R2: 0.761653</span></span>
<span><span class="co">#&gt; F-test (1st stage), x_endo_1: stat = 903.2    , p &lt; 2.2e-16 , on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt; F-test (1st stage), x_endo_2: stat =   3.25828, p = 0.041268, on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt;                   Wu-Hausman: stat =   6.79183, p = 0.001518, on 2 and 144 DoF.</span></span></code></pre></div>
<p><strong>Diagnostic Tests</strong></p>
<p>To assess instrument validity:</p>
<div class="sourceCode" id="cb883"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/fitstat.html">fitstat</a></span><span class="op">(</span><span class="va">est_iv</span>, type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"n"</span>, <span class="st">"f"</span>, <span class="st">"ivf"</span>, <span class="st">"ivf1"</span>, <span class="st">"ivf2"</span>, <span class="st">"ivwald"</span>, <span class="st">"cd"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;                 Observations: 150</span></span>
<span><span class="co">#&gt;                       F-test: stat = 132.0    , p &lt; 2.2e-16 , on 3 and 146 DoF.</span></span>
<span><span class="co">#&gt; F-test (1st stage), x_endo_1: stat = 903.2    , p &lt; 2.2e-16 , on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt; F-test (1st stage), x_endo_2: stat =   3.25828, p = 0.041268, on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt;           F-test (2nd stage): stat = 194.2    , p &lt; 2.2e-16 , on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt; Wald (1st stage), x_endo_1  : stat = 903.2    , p &lt; 2.2e-16 , on 2 and 146 DoF, VCOV: IID.</span></span>
<span><span class="co">#&gt; Wald (1st stage), x_endo_2  : stat =   3.25828, p = 0.041268, on 2 and 146 DoF, VCOV: IID.</span></span>
<span><span class="co">#&gt;                 Cragg-Donald: 3.11162</span></span></code></pre></div>
<p>To set default printing</p>
<div class="sourceCode" id="cb884"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># always add second-stage Wald test</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/print.fixest.html">setFixest_print</a></span><span class="op">(</span>fitstat <span class="op">=</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">ivwald2</span><span class="op">)</span></span>
<span><span class="va">est_iv</span></span></code></pre></div>
<p>To see results from different stages</p>
<div class="sourceCode" id="cb885"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># first-stage</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">est_iv</span>, stage <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># second-stage</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">est_iv</span>, stage <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># both stages</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">est_iv</span>, stage <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span>, fitstat <span class="op">=</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">ivfall</span> <span class="op">+</span> <span class="va">ivwaldall.p</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">est_iv</span>, stage <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span>, fitstat <span class="op">=</span> <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">ivfall</span> <span class="op">+</span> <span class="va">ivwaldall.p</span><span class="op">)</span></span>
<span><span class="co"># .p means p-value, not statistic</span></span>
<span><span class="co"># `all` means IV only</span></span></code></pre></div>
</div>
<div id="iv-gmm" class="section level3" number="34.3.2">
<h3>
<span class="header-section-number">34.3.2</span> IV-GMM<a class="anchor" aria-label="anchor" href="#iv-gmm"><i class="fas fa-link"></i></a>
</h3>
<p>The Generalized Method of Moments (GMM) provides a flexible estimation framework that generalizes the Instrumental Variables (IV) approach, including <a href="sec-instrumental-variables.html#sec-two-stage-least-squares-estimation">2SLS</a> as a special case. The key idea behind GMM is to use moment conditions derived from economic models to estimate parameters efficiently, even in the presence of endogeneity.</p>
<p>Consider the standard linear regression model:</p>
<p><span class="math display">\[
Y = X\beta + u, \quad u \sim (0, \Omega)
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(Y\)</span> is an <span class="math inline">\(N \times 1\)</span> vector of the dependent variable.</li>
<li>
<span class="math inline">\(X\)</span> is an <span class="math inline">\(N \times k\)</span> matrix of endogenous regressors.</li>
<li>
<span class="math inline">\(\beta\)</span> is a <span class="math inline">\(k \times 1\)</span> vector of coefficients.</li>
<li>
<span class="math inline">\(u\)</span> is an <span class="math inline">\(N \times 1\)</span> vector of error terms.</li>
<li>
<span class="math inline">\(\Omega\)</span> is the variance-covariance matrix of <span class="math inline">\(u\)</span>.</li>
</ul>
<p>To address endogeneity in <span class="math inline">\(X\)</span>, we introduce an <span class="math inline">\(N \times l\)</span> matrix of instruments, <span class="math inline">\(Z\)</span>, where <span class="math inline">\(l \geq k\)</span>. The moment conditions are then given by:</p>
<p><span class="math display">\[
E[Z_i' u_i] = E[Z_i' (Y_i - X_i \beta)] = 0.
\]</span></p>
<p>In practice, these expectations are replaced by their sample analogs. The empirical moment conditions are given by:</p>
<p><span class="math display">\[
\bar{g}(\beta) = \frac{1}{N} \sum_{i=1}^{N} Z_i' (Y_i - X_i \beta) = \frac{1}{N} Z' (Y - X\beta).
\]</span></p>
<p>GMM estimates <span class="math inline">\(\beta\)</span> by minimizing a quadratic function of these sample moments.</p>
<hr>
<div id="iv-and-gmm-estimators" class="section level4" number="34.3.2.1">
<h4>
<span class="header-section-number">34.3.2.1</span> IV and GMM Estimators<a class="anchor" aria-label="anchor" href="#iv-and-gmm-estimators"><i class="fas fa-link"></i></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<strong>Exactly Identified Case</strong> (<span class="math inline">\(l = k\)</span>)</li>
</ol>
<p>When the number of instruments equals the number of endogenous regressors (<span class="math inline">\(l = k\)</span>), the moment conditions uniquely determine <span class="math inline">\(\beta\)</span>. In this case, the IV estimator is:</p>
<p><span class="math display">\[
\hat{\beta}_{IV} = (Z'X)^{-1}Z'Y.
\]</span></p>
<p>This is equivalent to the classical 2SLS estimator.</p>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Overidentified Case</strong> (<span class="math inline">\(l &gt; k\)</span>)</li>
</ol>
<p>When there are more instruments than endogenous variables (<span class="math inline">\(l &gt; k\)</span>), the system has more moment conditions than parameters. In this case, we project <span class="math inline">\(X\)</span> onto the instrument space:</p>
<p><span class="math display">\[
\hat{X} = Z(Z'Z)^{-1} Z' X = P_Z X.
\]</span></p>
<p>The 2SLS estimator is then given by:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\beta}_{2SLS} &amp;= (\hat{X}'X)^{-1} \hat{X}' Y \\
&amp;= (X'P_Z X)^{-1} X' P_Z Y.
\end{aligned}
\]</span></p>
<p>However, 2SLS does not optimally weight the instruments when <span class="math inline">\(l &gt; k\)</span>. The IV-GMM approach resolves this issue.</p>
<hr>
</div>
<div id="iv-gmm-estimation" class="section level4" number="34.3.2.2">
<h4>
<span class="header-section-number">34.3.2.2</span> IV-GMM Estimation<a class="anchor" aria-label="anchor" href="#iv-gmm-estimation"><i class="fas fa-link"></i></a>
</h4>
<p>The GMM estimator is obtained by minimizing the objective function:</p>
<p><span class="math display">\[
J (\hat{\beta}_{GMM} ) = N \bar{g}(\hat{\beta}_{GMM})' W \bar{g} (\hat{\beta}_{GMM}),
\]</span></p>
<p>where <span class="math inline">\(W\)</span> is an <span class="math inline">\(l \times l\)</span> symmetric weighting matrix.</p>
<p>For the IV-GMM estimator, solving the first-order conditions yields:</p>
<p><span class="math display">\[
\hat{\beta}_{GMM} = (X'ZWZ' X)^{-1} X'ZWZ'Y.
\]</span></p>
<p>For any weighting matrix <span class="math inline">\(W\)</span>, this is a consistent estimator. The optimal choice of <span class="math inline">\(W\)</span> is <span class="math inline">\(S^{-1}\)</span>, where <span class="math inline">\(S\)</span> is the covariance matrix of the moment conditions:</p>
<p><span class="math display">\[
S = E[Z' u u' Z] = \lim_{N \to \infty} N^{-1} [Z' \Omega Z].
\]</span></p>
<p>A feasible estimator replaces <span class="math inline">\(S\)</span> with its sample estimate from the 2SLS residuals:</p>
<p><span class="math display">\[
\hat{\beta}_{FEGMM} = (X'Z \hat{S}^{-1} Z' X)^{-1} X'Z \hat{S}^{-1} Z'Y.
\]</span></p>
<p>When <span class="math inline">\(\Omega\)</span> satisfies standard assumptions:</p>
<ol style="list-style-type: decimal">
<li>Errors are independently and identically distributed.</li>
<li>
<span class="math inline">\(S = \sigma_u^2 I_N\)</span>.</li>
<li>The optimal weighting matrix is proportional to the identity matrix.</li>
</ol>
<p>Then, the IV-GMM estimator simplifies to the standard IV (or 2SLS) estimator.</p>
<hr>
<p>Comparison of 2SLS and IV-GMM</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="26%">
<col width="36%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th>Feature</th>
<th>2SLS</th>
<th>IV-GMM</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Instrument usage</td>
<td>Uses a subset of available instruments</td>
<td>Uses all available instruments</td>
</tr>
<tr class="even">
<td>Weighting</td>
<td>No weighting applied</td>
<td>Weights instruments for efficiency</td>
</tr>
<tr class="odd">
<td>Efficiency</td>
<td>Suboptimal in overidentified cases</td>
<td>Efficient when <span class="math inline">\(W = S^{-1}\)</span>
</td>
</tr>
<tr class="even">
<td>Overidentification test</td>
<td>Not available</td>
<td>Uses Hansen’s <span class="math inline">\(J\)</span>-test (overid test)</td>
</tr>
</tbody>
</table></div>
<p>Key Takeaways:</p>
<ul>
<li>Use IV-GMM whenever overidentification is a concern (i.e., <span class="math inline">\(l &gt; k\)</span>).</li>
<li>2SLS is a special case of IV-GMM when the weighting matrix is proportional to the identity matrix.</li>
<li>IV-GMM improves efficiency by optimally weighting the moment conditions.</li>
</ul>
<div class="sourceCode" id="cb886"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Standard approach</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">gmm</span><span class="op">)</span></span>
<span><span class="va">gmm_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gmm/man/gmm.html">gmm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span>, <span class="op">~</span> <span class="va">x_inst_1</span> <span class="op">+</span> <span class="va">x_inst_2</span>, data <span class="op">=</span> <span class="va">base</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">gmm_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; gmm(g = y ~ x1, x = ~x_inst_1 + x_inst_2, data = base)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method:  twoStep </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kernel:  Quadratic Spectral(with bw =  0.72368 )</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;              Estimate     Std. Error   t value      Pr(&gt;|t|)   </span></span>
<span><span class="co">#&gt; (Intercept)   1.4385e+01   1.8960e+00   7.5871e+00   3.2715e-14</span></span>
<span><span class="co">#&gt; x1           -2.7506e+00   6.2101e-01  -4.4292e+00   9.4584e-06</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; J-Test: degrees of freedom is 1 </span></span>
<span><span class="co">#&gt;                 J-test     P-value  </span></span>
<span><span class="co">#&gt; Test E(g)=0:    7.9455329  0.0048206</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Initial values of the coefficients</span></span>
<span><span class="co">#&gt; (Intercept)          x1 </span></span>
<span><span class="co">#&gt;   16.117875   -3.360622</span></span></code></pre></div>
<hr>
</div>
<div id="overidentification-test-hansens-j-statistic" class="section level4" number="34.3.2.3">
<h4>
<span class="header-section-number">34.3.2.3</span> Overidentification Test: Hansen’s <span class="math inline">\(J\)</span>-Statistic<a class="anchor" aria-label="anchor" href="#overidentification-test-hansens-j-statistic"><i class="fas fa-link"></i></a>
</h4>
<p>A key advantage of IV-GMM is that it allows testing of instrument validity through the <strong>Hansen</strong> <span class="math inline">\(J\)</span>-test (also known as the GMM distance test or Hayashi’s C-statistic). The test statistic is:</p>
<p><span class="math display">\[
J = N \bar{g}(\hat{\beta}_{GMM})' \hat{S}^{-1} \bar{g} (\hat{\beta}_{GMM}),
\]</span></p>
<p>which follows a <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom equal to the number of overidentifying restrictions (<span class="math inline">\(l - k\)</span>). A significant <span class="math inline">\(J\)</span>-statistic suggests that the instruments may not be valid.</p>
<hr>
</div>
<div id="cluster-robust-standard-errors" class="section level4" number="34.3.2.4">
<h4>
<span class="header-section-number">34.3.2.4</span> Cluster-Robust Standard Errors<a class="anchor" aria-label="anchor" href="#cluster-robust-standard-errors"><i class="fas fa-link"></i></a>
</h4>
<p>In empirical applications, errors often exhibit <strong>heteroskedasticity</strong> or <strong>intra-group correlation</strong> (clustering), violating the assumption of independently and identically distributed errors. Standard IV-GMM estimators remain consistent but <strong>may not be efficient</strong> if clustering is ignored.</p>
<p>To address this, we adjust the GMM weighting matrix by incorporating cluster-robust variance estimation. Specifically, the covariance matrix of the moment conditions <span class="math inline">\(S\)</span> is estimated as:</p>
<p><span class="math display">\[
\hat{S} = \frac{1}{N} \sum_{c=1}^{C} \left( \sum_{i \in c} Z_i' u_i \right) \left( \sum_{i \in c} Z_i' u_i \right)',
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(C\)</span> is the number of clusters,</p></li>
<li><p><span class="math inline">\(i \in c\)</span> represents observations belonging to cluster <span class="math inline">\(c\)</span>,</p></li>
<li><p><span class="math inline">\(u_i\)</span> is the residual for observation <span class="math inline">\(i\)</span>,</p></li>
<li><p><span class="math inline">\(Z_i\)</span> is the vector of instruments.</p></li>
</ul>
<p>Using this robust weighting matrix, we compute a <strong>clustered GMM estimator</strong> that remains consistent and improves inference when clustering is present.</p>
<hr>
<div class="sourceCode" id="cb887"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">gmm</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>  <span class="co"># For generalized inverse if needed</span></span>
<span></span>
<span><span class="co"># General IV-GMM function with clustering</span></span>
<span><span class="va">gmmcl</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">formula</span>, <span class="va">instruments</span>, <span class="va">data</span>, <span class="va">cluster_var</span>, <span class="va">lambda</span> <span class="op">=</span> <span class="fl">1e-6</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="co"># Ensure cluster_var exists in data</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="va">cluster_var</span> <span class="op"><a href="https://rdrr.io/pkg/BiocGenerics/man/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/stop.html">stop</a></span><span class="op">(</span><span class="st">"Error: Cluster variable not found in data."</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="co"># Step 1: Initial GMM estimation (identity weighting matrix)</span></span>
<span>  <span class="va">initial_gmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gmm/man/gmm.html">gmm</a></span><span class="op">(</span><span class="va">formula</span>, <span class="va">instruments</span>, data <span class="op">=</span> <span class="va">data</span>, vcov <span class="op">=</span> <span class="st">"TrueFixed"</span>, </span>
<span>                      weightsMatrix <span class="op">=</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">ncol</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">instruments</span>, <span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Extract residuals</span></span>
<span>  <span class="va">u_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">initial_gmm</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Matrix of instruments</span></span>
<span>  <span class="va">Z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">instruments</span>, <span class="va">data</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Ensure clusters are treated as a factor</span></span>
<span>  <span class="va">data</span><span class="op">[[</span><span class="va">cluster_var</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">data</span><span class="op">[[</span><span class="va">cluster_var</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Compute clustered weighting matrix</span></span>
<span>  <span class="va">cluster_groups</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">u_hat</span><span class="op">)</span>, <span class="va">data</span><span class="op">[[</span><span class="va">cluster_var</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Remove empty clusters (if any)</span></span>
<span>  <span class="va">cluster_groups</span> <span class="op">&lt;-</span> <span class="va">cluster_groups</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/lengths.html">lengths</a></span><span class="op">(</span><span class="va">cluster_groups</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Initialize cluster-based covariance matrix</span></span>
<span>  <span class="va">S_cluster</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">ncol</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">ncol</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Zero matrix</span></span>
<span>  </span>
<span>  <span class="co"># Compute clustered weight matrix</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">indices</span> <span class="kw">in</span> <span class="va">cluster_groups</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">indices</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> <span class="op">{</span>  <span class="co"># Ensure valid clusters</span></span>
<span>      <span class="va">u_cluster</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">u_hat</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>  <span class="co"># Convert to column matrix</span></span>
<span>      <span class="va">Z_cluster</span> <span class="op">&lt;-</span> <span class="va">Z</span><span class="op">[</span><span class="va">indices</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span>        <span class="co"># Keep matrix form</span></span>
<span>      <span class="va">S_cluster</span> <span class="op">&lt;-</span> <span class="va">S_cluster</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/t.html">t</a></span><span class="op">(</span><span class="va">Z_cluster</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="op">(</span><span class="va">u_cluster</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/t.html">t</a></span><span class="op">(</span><span class="va">u_cluster</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">Z_cluster</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="co"># Normalize by sample size</span></span>
<span>  <span class="va">S_cluster</span> <span class="op">&lt;-</span> <span class="va">S_cluster</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Ensure S_cluster is invertible</span></span>
<span>  <span class="va">S_cluster</span> <span class="op">&lt;-</span> <span class="va">S_cluster</span> <span class="op">+</span> <span class="va">lambda</span> <span class="op">*</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">ncol</a></span><span class="op">(</span><span class="va">S_cluster</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Regularization</span></span>
<span></span>
<span>  <span class="co"># Compute inverse or generalized inverse if needed</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/qr-methods.html">qr</a></span><span class="op">(</span><span class="va">S_cluster</span><span class="op">)</span><span class="op">$</span><span class="va">rank</span> <span class="op">&lt;</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">ncol</a></span><span class="op">(</span><span class="va">S_cluster</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">S_cluster_inv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/ginv.html">ginv</a></span><span class="op">(</span><span class="va">S_cluster</span><span class="op">)</span>  <span class="co"># Use generalized inverse (MASS package)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">S_cluster_inv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">S_cluster</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># Step 2: GMM estimation using clustered weighting matrix</span></span>
<span>  <span class="va">final_gmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gmm/man/gmm.html">gmm</a></span><span class="op">(</span><span class="va">formula</span>, <span class="va">instruments</span>, data <span class="op">=</span> <span class="va">data</span>, vcov <span class="op">=</span> <span class="st">"TrueFixed"</span>, </span>
<span>                    weightsMatrix <span class="op">=</span> <span class="va">S_cluster_inv</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">final_gmm</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Example: Simulated Data for IV-GMM with Clustering</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">200</span>   <span class="co"># Total observations</span></span>
<span><span class="va">C</span> <span class="op">&lt;-</span> <span class="fl">50</span>    <span class="co"># Number of clusters</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  cluster <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">C</span>, each <span class="op">=</span> <span class="va">n</span> <span class="op">/</span> <span class="va">C</span><span class="op">)</span>,  <span class="co"># Cluster variable</span></span>
<span>  z1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  z2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  x1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  y1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">data</span><span class="op">$</span><span class="va">x1</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">$</span><span class="va">z1</span> <span class="op">+</span> <span class="va">data</span><span class="op">$</span><span class="va">z2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>  <span class="co"># Endogenous regressor</span></span>
<span><span class="va">data</span><span class="op">$</span><span class="va">y1</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">$</span><span class="va">x1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>            <span class="co"># Outcome variable</span></span>
<span></span>
<span><span class="co"># Run standard IV-GMM (without clustering)</span></span>
<span><span class="va">gmm_results_standard</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gmm/man/gmm.html">gmm</a></span><span class="op">(</span><span class="va">y1</span> <span class="op">~</span> <span class="va">x1</span>, <span class="op">~</span> <span class="va">z1</span> <span class="op">+</span> <span class="va">z2</span>, data <span class="op">=</span> <span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Run IV-GMM with clustering</span></span>
<span><span class="va">gmm_results_clustered</span> <span class="op">&lt;-</span> <span class="fu">gmmcl</span><span class="op">(</span><span class="va">y1</span> <span class="op">~</span> <span class="va">x1</span>, <span class="op">~</span> <span class="va">z1</span> <span class="op">+</span> <span class="va">z2</span>, data <span class="op">=</span> <span class="va">data</span>, cluster_var <span class="op">=</span> <span class="st">"cluster"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display results for comparison</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">gmm_results_standard</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; gmm(g = y1 ~ x1, x = ~z1 + z2, data = data)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method:  twoStep </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kernel:  Quadratic Spectral(with bw =  1.09893 )</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;              Estimate     Std. Error   t value      Pr(&gt;|t|)   </span></span>
<span><span class="co">#&gt; (Intercept)   4.4919e-02   6.5870e-02   6.8193e-01   4.9528e-01</span></span>
<span><span class="co">#&gt; x1            9.8409e-01   4.4215e-02   2.2257e+01  9.6467e-110</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; J-Test: degrees of freedom is 1 </span></span>
<span><span class="co">#&gt;                 J-test  P-value</span></span>
<span><span class="co">#&gt; Test E(g)=0:    1.6171  0.2035 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Initial values of the coefficients</span></span>
<span><span class="co">#&gt; (Intercept)          x1 </span></span>
<span><span class="co">#&gt;  0.05138658  0.98580796</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">gmm_results_clustered</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; gmm(g = formula, x = instruments, vcov = "TrueFixed", weightsMatrix = S_cluster_inv, </span></span>
<span><span class="co">#&gt;     data = data)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Method:  One step GMM with fixed W </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Kernel:  Quadratic Spectral</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;              Estimate    Std. Error  t value     Pr(&gt;|t|)  </span></span>
<span><span class="co">#&gt; (Intercept)  4.9082e-02  7.0878e-05  6.9249e+02  0.0000e+00</span></span>
<span><span class="co">#&gt; x1           9.8238e-01  5.2798e-05  1.8606e+04  0.0000e+00</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; J-Test: degrees of freedom is 1 </span></span>
<span><span class="co">#&gt;                 J-test   P-value</span></span>
<span><span class="co">#&gt; Test E(g)=0:    1247099        0</span></span></code></pre></div>
<hr>
</div>
</div>
<div id="limited-information-maximum-likelihood" class="section level3" number="34.3.3">
<h3>
<span class="header-section-number">34.3.3</span> Limited Information Maximum Likelihood<a class="anchor" aria-label="anchor" href="#limited-information-maximum-likelihood"><i class="fas fa-link"></i></a>
</h3>
<p>LIML is an alternative to 2SLS that performs better when instruments are weak.</p>
<p>It solves: <span class="math display">\[
\min_{\lambda} \left| \begin{bmatrix} Y - X\beta \\ \lambda (D - X\gamma) \end{bmatrix} \right|
\]</span> where <span class="math inline">\(\lambda\)</span> is an eigenvalue.</p>
</div>
<div id="jackknife-iv" class="section level3" number="34.3.4">
<h3>
<span class="header-section-number">34.3.4</span> Jackknife IV<a class="anchor" aria-label="anchor" href="#jackknife-iv"><i class="fas fa-link"></i></a>
</h3>
<p>JIVE reduces small-sample bias by leaving each observation out when estimating first-stage fitted values:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{X}_i^{(-i)} &amp;= Z_i (Z_{-i}'Z_{-i})^{-1} Z_{-i}'X_{-i}. \\
\hat{\beta}_{JIVE} &amp;= (X^{(-i)'}X^{(-i)})^{-1}X^{(-i)'} Y
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb888"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span></span>
<span><span class="va">jive_model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/AER/man/ivreg.html">ivreg</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x_endo_1</span> <span class="op">|</span> <span class="va">x_inst_1</span>, data <span class="op">=</span> <span class="va">base</span>, method <span class="op">=</span> <span class="st">"jive"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">jive_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; ivreg(formula = y ~ x_endo_1 | x_inst_1, data = base, method = "jive")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1.2390 -0.3022 -0.0206  0.2772  1.0039 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  4.34586    0.08096   53.68   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; x_endo_1     0.39848    0.01964   20.29   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 0.4075 on 148 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-Squared: 0.7595,  Adjusted R-squared: 0.7578 </span></span>
<span><span class="co">#&gt; Wald test: 411.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<hr>
</div>
<div id="control-function-approach" class="section level3" number="34.3.5">
<h3>
<span class="header-section-number">34.3.5</span> Control Function Approach<a class="anchor" aria-label="anchor" href="#control-function-approach"><i class="fas fa-link"></i></a>
</h3>
<p>The Control Function (CF) approach, also known as two-stage residual inclusion (2SRI), is a method used to address endogeneity in regression models. This approach is particularly suited for models with nonadditive errors, such as discrete choice models or cases where both the endogenous variable and the outcome are binary.</p>
<p>The control function approach is particularly useful in:</p>
<ul>
<li>
<strong>Binary outcome and binary endogenous variable models</strong>:
<ul>
<li>In rare events, the second stage typically uses a <strong>logistic model</strong> <span class="citation">(<a href="references.html#ref-tchetgen2014note">E. Tchetgen Tchetgen 2014</a>)</span>.</li>
<li>In non-rare events, a <strong>risk ratio regression</strong> is often more appropriate.</li>
</ul>
</li>
<li>
<strong>Marketing applications</strong>:
<ul>
<li>Used in consumer choice models to account for endogeneity in demand estimation <span class="citation">(<a href="references.html#ref-petrin2010control">Petrin and Train 2010</a>)</span>.</li>
</ul>
</li>
</ul>
<p>The general model setup is:</p>
<p><span class="math display">\[
Y = g(X) + U  
\]</span></p>
<p><span class="math display">\[
X = \pi(Z) + V  
\]</span></p>
<p>with the key assumptions:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Conditional mean independence</strong>:<br><span class="math display">\[E(U |Z,V) = E(U|V)\]</span><br>
This implies that once we control for <span class="math inline">\(V\)</span>, the instrumental variable <span class="math inline">\(Z\)</span> does not directly affect <span class="math inline">\(U\)</span>.</p></li>
<li><p><strong>Instrument relevance</strong>:<br><span class="math display">\[E(V|Z) = 0\]</span><br>
This ensures that <span class="math inline">\(Z\)</span> is a valid instrument for <span class="math inline">\(X\)</span>.</p></li>
</ol>
<p>Under the control function approach, the expectation of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\((Z,V)\)</span> can be rewritten as:</p>
<p><span class="math display">\[
E(Y|Z,V) = g(X) + E(U|Z,V) = g(X) + E(U|V) = g(X) + h(V).
\]</span></p>
<p>Here, <span class="math inline">\(h(V)\)</span> is the control function that captures endogeneity through the first-stage residuals.</p>
<div id="implementation" class="section level4" number="34.3.5.1">
<h4>
<span class="header-section-number">34.3.5.1</span> Implementation<a class="anchor" aria-label="anchor" href="#implementation"><i class="fas fa-link"></i></a>
</h4>
<p>Rather than replacing the endogenous variable <span class="math inline">\(X_i\)</span> with its predicted value <span class="math inline">\(\hat{X}_i\)</span>, the CF approach explicitly incorporates the residuals from the first-stage regression:</p>
<p><strong>Stage 1: Estimate First-Stage Residuals</strong></p>
<p>Estimate the endogenous variable using its instrumental variables:</p>
<p><span class="math display">\[
X_i = Z_i \pi + v_i.
\]</span></p>
<p>Obtain the residuals:</p>
<p><span class="math display">\[
\hat{v}_i = X_i - Z_i \hat{\pi}.
\]</span></p>
<p><strong>Stage 2: Include Residuals in Outcome Equation</strong></p>
<p>Regress the outcome variable on <span class="math inline">\(X_i\)</span> and the first-stage residuals:</p>
<p><span class="math display">\[
Y_i = X_i \beta + \gamma \hat{v}_i + \varepsilon_i.
\]</span></p>
<p>If endogeneity is present, <span class="math inline">\(\gamma \neq 0\)</span>; otherwise, the endogenous regressor <span class="math inline">\(X\)</span> would be exogenous.</p>
</div>
<div id="comparison-to-two-stage-least-squares" class="section level4" number="34.3.5.2">
<h4>
<span class="header-section-number">34.3.5.2</span> Comparison to Two-Stage Least Squares<a class="anchor" aria-label="anchor" href="#comparison-to-two-stage-least-squares"><i class="fas fa-link"></i></a>
</h4>
<p>The control function method differs from <a href="sec-instrumental-variables.html#sec-two-stage-least-squares-estimation">2SLS</a> depending on whether the model is <strong>linear</strong> or <strong>nonlinear</strong>:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Linear Endogenous Variables</strong>:
<ul>
<li>When both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous, the CF approach is equivalent to 2SLS.</li>
</ul>
</li>
<li>
<strong>Nonlinear Endogenous Variables</strong>:
<ul>
<li>If <span class="math inline">\(X\)</span> is nonlinear (e.g., a binary treatment), CF differs from 2SLS and often performs better.</li>
</ul>
</li>
<li>
<strong>Nonlinear in Parameters</strong>:
<ul>
<li>In models where <span class="math inline">\(g(X)\)</span> is nonlinear (e.g., logit/probit models), CF is typically <strong>superior</strong> to 2SLS because it explicitly models endogeneity via the control function <span class="math inline">\(h(V)\)</span>.</li>
</ul>
</li>
</ol>
<div class="sourceCode" id="cb889"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lrberge.github.io/fixest/">fixest</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://vincentarelbundock.github.io/modelsummary/">modelsummary</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set the seed for reproducibility</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">10000</span></span>
<span><span class="co"># Generate the exogenous variable from a normal distribution</span></span>
<span><span class="va">exogenous</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate the omitted variable as a function of the exogenous variable</span></span>
<span><span class="va">omitted</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">2</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate the endogenous variable as a function of the omitted variable and the exogenous variable</span></span>
<span><span class="va">endogenous</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">*</span> <span class="va">omitted</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">exogenous</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># nonlinear endogenous variable</span></span>
<span><span class="va">endogenous_nonlinear</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">*</span> <span class="va">omitted</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">exogenous</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">unrelated</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="va">n</span>, rate <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate the response variable as a function of the endogenous variable and the omitted variable</span></span>
<span><span class="va">response</span> <span class="op">&lt;-</span> <span class="fl">4</span> <span class="op">+</span>  <span class="fl">3</span> <span class="op">*</span> <span class="va">endogenous</span> <span class="op">+</span> <span class="fl">6</span> <span class="op">*</span> <span class="va">omitted</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">response_nonlinear</span> <span class="op">&lt;-</span> <span class="fl">4</span> <span class="op">+</span>  <span class="fl">3</span> <span class="op">*</span> <span class="va">endogenous_nonlinear</span> <span class="op">+</span> <span class="fl">6</span> <span class="op">*</span> <span class="va">omitted</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">response_nonlinear_para</span> <span class="op">&lt;-</span> <span class="fl">4</span> <span class="op">+</span>  <span class="fl">3</span> <span class="op">*</span> <span class="va">endogenous</span> <span class="op">^</span> <span class="fl">2</span> <span class="op">+</span> <span class="fl">6</span> <span class="op">*</span> <span class="va">omitted</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Combine the variables into a data frame</span></span>
<span><span class="va">my_data</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>        <span class="va">exogenous</span>,</span>
<span>        <span class="va">omitted</span>,</span>
<span>        <span class="va">endogenous</span>,</span>
<span>        <span class="va">response</span>,</span>
<span>        <span class="va">unrelated</span>,</span>
<span>        <span class="va">response</span>,</span>
<span>        <span class="va">response_nonlinear</span>,</span>
<span>        <span class="va">response_nonlinear_para</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># View the first few rows of the data frame</span></span>
<span><span class="co"># head(my_data)</span></span>
<span></span>
<span><span class="va">wo_omitted</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">endogenous</span> <span class="op">+</span> <span class="fu">sw0</span><span class="op">(</span><span class="va">unrelated</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span></span>
<span><span class="va">w_omitted</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">endogenous</span> <span class="op">+</span> <span class="va">omitted</span> <span class="op">+</span> <span class="va">unrelated</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># ivreg::ivreg(response ~ endogenous + unrelated | exogenous, data = my_data)</span></span>
<span><span class="va">iv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu">sw0</span><span class="op">(</span><span class="va">unrelated</span><span class="op">)</span> <span class="op">|</span> <span class="va">endogenous</span> <span class="op">~</span> <span class="va">exogenous</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://lrberge.github.io/fixest/reference/etable.html">etable</a></span><span class="op">(</span></span>
<span>    <span class="va">wo_omitted</span>,</span>
<span>    <span class="va">w_omitted</span>,</span>
<span>    <span class="va">iv</span>, </span>
<span>    digits <span class="op">=</span> <span class="fl">2</span></span>
<span>    <span class="co"># vcov = list("each", "iid", "hetero")</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt;                   wo_omitted.1   wo_omitted.2      w_omitted           iv.1</span></span>
<span><span class="co">#&gt; Dependent Var.:       response       response       response       response</span></span>
<span><span class="co">#&gt;                                                                            </span></span>
<span><span class="co">#&gt; Constant        -3.9*** (0.10) -4.0*** (0.10)  4.0*** (0.05) 15.7*** (0.59)</span></span>
<span><span class="co">#&gt; endogenous      4.0*** (0.005) 4.0*** (0.005) 3.0*** (0.004)  3.0*** (0.03)</span></span>
<span><span class="co">#&gt; unrelated                         0.03 (0.03)  0.002 (0.010)               </span></span>
<span><span class="co">#&gt; omitted                                        6.0*** (0.02)               </span></span>
<span><span class="co">#&gt; _______________ ______________ ______________ ______________ ______________</span></span>
<span><span class="co">#&gt; S.E. type                  IID            IID            IID            IID</span></span>
<span><span class="co">#&gt; Observations            10,000         10,000         10,000         10,000</span></span>
<span><span class="co">#&gt; R2                     0.98566        0.98567        0.99803        0.92608</span></span>
<span><span class="co">#&gt; Adj. R2                0.98566        0.98566        0.99803        0.92607</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                           iv.2</span></span>
<span><span class="co">#&gt; Dependent Var.:       response</span></span>
<span><span class="co">#&gt;                               </span></span>
<span><span class="co">#&gt; Constant        15.6*** (0.59)</span></span>
<span><span class="co">#&gt; endogenous       3.0*** (0.03)</span></span>
<span><span class="co">#&gt; unrelated         0.10. (0.06)</span></span>
<span><span class="co">#&gt; omitted                       </span></span>
<span><span class="co">#&gt; _______________ ______________</span></span>
<span><span class="co">#&gt; S.E. type                  IID</span></span>
<span><span class="co">#&gt; Observations            10,000</span></span>
<span><span class="co">#&gt; R2                     0.92610</span></span>
<span><span class="co">#&gt; Adj. R2                0.92608</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Linear in parameter and linear in endogenous variable</p>
<div class="sourceCode" id="cb890"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># manual</span></span>
<span><span class="co"># 2SLS</span></span>
<span><span class="va">first_stage</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">endogenous</span> <span class="op">~</span> <span class="va">exogenous</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span></span>
<span><span class="va">new_data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">my_data</span>, new_endogenous <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">first_stage</span>, <span class="va">my_data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">second_stage</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">new_endogenous</span>, data <span class="op">=</span> <span class="va">new_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">second_stage</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = response ~ new_endogenous, data = new_data)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -77.683 -14.374  -0.107  14.289  78.274 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)     15.6743     2.0819   7.529 5.57e-14 ***</span></span>
<span><span class="co">#&gt; new_endogenous   3.0142     0.1039  29.025  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 21.26 on 9998 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.07771,    Adjusted R-squared:  0.07762 </span></span>
<span><span class="co">#&gt; F-statistic: 842.4 on 1 and 9998 DF,  p-value: &lt; 2.2e-16</span></span>
<span></span>
<span><span class="va">new_data_cf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">my_data</span>, residual <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">first_stage</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">second_stage_cf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">endogenous</span> <span class="op">+</span> <span class="va">residual</span>, data <span class="op">=</span> <span class="va">new_data_cf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">second_stage_cf</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = response ~ endogenous + residual, data = new_data_cf)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span><span class="co">#&gt; -5.360 -1.016  0.003  1.023  5.201 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept) 15.674265   0.149350   105.0   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; endogenous   3.014202   0.007450   404.6   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; residual     1.140920   0.008027   142.1   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 1.525 on 9997 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.9953, Adjusted R-squared:  0.9953 </span></span>
<span><span class="co">#&gt; F-statistic: 1.048e+06 on 2 and 9997 DF,  p-value: &lt; 2.2e-16</span></span>
<span></span>
<span><span class="fu"><a href="https://modelsummary.com/man/modelsummary.html">modelsummary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span><span class="va">second_stage</span>, <span class="va">second_stage_cf</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
 (1)
</th>
<th style="text-align:center;">
  (2)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:center;">
15.674
</td>
<td style="text-align:center;">
15.674
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(2.082)
</td>
<td style="text-align:center;">
(0.149)
</td>
</tr>
<tr>
<td style="text-align:left;">
new_endogenous
</td>
<td style="text-align:center;">
3.014
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.104)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
endogenous
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
3.014
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
(0.007)
</td>
</tr>
<tr>
<td style="text-align:left;">
residual
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
1.141
</td>
</tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">
</td>
<td style="text-align:center;box-shadow: 0px 1.5px">
</td>
<td style="text-align:center;box-shadow: 0px 1.5px">
(0.008)
</td>
</tr>
<tr>
<td style="text-align:left;">
Num.Obs.
</td>
<td style="text-align:center;">
10000
</td>
<td style="text-align:center;">
10000
</td>
</tr>
<tr>
<td style="text-align:left;">
R2
</td>
<td style="text-align:center;">
0.078
</td>
<td style="text-align:center;">
0.995
</td>
</tr>
<tr>
<td style="text-align:left;">
R2 Adj.
</td>
<td style="text-align:center;">
0.078
</td>
<td style="text-align:center;">
0.995
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:center;">
89520.9
</td>
<td style="text-align:center;">
36826.8
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:center;">
89542.5
</td>
<td style="text-align:center;">
36855.6
</td>
</tr>
<tr>
<td style="text-align:left;">
Log.Lik.
</td>
<td style="text-align:center;">
−44757.438
</td>
<td style="text-align:center;">
−18409.377
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
842.424
</td>
<td style="text-align:center;">
1048263.304
</td>
</tr>
<tr>
<td style="text-align:left;">
RMSE
</td>
<td style="text-align:center;">
21.26
</td>
<td style="text-align:center;">
1.53
</td>
</tr>
</tbody>
</table></div>
<p>Nonlinear in endogenous variable</p>
<div class="sourceCode" id="cb891"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 2SLS</span></span>
<span><span class="va">first_stage</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">endogenous_nonlinear</span> <span class="op">~</span> <span class="va">exogenous</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span></span>
<span></span>
<span><span class="va">new_data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">my_data</span>, new_endogenous_nonlinear <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">first_stage</span>, <span class="va">my_data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">second_stage</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response_nonlinear</span> <span class="op">~</span> <span class="va">new_endogenous_nonlinear</span>, data <span class="op">=</span> <span class="va">new_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">second_stage</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = response_nonlinear ~ new_endogenous_nonlinear, data = new_data)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span><span class="co">#&gt; -94.43 -52.10 -15.29  36.50 446.08 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                          Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)               15.3390    11.8175   1.298    0.194    </span></span>
<span><span class="co">#&gt; new_endogenous_nonlinear   3.0174     0.3376   8.938   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 69.51 on 9998 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.007927,   Adjusted R-squared:  0.007828 </span></span>
<span><span class="co">#&gt; F-statistic: 79.89 on 1 and 9998 DF,  p-value: &lt; 2.2e-16</span></span>
<span></span>
<span><span class="va">new_data_cf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">my_data</span>, residual <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">first_stage</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">second_stage_cf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response_nonlinear</span> <span class="op">~</span> <span class="va">endogenous_nonlinear</span> <span class="op">+</span> <span class="va">residual</span>, data <span class="op">=</span> <span class="va">new_data_cf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">second_stage_cf</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = response_nonlinear ~ endogenous_nonlinear + residual, </span></span>
<span><span class="co">#&gt;     data = new_data_cf)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -17.5437  -0.8348   0.4614   1.4424   4.8154 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)          15.33904    0.38459   39.88   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; endogenous_nonlinear  3.01737    0.01099  274.64   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; residual              0.24919    0.01104   22.58   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 2.262 on 9997 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.9989, Adjusted R-squared:  0.9989 </span></span>
<span><span class="co">#&gt; F-statistic: 4.753e+06 on 2 and 9997 DF,  p-value: &lt; 2.2e-16</span></span>
<span></span>
<span><span class="fu"><a href="https://modelsummary.com/man/modelsummary.html">modelsummary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span><span class="va">second_stage</span>, <span class="va">second_stage_cf</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
 (1)
</th>
<th style="text-align:center;">
  (2)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:center;">
15.339
</td>
<td style="text-align:center;">
15.339
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(11.817)
</td>
<td style="text-align:center;">
(0.385)
</td>
</tr>
<tr>
<td style="text-align:left;">
new_endogenous_nonlinear
</td>
<td style="text-align:center;">
3.017
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(0.338)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
endogenous_nonlinear
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
3.017
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
(0.011)
</td>
</tr>
<tr>
<td style="text-align:left;">
residual
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.249
</td>
</tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">
</td>
<td style="text-align:center;box-shadow: 0px 1.5px">
</td>
<td style="text-align:center;box-shadow: 0px 1.5px">
(0.011)
</td>
</tr>
<tr>
<td style="text-align:left;">
Num.Obs.
</td>
<td style="text-align:center;">
10000
</td>
<td style="text-align:center;">
10000
</td>
</tr>
<tr>
<td style="text-align:left;">
R2
</td>
<td style="text-align:center;">
0.008
</td>
<td style="text-align:center;">
0.999
</td>
</tr>
<tr>
<td style="text-align:left;">
R2 Adj.
</td>
<td style="text-align:center;">
0.008
</td>
<td style="text-align:center;">
0.999
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:center;">
113211.6
</td>
<td style="text-align:center;">
44709.6
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:center;">
113233.2
</td>
<td style="text-align:center;">
44738.4
</td>
</tr>
<tr>
<td style="text-align:left;">
Log.Lik.
</td>
<td style="text-align:center;">
−56602.782
</td>
<td style="text-align:center;">
−22350.801
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
79.887
</td>
<td style="text-align:center;">
4752573.052
</td>
</tr>
<tr>
<td style="text-align:left;">
RMSE
</td>
<td style="text-align:center;">
69.50
</td>
<td style="text-align:center;">
2.26
</td>
</tr>
</tbody>
</table></div>
<p>Nonlinear in parameters</p>
<div class="sourceCode" id="cb892"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 2SLS</span></span>
<span><span class="va">first_stage</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">endogenous</span> <span class="op">~</span> <span class="va">exogenous</span>, data <span class="op">=</span> <span class="va">my_data</span><span class="op">)</span></span>
<span></span>
<span><span class="va">new_data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">my_data</span>, new_endogenous <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">first_stage</span>, <span class="va">my_data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">second_stage</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response_nonlinear_para</span> <span class="op">~</span> <span class="va">new_endogenous</span>, data <span class="op">=</span> <span class="va">new_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">second_stage</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = response_nonlinear_para ~ new_endogenous, data = new_data)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1536.5  -452.4   -80.7   368.4  3780.9 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)    -1089.943     61.706  -17.66   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; new_endogenous   119.829      3.078   38.93   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 630.2 on 9998 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.1316, Adjusted R-squared:  0.1316 </span></span>
<span><span class="co">#&gt; F-statistic:  1516 on 1 and 9998 DF,  p-value: &lt; 2.2e-16</span></span>
<span></span>
<span><span class="va">new_data_cf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">my_data</span>, residual <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">first_stage</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">second_stage_cf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response_nonlinear_para</span> <span class="op">~</span> <span class="va">endogenous_nonlinear</span> <span class="op">+</span> <span class="va">residual</span>, data <span class="op">=</span> <span class="va">new_data_cf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">second_stage_cf</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = response_nonlinear_para ~ endogenous_nonlinear + </span></span>
<span><span class="co">#&gt;     residual, data = new_data_cf)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -961.00 -139.32  -16.02  135.57 1403.62 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)          678.1593     9.9177   68.38   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; endogenous_nonlinear  17.7884     0.2759   64.46   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; residual              52.5016     1.1552   45.45   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 231.9 on 9997 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.8824, Adjusted R-squared:  0.8824 </span></span>
<span><span class="co">#&gt; F-statistic: 3.751e+04 on 2 and 9997 DF,  p-value: &lt; 2.2e-16</span></span>
<span></span>
<span><span class="fu"><a href="https://modelsummary.com/man/modelsummary.html">modelsummary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span><span class="va">second_stage</span>, <span class="va">second_stage_cf</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
 (1)
</th>
<th style="text-align:center;">
  (2)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:center;">
−1089.943
</td>
<td style="text-align:center;">
678.159
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(61.706)
</td>
<td style="text-align:center;">
(9.918)
</td>
</tr>
<tr>
<td style="text-align:left;">
new_endogenous
</td>
<td style="text-align:center;">
119.829
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
(3.078)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:left;">
endogenous_nonlinear
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
17.788
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
(0.276)
</td>
</tr>
<tr>
<td style="text-align:left;">
residual
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
52.502
</td>
</tr>
<tr>
<td style="text-align:left;box-shadow: 0px 1.5px">
</td>
<td style="text-align:center;box-shadow: 0px 1.5px">
</td>
<td style="text-align:center;box-shadow: 0px 1.5px">
(1.155)
</td>
</tr>
<tr>
<td style="text-align:left;">
Num.Obs.
</td>
<td style="text-align:center;">
10000
</td>
<td style="text-align:center;">
10000
</td>
</tr>
<tr>
<td style="text-align:left;">
R2
</td>
<td style="text-align:center;">
0.132
</td>
<td style="text-align:center;">
0.882
</td>
</tr>
<tr>
<td style="text-align:left;">
R2 Adj.
</td>
<td style="text-align:center;">
0.132
</td>
<td style="text-align:center;">
0.882
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:center;">
157302.4
</td>
<td style="text-align:center;">
137311.3
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:center;">
157324.1
</td>
<td style="text-align:center;">
137340.1
</td>
</tr>
<tr>
<td style="text-align:left;">
Log.Lik.
</td>
<td style="text-align:center;">
−78648.225
</td>
<td style="text-align:center;">
−68651.628
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
1515.642
</td>
<td style="text-align:center;">
37505.777
</td>
</tr>
<tr>
<td style="text-align:left;">
RMSE
</td>
<td style="text-align:center;">
630.10
</td>
<td style="text-align:center;">
231.88
</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="fuller-and-bias-reduced-iv" class="section level3" number="34.3.6">
<h3>
<span class="header-section-number">34.3.6</span> Fuller and Bias-Reduced IV<a class="anchor" aria-label="anchor" href="#fuller-and-bias-reduced-iv"><i class="fas fa-link"></i></a>
</h3>
<p>Fuller adjusts LIML for bias reduction.</p>
<div class="sourceCode" id="cb893"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fuller_model</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/AER/man/ivreg.html">ivreg</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x_endo_1</span> <span class="op">|</span> <span class="va">x_inst_1</span>, data <span class="op">=</span> <span class="va">base</span>, method <span class="op">=</span> <span class="st">"fuller"</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fuller_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; ivreg(formula = y ~ x_endo_1 | x_inst_1, data = base, method = "fuller", </span></span>
<span><span class="co">#&gt;     k = 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -1.2390 -0.3022 -0.0206  0.2772  1.0039 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  4.34586    0.08096   53.68   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; x_endo_1     0.39848    0.01964   20.29   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 0.4075 on 148 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-Squared: 0.7595,  Adjusted R-squared: 0.7578 </span></span>
<span><span class="co">#&gt; Wald test: 411.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<hr>
</div>
</div>
<div id="sec-inference-iv" class="section level2" number="34.4">
<h2>
<span class="header-section-number">34.4</span> Inference<a class="anchor" aria-label="anchor" href="#sec-inference-iv"><i class="fas fa-link"></i></a>
</h2>
<p>Inference in IV models, particularly when instruments are weak, presents serious challenges that can undermine standard testing and confidence interval procedures. In this section, we explore the core issues of IV inference under weak instruments, discuss the standard and alternative approaches, and outline practical guidelines for applied research.</p>
<p>Consider the just-identified linear IV model:</p>
<p><span class="math display">\[
Y = \beta X + u
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(X\)</span> is endogenous: <span class="math inline">\(\text{Cov}(X, u) \neq 0\)</span>.</p></li>
<li>
<p><span class="math inline">\(Z\)</span> is an instrumental variable satisfying:</p>
<ul>
<li><p><strong>Relevance</strong>: <span class="math inline">\(\text{Cov}(Z, X) \neq 0\)</span>.</p></li>
<li><p><strong>Exogeneity</strong>: <span class="math inline">\(\text{Cov}(Z, u) = 0\)</span>.</p></li>
</ul>
</li>
</ul>
<p>The IV estimator of <span class="math inline">\(\beta\)</span> is consistent under these assumptions.</p>
<p>A commonly used approach for inference is the t-ratio method, constructing a 95% confidence interval as:</p>
<p><span class="math display">\[
\hat{\beta} \pm 1.96 \sqrt{\hat{V}_N(\hat{\beta})}
\]</span></p>
<p>However, this approach is invalid when instruments are weak. Specifically:</p>
<ul>
<li><p>The t-ratio does not follow a standard normal distribution under weak instruments.</p></li>
<li><p>Confidence intervals based on this method can severely under-cover the true parameter.</p></li>
<li><p>Hypothesis tests can over-reject, even in large samples.</p></li>
</ul>
<p>This problem was first systematically identified by <span class="citation">Staiger and Stock (<a href="references.html#ref-staiger1997instrumental">1997</a>)</span> and <span class="citation">Dufour (<a href="references.html#ref-dufour1997some">1997</a>)</span>. Weak instruments create distortions in the finite-sample distribution of <span class="math inline">\(\hat{\beta}\)</span>.</p>
<p><strong>Common Practices and Misinterpretations</strong></p>
<ol style="list-style-type: decimal">
<li>Overreliance on t-Ratio Tests</li>
</ol>
<ul>
<li>Popular but problematic when instruments are weak.</li>
<li>Known to over-reject null hypotheses and under-cover confidence intervals.</li>
<li>Documented extensively by <span class="citation">Nelson and Startz (<a href="references.html#ref-nelson1990distribution">1990</a>)</span>, <span class="citation">Bound, Jaeger, and Baker (<a href="references.html#ref-bound1995problems">1995</a>)</span>, <span class="citation">Dufour (<a href="references.html#ref-dufour1997some">1997</a>)</span>, and <span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span>.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Weak Instrument Diagnostics</li>
</ol>
<ul>
<li>First-Stage F-Statistic:
<ul>
<li>Rule of thumb: <span class="math inline">\(F &gt; 10\)</span> often used but simplistic and misleading.</li>
<li>More accurate critical values provided by <span class="citation">J. H. Stock and Yogo (<a href="references.html#ref-stock2005testing">2005</a>)</span>.</li>
<li>For 95% coverage, <span class="math inline">\(F &gt; 16.38\)</span> is often cited <span class="citation">(<a href="references.html#ref-staiger1997instrumental">Staiger and Stock 1997</a>)</span>.</li>
</ul>
</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Misinterpretations and Pitfalls</li>
</ol>
<ul>
<li>Mistakenly interpreting <span class="math inline">\(\hat{\beta} \pm 1.96 \times \hat{SE}\)</span> as a 95% CI when the instrument is weak, <span class="citation">Staiger and Stock (<a href="references.html#ref-staiger1997instrumental">1997</a>)</span> show that under <span class="math inline">\(F &gt; 16.38\)</span>, the nominal 95% CI may only offer 85% coverage.</li>
<li>Pretesting for weak instruments can exacerbate inference problems <span class="citation">(<a href="references.html#ref-hall1996judging">A. R. Hall, Rudebusch, and Wilcox 1996</a>)</span>.</li>
<li>Selective model specification based on weak instrument diagnostics may introduce additional distortions <span class="citation">(<a href="references.html#ref-andrews2019weak">I. Andrews, Stock, and Sun 2019</a>)</span>.</li>
</ul>
<hr>
<div id="weak-instruments-problem" class="section level3" number="34.4.1">
<h3>
<span class="header-section-number">34.4.1</span> Weak Instruments Problem<a class="anchor" aria-label="anchor" href="#weak-instruments-problem"><i class="fas fa-link"></i></a>
</h3>
<p>An alternative statistic accounts for weak instrument issues by adjusting the standard Anderson-Rubin (AR) test:</p>
<p><span class="math display">\[
\hat{t}^2 = \hat{t}^2_{AR} \times \frac{1}{1 - \hat{\rho} \frac{\hat{t}_{AR}}{\hat{f}} + \frac{\hat{t}^2_{AR}}{\hat{f}^2}}
\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(\hat{t}^2_{AR} \sim \chi^2(1)\)</span> under the null, even with weak instruments <span class="citation">(<a href="references.html#ref-anderson1949estimation">T. W. Anderson and Rubin 1949</a>)</span>.</p></li>
<li><p><span class="math inline">\(\hat{t}_{AR} = \dfrac{\hat{\pi}(\hat{\beta} - \beta_0)}{\sqrt{\hat{V}_N (\hat{\pi} (\hat{\beta} - \beta_0))}} \sim N(0,1)\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{f} = \dfrac{\hat{\pi}}{\sqrt{\hat{V}_N(\hat{\pi})}}\)</span> measures instrument strength (first-stage F-stat).</p></li>
<li><p><span class="math inline">\(\hat{\pi}\)</span> is the coefficient from the first-stage regression of <span class="math inline">\(X\)</span> on <span class="math inline">\(Z\)</span>.</p></li>
<li><p><span class="math inline">\(\hat{\rho} = \text{Cov}(Zv, Zu)\)</span> captures the correlation between first-stage residuals and <span class="math inline">\(u\)</span>.</p></li>
</ul>
<p><strong>Implications</strong></p>
<ul>
<li>Even in large samples, <span class="math inline">\(\hat{t}^2 \neq \hat{t}^2_{AR}\)</span> because the adjustment term does not converge to zero unless instruments are strong and <span class="math inline">\(\rho = 0\)</span>.</li>
<li>The distribution of <span class="math inline">\(\hat{t}\)</span> does not match the standard normal but follows a more complex distribution described by <span class="citation">Staiger and Stock (<a href="references.html#ref-staiger1997instrumental">1997</a>)</span> and <span class="citation">J. H. Stock and Yogo (<a href="references.html#ref-stock2005testing">2005</a>)</span>.</li>
</ul>
<hr>
<p>The divergence between <span class="math inline">\(\hat{t}^2\)</span> and <span class="math inline">\(\hat{t}^2_{AR}\)</span> depends on:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Instrument Strength</strong> (<span class="math inline">\(\pi\)</span>): Higher correlation between <span class="math inline">\(Z\)</span> and <span class="math inline">\(X\)</span> mitigates the problem.</li>
<li>
<strong>First-Stage F-statistic</strong> (<span class="math inline">\(E(F)\)</span>): A weak first-stage regression increases the bias and distortion.</li>
<li>
<strong>Endogeneity Level</strong> (<span class="math inline">\(|\rho|\)</span>): Greater correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(u\)</span> exacerbates inference errors.</li>
</ol>
<hr>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="25%">
<col width="30%">
<col width="44%">
</colgroup>
<thead><tr class="header">
<th><strong>Scenario</strong></th>
<th><strong>Conditions</strong></th>
<th><strong>Inference Quality</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Worst Case</td>
<td>
<span class="math inline">\(\pi = 0\)</span>, <span class="math inline">\(|\rho| = 1\)</span>
</td>
<td>
<span class="math inline">\(\hat{\beta} \pm 1.96 \times SE\)</span> fails; Type I error = 100%</td>
</tr>
<tr class="even">
<td>Best Case</td>
<td>
<span class="math inline">\(\rho = 0\)</span> (No endogeneity) or very large <span class="math inline">\(\hat{f}\)</span> (strong <span class="math inline">\(Z\)</span>)</td>
<td>Standard inference works; intervals cover <span class="math inline">\(\beta\)</span> with correct rate</td>
</tr>
<tr class="odd">
<td>Intermediate Case</td>
<td>Moderate <span class="math inline">\(\pi\)</span>, <span class="math inline">\(\rho\)</span>, and <span class="math inline">\(F\)</span>
</td>
<td>Coverage and Type I error lie between extremes; standard inference risky</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
<div id="solutions-and-approaches-for-valid-inference" class="section level3" number="34.4.2">
<h3>
<span class="header-section-number">34.4.2</span> Solutions and Approaches for Valid Inference<a class="anchor" aria-label="anchor" href="#solutions-and-approaches-for-valid-inference"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>
<strong>Assume the Problem Away (Risky Assumptions)</strong>
<ol style="list-style-type: decimal">
<li>
<strong>High First-Stage F-statistic</strong>:
<ul>
<li>Require <span class="math inline">\(E(F) &gt; 142.6\)</span> for near-validity <span class="citation">(<a href="references.html#ref-lee2022valid">Lee et al. 2022</a>)</span>.</li>
<li>While the first-stage <span class="math inline">\(F\)</span> is observable, this threshold is high and often impractical.</li>
</ul>
</li>
<li>
<strong>Low Endogeneity</strong>:
<ul>
<li>Assume <span class="math inline">\(|\rho| &lt; 0.565\)</span> <span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span>. In other words, we assume endogeneity to be less than moderat level.</li>
<li>This undermines the motivation for IV in the first place, which exists precisely because of suspected endogeneity.</li>
</ul>
</li>
</ol>
</li>
<li>
<strong>Confront the Problem Directly (Robust Methods)</strong>
<ol style="list-style-type: decimal">
<li>
<a href="sec-instrumental-variables.html#sec-anderson-rubin-approach">Anderson-Rubin (AR) Test</a> <span class="citation">(<a href="references.html#ref-anderson1949estimation">T. W. Anderson and Rubin 1949</a>)</span>:
<ul>
<li>Valid under weak instruments.</li>
<li>Tests whether <span class="math inline">\(Z\)</span> explains variation in <span class="math inline">\(Y - \beta_0 X\)</span>.</li>
</ul>
</li>
<li>
<a href="sec-instrumental-variables.html#sec-tf-procedure">tF Procedure</a> <span class="citation">(<a href="references.html#ref-lee2022valid">Lee et al. 2022</a>)</span>:
<ul>
<li>Combines t-statistics and F-statistics in a unified testing framework.</li>
<li>Offers valid inference in presence of weak instruments.</li>
</ul>
</li>
<li>
<a href="sec-instrumental-variables.html#sec-ak-approach">Andrews-Kolesár (AK) Procedure</a> <span class="citation">(<a href="references.html#ref-angrist2023one">J. Angrist and Kolesár 2023</a>)</span>:
<ul>
<li>Provides uniformly valid confidence intervals for <span class="math inline">\(\beta\)</span>.</li>
<li>Allows for weak instruments and arbitrary heteroskedasticity.</li>
<li>Especially useful in overidentified settings.</li>
</ul>
</li>
</ol>
</li>
</ol>
<hr>
</div>
<div id="sec-anderson-rubin-approach" class="section level3" number="34.4.3">
<h3>
<span class="header-section-number">34.4.3</span> Anderson-Rubin Approach<a class="anchor" aria-label="anchor" href="#sec-anderson-rubin-approach"><i class="fas fa-link"></i></a>
</h3>
<p>The Anderson-Rubin (AR) test, originally proposed by <span class="citation">T. W. Anderson and Rubin (<a href="references.html#ref-anderson1949estimation">1949</a>)</span>, remains one of the most robust inferential tools in the context of instrumental variable estimation, particularly when instruments are weak or endogenous regressors exhibit complex error structures.</p>
<p>The AR test directly evaluates the joint null hypothesis that:</p>
<p><span class="math display">\[
H_0: \beta = \beta_0
\]</span></p>
<p>by testing whether the instruments explain any variation in the residuals <span class="math inline">\(Y - \beta_0 X\)</span>. Under the null, the model becomes:</p>
<p><span class="math display">\[
Y - \beta_0 X = u
\]</span></p>
<p>Given that <span class="math inline">\(\text{Cov}(Z, u) = 0\)</span> (by the IV exogeneity assumption), the test regresses <span class="math inline">\((Y - \beta_0 X)\)</span> on <span class="math inline">\(Z\)</span>. The test statistic is constructed as:</p>
<p><span class="math display">\[
AR(\beta_0) = \frac{(Y - \beta_0 X)' P_Z (Y - \beta_0 X)}{\hat{\sigma}^2}
\]</span></p>
<ul>
<li>
<span class="math inline">\(P_Z\)</span> is the projection matrix onto the column space of <span class="math inline">\(Z\)</span>: <span class="math inline">\(P_Z = Z (Z'Z)^{-1} Z'\)</span>.</li>
<li>
<span class="math inline">\(\hat{\sigma}^2\)</span> is an estimate of the error variance (under homoskedasticity).</li>
</ul>
<p>Under <span class="math inline">\(H_0\)</span>, the statistic follows a chi-squared distribution:</p>
<p><span class="math display">\[
AR(\beta_0) \sim \chi^2(q)
\]</span></p>
<p>where <span class="math inline">\(q\)</span> is the number of instruments (1 in a just-identified model).</p>
<hr>
<p><strong>Key Properties of the AR Test</strong></p>
<ul>
<li>
<strong>Robust to Weak Instruments</strong>:
<ul>
<li>The AR test does not rely on the strength of the instruments.</li>
<li>Its distribution under the null hypothesis remains valid even when the instruments are weak <span class="citation">(<a href="references.html#ref-staiger1997instrumental">Staiger and Stock 1997</a>)</span>.</li>
</ul>
</li>
<li>
<strong>Robust to Non-Normality and Homoskedastic Errors</strong>:
<ul>
<li>Maintains correct Type I error rates even under non-normal errors <span class="citation">(<a href="references.html#ref-staiger1997instrumental">Staiger and Stock 1997</a>)</span>.</li>
<li>Optimality properties under homoskedastic errors are established in <span class="citation">D. W. Andrews, Moreira, and Stock (<a href="references.html#ref-andrews2006optimal">2006</a>)</span> and <span class="citation">M. J. Moreira (<a href="references.html#ref-moreira2009tests">2009</a>)</span>.</li>
</ul>
</li>
<li>
<strong>Robust to Heteroskedasticity, Clustering, and Autocorrelation</strong>:
<ul>
<li>The AR test has been generalized to account for heteroskedasticity, clustered errors, and autocorrelation <span class="citation">(<a href="references.html#ref-stock2000gmm">J. H. Stock and Wright 2000</a>; <a href="references.html#ref-moreira2019optimal">H. Moreira and Moreira 2019</a>)</span>.</li>
<li>Valid inference is possible when combined with heteroskedasticity-robust variance estimators or cluster-robust techniques.</li>
</ul>
</li>
</ul>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="26%">
<col width="47%">
<col width="26%">
</colgroup>
<thead><tr class="header">
<th><strong>Setting</strong></th>
<th><strong>Validity</strong></th>
<th><strong>Reference</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Non-Normal, Homoskedastic Errors</td>
<td>Valid without distributional assumptions</td>
<td><span class="citation">(<a href="references.html#ref-staiger1997instrumental">Staiger and Stock 1997</a>)</span></td>
</tr>
<tr class="even">
<td>Heteroskedastic Errors</td>
<td>Generalized AR test remains valid; robust variance estimation recommended</td>
<td><span class="citation">(<a href="references.html#ref-stock2000gmm">J. H. Stock and Wright 2000</a>)</span></td>
</tr>
<tr class="odd">
<td>Clustered or Autocorrelated Errors</td>
<td>Extensions available using cluster-robust and HAC variance estimators</td>
<td><span class="citation">(<a href="references.html#ref-moreira2019optimal">H. Moreira and Moreira 2019</a>)</span></td>
</tr>
<tr class="even">
<td>Optimality under Homoskedasticity</td>
<td>AR test minimizes Type II error among invariant tests</td>
<td><span class="citation">(<a href="references.html#ref-andrews2006optimal">D. W. Andrews, Moreira, and Stock 2006</a>; <a href="references.html#ref-moreira2009tests">M. J. Moreira 2009</a>)</span></td>
</tr>
</tbody>
</table></div>
<hr>
<p>The AR test is relatively simple to implement and is available in most econometric software. Here’s an intuitive step-by-step breakdown:</p>
<ol style="list-style-type: decimal">
<li>Specify the null hypothesis value <span class="math inline">\(\beta_0\)</span>.</li>
<li>Compute the residual <span class="math inline">\(u = Y - \beta_0 X\)</span>.</li>
<li>Regress <span class="math inline">\(u\)</span> on <span class="math inline">\(Z\)</span> and obtain the <span class="math inline">\(R^2\)</span> from this regression.</li>
<li>Compute the test statistic:</li>
</ol>
<p><span class="math display">\[
AR(\beta_0) = \frac{R^2 \cdot n}{q}
\]</span></p>
<p>(For a just-identified model with a single instrument, <span class="math inline">\(q=1\)</span>.)</p>
<ol start="5" style="list-style-type: decimal">
<li>Compare <span class="math inline">\(AR(\beta_0)\)</span> to the <span class="math inline">\(\chi^2(q)\)</span> distribution to determine significance.</li>
</ol>
<div class="sourceCode" id="cb894"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://yiqingxu.org/packages/ivDiag/">ivDiag</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># AR test (robust to weak instruments)</span></span>
<span><span class="co"># example by the package's authors</span></span>
<span><span class="fu">ivDiag</span><span class="fu">::</span><span class="fu"><a href="https://yiqingxu.org/packages/ivDiag/reference/AR_test.html">AR_test</a></span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">rueda</span>,</span>
<span>    Y <span class="op">=</span> <span class="st">"e_vote_buying"</span>,</span>
<span>    <span class="co"># treatment</span></span>
<span>    D <span class="op">=</span> <span class="st">"lm_pob_mesa"</span>,</span>
<span>    <span class="co"># instruments</span></span>
<span>    Z <span class="op">=</span> <span class="st">"lz_pob_mesa_f"</span>,</span>
<span>    controls <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lpopulation"</span>, <span class="st">"lpotencial"</span><span class="op">)</span>,</span>
<span>    cl <span class="op">=</span> <span class="st">"muni_code"</span>,</span>
<span>    CI <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; $Fstat</span></span>
<span><span class="co">#&gt;         F       df1       df2         p </span></span>
<span><span class="co">#&gt;   50.5097    1.0000 4350.0000    0.0000</span></span>
<span></span>
<span><span class="va">g</span> <span class="op">&lt;-</span> <span class="fu">ivDiag</span><span class="fu">::</span><span class="fu"><a href="https://yiqingxu.org/packages/ivDiag/reference/ivDiag.html">ivDiag</a></span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">rueda</span>,</span>
<span>    Y <span class="op">=</span> <span class="st">"e_vote_buying"</span>,</span>
<span>    D <span class="op">=</span> <span class="st">"lm_pob_mesa"</span>,</span>
<span>    Z <span class="op">=</span> <span class="st">"lz_pob_mesa_f"</span>,</span>
<span>    controls <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lpopulation"</span>, <span class="st">"lpotencial"</span><span class="op">)</span>,</span>
<span>    cl <span class="op">=</span> <span class="st">"muni_code"</span>,</span>
<span>    cores <span class="op">=</span> <span class="fl">4</span>,</span>
<span>    bootstrap <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">g</span><span class="op">$</span><span class="va">AR</span></span>
<span><span class="co">#&gt; $Fstat</span></span>
<span><span class="co">#&gt;         F       df1       df2         p </span></span>
<span><span class="co">#&gt;   50.5097    1.0000 4350.0000    0.0000 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $ci.print</span></span>
<span><span class="co">#&gt; [1] "[-1.2545, -0.7156]"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $ci</span></span>
<span><span class="co">#&gt; [1] -1.2545169 -0.7155854</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $bounded</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span>
<span><span class="fu">ivDiag</span><span class="fu">::</span><span class="fu"><a href="https://yiqingxu.org/packages/ivDiag/reference/plot_coef.html">plot_coef</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="34-instrumental_var_files/figure-html/unnamed-chunk-13-1.png" width="90%" style="display: block; margin: auto;"></div>
<hr>
</div>
<div id="sec-tf-procedure" class="section level3" number="34.4.4">
<h3>
<span class="header-section-number">34.4.4</span> tF Procedure<a class="anchor" aria-label="anchor" href="#sec-tf-procedure"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span> introduce the tF procedure, an inference method specifically designed for just-identified IV models (single endogenous regressor and single instrument). It addresses the shortcomings of traditional 2SLS <span class="math inline">\(t\)</span>-tests under weak instruments and offers a solution that is conceptually familiar to researchers trained in standard econometric practices.</p>
<p>Unlike the <a href="sec-instrumental-variables.html#sec-anderson-rubin-approach">Anderson-Rubin test</a>, which inverts hypothesis tests to form confidence sets, the tF procedure adjusts standard <span class="math inline">\(t\)</span>-statistics and standard errors directly, making it a more intuitive extension of traditional hypothesis testing.</p>
<p>The tF procedure is widely applicable in settings where just-identified IV models arise, including:</p>
<ul>
<li><p><strong>Randomized controlled trials with imperfect compliance</strong><br>
(e.g., <a href="sec-causal-inference.html#sec-local-average-treatment-effects">Local Average Treatment Effects</a> in <span class="citation">G. W. Imbens and Angrist (<a href="references.html#ref-imbens1994identification">1994</a>)</span>).</p></li>
<li><p><a href="sec-regression-discontinuity.html#sec-fuzzy-regression-discontinuity-design">Fuzzy Regression Discontinuity Designs</a><br>
(e.g., <span class="citation">Lee and Lemieux (<a href="references.html#ref-lee2010regression">2010</a>)</span>).</p></li>
<li><p><a href="sec-regression-discontinuity.html#sec-identification-in-fuzzy-regression-kink-design">Fuzzy Regression Kink Designs</a><br>
(e.g., <span class="citation">(<a href="references.html#ref-card2015inference">Card et al. 2015</a>)</span>).</p></li>
</ul>
<p>A comparison of the <a href="sec-instrumental-variables.html#sec-anderson-rubin-approach">AR approach</a> and the <a href="sec-instrumental-variables.html#sec-tf-procedure">tF procedure</a> can be found in <span class="citation">I. Andrews, Stock, and Sun (<a href="references.html#ref-andrews2019weak">2019</a>)</span>.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="25%">
<col width="40%">
<col width="34%">
</colgroup>
<thead><tr class="header">
<th><strong>Feature</strong></th>
<th><strong>Anderson-Rubin</strong></th>
<th><strong>tF Procedure</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Robustness to Weak IV</strong></td>
<td>Yes (valid under weak instruments)</td>
<td>Yes (valid under weak instruments)</td>
</tr>
<tr class="even">
<td><strong>Finite Confidence Intervals</strong></td>
<td>No (interval becomes infinite for <span class="math inline">\(F \le 3.84\)</span>)</td>
<td>Yes (finite intervals for all <span class="math inline">\(F\)</span> values)</td>
</tr>
<tr class="odd">
<td><strong>Interval Length</strong></td>
<td>Often longer, especially when <span class="math inline">\(F\)</span> is moderate (e.g., <span class="math inline">\(F = 16\)</span>)</td>
<td>Typically shorter than AR intervals for <span class="math inline">\(F &gt; 3.84\)</span>
</td>
</tr>
<tr class="even">
<td><strong>Ease of Interpretation</strong></td>
<td>Requires inverting tests; less intuitive</td>
<td>Directly adjusts <span class="math inline">\(t\)</span>-based standard errors; more intuitive</td>
</tr>
<tr class="odd">
<td><strong>Computational Simplicity</strong></td>
<td>Moderate (inversion of hypothesis tests)</td>
<td>Simple (multiplicative adjustment to standard errors)</td>
</tr>
</tbody>
</table></div>
<ul>
<li>With <span class="math inline">\(F &gt; 3.84\)</span>, the AR test’s expected interval length is infinite, whereas the tF procedure guarantees finite intervals, making it superior in practical applications with weak instruments.</li>
</ul>
<p>The tF procedure adjusts the conventional 2SLS <span class="math inline">\(t\)</span>-ratio for the first-stage F-statistic strength. Instead of relying on a pre-testing threshold (e.g., <span class="math inline">\(F &gt; 10\)</span>), the tF approach provides a smooth adjustment to the standard errors.</p>
<p>Key Features:</p>
<ul>
<li>Adjusts the 2SLS <span class="math inline">\(t\)</span>-ratio based on the observed first-stage F-statistic.</li>
<li>Applies different adjustment factors for different significance levels (e.g., 95% and 99%).</li>
<li>Remains valid even when the instrument is weak, offering finite confidence intervals even when the first-stage F-statistic is low.</li>
</ul>
<p><strong>Advantages of the tF Procedure</strong></p>
<ol style="list-style-type: decimal">
<li>Smooth Adjustment for First-Stage Strength</li>
</ol>
<ul>
<li><p>The tF procedure smoothly adjusts inference based on the observed first-stage F-statistic, avoiding the need for arbitrary pre-testing thresholds (e.g., <span class="math inline">\(F &gt; 10\)</span>).</p></li>
<li>
<p>It produces finite and usable confidence intervals even when the first-stage F-statistic is low:</p>
<p><span class="math display">\[
F &gt; 3.84
\]</span></p>
</li>
<li>
<p>This threshold aligns with the critical value of 3.84 for a 95% <a href="sec-instrumental-variables.html#sec-anderson-rubin-approach">Anderson-Rubin</a> confidence interval, but with a crucial advantage:</p>
<ul>
<li>The AR interval becomes unbounded (i.e., infinite length) when <span class="math inline">\(F \le 3.84\)</span>.</li>
<li>The tF procedure, in contrast, still provides a finite confidence interval, making it more practical in weak instrument cases.</li>
</ul>
</li>
</ul>
<hr>
<ol start="2" style="list-style-type: decimal">
<li>Clear and Interpretable Confidence Levels</li>
</ol>
<ul>
<li>
<p>The tF procedure offers transparent confidence intervals that:</p>
<ul>
<li><p>Directly incorporate the impact of first-stage instrument strength on the critical values used for inference.</p></li>
<li><p>Mirror the distortion-free properties of robust methods like the <a href="sec-instrumental-variables.html#sec-anderson-rubin-approach">Anderson-Rubin</a> test, but remain closer in spirit to conventional <span class="math inline">\(t\)</span>-based inference.</p></li>
</ul>
</li>
<li><p>Researchers can interpret tF-based 95% and 99% confidence intervals using familiar econometric tools, without needing to invert hypothesis tests or construct confidence sets.</p></li>
</ul>
<hr>
<ol start="3" style="list-style-type: decimal">
<li>Robustness to Common Error Structures</li>
</ol>
<ul>
<li>
<p>The tF procedure remains robust in the presence of:</p>
<ul>
<li>Heteroskedasticity</li>
<li>Clustering</li>
<li>Autocorrelation</li>
</ul>
</li>
<li>
<p>No additional adjustments are necessary beyond the use of a robust variance estimator for both:</p>
<ul>
<li>The first-stage regression</li>
<li>The second-stage IV regression</li>
</ul>
</li>
<li><p>As long as the same robust variance estimator is applied consistently, the tF adjustment maintains valid inference without imposing additional computational complexity.</p></li>
</ul>
<hr>
<ol start="4" style="list-style-type: decimal">
<li>Applicability to Published Research</li>
</ol>
<ul>
<li>
<p>One of the most powerful features of the tF procedure is its flexibility for re-evaluating published studies:</p>
<ul>
<li><p>Researchers only need the reported first-stage F-statistic and standard errors from the 2SLS estimates.</p></li>
<li><p>No access to the original data is required to recalculate confidence intervals or test statistical significance using the tF adjustment.</p></li>
</ul>
</li>
<li>
<p>This makes the tF procedure particularly valuable for meta-analyses, replications, and robustness checks of published IV studies, where:</p>
<ul>
<li>Raw data may be unavailable, or</li>
<li>Replication costs are high.</li>
</ul>
</li>
</ul>
<hr>
<p>Consider the linear IV model with additional covariates <span class="math inline">\(W\)</span>:</p>
<p><span class="math display">\[
Y = X \beta + W \gamma + u
\]</span></p>
<p><span class="math display">\[
X = Z \pi + W \xi + \nu
\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(Y\)</span>: Outcome variable.</p></li>
<li><p><span class="math inline">\(X\)</span>: Endogenous regressor of interest.</p></li>
<li><p><span class="math inline">\(Z\)</span>: Instrumental variable (single instrument case).</p></li>
<li><p><span class="math inline">\(W\)</span>: Vector of exogenous controls, possibly including an intercept.</p></li>
<li><p><span class="math inline">\(u\)</span>, <span class="math inline">\(\nu\)</span>: Error terms.</p></li>
</ul>
<p>Key Statistics:</p>
<ul>
<li>
<p><span class="math inline">\(t\)</span>-ratio for the IV estimator:</p>
<p><span class="math display">\[
\hat{t} = \frac{\hat{\beta} - \beta_0}{\sqrt{\hat{V}_N (\hat{\beta})}}
\]</span></p>
</li>
<li>
<p><span class="math inline">\(t\)</span>-ratio for the first-stage coefficient:</p>
<p><span class="math display">\[
\hat{f} = \frac{\hat{\pi}}{\sqrt{\hat{V}_N (\hat{\pi})}}
\]</span></p>
</li>
<li>
<p>First-stage F-statistic:</p>
<p><span class="math display">\[
\hat{F} = \hat{f}^2
\]</span></p>
</li>
</ul>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\hat{\beta}\)</span>: Instrumental variable estimator.</li>
<li>
<span class="math inline">\(\hat{V}_N (\hat{\beta})\)</span>: Estimated variance of <span class="math inline">\(\hat{\beta}\)</span>, possibly robust to deal with non-iid errors.</li>
<li>
<span class="math inline">\(\hat{t}\)</span>: <span class="math inline">\(t\)</span>-ratio under the null hypothesis.</li>
<li>
<span class="math inline">\(\hat{f}\)</span>: <span class="math inline">\(t\)</span>-ratio under the null hypothesis of <span class="math inline">\(\pi=0\)</span>.</li>
</ul>
<hr>
<p>Under traditional asymptotics large samples, the <span class="math inline">\(t\)</span>-ratio statistic follows:</p>
<p><span class="math display">\[
\hat{t}^2 \to^d t^2
\]</span></p>
<p>With critical values:</p>
<ul>
<li><p><span class="math inline">\(\pm 1.96\)</span> for a 5% significance test.</p></li>
<li><p><span class="math inline">\(\pm 2.58\)</span> for a 1% significance test.</p></li>
</ul>
<p>However, in IV settings (particularly with weak instruments):</p>
<ul>
<li><p>The distribution of the <span class="math inline">\(t\)</span>-statistic is distorted (i.e., <span class="math inline">\(t\)</span>-distribution might not be normal), even in large samples.</p></li>
<li><p>The distortion arises because the strength of the instrument (<span class="math inline">\(F\)</span>) and the degree of endogeneity (<span class="math inline">\(\rho\)</span>) affect the <span class="math inline">\(t\)</span>-distribution.</p></li>
</ul>
<p><span class="citation">J. H. Stock and Yogo (<a href="references.html#ref-stock2005testing">2005</a>)</span> provide a formula to quantify this distortion (in the just-identified case) for Wald test statistics using 2SLS.:</p>
<p><span class="math display">\[
t^2 = f + t_{AR} + \rho f t_{AR}
\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(\hat{f} \to^d f\)</span></p></li>
<li><p><span class="math inline">\(\bar{f} = \dfrac{\pi}{\sqrt{\dfrac{1}{N} AV(\hat{\pi})}}\)</span> and <span class="math inline">\(AV(\hat{\pi})\)</span> is the asymptotic variance of <span class="math inline">\(\hat{\pi}\)</span></p></li>
<li><p><span class="math inline">\(t_{AR}\)</span> is asymptotically standard normal (<span class="math inline">\(AR = t^2_{AR}\)</span>)</p></li>
<li><p><span class="math inline">\(\rho\)</span> measures the correlation (degree of endogeneity) between <span class="math inline">\(Zu\)</span> and <span class="math inline">\(Z\nu\)</span> (when data are homoskedastic, <span class="math inline">\(\rho\)</span> is the correlation between <span class="math inline">\(u\)</span> and <span class="math inline">\(\nu\)</span>).</p></li>
</ul>
<p>Implications:</p>
<ul>
<li>For low <span class="math inline">\(\rho\)</span> (<span class="math inline">\(\rho \in [0, 0.5]\)</span>), rejection probabilities can be below nominal levels.</li>
<li>For high <span class="math inline">\(\rho\)</span> (<span class="math inline">\(\rho = 0.8\)</span>), rejection rates can be inflated, e.g., 13% rejection at a nominal 5% significance level.</li>
<li>Reliance on standard <span class="math inline">\(t\)</span>-ratios leads to incorrect test sizes and invalid confidence intervals.</li>
</ul>
<hr>
<p>The tF procedure corrects for these distortions by adjusting the standard error of the 2SLS estimator based on the observed first-stage F-statistic.</p>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate <span class="math inline">\(\hat{\beta}\)</span> and its conventional SE from 2SLS.</li>
<li>Compute the first-stage <span class="math inline">\(\hat{F}\)</span>.</li>
<li>Multiply the conventional SE by an adjustment factor, which depends on <span class="math inline">\(\hat{F}\)</span> and the desired confidence level.</li>
<li>Compute new <span class="math inline">\(t\)</span>-ratios and construct confidence intervals using standard critical values (e.g., <span class="math inline">\(\pm 1.96\)</span> for 95% CI).</li>
</ol>
<p><span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span> refer to the adjusted standard errors as “0.05 tF SE” (for a 5% significance level) and “0.01 tF SE” (for 1%).</p>
<hr>
<p><span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span> conducted a review of recent single-instrument studies in the American Economic Review.</p>
<p>Key Findings:</p>
<ul>
<li>For at least 25% of the examined specifications:
<ul>
<li>tF-adjusted confidence intervals were 49% longer at the 5% level.</li>
<li>tF-adjusted confidence intervals were 136% longer at the 1% level.</li>
</ul>
</li>
<li>Even among specifications with <span class="math inline">\(F &gt; 10\)</span> and <span class="math inline">\(t &gt; 1.96\)</span>:
<ul>
<li>Approximately 25% became statistically insignificant at the 5% level after applying the tF adjustment.</li>
</ul>
</li>
</ul>
<p>Takeaway:</p>
<ul>
<li>The tF procedure can substantially alter inference conclusions.</li>
<li>Published studies can be re-evaluated with the tF method using only the reported first-stage F-statistics, without requiring access to the underlying microdata.</li>
</ul>
<hr>
<div class="sourceCode" id="cb895"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://yiqingxu.org/packages/ivDiag/">ivDiag</a></span><span class="op">)</span></span>
<span><span class="va">g</span> <span class="op">&lt;-</span> <span class="fu">ivDiag</span><span class="fu">::</span><span class="fu"><a href="https://yiqingxu.org/packages/ivDiag/reference/ivDiag.html">ivDiag</a></span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">rueda</span>,</span>
<span>    Y <span class="op">=</span> <span class="st">"e_vote_buying"</span>,</span>
<span>    D <span class="op">=</span> <span class="st">"lm_pob_mesa"</span>,</span>
<span>    Z <span class="op">=</span> <span class="st">"lz_pob_mesa_f"</span>,</span>
<span>    controls <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lpopulation"</span>, <span class="st">"lpotencial"</span><span class="op">)</span>,</span>
<span>    cl <span class="op">=</span> <span class="st">"muni_code"</span>,</span>
<span>    cores <span class="op">=</span> <span class="fl">4</span>,</span>
<span>    bootstrap <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">g</span><span class="op">$</span><span class="va">tF</span></span>
<span><span class="co">#&gt;         F        cF      Coef        SE         t    CI2.5%   CI97.5%   p-value </span></span>
<span><span class="co">#&gt; 8598.3264    1.9600   -0.9835    0.1540   -6.3872   -1.2853   -0.6817    0.0000</span></span></code></pre></div>
<div class="sourceCode" id="cb896"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># example in fixest package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lrberge.github.io/fixest/">fixest</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="va">base</span> <span class="op">=</span> <span class="va">iris</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">base</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"y"</span>, <span class="st">"x1"</span>, <span class="st">"x_endo_1"</span>, <span class="st">"x_inst_1"</span>, <span class="st">"fe"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">base</span><span class="op">$</span><span class="va">x_inst_2</span> <span class="op">=</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">y</span> <span class="op">+</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">x_endo_1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">150</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">base</span><span class="op">$</span><span class="va">x_endo_2</span> <span class="op">=</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="fl">0.2</span> <span class="op">*</span> <span class="va">base</span><span class="op">$</span><span class="va">x_inst_1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">150</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">est_iv</span> <span class="op">=</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x1</span> <span class="op">|</span> <span class="va">x_endo_1</span> <span class="op">+</span> <span class="va">x_endo_2</span> <span class="op">~</span> <span class="va">x_inst_1</span> <span class="op">+</span> <span class="va">x_inst_2</span>, <span class="va">base</span><span class="op">)</span></span>
<span><span class="va">est_iv</span></span>
<span><span class="co">#&gt; TSLS estimation - Dep. Var.: y</span></span>
<span><span class="co">#&gt;                   Endo.    : x_endo_1, x_endo_2</span></span>
<span><span class="co">#&gt;                   Instr.   : x_inst_1, x_inst_2</span></span>
<span><span class="co">#&gt; Second stage: Dep. Var.: y</span></span>
<span><span class="co">#&gt; Observations: 150</span></span>
<span><span class="co">#&gt; Standard-errors: IID </span></span>
<span><span class="co">#&gt;              Estimate Std. Error  t value   Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  1.831380   0.411435  4.45121 1.6844e-05 ***</span></span>
<span><span class="co">#&gt; fit_x_endo_1 0.444982   0.022086 20.14744  &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; fit_x_endo_2 0.639916   0.307376  2.08186 3.9100e-02 *  </span></span>
<span><span class="co">#&gt; x1           0.565095   0.084715  6.67051 4.9180e-10 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; RMSE: 0.398842   Adj. R2: 0.761653</span></span>
<span><span class="co">#&gt; F-test (1st stage), x_endo_1: stat = 903.2    , p &lt; 2.2e-16 , on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt; F-test (1st stage), x_endo_2: stat =   3.25828, p = 0.041268, on 2 and 146 DoF.</span></span>
<span><span class="co">#&gt;                   Wu-Hausman: stat =   6.79183, p = 0.001518, on 2 and 144 DoF.</span></span>
<span></span>
<span><span class="va">res_est_iv</span> <span class="op">&lt;-</span> <span class="va">est_iv</span><span class="op">$</span><span class="va">coeftable</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu"><a href="https://tibble.tidyverse.org/reference/rownames.html">rownames_to_column</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">coef_of_interest</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">res_est_iv</span><span class="op">[</span><span class="va">res_est_iv</span><span class="op">$</span><span class="va">rowname</span> <span class="op">==</span> <span class="st">"fit_x_endo_1"</span>, <span class="st">"Estimate"</span><span class="op">]</span></span>
<span><span class="va">se_of_interest</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">res_est_iv</span><span class="op">[</span><span class="va">res_est_iv</span><span class="op">$</span><span class="va">rowname</span> <span class="op">==</span> <span class="st">"fit_x_endo_1"</span>, <span class="st">"Std. Error"</span><span class="op">]</span></span>
<span><span class="va">fstat_1st</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/fitstat.html">fitstat</a></span><span class="op">(</span><span class="va">est_iv</span>, type <span class="op">=</span> <span class="st">"ivf1"</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">stat</span></span>
<span></span>
<span><span class="co"># To get the correct SE based on 1st-stage F-stat (This result is similar without adjustment since F is large)</span></span>
<span><span class="co"># the results are the new CIS and p.value</span></span>
<span><span class="fu"><a href="https://yiqingxu.org/packages/ivDiag/reference/tF.html">tF</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">coef_of_interest</span>, se <span class="op">=</span> <span class="va">se_of_interest</span>, Fstat <span class="op">=</span> <span class="va">fstat_1st</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">causalverse</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/causalverse/man/nice_tab.html">nice_tab</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt;          F   cF    Coef      SE        t  CI2.5. CI97.5. p.value</span></span>
<span><span class="co">#&gt; 1 903.1628 1.96 0.44498 0.02209 20.14744 0.40169 0.48827       0</span></span>
<span></span>
<span><span class="co"># We can try to see a different 1st-stage F-stat and how it changes the results</span></span>
<span><span class="fu"><a href="https://yiqingxu.org/packages/ivDiag/reference/tF.html">tF</a></span><span class="op">(</span>coef <span class="op">=</span> <span class="va">coef_of_interest</span>, se <span class="op">=</span> <span class="va">se_of_interest</span>, Fstat <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">causalverse</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/causalverse/man/nice_tab.html">nice_tab</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt;   F    cF    Coef      SE        t  CI2.5. CI97.5. p.value</span></span>
<span><span class="co">#&gt; 1 2 18.66 0.44498 0.02209 20.14744 0.03285 0.85711 0.03432</span></span></code></pre></div>
<hr>
</div>
<div id="sec-ak-approach" class="section level3" number="34.4.5">
<h3>
<span class="header-section-number">34.4.5</span> AK Approach<a class="anchor" aria-label="anchor" href="#sec-ak-approach"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">J. Angrist and Kolesár (<a href="references.html#ref-angrist2024one">2024</a>)</span> offer a reappraisal of just-identified IV models, focusing on the finite-sample properties of conventional inference in cases where a single instrument is used for a single endogenous variable. Their findings challenge some of the more pessimistic views about weak instruments and inference distortions in microeconometric applications.</p>
<p>Rather than propose a new estimator or test, Angrist and Kolesár provide a framework and rationale supporting the validity of traditional just-ID IV inference in many practical settings. Their insights clarify when conventional t-tests and confidence intervals can be trusted, and they offer practical guidance on first-stage pretesting, bias reduction, and endogeneity considerations.</p>
<p>AK apply their framework to three canonical studies:</p>
<ol style="list-style-type: decimal">
<li>
<span class="citation">J. D. Angrist and Krueger (<a href="references.html#ref-angrist1991does">1991</a>)</span> - Education returns</li>
<li>
<span class="citation">J. D. Angrist and Evans (<a href="references.html#ref-angrist1998children">1998</a>)</span> - Family size and female labor supply</li>
<li>
<span class="citation">J. D. Angrist and Lavy (<a href="references.html#ref-angrist1999using">1999</a>)</span> - Class size effects</li>
</ol>
<p>Findings:</p>
<ul>
<li><p>Endogeneity (<span class="math inline">\(\rho\)</span>) in these studies is moderate (typically <span class="math inline">\(|\rho| &lt; 0.47\)</span>).</p></li>
<li><p>Conventional t-tests and confidence intervals work reasonably well.</p></li>
<li><p>In many micro applications, theoretical bounds on causal effects and plausible OVB scenarios limit <span class="math inline">\(\rho\)</span>, supporting the validity of conventional inference.</p></li>
</ul>
<hr>
<p><strong>Key Contributions of the AK Approach</strong></p>
<ul>
<li><p><strong>Reassessing Bias and Coverage</strong>:<br>
AK demonstrate that conventional IV estimates and t-tests in just-ID IV models often perform better than theory might suggest—provided the degree of endogeneity (<span class="math inline">\(\rho\)</span>) is moderate, and the first-stage F-statistic is not extremely weak.</p></li>
<li>
<p><strong>First-Stage Sign Screening</strong>:</p>
<ul>
<li>They propose sign screening as a simple, costless strategy to halve the median bias of IV estimators.</li>
<li>Screening on the sign of the estimated first-stage coefficient (i.e., using only samples where the first-stage estimate has the correct sign) improves the finite-sample performance of just-ID IV estimates without degrading confidence interval coverage.</li>
</ul>
</li>
<li>
<p><strong>Bias-Minimizing Screening Rule</strong>:</p>
<ul>
<li>AK show that setting the first-stage t-statistic threshold <span class="math inline">\(c = 0\)</span>, i.e., requiring only the correct sign of the first-stage estimate, minimizes median bias while preserving conventional coverage properties.</li>
</ul>
</li>
<li>
<p><strong>Practical Implication</strong>:</p>
<ul>
<li>They argue that conventional just-ID IV inference, including t-tests and confidence intervals, is likely valid in most microeconometric applications, especially where theory or institutional knowledge suggests the direction of the first-stage relationship.</li>
</ul>
</li>
</ul>
<hr>
<div id="model-setup-and-notation" class="section level4" number="34.4.5.1">
<h4>
<span class="header-section-number">34.4.5.1</span> Model Setup and Notation<a class="anchor" aria-label="anchor" href="#model-setup-and-notation"><i class="fas fa-link"></i></a>
</h4>
<p>AK adopt a reduced-form and first-stage specification for just-ID IV models:</p>
<p><span class="math display">\[
Y_i = Z_i \delta + X_i' \psi_1 + u_i \\
D_i = Z_i \pi + X_i' \psi_2 + v_i
\]</span></p>
<ul>
<li>
<span class="math inline">\(Y_i\)</span>: Outcome variable</li>
<li>
<span class="math inline">\(D_i\)</span>: Endogenous treatment variable</li>
<li>
<span class="math inline">\(Z_i\)</span>: Instrumental variable (single instrument)</li>
<li>
<span class="math inline">\(X_i\)</span>: Control variables</li>
<li>
<span class="math inline">\(u_i, v_i\)</span>: Error terms</li>
</ul>
<p>Parameter of Interest:</p>
<p><span class="math display">\[
\beta = \frac{\delta}{\pi}
\]</span></p>
<hr>
</div>
<div id="endogeneity-and-instrument-strength" class="section level4" number="34.4.5.2">
<h4>
<span class="header-section-number">34.4.5.2</span> Endogeneity and Instrument Strength<a class="anchor" aria-label="anchor" href="#endogeneity-and-instrument-strength"><i class="fas fa-link"></i></a>
</h4>
<p>AK characterize the two key parameters governing finite-sample inference:</p>
<ul>
<li><p><strong>Instrument Strength</strong>:<br><span class="math display">\[ E[F] = \frac{\pi^2}{\sigma^2_{\hat{\pi}}} + 1 \]</span><br>
(Expected value of the first-stage F-statistic.)</p></li>
<li><p><strong>Endogeneity</strong>:<br><span class="math display">\[ \rho = \text{cor}(\hat{\delta} - \hat{\pi} \beta, \hat{\pi}) \]</span><br>
Measures the degree of correlation between reduced-form and first-stage residuals (or between <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> under homoskedasticity).</p></li>
</ul>
<p>Key Insight:</p>
<p>For <span class="math inline">\(\rho &lt; 0.76\)</span>, the coverage of conventional 95% confidence intervals is distorted by less than 5%, regardless of the first-stage F-statistic.</p>
<hr>
</div>
<div id="first-stage-sign-screening" class="section level4" number="34.4.5.3">
<h4>
<span class="header-section-number">34.4.5.3</span> First-Stage Sign Screening<a class="anchor" aria-label="anchor" href="#first-stage-sign-screening"><i class="fas fa-link"></i></a>
</h4>
<p>AK argue that pre-screening based on the sign of the first-stage estimate (<span class="math inline">\(\hat{\pi}\)</span>) offers bias reduction without compromising confidence interval coverage.</p>
<p>Screening Rule:</p>
<ul>
<li>Screen if <span class="math inline">\(\hat{\pi} &gt; 0\)</span><br>
(or <span class="math inline">\(\hat{\pi} &lt; 0\)</span> if the theoretical sign is negative).</li>
</ul>
<p>Results:</p>
<ul>
<li>Halves median bias of the IV estimator.</li>
<li>No degradation of confidence interval coverage.</li>
</ul>
<p>This screening approach:</p>
<ul>
<li><p>Avoids the pitfalls of pre-testing based on first-stage F-statistics (which can exacerbate bias and distort inference).</p></li>
<li><p>Provides a “free lunch”: bias reduction with no coverage cost.</p></li>
</ul>
<hr>
</div>
<div id="rejection-rates-and-confidence-interval-coverage" class="section level4" number="34.4.5.4">
<h4>
<span class="header-section-number">34.4.5.4</span> Rejection Rates and Confidence Interval Coverage<a class="anchor" aria-label="anchor" href="#rejection-rates-and-confidence-interval-coverage"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>Rejection rates of conventional t-tests stay close to the nominal level (5%) if <span class="math inline">\(|\rho| &lt; 0.76\)</span>, independent of instrument strength.</li>
<li>For <span class="math inline">\(|\rho| &lt; 0.565\)</span>, conventional t-tests exhibit no over-rejection, aligning with findings from <span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span>.</li>
</ul>
<p>Comparison with AR and tF Procedures:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="24%">
<col width="24%">
<col width="24%">
<col width="26%">
</colgroup>
<thead><tr class="header">
<th><strong>Approach</strong></th>
<th><strong>Bias Reduction</strong></th>
<th><strong>Coverage</strong></th>
<th><strong>CI Length (F &gt; 3.84)</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>AK Sign Screening</strong></td>
<td>Halves median bias</td>
<td>Near-nominal</td>
<td>Finite</td>
</tr>
<tr class="even">
<td><strong>AR Test</strong></td>
<td>No bias (inversion method)</td>
<td>Exact</td>
<td>Infinite</td>
</tr>
<tr class="odd">
<td><strong>tF Procedure</strong></td>
<td>Bias adjusted</td>
<td>Near-nominal</td>
<td>Longer than AK (especially for moderate F)</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
</div>
</div>
<div id="testing-assumptions" class="section level2" number="34.5">
<h2>
<span class="header-section-number">34.5</span> Testing Assumptions<a class="anchor" aria-label="anchor" href="#testing-assumptions"><i class="fas fa-link"></i></a>
</h2>
<p><span class="math display">\[
Y = \beta_1 X_1 + \beta_2 X_2 + \epsilon
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(X_1\)</span> are exogenous variables</p></li>
<li><p><span class="math inline">\(X_2\)</span> are endogenous variables</p></li>
<li><p><span class="math inline">\(Z\)</span> are instrumental variables</p></li>
</ul>
<p>If <span class="math inline">\(Z\)</span> satisfies the relevance condition, it means <span class="math inline">\(Cov(Z, X_2) \neq 0\)</span></p>
<p>This is important because we need this to be able to estimate <span class="math inline">\(\beta_2\)</span> where</p>
<p><span class="math display">\[
\beta_2 = \frac{Cov(Z,Y)}{Cov(Z, X_2)}
\]</span></p>
<p>If <span class="math inline">\(Z\)</span> satisfies the exogeneity condition, <span class="math inline">\(E[Z\epsilon]=0\)</span>, this can achieve by</p>
<ul>
<li><p><span class="math inline">\(Z\)</span> having no direct effect on <span class="math inline">\(Y\)</span> except through <span class="math inline">\(X_2\)</span></p></li>
<li><p>In the presence of omitted variable, <span class="math inline">\(Z\)</span> is uncorrelated with this variable.</p></li>
</ul>
<p>If we just want to know the effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span> (<strong>reduced form</strong>) where the coefficient of <span class="math inline">\(Z\)</span> is</p>
<p><span class="math display">\[
\rho = \frac{Cov(Y, Z)}{Var(Z)}
\]</span></p>
<p>and this effect is only through <span class="math inline">\(X_2\)</span> (by the exclusion restriction assumption).</p>
<p>We can also consistently estimate the effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(X\)</span> (<strong>first stage</strong>) where the the coefficient of <span class="math inline">\(X_2\)</span> is</p>
<p><span class="math display">\[
\pi = \frac{Cov(X_2, Z)}{Var(Z)}
\]</span></p>
<p>and the IV estimate is</p>
<p><span class="math display">\[
\beta_2 = \frac{Cov(Y,Z)}{Cov(X_2, Z)} = \frac{\rho}{\pi}
\]</span></p>
<div id="relevance-assumption" class="section level3" number="34.5.1">
<h3>
<span class="header-section-number">34.5.1</span> Relevance Assumption<a class="anchor" aria-label="anchor" href="#relevance-assumption"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<p><strong>Weak instruments</strong>: can explain little variation in the endogenous regressor</p>
<ul>
<li>Coefficient estimate of the endogenous variable will be inaccurate.</li>
<li>For cases where weak instruments are unavoidable, <span class="citation">M. J. Moreira (<a href="references.html#ref-moreira2003conditional">2003</a>)</span> proposes the conditional likelihood ratio test for robust inference. This test is considered approximately optimal for weak instrument scenarios <span class="citation">(<a href="references.html#ref-andrews2008efficient">D. W. Andrews, Moreira, and Stock 2008</a>; <a href="references.html#ref-andrews2008exactly">D. W. Andrews and Marmer 2008</a>)</span>.</li>
</ul>
</li>
<li>
<p>Rule of thumb:</p>
<ul>
<li><p>Compute F-statistic in the first-stage, where it should be greater than 10. But this is discouraged now by <span class="citation">Lee et al. (<a href="references.html#ref-lee2022valid">2022</a>)</span></p></li>
<li><p>use <code><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis()</a></code> to see only instrument coefficients.</p></li>
</ul>
</li>
</ul>
<p><strong>First-Stage F-Test</strong></p>
<p>In the context of a two-stage least squares (2SLS) setup where you are estimating the equation:</p>
<p><span class="math display">\[
Y = X \beta + \epsilon
\]</span></p>
<p>and <span class="math inline">\(X\)</span> is endogenous, you typically estimate a first-stage regression of:</p>
<p><span class="math display">\[
X = Z \pi + u
\]</span></p>
<p>where 𝑍Z is the instrument.</p>
<p>The first-stage F-test evaluates the joint significance of the instruments in this first stage:</p>
<p><span class="math display">\[
F = \frac{(SSR_r - SSR_{ur})/q}{SSR_{ur}/ (n - k - 1)}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(SSR_r\)</span> is the sum of squared residuals from the restricted model (no instruments, just the constant).</p></li>
<li><p><span class="math inline">\(SSR_{ur}\)</span> is the sum of squared residuals from the unrestricted model (with instruments).</p></li>
<li><p><span class="math inline">\(q\)</span> is the number of instruments excluded from the main equation.</p></li>
<li><p><span class="math inline">\(n\)</span> is the number of observations.</p></li>
<li><p><span class="math inline">\(k\)</span> is the number of explanatory variables excluding the instruments.</p></li>
</ul>
<p><strong>Cragg-Donald Test</strong></p>
<p>The Cragg-Donald statistic is essentially the same as the Wald statistic of the joint significance of the instruments in the first stage, and it’s used specifically when you have multiple endogenous regressors. It’s calculated as:</p>
<p><span class="math display">\[
CD = n \times (R_{ur}^2 - R_r^2)
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(R_{ur}^2\)</span> and <span class="math inline">\(R_r^2\)</span> are the R-squared values from the unrestricted and restricted models respectively.</p></li>
<li><p><span class="math inline">\(n\)</span> is the number of observations.</p></li>
</ul>
<p>For one endogenous variable, the Cragg-Donald test results should align closely with those from Stock and Yogo. The Anderson canonical correlation test, a likelihood ratio test, also works under similar conditions, contrasting with Cragg-Donald’s Wald statistic approach. Both are valid with one endogenous variable and at least one instrument.</p>
<p><strong>Stock-Yogo Weak IV Test</strong></p>
<p>The Stock-Yogo test does not directly compute a statistic like the F-test or Cragg-Donald, but rather uses pre-computed critical values to assess the strength of instruments. It often uses the eigenvalues derived from the concentration matrix:</p>
<p><span class="math display">\[
S = \frac{1}{n} (Z' X) (X'Z)
\]</span></p>
<p>where <span class="math inline">\(Z\)</span> is the matrix of instruments and <span class="math inline">\(X\)</span> is the matrix of endogenous regressors.</p>
<p>Stock and Yogo provide critical values for different scenarios (bias, size distortion) for a given number of instruments and endogenous regressors, based on the smallest eigenvalue of <span class="math inline">\(S\)</span>. The test compares these eigenvalues against critical values that correspond to thresholds of permissible bias or size distortion in a 2SLS estimator.</p>
<ul>
<li>
<strong>Critical Values and Test Conditions</strong>: The critical values derived by Stock and Yogo depend on the level of acceptable bias, the number of endogenous regressors, and the number of instruments. For example, with a 5% maximum acceptable bias, one endogenous variable, and three instruments, the critical value for a sufficient first stage F-statistic is 13.91. Note that this framework requires at least two overidentifying degree of freedom.</li>
</ul>
<p><strong>Comparison</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="24%">
<col width="24%">
<col width="24%">
<col width="26%">
</colgroup>
<thead><tr class="header">
<th><strong>Test</strong></th>
<th><strong>Description</strong></th>
<th><strong>Focus</strong></th>
<th><strong>Usage</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>First-Stage F-Test</strong></td>
<td>Evaluates the joint significance of instruments in the first stage.</td>
<td>Predictive power of instruments for the endogenous variable.</td>
<td>Simplest and most direct test, widely used especially with a single endogenous variable. Rule of thumb: F &lt; 10 suggests weak instruments.</td>
</tr>
<tr class="even">
<td><strong>Cragg-Donald Test</strong></td>
<td>Wald statistic for joint significance of instruments.</td>
<td>Joint strength of multiple instruments with multiple endogenous variables.</td>
<td>More appropriate in complex IV setups with multiple endogenous variables. Compares statistic against critical values for assessing instrument strength.</td>
</tr>
<tr class="odd">
<td><strong>Stock-Yogo Weak IV Test</strong></td>
<td>Compares test statistic to pre-determined critical values.</td>
<td>Minimizing size distortions and bias from weak instruments.</td>
<td>Theoretical evaluation of instrument strength, ensuring the reliability of 2SLS estimates against specific thresholds of bias or size distortion.</td>
</tr>
</tbody>
</table></div>
<p>All the mentioned tests (Stock Yogo, Cragg-Donald, Anderson canonical correlation test) assume errors are independently and identically distributed. If this assumption is violated, the Kleinbergen-Paap test is robust against violations of the iid assumption and can be applied even with a single endogenous variable and instrument, provided the model is properly identified <span class="citation">(<a href="references.html#ref-baum2021ivreg2h">Baum and Schaffer 2021</a>)</span>.</p>
<div id="weak-instrument-tests" class="section level4" number="34.5.1.1">
<h4>
<span class="header-section-number">34.5.1.1</span> Weak Instrument Tests<a class="anchor" aria-label="anchor" href="#weak-instrument-tests"><i class="fas fa-link"></i></a>
</h4>
</div>
<div id="cragg-donald" class="section level4" number="34.5.1.2">
<h4>
<span class="header-section-number">34.5.1.2</span> Cragg-Donald<a class="anchor" aria-label="anchor" href="#cragg-donald"><i class="fas fa-link"></i></a>
</h4>
<p><span class="citation">(<a href="references.html#ref-cragg1993testing">Cragg and Donald 1993</a>)</span></p>
<p>Similar to the first-stage F-statistic</p>
<div class="sourceCode" id="cb897"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">cragg</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span> <span class="co"># for dataaset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"WeakInstrument"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/cragg/man/cragg_donald.html">cragg_donald</a></span><span class="op">(</span></span>
<span>    <span class="co"># control variables</span></span>
<span>    X <span class="op">=</span> <span class="op">~</span> <span class="fl">1</span>, </span>
<span>    <span class="co"># endogeneous variables</span></span>
<span>    D <span class="op">=</span> <span class="op">~</span> <span class="va">x</span>, </span>
<span>    <span class="co"># instrument variables </span></span>
<span>    Z <span class="op">=</span> <span class="op">~</span> <span class="va">z</span>, </span>
<span>    data <span class="op">=</span> <span class="va">WeakInstrument</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Cragg-Donald test for weak instruments:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      Data:                        WeakInstrument </span></span>
<span><span class="co">#&gt;      Controls:                    ~1 </span></span>
<span><span class="co">#&gt;      Treatments:                  ~x </span></span>
<span><span class="co">#&gt;      Instruments:                 ~z </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      Cragg-Donald Statistic:        4.566136 </span></span>
<span><span class="co">#&gt;      Df:                                 198</span></span></code></pre></div>
<p>Large CD statistic implies that the instruments are strong, but not in our case here. But to judge it against some critical value, we have to look at <a href="sec-instrumental-variables.html#stock-yogo">Stock-Yogo</a></p>
</div>
<div id="stock-yogo" class="section level4" number="34.5.1.3">
<h4>
<span class="header-section-number">34.5.1.3</span> Stock-Yogo<a class="anchor" aria-label="anchor" href="#stock-yogo"><i class="fas fa-link"></i></a>
</h4>
<p><span class="citation">J. H. Stock and Yogo (<a href="references.html#ref-stock2002testing">2002</a>)</span> set the critical values such that the bias is less then 10% (default)</p>
<p><span class="math inline">\(H_0:\)</span> Instruments are weak</p>
<p><span class="math inline">\(H_1:\)</span> Instruments are not weak</p>
<div class="sourceCode" id="cb898"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">cragg</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span> <span class="co"># for dataaset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"WeakInstrument"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/cragg/man/stock_yogo_test.html">stock_yogo_test</a></span><span class="op">(</span></span>
<span>    <span class="co"># control variables</span></span>
<span>    X <span class="op">=</span> <span class="op">~</span> <span class="fl">1</span>,</span>
<span>    <span class="co"># endogeneous variables</span></span>
<span>    D <span class="op">=</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>    <span class="co"># instrument variables</span></span>
<span>    Z <span class="op">=</span> <span class="op">~</span> <span class="va">z</span>,</span>
<span>    size_bias <span class="op">=</span> <span class="st">"bias"</span>,</span>
<span>    data <span class="op">=</span> <span class="va">WeakInstrument</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The CD statistic should be bigger than the set critical value to be considered strong instruments.</p>
</div>
<div id="anderson-rubin" class="section level4" number="34.5.1.4">
<h4>
<span class="header-section-number">34.5.1.4</span> Anderson-Rubin<a class="anchor" aria-label="anchor" href="#anderson-rubin"><i class="fas fa-link"></i></a>
</h4>
</div>
<div id="stock-wright" class="section level4" number="34.5.1.5">
<h4>
<span class="header-section-number">34.5.1.5</span> Stock-Wright<a class="anchor" aria-label="anchor" href="#stock-wright"><i class="fas fa-link"></i></a>
</h4>
</div>
</div>
<div id="exogeneity-assumption" class="section level3" number="34.5.2">
<h3>
<span class="header-section-number">34.5.2</span> Exogeneity Assumption<a class="anchor" aria-label="anchor" href="#exogeneity-assumption"><i class="fas fa-link"></i></a>
</h3>
<p>The local average treatment effect (LATE) is defined as:</p>
<p><span class="math display">\[
\text{LATE} = \frac{\text{reduced form}}{\text{first stage}} = \frac{\rho}{\phi}
\]</span></p>
<p>This implies that the reduced form (<span class="math inline">\(\rho\)</span>) is the product of the first stage (<span class="math inline">\(\phi\)</span>) and LATE:</p>
<p><span class="math display">\[
\rho = \phi \times \text{LATE}
\]</span></p>
<p>Thus, if the first stage (<span class="math inline">\(\phi\)</span>) is 0, the reduced form (<span class="math inline">\(\rho\)</span>) should also be 0.</p>
<div class="sourceCode" id="cb899"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://shiny.posit.co/">shiny</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AER</span><span class="op">)</span>  <span class="co"># for ivreg</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>  <span class="co"># for visualization</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>  <span class="co"># for data manipulation</span></span>
<span></span>
<span><span class="co"># Function to simulate the dataset</span></span>
<span><span class="va">simulate_iv_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>, <span class="va">beta</span>, <span class="va">phi</span>, <span class="va">direct_effect</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">Z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">epsilon_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">epsilon_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">X</span> <span class="op">&lt;-</span> <span class="va">phi</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">epsilon_x</span></span>
<span>  <span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">beta</span> <span class="op">*</span> <span class="va">X</span> <span class="op">+</span> <span class="va">direct_effect</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">epsilon_y</span></span>
<span>  <span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>Y <span class="op">=</span> <span class="va">Y</span>, X <span class="op">=</span> <span class="va">X</span>, Z <span class="op">=</span> <span class="va">Z</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Function to run the simulations and calculate the effects</span></span>
<span><span class="va">run_simulation</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>, <span class="va">beta</span>, <span class="va">phi</span>, <span class="va">direct_effect</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Simulate the data</span></span>
<span>  <span class="va">simulated_data</span> <span class="op">&lt;-</span> <span class="fu">simulate_iv_data</span><span class="op">(</span><span class="va">n</span>, <span class="va">beta</span>, <span class="va">phi</span>, <span class="va">direct_effect</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Estimate first-stage effect (phi)</span></span>
<span>  <span class="va">first_stage</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">X</span> <span class="op">~</span> <span class="va">Z</span>, data <span class="op">=</span> <span class="va">simulated_data</span><span class="op">)</span></span>
<span>  <span class="va">phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">first_stage</span><span class="op">)</span><span class="op">[</span><span class="st">"Z"</span><span class="op">]</span></span>
<span>  <span class="va">phi_ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">first_stage</span><span class="op">)</span><span class="op">[</span><span class="st">"Z"</span>, <span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Estimate reduced-form effect (rho)</span></span>
<span>  <span class="va">reduced_form</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span>, data <span class="op">=</span> <span class="va">simulated_data</span><span class="op">)</span></span>
<span>  <span class="va">rho</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">reduced_form</span><span class="op">)</span><span class="op">[</span><span class="st">"Z"</span><span class="op">]</span></span>
<span>  <span class="va">rho_ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">reduced_form</span><span class="op">)</span><span class="op">[</span><span class="st">"Z"</span>, <span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Estimate LATE using IV regression</span></span>
<span>  <span class="va">iv_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/AER/man/ivreg.html">ivreg</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">X</span> <span class="op">|</span> <span class="va">Z</span>, data <span class="op">=</span> <span class="va">simulated_data</span><span class="op">)</span></span>
<span>  <span class="va">iv_late</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">iv_model</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span><span class="op">]</span></span>
<span>  <span class="va">iv_late_ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">iv_model</span><span class="op">)</span><span class="op">[</span><span class="st">"X"</span>, <span class="op">]</span></span>
<span>  </span>
<span>  <span class="co"># Calculate LATE as the ratio of reduced-form and first-stage coefficients</span></span>
<span>  <span class="va">calculated_late</span> <span class="op">&lt;-</span> <span class="va">rho</span> <span class="op">/</span> <span class="va">phi</span></span>
<span>  <span class="va">calculated_late_se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span></span>
<span>    <span class="op">(</span><span class="va">rho_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">-</span> <span class="va">rho</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">phi</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="va">rho</span> <span class="op">*</span> <span class="op">(</span><span class="va">phi_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">-</span> <span class="va">phi</span><span class="op">)</span> <span class="op">/</span> <span class="va">phi</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">calculated_late_ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">calculated_late</span> <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> <span class="va">calculated_late_se</span>, </span>
<span>                          <span class="va">calculated_late</span> <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> <span class="va">calculated_late_se</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Return a list of results</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>phi <span class="op">=</span> <span class="va">phi</span>, </span>
<span>       phi_ci <span class="op">=</span> <span class="va">phi_ci</span>,</span>
<span>       rho <span class="op">=</span> <span class="va">rho</span>, </span>
<span>       rho_ci <span class="op">=</span> <span class="va">rho_ci</span>,</span>
<span>       direct_effect <span class="op">=</span> <span class="va">direct_effect</span>,</span>
<span>       direct_effect_ci <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">direct_effect</span>, <span class="va">direct_effect</span><span class="op">)</span>,  <span class="co"># Placeholder for direct effect CI</span></span>
<span>       iv_late <span class="op">=</span> <span class="va">iv_late</span>, </span>
<span>       iv_late_ci <span class="op">=</span> <span class="va">iv_late_ci</span>,</span>
<span>       calculated_late <span class="op">=</span> <span class="va">calculated_late</span>, </span>
<span>       calculated_late_ci <span class="op">=</span> <span class="va">calculated_late_ci</span>,</span>
<span>       true_effect <span class="op">=</span> <span class="va">beta</span>,</span>
<span>       true_effect_ci <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">beta</span>, <span class="va">beta</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Placeholder for true effect CI</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Define UI for the sliders</span></span>
<span><span class="va">ui</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/fluidPage.html">fluidPage</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/titlePanel.html">titlePanel</a></span><span class="op">(</span><span class="st">"IV Model Simulation"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/sidebarLayout.html">sidebarLayout</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/sidebarLayout.html">sidebarPanel</a></span><span class="op">(</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/sliderInput.html">sliderInput</a></span><span class="op">(</span><span class="st">"beta"</span>, <span class="st">"True Effect of X on Y (beta):"</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1.0</span>, value <span class="op">=</span> <span class="fl">0.5</span>, step <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/sliderInput.html">sliderInput</a></span><span class="op">(</span><span class="st">"phi"</span>, <span class="st">"First Stage Effect (phi):"</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1.0</span>, value <span class="op">=</span> <span class="fl">0.7</span>, step <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/sliderInput.html">sliderInput</a></span><span class="op">(</span><span class="st">"direct_effect"</span>, <span class="st">"Direct Effect of Z on Y:"</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, max <span class="op">=</span> <span class="fl">0.5</span>, value <span class="op">=</span> <span class="fl">0</span>, step <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span>    <span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/sidebarLayout.html">mainPanel</a></span><span class="op">(</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/plotOutput.html">plotOutput</a></span><span class="op">(</span><span class="st">"dotPlot"</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define server logic to run the simulation and generate the plot</span></span>
<span><span class="va">server</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input</span>, <span class="va">output</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">output</span><span class="op">$</span><span class="va">dotPlot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/shiny/man/renderPlot.html">renderPlot</a></span><span class="op">(</span><span class="op">{</span></span>
<span>    <span class="co"># Run simulation</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu">run_simulation</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, beta <span class="op">=</span> <span class="va">input</span><span class="op">$</span><span class="va">beta</span>, phi <span class="op">=</span> <span class="va">input</span><span class="op">$</span><span class="va">phi</span>, direct_effect <span class="op">=</span> <span class="va">input</span><span class="op">$</span><span class="va">direct_effect</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Prepare data for plotting</span></span>
<span>    <span class="va">plot_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>      Effect <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"First Stage (phi)"</span>, <span class="st">"Reduced Form (rho)"</span>, <span class="st">"Direct Effect"</span>, <span class="st">"LATE (Ratio)"</span>, <span class="st">"LATE (IV)"</span>, <span class="st">"True Effect"</span><span class="op">)</span>,</span>
<span>      Value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">phi</span>, <span class="va">results</span><span class="op">$</span><span class="va">rho</span>, <span class="va">results</span><span class="op">$</span><span class="va">direct_effect</span>, <span class="va">results</span><span class="op">$</span><span class="va">calculated_late</span>, <span class="va">results</span><span class="op">$</span><span class="va">iv_late</span>, <span class="va">results</span><span class="op">$</span><span class="va">true_effect</span><span class="op">)</span>,</span>
<span>      CI_Lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">phi_ci</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">rho_ci</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">direct_effect_ci</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">calculated_late_ci</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">iv_late_ci</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">true_effect_ci</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>      CI_Upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">results</span><span class="op">$</span><span class="va">phi_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">rho_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">direct_effect_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">calculated_late_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">iv_late_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="va">results</span><span class="op">$</span><span class="va">true_effect_ci</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># Create dot plot with confidence intervals</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">plot_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Effect</span>, y <span class="op">=</span> <span class="va">Value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html">geom_errorbar</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>ymin <span class="op">=</span> <span class="va">CI_Lower</span>, ymax <span class="op">=</span> <span class="va">CI_Upper</span><span class="op">)</span>, width <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"IV Model Effects"</span>,</span>
<span>           y <span class="op">=</span> <span class="st">"Coefficient Value"</span><span class="op">)</span> <span class="op">+</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>  <span class="co"># Limits the y-axis to -1 to 1 but allows CI beyond</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>      <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">45</span>, hjust <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Run the application </span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/shiny/man/shinyApp.html">shinyApp</a></span><span class="op">(</span>ui <span class="op">=</span> <span class="va">ui</span>, server <span class="op">=</span> <span class="va">server</span><span class="op">)</span></span></code></pre></div>
<p>A statistically significant reduced form estimate without a corresponding first stage indicates an issue, suggesting an alternative channel linking instruments to outcomes or a direct effect of the IV on the outcome.</p>
<ul>
<li>
<strong>No Direct Effect</strong>: When the direct effect is 0 and the first stage is 0, the reduced form is 0.
<ul>
<li>Note: Extremely rare cases with multiple additional paths that perfectly cancel each other out can also produce this result, but testing for all possible paths is impractical.</li>
</ul>
</li>
<li>
<strong>With Direct Effect</strong>: When there is a direct effect of the IV on the outcome, the reduced form can be significantly different from 0, even if the first stage is 0.
<ul>
<li>This violates the exogeneity assumption, as the IV should only affect the outcome through the treatment variable.</li>
</ul>
</li>
</ul>
<p>To test the validity of the exogeneity assumption, we can use a sanity test:</p>
<ul>
<li>Identify groups for which the effects of instruments on the treatment variable are small and not significantly different from 0. The reduced form estimate for these groups should also be 0. These “no-first-stage samples” provide evidence of whether the exogeneity assumption is violated.</li>
</ul>
<div id="overid-tests" class="section level4" number="34.5.2.1">
<h4>
<span class="header-section-number">34.5.2.1</span> Overid Tests<a class="anchor" aria-label="anchor" href="#overid-tests"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>
<p>Wald test and Hausman test for exogeneity of <span class="math inline">\(X\)</span> assuming <span class="math inline">\(Z\)</span> is exogenous</p>
<ul>
<li>People might prefer Wald test over Hausman test.</li>
</ul>
</li>
<li><p>Sargan (for 2SLS) is a simpler version of Hansen’s J test (for IV-GMM)</p></li>
<li><p>Modified J test (i.e., Regularized jacknife IV): can handle weak instruments and small sample size <span class="citation">(<a href="references.html#ref-carrasco2022testing">Carrasco and Doukali 2022</a>)</span> (also proposed a regularized F-test to test relevance assumption that is robust to heteroskedasticity).</p></li>
<li><p>New advances: endogeneity robust inference in finite sample and sensitivity analysis of inference <span class="citation">(<a href="references.html#ref-kiviet2020testing">Kiviet 2020</a>)</span></p></li>
</ul>
<p>These tests that can provide evidence fo the validity of the over-identifying restrictions is not sufficient or necessary for the validity of the moment conditions (i.e., this assumption cannot be tested). <span class="citation">(<a href="references.html#ref-deaton2010instruments">Deaton 2010</a>; <a href="references.html#ref-parente2012cautionary">Parente and Silva 2012</a>)</span></p>
<ul>
<li><p>The over-identifying restriction can still be valid even when the instruments are correlated with the error terms, but then in this case, what you’re estimating is no longer your parameters of interest.</p></li>
<li><p>Rejection of the over-identifying restrictions can also be the result of <strong>parameter heterogeneity</strong> <span class="citation">(<a href="references.html#ref-angrist2000interpretation">J. D. Angrist, Graddy, and Imbens 2000</a>)</span></p></li>
</ul>
<p>Why overid tests hold no value/info?</p>
<ul>
<li>
<p>Overidentifying restrictions are valid irrespective of the instruments’ validity</p>
<ul>
<li>Whenever instruments have the same motivation and are on the same scale, the estimated parameter of interests will be very close <span class="citation">(<a href="references.html#ref-parente2012cautionary">Parente and Silva 2012, 316</a>)</span>
</li>
</ul>
</li>
<li>
<p>Overidentifying restriction are invalid when each instrument is valid</p>
<ul>
<li>When the effect of your parameter of interest is heterogeneous (e.g., you have two groups with two different true effects), your first instrument can be correlated with your variable of interest only for the first group and your second interments can be correlated with your variable of interest only for the second group (i.e., each instrument is valid), and if you use each instrument, you can still identify the parameter of interest. However, if you use both of them, what you estimate is a mixture of the two groups. Hence, the overidentifying restriction will be invalid (because no single parameters can make the errors of the model orthogonal to both instruments). The result may seem confusing at first because if each subset of overidentifying restrictions is valid, the full set should also be valid. However, this interpretation is flawed because the residual’s orthogonality to the instruments depends on the chosen set of instruments, and therefore the set of restrictions tested when using two sets of instruments together is not the same as the union of the sets of restrictions tested when using each set of instruments separately <span class="citation">(<a href="references.html#ref-parente2012cautionary">Parente and Silva 2012, 316</a>)</span>
</li>
</ul>
</li>
</ul>
<p>These tests (of overidentifying restrictions) should be used to check whether different instruments identify the same parameters of interest, not to check their validity</p>
<p><span class="citation">(<a href="references.html#ref-hausman1983specification">J. A. Hausman 1983</a>; <a href="references.html#ref-parente2012cautionary">Parente and Silva 2012</a>)</span></p>
<div id="wald-test" class="section level5" number="34.5.2.1.1">
<h5>
<span class="header-section-number">34.5.2.1.1</span> Wald Test<a class="anchor" aria-label="anchor" href="#wald-test"><i class="fas fa-link"></i></a>
</h5>
<p>Assuming that <span class="math inline">\(Z\)</span> is exogenous (a valid instrument), we want to know whether <span class="math inline">\(X_2\)</span> is exogenous</p>
<p>1st stage:</p>
<p><span class="math display">\[
X_2 = \hat{\alpha} Z + \hat{\epsilon}
\]</span></p>
<p>2nd stage:</p>
<p><span class="math display">\[
Y = \delta_0 X_1 + \delta_1 X_2 + \delta_2 \hat{\epsilon} + u
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(\hat{\epsilon}\)</span> is the residuals from the 1st stage</li>
</ul>
<p>The Wald test of exogeneity assumes</p>
<p><span class="math display">\[
H_0: \delta_2 = 0 \\
H_1: \delta_2 \neq 0
\]</span></p>
<p>If you have more than one endogenous variable with more than one instrument, <span class="math inline">\(\delta_2\)</span> is a vector of all residuals from all the first-stage equations. And the null hypothesis is that they are jointly equal 0.</p>
<p>If you reject this hypothesis, it means that <span class="math inline">\(X_2\)</span> is <strong>not endogenous</strong>. Hence, for this test, we do not want to reject the null hypothesis.</p>
<p>If the test is not sacrificially significant, we might just don’t have enough information to reject the null.</p>
<p>When you have a valid instrument <span class="math inline">\(Z\)</span>, whether <span class="math inline">\(X_2\)</span> is endogenous or exogenous, your coefficient estimates of <span class="math inline">\(X_2\)</span> should still be consistent. But if <span class="math inline">\(X_2\)</span> is exogenous, then 2SLS will be inefficient (i.e., larger standard errors).</p>
<p>Intuition:</p>
<p><span class="math inline">\(\hat{\epsilon}\)</span> is the supposed endogenous part of <span class="math inline">\(X_2\)</span>, When we regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(\hat{\epsilon}\)</span> and observe that its coefficient is not different from 0. It means that the exogenous part of <span class="math inline">\(X_2\)</span> can explain well the impact on <span class="math inline">\(Y\)</span>, and there is no endogenous part.</p>
</div>
<div id="hausmans-test" class="section level5" number="34.5.2.1.2">
<h5>
<span class="header-section-number">34.5.2.1.2</span> Hausman’s Test<a class="anchor" aria-label="anchor" href="#hausmans-test"><i class="fas fa-link"></i></a>
</h5>
<p>Similar to <a href="generalized-linear-models.html#sec-wald-test-logistic">Wald Test</a> and identical to <a href="generalized-linear-models.html#sec-wald-test-logistic">Wald Test</a> when we have homoskedasticity (i.e., homogeneity of variances). Because of this assumption, it’s used less often than <a href="generalized-linear-models.html#sec-wald-test-logistic">Wald Test</a></p>
</div>
<div id="hansens-j" class="section level5" number="34.5.2.1.3">
<h5>
<span class="header-section-number">34.5.2.1.3</span> Hansen’s J<a class="anchor" aria-label="anchor" href="#hansens-j"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p><span class="citation">(<a href="references.html#ref-hansen1982large">L. P. Hansen 1982</a>)</span></p></li>
<li>
<p>J-test (over-identifying restrictions test): test whether <strong>additional</strong> instruments are exogenous</p>
<ul>
<li>Can only be applied in cases where you have more instruments than endogenous variables
<ul>
<li><span class="math inline">\(dim(Z) &gt; dim(X_2)\)</span></li>
</ul>
</li>
<li>Assume at least one instrument within <span class="math inline">\(Z\)</span> is exogenous</li>
</ul>
</li>
</ul>
<p>Procedure IV-GMM:</p>
<ol style="list-style-type: decimal">
<li>Obtain the residuals of the 2SLS estimation</li>
<li>Regress the residuals on all instruments and exogenous variables.</li>
<li>Test the joint hypothesis that all coefficients of the residuals across instruments are 0 (i.e., this is true when instruments are exogenous).
<ol style="list-style-type: decimal">
<li><p>Compute <span class="math inline">\(J = mF\)</span> where <span class="math inline">\(m\)</span> is the number of instruments, and <span class="math inline">\(F\)</span> is your equation <span class="math inline">\(F\)</span> statistic (can you use <code><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis()</a></code> again).</p></li>
<li><p>If your exogeneity assumption is true, then <span class="math inline">\(J \sim \chi^2_{m-k}\)</span> where <span class="math inline">\(k\)</span> is the number of endogenous variables.</p></li>
</ol>
</li>
<li>If you reject this hypothesis, it can be that
<ol style="list-style-type: decimal">
<li><p>The first sets of instruments are invalid</p></li>
<li><p>The second sets of instruments are invalid</p></li>
<li><p>Both sets of instruments are invalid</p></li>
</ol>
</li>
</ol>
<p><strong>Note</strong>: This test is only true when your residuals are homoskedastic.</p>
<p>For a heteroskedasticity-robust <span class="math inline">\(J\)</span>-statistic, see <span class="citation">(<a href="references.html#ref-carrasco2022testing">Carrasco and Doukali 2022</a>; <a href="references.html#ref-li2022testing">H. Li et al. 2022</a>)</span></p>
</div>
<div id="sargan-test" class="section level5" number="34.5.2.1.4">
<h5>
<span class="header-section-number">34.5.2.1.4</span> Sargan Test<a class="anchor" aria-label="anchor" href="#sargan-test"><i class="fas fa-link"></i></a>
</h5>
<p><span class="citation">(<a href="references.html#ref-sargan1958estimation">Sargan 1958</a>)</span></p>
<p>Similar to <a href="sec-instrumental-variables.html#hansens-j">Hansen’s J</a>, but it assumes homoskedasticity</p>
<ul>
<li><p>Have to be careful when sample is not collected exogenously. As such, when you have choice-based sampling design, the sampling weights have to be considered to have consistent estimates. However, even if we apply sampling weights, the tests are not suitable because the iid assumption off errors are already violated. Hence, the test is invalid in this case <span class="citation">(<a href="references.html#ref-pitt2011overidentification">Pitt 2011</a>)</span>.</p></li>
<li><p>If one has heteroskedasticity in its design, the Sargan test is invalid <span class="citation">(<a href="references.html#ref-pitt2011overidentification">Pitt 2011</a>})</span></p></li>
</ul>
<hr>
</div>
</div>
</div>
</div>
<div id="negative-r2-in-iv-regression" class="section level2" number="34.6">
<h2>
<span class="header-section-number">34.6</span> Negative <span class="math inline">\(R^2\)</span> in IV Regression<a class="anchor" aria-label="anchor" href="#negative-r2-in-iv-regression"><i class="fas fa-link"></i></a>
</h2>
<p>In IV estimation, particularly 2SLS and 3SLS, it is common and not problematic to encounter negative <span class="math inline">\(R^2\)</span> values in the second stage regression. Unlike <a href="linear-regression.html#ordinary-least-squares">Ordinary Least Squares</a>, where <span class="math inline">\(R^2\)</span> is often used to assess the fit of the model, in IV regression the primary concern is consistency and unbiased estimation of the coefficients of interest, not the goodness-of-fit.</p>
<p>What Should You Look At Instead of <span class="math inline">\(R^2\)</span> in IV?</p>
<ol style="list-style-type: decimal">
<li>
<strong>Instrument Relevance</strong> (First-stage <span class="math inline">\(F\)</span>-statistics, Partial <span class="math inline">\(R^2\)</span>)</li>
<li>
<strong>Weak Instrument Tests</strong> (Kleibergen-Paap, Anderson-Rubin tests)</li>
<li>
<strong>Validity of Instruments</strong> (Overidentification tests like Sargan/Hansen J-test)</li>
<li>
<strong>Endogeneity Tests</strong> (Durbin-Wu-Hausman test for endogeneity)</li>
<li>
<a href="sec-instrumental-variables.html#sec-inference-iv">Confidence Intervals and Standard Errors</a>, focusing on inference for <span class="math inline">\(\hat{\beta}\)</span>.</li>
</ol>
<p><strong>Geometric Intuition</strong></p>
<ul>
<li>In OLS, the fitted values <span class="math inline">\(\hat{y}\)</span> are the orthogonal projection of <span class="math inline">\(y\)</span> onto the column space of <span class="math inline">\(X\)</span>.</li>
<li>In 2SLS, <span class="math inline">\(\hat{y}\)</span> is the projection onto the space spanned by <span class="math inline">\(Z\)</span>, not <span class="math inline">\(X\)</span>.</li>
<li>As a result, the angle between <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{y}\)</span> may not minimize the residual variance, and RSS can be larger than in OLS.</li>
</ul>
<hr>
<p>Recall the formula for the coefficient of determination (<span class="math inline">\(R^2\)</span>) in a regression model:</p>
<p><span class="math display">\[
R^2 = 1 - \frac{RSS}{TSS} = \frac{MSS}{TSS}
\]</span></p>
<p>Where:</p>
<ul>
<li>
<span class="math inline">\(TSS\)</span> is the Total Sum of Squares: <span class="math display">\[
TSS = \sum_{i=1}^n (y_i - \bar{y})^2
\]</span>
</li>
</ul>
<!-- --><ul>
<li><p><span class="math inline">\(MSS\)</span> is the Model Sum of Squares: <span class="math display">\[
MSS = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2
\]</span></p></li>
<li><p><span class="math inline">\(RSS\)</span> is the Residual Sum of Squares: <span class="math display">\[
RSS = \sum_{i=1}^n (y_i - \hat{y}_i)^2
\]</span></p></li>
</ul>
<p>In OLS, the <span class="math inline">\(R^2\)</span> measures the proportion of variance in <span class="math inline">\(Y\)</span> that is explained by the regressors <span class="math inline">\(X\)</span>.</p>
<p>Key Properties in OLS:</p>
<ul>
<li><span class="math inline">\(R^2 \in [0, 1]\)</span></li>
<li>Adding more regressors (even irrelevant ones) never decreases <span class="math inline">\(R^2\)</span>.</li>
<li>
<span class="math inline">\(R^2\)</span> measures in-sample goodness-of-fit, not causal interpretation.</li>
</ul>
<hr>
<div id="why-does-r2-lose-its-meaning-in-iv-regression" class="section level3" number="34.6.1">
<h3>
<span class="header-section-number">34.6.1</span> Why Does <span class="math inline">\(R^2\)</span> Lose Its Meaning in IV Regression?<a class="anchor" aria-label="anchor" href="#why-does-r2-lose-its-meaning-in-iv-regression"><i class="fas fa-link"></i></a>
</h3>
<p>In IV regression, the second stage regression replaces the endogenous variable <span class="math inline">\(X_2\)</span> with its predicted values from the first stage:</p>
<p>Stage 1:</p>
<p><span class="math display">\[
X_2 = Z \pi + v
\]</span></p>
<p>Stage 2:</p>
<p><span class="math display">\[
Y = X_1 \beta_1 + \hat{X}_2 \beta_2 + \epsilon
\]</span></p>
<ul>
<li>
<span class="math inline">\(\hat{X}_2\)</span> is not the observed <span class="math inline">\(X_2\)</span>, but a proxy constructed from <span class="math inline">\(Z\)</span>.</li>
<li>
<span class="math inline">\(\hat{X}_2\)</span> isolates the exogenous variation in <span class="math inline">\(X_2\)</span> that is independent of <span class="math inline">\(\epsilon\)</span>.</li>
<li>This reduces bias, but comes at a cost:
<ul>
<li>The variation in <span class="math inline">\(\hat{X}_2\)</span> is typically less than that in <span class="math inline">\(X_2\)</span>.</li>
<li>The predicted values <span class="math inline">\(\hat{y}_i\)</span> from the second stage are not necessarily close to <span class="math inline">\(y_i\)</span>.</li>
</ul>
</li>
</ul>
</div>
<div id="why-r2-can-be-negative" class="section level3" number="34.6.2">
<h3>
<span class="header-section-number">34.6.2</span> Why <span class="math inline">\(R^2\)</span> Can Be Negative:<a class="anchor" aria-label="anchor" href="#why-r2-can-be-negative"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(R^2\)</span> is calculated using: <span class="math display">\[
R^2 = 1 - \frac{RSS}{TSS}
\]</span> But in IV:</li>
</ol>
<ul>
<li>The predicted values of <span class="math inline">\(Y\)</span> are not chosen to minimize RSS, because IV is not minimizing the residuals in the second stage.</li>
<li>Unlike OLS, 2SLS chooses <span class="math inline">\(\hat{\beta}\)</span> to satisfy moment conditions rather than minimizing the sum of squared errors.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>It is possible (and common in IV) for the residual sum of squares to be greater than the total sum of squares: <span class="math display">\[
RSS &gt; TSS
\]</span> Which makes: <span class="math display">\[
R^2 = 1 - \frac{RSS}{TSS} &lt; 0
\]</span></p></li>
<li>
<p>This happens because:</p>
<ul>
<li>The predicted values <span class="math inline">\(\hat{y}_i\)</span> in IV are not optimized to fit the observed <span class="math inline">\(y_i\)</span>.</li>
<li>The residuals can be larger, because IV focuses on identifying causal effects, not prediction.</li>
</ul>
</li>
</ol>
<p>For example, assume we have:</p>
<ul>
<li><p><span class="math inline">\(TSS = 100\)</span></p></li>
<li><p><span class="math inline">\(RSS = 120\)</span></p></li>
</ul>
<p>Then: <span class="math display">\[ R^2 = 1 - \frac{120}{100} = -0.20 \]</span></p>
<p>This happens because the IV procedure does not minimize RSS. It prioritizes solving the endogeneity problem over explaining the variance in <span class="math inline">\(Y\)</span>.</p>
<hr>
</div>
<div id="why-we-dont-care-about-r2-in-iv" class="section level3" number="34.6.3">
<h3>
<span class="header-section-number">34.6.3</span> Why We Don’t Care About <span class="math inline">\(R^2\)</span> in IV<a class="anchor" aria-label="anchor" href="#why-we-dont-care-about-r2-in-iv"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>IV Estimates Focus on <strong>Consistency</strong>, Not <strong>Prediction</strong>
</li>
</ol>
<ul>
<li>The goal of IV is to obtain a consistent estimate of <span class="math inline">\(\beta_2\)</span>.</li>
<li>IV sacrifices fit (higher variance in <span class="math inline">\(\hat{y}_i\)</span>) to remove endogeneity bias.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>
<span class="math inline">\(R^2\)</span> Does Not Reflect the Quality of an IV Estimator</li>
</ol>
<ul>
<li>A high <span class="math inline">\(R^2\)</span> in IV may be misleading (for instance, when instruments are weak or invalid).</li>
<li>A negative <span class="math inline">\(R^2\)</span> does not imply a bad IV estimator if the assumptions of instrument validity are met.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>IV Regression Is About Identification, Not In-Sample Fit</li>
</ol>
<ul>
<li>IV relies on relevance and exogeneity of instruments, not residual minimization.</li>
</ul>
<hr>
</div>
<div id="technical-details-on-r2" class="section level3" number="34.6.4">
<h3>
<span class="header-section-number">34.6.4</span> Technical Details on <span class="math inline">\(R^2\)</span><a class="anchor" aria-label="anchor" href="#technical-details-on-r2"><i class="fas fa-link"></i></a>
</h3>
<p>In OLS: <span class="math display">\[
\hat{\beta}^{OLS} = (X'X)^{-1} X'Y
\]</span> Minimizes: <span class="math display">\[
RSS = (Y - X \hat{\beta}^{OLS})'(Y - X \hat{\beta}^{OLS})
\]</span></p>
<p>In IV: <span class="math display">\[
\hat{\beta}^{IV} = (X'P_Z X)^{-1} X'P_Z Y
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(P_Z = Z (Z'Z)^{-1} Z'\)</span> is the projection matrix onto <span class="math inline">\(Z\)</span>.</p></li>
<li><p>The IV estimator solves: <span class="math display">\[
Z'(Y - X\hat{\beta}) = 0
\]</span></p></li>
<li><p>No guarantee that this minimizes RSS.</p></li>
</ul>
<p>Residuals:</p>
<p><span class="math display">\[
e^{IV} = Y - X \hat{\beta}^{IV}
\]</span></p>
<p>The norm of <span class="math inline">\(e^{IV}\)</span> is typically larger than in OLS because IV uses fewer effective degrees of freedom (constrained variation via <span class="math inline">\(Z\)</span>).</p>
<p>A Note on <span class="math inline">\(R^2\)</span> in 3SLS and GMM</p>
<ul>
<li>In 3SLS or GMM IV, <span class="math inline">\(R^2\)</span> can be similarly misleading.</li>
<li>These methods often operate under moment conditions or system estimation, not residual minimization.</li>
</ul>
<hr>
</div>
</div>
<div id="treatment-intensity" class="section level2" number="34.7">
<h2>
<span class="header-section-number">34.7</span> Treatment Intensity<a class="anchor" aria-label="anchor" href="#treatment-intensity"><i class="fas fa-link"></i></a>
</h2>
<p>Two-Stage Least Squares (TSLS) can be used to estimate the average causal effect of variable treatment intensity, and it “identifies a weighted average of per-unit treatment effects along the length of a causal response function” <span class="citation">(<a href="references.html#ref-angrist1995two">J. D. Angrist and Imbens 1995, 431</a>)</span>. For example</p>
<ul>
<li><p>Drug dosage</p></li>
<li><p>Hours of exam prep on score <span class="citation">(<a href="references.html#ref-powers1984effects">Powers and Swinton 1984</a>)</span></p></li>
<li><p>Cigarette smoking on birth weights <span class="citation">(<a href="references.html#ref-permutt1989simultaneous">Permutt and Hebel 1989</a>)</span></p></li>
<li><p>Years of education</p></li>
<li><p>Class size on test score <span class="citation">(<a href="references.html#ref-angrist1999using">J. D. Angrist and Lavy 1999</a>)</span></p></li>
<li><p>Sibship size on earning <span class="citation">(<a href="references.html#ref-lavy2006new">Lavy, Angrist, and Schlosser 2006</a>)</span></p></li>
<li><p>Social Media Adoption</p></li>
</ul>
<p>The <strong>average causal effect</strong> here refers to the conditional expectation of the difference in outcomes between the treated and what would have happened in the counterfactual world.</p>
<p>Notes:</p>
<ul>
<li>We do not need a linearity assumption of the relationships between the dependent variable, treatment intensities, and instruments.</li>
</ul>
<p>Example</p>
<p>In their original paper, <span class="citation">J. D. Angrist and Imbens (<a href="references.html#ref-angrist1995two">1995</a>)</span> take the example of schooling effect on earnings where they have quarters of birth as the instrumental variable.</p>
<p>For each additional year of schooling, there can be an increase in earnings, and each additional year can be heterogeneous (both in the sense that grade 9th to grade 10th is qualitatively different and one can change to a different school).</p>
<p><span class="math display">\[
Y = \gamma_0 + \gamma_1 X_1 + \rho S + \epsilon
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(S\)</span> is years of schooling (i.e., endogenous regressor)</p></li>
<li><p><span class="math inline">\(\rho\)</span> is the return to a year of schooling</p></li>
<li><p><span class="math inline">\(X_1\)</span> is a matrix of exogenous covariates</p></li>
</ul>
<p>Schooling can also be related to the exogenous variable <span class="math inline">\(X_1\)</span></p>
<p><span class="math display">\[
S = \delta_0 + X_1 \delta_1 + X_2 \delta_2 + \eta
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(X_2\)</span> is an exogenous instrument</p></li>
<li><p><span class="math inline">\(\delta_2\)</span> is the coefficient of the instrument</p></li>
</ul>
<p>by using only the fitted value in the second, the TSLS can give a consistent estimate of the effect of schooling on earning</p>
<p><span class="math display">\[
Y = \gamma_0 + X_1 \gamma-1 + \rho \hat{S} + \nu
\]</span></p>
<p>To give <span class="math inline">\(\rho\)</span> a causal interpretation,</p>
<ol style="list-style-type: decimal">
<li>We first have to have the SUTVA (stable unit treatment value assumption), where the potential outcomes of the same person with different years of schooling are independent.</li>
<li>When <span class="math inline">\(\rho\)</span> has a probability limit equal to a weighted average of <span class="math inline">\(E[Y_j - Y_{j-1}] \forall j\)</span>
</li>
</ol>
<p>Even though the first bullet point is not trivial, most of the time we don’t have to defend much about it in a research article, the second bullet point is the harder one to argue and only apply to certain cases.</p>
<!-- ## Application in Marketing -->
<!-- ### Peer-based IV -->
</div>
<div id="new-advances" class="section level2" number="34.8">
<h2>
<span class="header-section-number">34.8</span> New Advances<a class="anchor" aria-label="anchor" href="#new-advances"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Combine ML and IV <span class="citation">(<a href="references.html#ref-singh2020machine">Singh, Hosanagar, and Gandhi 2020</a>)</span>
</li>
</ul>
<hr>
</div>
<div id="special-considerations-for-zero-valued-outcomes" class="section level2" number="34.9">
<h2>
<span class="header-section-number">34.9</span> Special Considerations for Zero-Valued Outcomes<a class="anchor" aria-label="anchor" href="#special-considerations-for-zero-valued-outcomes"><i class="fas fa-link"></i></a>
</h2>
<p>For outcomes that take zero values, log transformations can introduce interpretation issues. Specifically, the coefficient on a log-transformed outcome does not directly represent a percentage change <span class="citation">(<a href="references.html#ref-chen2023logs">J. Chen and Roth 2023</a>)</span>. We have to distinguish the treatment effect on the intensive (outcome: 10 to 11) vs. extensive margins (outcome: 0 to 1), and we can’t readily interpret the treatment coefficient of log-transformed outcome regression as percentage change. In such cases, researchers use alternative methods:</p>
<div id="proportional-late-estimation" class="section level3" number="34.9.1">
<h3>
<span class="header-section-number">34.9.1</span> Proportional LATE Estimation<a class="anchor" aria-label="anchor" href="#proportional-late-estimation"><i class="fas fa-link"></i></a>
</h3>
<p>When dealing with zero-valued outcomes, direct log transformations can lead to interpretation issues. To obtain an interpretable percentage change in the outcome due to treatment among <em>compliers</em>, we estimate the <strong>proportional Local Average Treatment Effect (LATE)</strong>, denoted as <span class="math inline">\(\theta_{ATE\%}\)</span>.</p>
<p>Steps to Estimate Proportional LATE:</p>
<ol style="list-style-type: decimal">
<li>
<p><strong>Estimate LATE using 2SLS:</strong></p>
<p>We first estimate the treatment effect using a standard Two-Stage Least Squares regression: <span class="math display">\[ Y_i = \beta D_i + X_i + \epsilon_i, \]</span> where:</p>
<ul>
<li>
<span class="math inline">\(D_i\)</span> is the endogenous treatment variable.</li>
<li>
<span class="math inline">\(X_i\)</span> includes any exogenous controls.</li>
<li>
<span class="math inline">\(\beta\)</span> represents the LATE in <em>levels</em> for the mean of the control group’s compliers.</li>
</ul>
</li>
<li>
<p><strong>Estimate the control complier mean</strong> (<span class="math inline">\(\beta_{cc}\)</span>):</p>
<p>Using the same 2SLS setup, we estimate the control mean for compliers by transforming the outcome variable <span class="citation">(<a href="references.html#ref-abadie2002instrumental">Abadie, Angrist, and Imbens 2002</a>)</span>: <span class="math display">\[ Y_i^{CC} = -(D_i - 1) Y_i. \]</span> The estimated coefficient from this regression, <span class="math inline">\(\beta_{cc}\)</span>, captures the mean outcome for compliers in the control group.</p>
</li>
<li>
<p><strong>Compute the proportional LATE:</strong></p>
<p>The estimated proportional LATE is given by: <span class="math display">\[ \theta_{ATE\%} = \frac{\hat{\beta}}{\hat{\beta}_{cc}}, \]</span> which provides a direct <em>percentage change</em> interpretation for the outcome among compliers induced by the instrument.</p>
</li>
<li>
<p><strong>Obtain standard errors via non-parametric bootstrap:</strong></p>
<p>Since <span class="math inline">\(\theta_{ATE\%}\)</span> is a ratio of estimated coefficients, standard errors are best obtained using non-parametric bootstrap methods.</p>
</li>
<li>
<p><strong>Special case: Binary instrument</strong></p>
<p>If the instrument is binary, <span class="math inline">\(\theta_{ATE\%}\)</span> for the intensive margin of compliers can be directly estimated using <strong>Poisson IV regression</strong> (<code>ivpoisson</code> in Stata).</p>
</li>
</ol>
</div>
<div id="bounds-on-intensive-margin-effects" class="section level3" number="34.9.2">
<h3>
<span class="header-section-number">34.9.2</span> Bounds on Intensive-Margin Effects<a class="anchor" aria-label="anchor" href="#bounds-on-intensive-margin-effects"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">Lee (<a href="references.html#ref-lee2009training">2009</a>)</span> proposed a bounding approach for intensive-margin effects, assuming that compliers always have positive outcomes regardless of treatment (i.e., intensive-margin effect). These bounds help estimate treatment effects without relying on log transformations. However, this requires a monotonicity assumption for compliers where they should still have positive outcome regardless of treatment status.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></div>
<div class="next"><a href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-instrumental-variables"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="nav-link" href="#challenges-with-instrumental-variables"><span class="header-section-number">34.1</span> Challenges with Instrumental Variables</a></li>
<li>
<a class="nav-link" href="#framework-for-instrumental-variables"><span class="header-section-number">34.2</span> Framework for Instrumental Variables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#constant-treatment-effect-model"><span class="header-section-number">34.2.1</span> Constant-Treatment-Effect Model</a></li>
<li><a class="nav-link" href="#instrumental-variable-solution"><span class="header-section-number">34.2.2</span> Instrumental Variable Solution</a></li>
<li><a class="nav-link" href="#heterogeneous-treatment-effects-and-the-late-framework"><span class="header-section-number">34.2.3</span> Heterogeneous Treatment Effects and the LATE Framework</a></li>
<li><a class="nav-link" href="#assumptions-for-late-identification"><span class="header-section-number">34.2.4</span> Assumptions for LATE Identification</a></li>
<li><a class="nav-link" href="#local-average-treatment-effect-theorem"><span class="header-section-number">34.2.5</span> Local Average Treatment Effect Theorem</a></li>
<li><a class="nav-link" href="#iv-in-randomized-trials-noncompliance"><span class="header-section-number">34.2.6</span> IV in Randomized Trials (Noncompliance)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-estimation"><span class="header-section-number">34.3</span> Estimation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-two-stage-least-squares-estimation"><span class="header-section-number">34.3.1</span> Two-Stage Least Squares Estimation</a></li>
<li><a class="nav-link" href="#iv-gmm"><span class="header-section-number">34.3.2</span> IV-GMM</a></li>
<li><a class="nav-link" href="#limited-information-maximum-likelihood"><span class="header-section-number">34.3.3</span> Limited Information Maximum Likelihood</a></li>
<li><a class="nav-link" href="#jackknife-iv"><span class="header-section-number">34.3.4</span> Jackknife IV</a></li>
<li><a class="nav-link" href="#control-function-approach"><span class="header-section-number">34.3.5</span> Control Function Approach</a></li>
<li><a class="nav-link" href="#fuller-and-bias-reduced-iv"><span class="header-section-number">34.3.6</span> Fuller and Bias-Reduced IV</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-inference-iv"><span class="header-section-number">34.4</span> Inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#weak-instruments-problem"><span class="header-section-number">34.4.1</span> Weak Instruments Problem</a></li>
<li><a class="nav-link" href="#solutions-and-approaches-for-valid-inference"><span class="header-section-number">34.4.2</span> Solutions and Approaches for Valid Inference</a></li>
<li><a class="nav-link" href="#sec-anderson-rubin-approach"><span class="header-section-number">34.4.3</span> Anderson-Rubin Approach</a></li>
<li><a class="nav-link" href="#sec-tf-procedure"><span class="header-section-number">34.4.4</span> tF Procedure</a></li>
<li><a class="nav-link" href="#sec-ak-approach"><span class="header-section-number">34.4.5</span> AK Approach</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#testing-assumptions"><span class="header-section-number">34.5</span> Testing Assumptions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#relevance-assumption"><span class="header-section-number">34.5.1</span> Relevance Assumption</a></li>
<li><a class="nav-link" href="#exogeneity-assumption"><span class="header-section-number">34.5.2</span> Exogeneity Assumption</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#negative-r2-in-iv-regression"><span class="header-section-number">34.6</span> Negative \(R^2\) in IV Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#why-does-r2-lose-its-meaning-in-iv-regression"><span class="header-section-number">34.6.1</span> Why Does \(R^2\) Lose Its Meaning in IV Regression?</a></li>
<li><a class="nav-link" href="#why-r2-can-be-negative"><span class="header-section-number">34.6.2</span> Why \(R^2\) Can Be Negative:</a></li>
<li><a class="nav-link" href="#why-we-dont-care-about-r2-in-iv"><span class="header-section-number">34.6.3</span> Why We Don’t Care About \(R^2\) in IV</a></li>
<li><a class="nav-link" href="#technical-details-on-r2"><span class="header-section-number">34.6.4</span> Technical Details on \(R^2\)</a></li>
</ul>
</li>
<li><a class="nav-link" href="#treatment-intensity"><span class="header-section-number">34.7</span> Treatment Intensity</a></li>
<li><a class="nav-link" href="#new-advances"><span class="header-section-number">34.8</span> New Advances</a></li>
<li>
<a class="nav-link" href="#special-considerations-for-zero-valued-outcomes"><span class="header-section-number">34.9</span> Special Considerations for Zero-Valued Outcomes</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#proportional-late-estimation"><span class="header-section-number">34.9.1</span> Proportional LATE Estimation</a></li>
<li><a class="nav-link" href="#bounds-on-intensive-margin-effects"><span class="header-section-number">34.9.2</span> Bounds on Intensive-Margin Effects</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/34-instrumental_var.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/34-instrumental_var.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-03-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
