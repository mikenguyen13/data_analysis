<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 25 Multivariate Methods | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="In the previous section on ANOVA, we examined how to compare means across multiple groups. However, ANOVA primarily deals with a single response variable. In many business and financial...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapter 25 Multivariate Methods | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/sec-multivariate-methods.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="In the previous section on ANOVA, we examined how to compare means across multiple groups. However, ANOVA primarily deals with a single response variable. In many business and financial...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 25 Multivariate Methods | A Guide on Data Analysis">
<meta name="twitter:description" content="In the previous section on ANOVA, we examined how to compare means across multiple groups. However, ANOVA primarily deals with a single response variable. In many business and financial...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li><a class="" href="sec-nonparametric-regression.html"><span class="header-section-number">10</span> Nonparametric Regression</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="data.html"><span class="header-section-number">11</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">12</span> Variable Transformation</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">13</span> Imputation (Missing Data)</a></li>
<li><a class="" href="model-specification-tests.html"><span class="header-section-number">14</span> Model Specification Tests</a></li>
<li><a class="" href="variable-selection.html"><span class="header-section-number">15</span> Variable Selection</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">16</span> Hypothesis Testing</a></li>
<li><a class="" href="sec-marginal-effects.html"><span class="header-section-number">17</span> Marginal Effects</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">18</span> Moderation</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">19</span> Mediation</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">20</span> Prediction and Estimation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="sec-causal-inference.html"><span class="header-section-number">21</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-experimental-design.html"><span class="header-section-number">22</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">23</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></li>
<li><a class="active" href="sec-multivariate-methods.html"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></li>
<li><a class="" href="sec-regression-discontinuity.html"><span class="header-section-number">27</span> Regression Discontinuity</a></li>
<li><a class="" href="temporal-discontinuity-designs.html"><span class="header-section-number">28</span> Temporal Discontinuity Designs</a></li>
<li><a class="" href="sec-synthetic-difference-in-differences.html"><span class="header-section-number">29</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="sec-difference-in-differences.html"><span class="header-section-number">30</span> Difference-in-Differences</a></li>
<li><a class="" href="sec-changes-in-changes.html"><span class="header-section-number">31</span> Changes-in-Changes</a></li>
<li><a class="" href="sec-synthetic-control.html"><span class="header-section-number">32</span> Synthetic Control</a></li>
<li><a class="" href="sec-event-studies.html"><span class="header-section-number">33</span> Event Studies</a></li>
<li><a class="" href="sec-instrumental-variables.html"><span class="header-section-number">34</span> Instrumental Variables</a></li>
<li><a class="" href="sec-matching-methods.html"><span class="header-section-number">35</span> Matching Methods</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="sec-endogeneity.html"><span class="header-section-number">36</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">37</span> Other Biases</a></li>
<li><a class="" href="sec-directed-acyclic-graphs.html"><span class="header-section-number">38</span> Directed Acyclic Graphs</a></li>
<li><a class="" href="sec-controls.html"><span class="header-section-number">39</span> Controls</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">40</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">41</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">42</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">43</span> Replication and Synthetic Data</a></li>
<li><a class="" href="high-performance-computing.html"><span class="header-section-number">44</span> High-Performance Computing</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="chapter-cluster-randomization-and-interference-bias.html"><span class="header-section-number">C</span> Chapter: Cluster Randomization and Interference Bias</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="sec-multivariate-methods" class="section level1" number="25">
<h1>
<span class="header-section-number">25</span> Multivariate Methods<a class="anchor" aria-label="anchor" href="#sec-multivariate-methods"><i class="fas fa-link"></i></a>
</h1>
<p>In the previous section on <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a>, we examined how to compare means across multiple groups. However, <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a> primarily deals with a <strong>single response variable</strong>. In many business and financial applications, we often need to analyze multiple interrelated variables simultaneously. For instance:</p>
<ul>
<li>In <strong>marketing</strong>, customer purchase behavior, brand perception, and loyalty scores are often studied together.</li>
<li>In <strong>finance</strong>, portfolio risk assessment involves analyzing correlations between different asset returns.</li>
</ul>
<p>To handle such cases, we use <a href="sec-multivariate-methods.html#sec-multivariate-methods">multivariate methods</a>, which extend classical statistical techniques to multiple dependent variables. At the core of multivariate analysis lies the <a href="sec-multivariate-methods.html#sec-covariance-matrix-multivariate">covariance matrix</a>, which captures relationships between multiple random variables.</p>
<div id="basic-understanding" class="section level2" number="25.1">
<h2>
<span class="header-section-number">25.1</span> Basic Understanding<a class="anchor" aria-label="anchor" href="#basic-understanding"><i class="fas fa-link"></i></a>
</h2>
<div id="multivariate-random-vectors" class="section level3" number="25.1.1">
<h3>
<span class="header-section-number">25.1.1</span> Multivariate Random Vectors<a class="anchor" aria-label="anchor" href="#multivariate-random-vectors"><i class="fas fa-link"></i></a>
</h3>
<p>Let <span class="math inline">\(y_1, \dots, y_p\)</span> be random variables, possibly correlated, with means <span class="math inline">\(\mu_1, \dots, \mu_p\)</span>. We define the random vector:</p>
<p><span class="math display">\[
\mathbf{y} =
\begin{bmatrix}
y_1 \\
\vdots \\
y_p
\end{bmatrix}
\]</span></p>
<p>The expected value (mean vector) is:</p>
<p><span class="math display">\[
E(\mathbf{y}) =
\begin{bmatrix}
\mu_1 \\
\vdots \\
\mu_p
\end{bmatrix}
\]</span></p>
</div>
<div id="sec-covariance-matrix-multivariate" class="section level3" number="25.1.2">
<h3>
<span class="header-section-number">25.1.2</span> Covariance Matrix<a class="anchor" aria-label="anchor" href="#sec-covariance-matrix-multivariate"><i class="fas fa-link"></i></a>
</h3>
<p>The covariance between any two variables <span class="math inline">\(y_i\)</span> and <span class="math inline">\(y_j\)</span> is:</p>
<p><span class="math display">\[
\sigma_{ij} = \text{cov}(y_i, y_j) = E[(y_i - \mu_i)(y_j - \mu_j)]
\]</span></p>
<p>This leads to the <strong>variance-covariance matrix</strong>, also called the <strong>dispersion matrix</strong>:</p>
<p><span class="math display">\[
\mathbf{\Sigma} = (\sigma_{ij}) =
\begin{bmatrix}
\sigma_{11} &amp; \sigma_{12} &amp; \dots &amp; \sigma_{1p} \\
\sigma_{21} &amp; \sigma_{22} &amp; \dots &amp; \sigma_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\sigma_{p1} &amp; \sigma_{p2} &amp; \dots &amp; \sigma_{pp}
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(\sigma_{ii} = \text{Var}(y_i)\)</span> represents the variance of <span class="math inline">\(y_i\)</span>. Since covariance is symmetric, we have:</p>
<p><span class="math display">\[
\sigma_{ij} = \sigma_{ji}, \quad \forall i, j.
\]</span></p>
<p>If we consider two random vectors <span class="math inline">\(\mathbf{u}_{p \times 1}\)</span> and <span class="math inline">\(\mathbf{v}_{q \times 1}\)</span> with means <span class="math inline">\(\mu_u\)</span> and <span class="math inline">\(\mu_v\)</span>, their <strong>cross-covariance matrix</strong> is:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{uv} = \text{cov}(\mathbf{u}, \mathbf{v}) = E[(\mathbf{u} - \mu_u)(\mathbf{v} - \mu_v)']
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\Sigma}_{uv} \neq \mathbf{\Sigma}_{vu}\)</span>, but they satisfy:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{uv} = \mathbf{\Sigma}_{vu}'.
\]</span></p>
<div id="properties-of-covariance-matrices" class="section level4" number="25.1.2.1">
<h4>
<span class="header-section-number">25.1.2.1</span> Properties of Covariance Matrices<a class="anchor" aria-label="anchor" href="#properties-of-covariance-matrices"><i class="fas fa-link"></i></a>
</h4>
<p>A valid covariance matrix <span class="math inline">\(\mathbf{\Sigma}\)</span> satisfies the following properties:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Symmetry</strong>:<br><span class="math display">\[\mathbf{\Sigma}' = \mathbf{\Sigma}.\]</span></p></li>
<li><p><strong>Non-negative definiteness</strong>:<br><span class="math display">\[\mathbf{a}'\mathbf{\Sigma} \mathbf{a} \geq 0, \quad \forall \mathbf{a} \in \mathbb{R}^p,\]</span> which implies that the <strong>eigenvalues</strong> <span class="math inline">\(\lambda_1, \dots, \lambda_p\)</span> satisfy: <span class="math display">\[\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_p \geq 0.\]</span></p></li>
<li><p><strong>Generalized variance</strong> (determinant of <span class="math inline">\(\mathbf{\Sigma}\)</span>):<br><span class="math display">\[|\mathbf{\Sigma}| = \lambda_1 \lambda_2 \dots \lambda_p \geq 0.\]</span></p></li>
<li><p><strong>Total variance</strong> (trace of <span class="math inline">\(\mathbf{\Sigma}\)</span>):<br><span class="math display">\[\text{tr}(\mathbf{\Sigma}) = \sum_{i=1}^{p} \lambda_i = \sum_{i=1}^{p} \sigma_{ii}.\]</span></p></li>
<li>
<p><strong>Positive definiteness</strong> (a common assumption in multivariate analysis):</p>
<ul>
<li>All eigenvalues of <span class="math inline">\(\mathbf{\Sigma}\)</span> are strictly positive.</li>
<li>
<span class="math inline">\(\mathbf{\Sigma}\)</span> has an inverse <span class="math inline">\(\mathbf{\Sigma}^{-1}\)</span>, satisfying: <span class="math display">\[\mathbf{\Sigma}^{-1} \mathbf{\Sigma} = \mathbf{I}_{p \times p} = \mathbf{\Sigma} \mathbf{\Sigma}^{-1}.\]</span>
</li>
</ul>
</li>
</ol>
</div>
<div id="correlation-matrices-1" class="section level4" number="25.1.2.2">
<h4>
<span class="header-section-number">25.1.2.2</span> Correlation Matrices<a class="anchor" aria-label="anchor" href="#correlation-matrices-1"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>correlation matrix</strong> provides a standardized measure of linear relationships between variables. The correlation between two variables <span class="math inline">\(y_i\)</span> and <span class="math inline">\(y_j\)</span> is defined as:</p>
<p><span class="math display">\[
\rho_{ij} = \frac{\sigma_{ij}}{\sqrt{\sigma_{ii} \sigma_{jj}}}
\]</span></p>
<p>where <span class="math inline">\(\sigma_{ij}\)</span> is the covariance and <span class="math inline">\(\sigma_{ii}\)</span> and <span class="math inline">\(\sigma_{jj}\)</span> are variances.</p>
<p>Thus, the <strong>correlation matrix</strong> <span class="math inline">\(\mathbf{R}\)</span> is:</p>
<p><span class="math display">\[
\mathbf{R} =
\begin{bmatrix}
\rho_{11} &amp; \rho_{12} &amp; \dots &amp; \rho_{1p} \\
\rho_{21} &amp; \rho_{22} &amp; \dots &amp; \rho_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\rho_{p1} &amp; \rho_{p2} &amp; \dots &amp; \rho_{pp}
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(\rho_{ii} = 1\)</span> for all <span class="math inline">\(i\)</span>.</p>
<p>Alternatively, the correlation matrix can be expressed as:</p>
<p><span class="math display">\[
\mathbf{R} = [\text{diag}(\mathbf{\Sigma})]^{-1/2} \mathbf{\Sigma} [\text{diag}(\mathbf{\Sigma})]^{-1/2}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\text{diag}(\mathbf{\Sigma})\)</span> is a diagonal matrix with elements <span class="math inline">\(\sigma_{ii}\)</span> on the diagonal and zeros elsewhere.</li>
<li>
<span class="math inline">\(\mathbf{A}^{1/2}\)</span> (the square root of a symmetric matrix) is a symmetric matrix satisfying <span class="math inline">\(\mathbf{A} = \mathbf{A}^{1/2} \mathbf{A}^{1/2}\)</span>.</li>
</ul>
<hr>
</div>
</div>
<div id="equalities-in-expectation-and-variance" class="section level3" number="25.1.3">
<h3>
<span class="header-section-number">25.1.3</span> Equalities in Expectation and Variance<a class="anchor" aria-label="anchor" href="#equalities-in-expectation-and-variance"><i class="fas fa-link"></i></a>
</h3>
<p>Let:</p>
<ul>
<li>
<span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> be random vectors with means <span class="math inline">\(\mu_x\)</span> and <span class="math inline">\(\mu_y\)</span> and covariance matrices <span class="math inline">\(\mathbf{\Sigma}_x\)</span> and <span class="math inline">\(\mathbf{\Sigma}_y\)</span>.</li>
<li>
<span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> be matrices of constants, and <span class="math inline">\(\mathbf{c}\)</span> and <span class="math inline">\(\mathbf{d}\)</span> be vectors of constants.</li>
</ul>
<p>Then the following properties hold:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Expectation transformations</strong>: <span class="math display">\[
E(\mathbf{Ay + c}) = \mathbf{A} \mu_y + \mathbf{c}
\]</span></p></li>
<li><p><strong>Variance transformations</strong>: <span class="math display">\[
\text{Var}(\mathbf{Ay + c}) = \mathbf{A} \text{Var}(\mathbf{y}) \mathbf{A}' = \mathbf{A \Sigma_y A'}
\]</span></p></li>
<li><p><strong>Covariance of linear transformations</strong>: <span class="math display">\[
\text{Cov}(\mathbf{Ay + c}, \mathbf{By + d}) = \mathbf{A \Sigma_y B'}
\]</span></p></li>
<li><p><strong>Expectation of combined variables</strong>: <span class="math display">\[
E(\mathbf{Ay + Bx + c}) = \mathbf{A} \mu_y + \mathbf{B} \mu_x + \mathbf{c}
\]</span></p></li>
<li><p><strong>Variance of combined variables</strong>: <span class="math display">\[
\text{Var}(\mathbf{Ay + Bx + c}) =
\mathbf{A \Sigma_y A' + B \Sigma_x B' + A \Sigma_{yx} B' + B\Sigma'_{yx}A'}
\]</span></p></li>
</ol>
<hr>
</div>
<div id="multivariate-normal-distribution-1" class="section level3" number="25.1.4">
<h3>
<span class="header-section-number">25.1.4</span> Multivariate Normal Distribution<a class="anchor" aria-label="anchor" href="#multivariate-normal-distribution-1"><i class="fas fa-link"></i></a>
</h3>
<p>The <strong>multivariate normal distribution (MVN)</strong> is fundamental in multivariate analysis. Let <span class="math inline">\(\mathbf{y}\)</span> be a multivariate normal random variable with mean <span class="math inline">\(\mu\)</span> and covariance matrix <span class="math inline">\(\mathbf{\Sigma}\)</span>. Then its <strong>probability density function (PDF)</strong> is:</p>
<p><span class="math display">\[
f(\mathbf{y}) = \frac{1}{(2\pi)^{p/2} |\mathbf{\Sigma}|^{1/2}}
\exp \left(-\frac{1}{2} (\mathbf{y} - \mu)' \mathbf{\Sigma}^{-1} (\mathbf{y} - \mu) \right).
\]</span></p>
<p>We denote this distribution as:</p>
<p><span class="math display">\[
\mathbf{y} \sim N_p(\mu, \mathbf{\Sigma}).
\]</span></p>
<hr>
<div id="properties-of-the-multivariate-normal-distribution" class="section level4" number="25.1.4.1">
<h4>
<span class="header-section-number">25.1.4.1</span> Properties of the Multivariate Normal Distribution<a class="anchor" aria-label="anchor" href="#properties-of-the-multivariate-normal-distribution"><i class="fas fa-link"></i></a>
</h4>
<p>The multivariate normal distribution has several important properties that are fundamental to multivariate statistical methods.</p>
<ul>
<li>
<p><strong>Linear Transformations</strong>:<br>
Let <span class="math inline">\(\mathbf{A}_{r \times p}\)</span> be a fixed matrix. Then:</p>
<p><span class="math display">\[
\mathbf{Ay} \sim N_r (\mathbf{A \mu}, \mathbf{A \Sigma A'})
\]</span></p>
<p>where <span class="math inline">\(r \leq p\)</span>. Additionally, for <span class="math inline">\(\mathbf{A \Sigma A'}\)</span> to be <strong>non-singular</strong>, the rows of <span class="math inline">\(\mathbf{A}\)</span> must be <strong>linearly independent</strong>.</p>
</li>
<li>
<p><strong>Standardization using Precision Matrix</strong>:<br>
Let <span class="math inline">\(\mathbf{G}\)</span> be a matrix such that:</p>
<p><span class="math display">\[
\mathbf{\Sigma}^{-1} = \mathbf{GG}'
\]</span></p>
<p>Then:</p>
<p><span class="math display">\[
\mathbf{G'y} \sim N_p(\mathbf{G' \mu}, \mathbf{I})
\]</span></p>
<p>and:</p>
<p><span class="math display">\[
\mathbf{G'(y-\mu)} \sim N_p (0,\mathbf{I}).
\]</span></p>
<p>This transformation <strong>whitens</strong> the data, converting it into an identity covariance structure.</p>
</li>
<li>
<p><strong>Linear Combinations</strong>:<br>
Any fixed linear combination of <span class="math inline">\(y_1, \dots, y_p\)</span>, say <span class="math inline">\(\mathbf{c'y}\)</span>, follows:</p>
<p><span class="math display">\[
\mathbf{c'y} \sim N_1 (\mathbf{c' \mu}, \mathbf{c' \Sigma c}).
\]</span></p>
</li>
</ul>
<hr>
</div>
<div id="partitioning-the-mvn-distribution" class="section level4" number="25.1.4.2">
<h4>
<span class="header-section-number">25.1.4.2</span> Partitioning the MVN Distribution<a class="anchor" aria-label="anchor" href="#partitioning-the-mvn-distribution"><i class="fas fa-link"></i></a>
</h4>
<p>Consider a partitioned random vector:</p>
<p><span class="math display">\[
\mathbf{y} =
\begin{bmatrix}
\mathbf{y}_1 \\
\mathbf{y}_2
\end{bmatrix}
\sim
N_p
\left(
\begin{bmatrix}
\mu_1 \\
\mu_2
\end{bmatrix},
\begin{bmatrix}
\mathbf{\Sigma}_{11} &amp; \mathbf{\Sigma}_{12} \\
\mathbf{\Sigma}_{21} &amp; \mathbf{\Sigma}_{22}
\end{bmatrix}
\right).
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\mathbf{y}_1\)</span> is <span class="math inline">\(p_1 \times 1\)</span>,</li>
<li>
<span class="math inline">\(\mathbf{y}_2\)</span> is <span class="math inline">\(p_2 \times 1\)</span>,</li>
<li>
<span class="math inline">\(p_1 + p_2 = p\)</span>,</li>
<li>and <span class="math inline">\(p_1, p_2 \geq 1\)</span>.</li>
</ul>
<p>The marginal distributions of <span class="math inline">\(\mathbf{y}_1\)</span> and <span class="math inline">\(\mathbf{y}_2\)</span> are:</p>
<p><span class="math display">\[
\mathbf{y}_1 \sim N_{p_1}(\mathbf{\mu_1}, \mathbf{\Sigma_{11}})
\quad \text{and} \quad
\mathbf{y}_2 \sim N_{p_2}(\mathbf{\mu_2}, \mathbf{\Sigma_{22}}).
\]</span></p>
<p>Each component <span class="math inline">\(y_i\)</span> follows:</p>
<p><span class="math display">\[
y_i \sim N_1(\mu_i, \sigma_{ii}).
\]</span></p>
<p>The <strong>conditional distribution</strong> of <span class="math inline">\(\mathbf{y}_1\)</span> given <span class="math inline">\(\mathbf{y}_2\)</span> is also normal:</p>
<p><span class="math display">\[
\mathbf{y}_1 | \mathbf{y}_2 \sim N_{p_1} \Big(
\mathbf{\mu_1 + \Sigma_{12} \Sigma_{22}^{-1}(y_2 - \mu_2)},
\mathbf{\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}
\Big).
\]</span></p>
<p>This equation shows that <strong>knowing</strong> <span class="math inline">\(\mathbf{y}_2\)</span> adjusts the mean of <span class="math inline">\(\mathbf{y}_1\)</span>, and the variance is reduced.<br>
Similarly, the conditional distribution of <span class="math inline">\(\mathbf{y}_2\)</span> given <span class="math inline">\(\mathbf{y}_1\)</span> follows the same structure.</p>
<ul>
<li>
<p><span class="math inline">\(\mathbf{y}_1\)</span> and <span class="math inline">\(\mathbf{y}_2\)</span> are <strong>independent</strong> if and only if:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{12} = 0.
\]</span></p>
</li>
</ul>
<p>If <span class="math inline">\(\mathbf{y} \sim N(\mathbf{\mu}, \mathbf{\Sigma})\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> is <strong>positive definite</strong>, then:</p>
<p><span class="math display">\[
(\mathbf{y} - \mu)' \mathbf{\Sigma}^{-1} (\mathbf{y} - \mu) \sim \chi^2_p.
\]</span></p>
<p>This property is essential in <strong>hypothesis testing</strong> and <strong>Mahalanobis distance calculations</strong>.</p>
<hr>
</div>
<div id="summation-of-independent-mvn-variables" class="section level4" number="25.1.4.3">
<h4>
<span class="header-section-number">25.1.4.3</span> Summation of Independent MVN Variables<a class="anchor" aria-label="anchor" href="#summation-of-independent-mvn-variables"><i class="fas fa-link"></i></a>
</h4>
<p>If <span class="math inline">\(\mathbf{y}_i\)</span> are independent random vectors following:</p>
<p><span class="math display">\[
\mathbf{y}_i \sim N_p (\mathbf{\mu}_i , \mathbf{\Sigma}_i),
\]</span></p>
<p>then for fixed matrices <span class="math inline">\(\mathbf{A}_{i(m \times p)}\)</span>, the sum:</p>
<p><span class="math display">\[
\sum_{i=1}^k \mathbf{A}_i \mathbf{y}_i
\]</span></p>
<p>follows:</p>
<p><span class="math display">\[
\sum_{i=1}^k \mathbf{A}_i \mathbf{y}_i \sim N_m \Big(
\sum_{i=1}^{k} \mathbf{A}_i \mathbf{\mu}_i, \sum_{i=1}^k \mathbf{A}_i \mathbf{\Sigma}_i \mathbf{A}_i'
\Big).
\]</span></p>
<p>This property underpins <strong>multivariate regression</strong> and <strong>linear discriminant analysis</strong>.</p>
<hr>
</div>
<div id="multiple-regression" class="section level4" number="25.1.4.4">
<h4>
<span class="header-section-number">25.1.4.4</span> Multiple Regression<a class="anchor" aria-label="anchor" href="#multiple-regression"><i class="fas fa-link"></i></a>
</h4>
<p>In multivariate analysis, multiple regression extends simple regression to cases where multiple predictor variables influence a response variable. Suppose:</p>
<p><span class="math display">\[
\left(
\begin{array}
{c}
Y \\
\mathbf{x}
\end{array}
\right)
\sim
N_{p+1}
\left(
\left[
\begin{array}
{c}
\mu_y \\
\mathbf{\mu}_x
\end{array}
\right]
,
\left[
\begin{array}
{cc}
\sigma^2_Y &amp; \mathbf{\Sigma}_{yx} \\
\mathbf{\Sigma}_{yx} &amp; \mathbf{\Sigma}_{xx}
\end{array}
\right]
\right)
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(Y\)</span> is a scalar response variable.</li>
<li>
<span class="math inline">\(\mathbf{x}\)</span> is a <span class="math inline">\(p \times 1\)</span> vector of predictors.</li>
<li>
<span class="math inline">\(\mu_y\)</span> and <span class="math inline">\(\mathbf{\mu}_x\)</span> are the respective means.</li>
<li>
<span class="math inline">\(\sigma_Y^2\)</span> is the variance of <span class="math inline">\(Y\)</span>.</li>
<li>
<span class="math inline">\(\mathbf{\Sigma}_{xx}\)</span> is the covariance matrix of <span class="math inline">\(\mathbf{x}\)</span>.</li>
<li>
<span class="math inline">\(\mathbf{\Sigma}_{yx}\)</span> is the covariance vector between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\mathbf{x}\)</span>.</li>
</ul>
<p>From the properties of the <strong>multivariate normal distribution</strong>, the conditional expectation of <span class="math inline">\(Y\)</span> given <span class="math inline">\(\mathbf{x}\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
E(Y| \mathbf{x}) &amp;= \mu_y + \mathbf{\Sigma}_{yx} \mathbf{\Sigma}_{xx}^{-1} (\mathbf{x}- \mathbf{\mu}_x) \\
&amp;= \mu_y - \mathbf{\Sigma}_{yx} \mathbf{\Sigma}_{xx}^{-1} \mathbf{\mu}_x + \mathbf{\Sigma}_{yx} \mathbf{\Sigma}_{xx}^{-1} \mathbf{x} \\
&amp;= \beta_0 + \mathbf{\beta' x},
\end{aligned}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\beta_0 = \mu_y - \mathbf{\Sigma}_{yx} \mathbf{\Sigma}_{xx}^{-1} \mathbf{\mu}_x\)</span> (intercept).</li>
<li>
<span class="math inline">\(\mathbf{\beta} = (\beta_1, \dots, \beta_p)' = \mathbf{\Sigma}_{xx}^{-1} \mathbf{\Sigma}_{yx}'\)</span> (regression coefficients).</li>
</ul>
<p>This resembles the least squares estimator:</p>
<p><span class="math display">\[
\mathbf{\beta} = (\mathbf{x'x})^{-1} \mathbf{x'y},
\]</span></p>
<p>but differs when considering the theoretical covariance relationships rather than empirical estimates.</p>
<p>The <strong>conditional variance</strong> of <span class="math inline">\(Y\)</span> given <span class="math inline">\(\mathbf{x}\)</span> is:</p>
<p><span class="math display">\[
\text{Var}(Y | \mathbf{x}) = \sigma^2_Y - \mathbf{\Sigma}_{yx} \mathbf{\Sigma}_{xx}^{-1} \mathbf{\Sigma'}_{yx}.
\]</span></p>
<p>This shows that knowing <span class="math inline">\(\mathbf{x}\)</span> <strong>reduces uncertainty</strong> in predicting <span class="math inline">\(Y\)</span>.</p>
<hr>
</div>
<div id="samples-from-multivariate-normal-populations" class="section level4" number="25.1.4.5">
<h4>
<span class="header-section-number">25.1.4.5</span> Samples from Multivariate Normal Populations<a class="anchor" aria-label="anchor" href="#samples-from-multivariate-normal-populations"><i class="fas fa-link"></i></a>
</h4>
<p>Suppose we have a random sample of size <span class="math inline">\(n\)</span>, denoted as:</p>
<p><span class="math display">\[
\mathbf{y}_1, \dots, \mathbf{y}_n \sim N_p (\mathbf{\mu}, \mathbf{\Sigma}).
\]</span></p>
<p>Then:</p>
<ol style="list-style-type: decimal">
<li>
<p><strong>Sample Mean</strong>: The sample mean is given by:</p>
<p><span class="math display">\[
\bar{\mathbf{y}} = \frac{1}{n} \sum_{i=1}^n \mathbf{y}_i.
\]</span></p>
<p>Since <span class="math inline">\(\mathbf{y}_i\)</span> are independent and identically distributed (iid), it follows that:</p>
<p><span class="math display">\[
\bar{\mathbf{y}} \sim N_p (\mathbf{\mu}, \mathbf{\Sigma} / n).
\]</span></p>
<p>This implies that <span class="math inline">\(\bar{\mathbf{y}}\)</span> is an unbiased estimator of <span class="math inline">\(\mathbf{\mu}\)</span>.</p>
</li>
<li>
<p><strong>Sample Covariance Matrix</strong>: The <span class="math inline">\(p \times p\)</span> sample variance-covariance matrix is:</p>
<p><span class="math display">\[
\mathbf{S} = \frac{1}{n-1} \sum_{i=1}^n (\mathbf{y}_i - \bar{\mathbf{y}})(\mathbf{y}_i - \bar{\mathbf{y}})'.
\]</span></p>
<p>Expanding this:</p>
<p><span class="math display">\[
\mathbf{S} = \frac{1}{n-1} \left( \sum_{i=1}^n \mathbf{y}_i \mathbf{y}_i' - n \bar{\mathbf{y}} \bar{\mathbf{y}}' \right).
\]</span></p>
<ul>
<li>
<span class="math inline">\(\mathbf{S}\)</span> is symmetric.</li>
<li>
<span class="math inline">\(\mathbf{S}\)</span> is an unbiased estimator of <span class="math inline">\(\mathbf{\Sigma}\)</span>.</li>
<li>
<span class="math inline">\(\mathbf{S}\)</span> contains <span class="math inline">\(p(p+1)/2\)</span> unique random variables.</li>
</ul>
</li>
<li>
<p><strong>Wishart Distribution</strong>: The scaled sample covariance matrix follows a Wishart distribution:</p>
<p><span class="math display">\[
(n-1) \mathbf{S} \sim W_p(n-1, \mathbf{\Sigma}).
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(W_p(n-1, \mathbf{\Sigma})\)</span> is a Wishart distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</li>
<li>
<span class="math inline">\(E[(n-1) \mathbf{S}] = (n-1) \mathbf{\Sigma}\)</span>.</li>
</ul>
<p>The Wishart distribution is a multivariate generalization of the chi-square distribution.</p>
</li>
<li>
<p><strong>Independence of</strong> <span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{S}\)</span>: The sample mean <span class="math inline">\(\bar{\mathbf{y}}\)</span> and sample covariance matrix <span class="math inline">\(\mathbf{S}\)</span> are independent:</p>
<p><span class="math display">\[
\bar{\mathbf{y}} \perp \mathbf{S}.
\]</span></p>
<p>This result is crucial for inference in multivariate hypothesis testing.</p>
</li>
<li><p><strong>Sufficiency of</strong> <span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{S}\)</span>: The pair <span class="math inline">\((\bar{\mathbf{y}}, \mathbf{S})\)</span> are sufficient statistics for <span class="math inline">\((\mathbf{\mu}, \mathbf{\Sigma})\)</span>.<br>
That is, all the information about <span class="math inline">\(\mathbf{\mu}\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> in the sample is contained in <span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{S}\)</span>, regardless of sample size.</p></li>
</ol>
<hr>
</div>
<div id="large-sample-properties-1" class="section level4" number="25.1.4.6">
<h4>
<span class="header-section-number">25.1.4.6</span> Large Sample Properties<a class="anchor" aria-label="anchor" href="#large-sample-properties-1"><i class="fas fa-link"></i></a>
</h4>
<p>Consider a random sample <span class="math inline">\(\mathbf{y}_1, \dots, \mathbf{y}_n\)</span> drawn from a population with mean <span class="math inline">\(\mathbf{\mu}\)</span> and variance-covariance matrix <span class="math inline">\(\mathbf{\Sigma}\)</span>.</p>
<p><strong>Key Properties</strong></p>
<ul>
<li>
<p><strong>Consistency of Estimators</strong>:</p>
<ul>
<li>The sample mean <span class="math inline">\(\bar{\mathbf{y}}\)</span> is a consistent estimator of <span class="math inline">\(\mathbf{\mu}\)</span>.</li>
<li>The sample covariance matrix <span class="math inline">\(\mathbf{S}\)</span> is a consistent estimator of <span class="math inline">\(\mathbf{\Sigma}\)</span>.</li>
</ul>
</li>
<li>
<p>Multivariate <a href="prerequisites.html#central-limit-theorem">Central Limit Theorem</a>:</p>
<ul>
<li>
<p>Similar to the univariate case, the sample mean follows approximately:</p>
<p><span class="math display">\[
\sqrt{n}(\bar{\mathbf{y}} - \mu) \dot{\sim} N_p (\mathbf{0}, \mathbf{\Sigma})
\]</span></p>
<p>This approximation holds when the sample size is large relative to the number of variables (<span class="math inline">\(n \geq 25p\)</span>).</p>
</li>
<li>
<p>Equivalently, the sample mean follows:</p>
<p><span class="math display">\[
\bar{\mathbf{y}} \dot{\sim} N_p (\mathbf{\mu}, \mathbf{\Sigma} / n).
\]</span></p>
</li>
</ul>
</li>
<li>
<p><strong>Wald’s Theorem</strong>:</p>
<ul>
<li>
<p>When <span class="math inline">\(n\)</span> is large relative to <span class="math inline">\(p\)</span>:</p>
<p><span class="math display">\[
n(\bar{\mathbf{y}} - \mathbf{\mu})' \mathbf{S}^{-1} (\bar{\mathbf{y}} - \mathbf{\mu}) \sim \chi^2_p.
\]</span></p>
</li>
</ul>
<p>This is useful for hypothesis testing about <span class="math inline">\(\mathbf{\mu}\)</span>.</p>
</li>
</ul>
<hr>
</div>
<div id="maximum-likelihood-estimation-for-mvn" class="section level4" number="25.1.4.7">
<h4>
<span class="header-section-number">25.1.4.7</span> Maximum Likelihood Estimation for MVN<a class="anchor" aria-label="anchor" href="#maximum-likelihood-estimation-for-mvn"><i class="fas fa-link"></i></a>
</h4>
<p>Suppose <span class="math inline">\(\mathbf{y}_1, \dots, \mathbf{y}_n\)</span> are iid random vectors from:</p>
<p><span class="math display">\[
\mathbf{y}_i \sim N_p (\mathbf{\mu}, \mathbf{\Sigma}).
\]</span></p>
<p>The likelihood function for the sample is:</p>
<p><span class="math display">\[
\begin{aligned}
L(\mathbf{\mu}, \mathbf{\Sigma}) &amp;= \prod_{j=1}^n \left[ \frac{1}{(2\pi)^{p/2}|\mathbf{\Sigma}|^{1/2}}
\exp \left(-\frac{1}{2} (\mathbf{y}_j - \mathbf{\mu})' \mathbf{\Sigma}^{-1} (\mathbf{y}_j - \mathbf{\mu}) \right) \right] \\
&amp;= \frac{1}{(2\pi)^{np/2}|\mathbf{\Sigma}|^{n/2}}
\exp \left(-\frac{1}{2} \sum_{j=1}^n (\mathbf{y}_j - \mathbf{\mu})' \mathbf{\Sigma}^{-1} (\mathbf{y}_j - \mathbf{\mu}) \right).
\end{aligned}
\]</span></p>
<p>Taking the log-likelihood function and differentiating with respect to <span class="math inline">\(\mathbf{\mu}\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> leads to the maximum likelihood estimators:</p>
<p>The MLE for the mean is simply the sample mean:</p>
<p><span class="math display">\[
\hat{\mathbf{\mu}} = \bar{\mathbf{y}}.
\]</span></p>
<p>The MLE for the covariance matrix is:</p>
<p><span class="math display">\[
\hat{\mathbf{\Sigma}} = \frac{n-1}{n} \mathbf{S}.
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\mathbf{S} = \frac{1}{n-1} \sum_{j=1}^n (\mathbf{y}_j - \bar{\mathbf{y}})(\mathbf{y}_j - \bar{\mathbf{y}})'.
\]</span></p>
<p>This differs from <span class="math inline">\(\mathbf{S}\)</span> by the factor <span class="math inline">\(\frac{n-1}{n}\)</span>, making <span class="math inline">\(\hat{\mathbf{\Sigma}}\)</span> a <strong>biased estimator</strong> of <span class="math inline">\(\mathbf{\Sigma}\)</span>.</p>
<hr>
<div id="properties-of-maximum-likelihood-estimators" class="section level5" number="25.1.4.7.1">
<h5>
<span class="header-section-number">25.1.4.7.1</span> Properties of Maximum Likelihood Estimators<a class="anchor" aria-label="anchor" href="#properties-of-maximum-likelihood-estimators"><i class="fas fa-link"></i></a>
</h5>
<p>MLEs have several important theoretical properties:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Invariance</strong>:
<ul>
<li>
<p>If <span class="math inline">\(\hat{\theta}\)</span> is the MLE of <span class="math inline">\(\theta\)</span>, then the MLE of any function <span class="math inline">\(h(\theta)\)</span> is:</p>
<p><span class="math display">\[
h(\hat{\theta}).
\]</span></p>
</li>
</ul>
</li>
<li>
<strong>Consistency</strong>:
<ul>
<li>MLEs are consistent estimators, meaning they converge to the true parameter values as <span class="math inline">\(n \to \infty\)</span>.</li>
<li>However, they can be biased for finite samples.</li>
</ul>
</li>
<li>
<strong>Efficiency</strong>:
<ul>
<li>MLEs are asymptotically efficient, meaning they achieve the Cramér-Rao lower bound for variance in large samples.</li>
<li>No other estimator has a smaller variance asymptotically.</li>
</ul>
</li>
<li>
<strong>Asymptotic Normality</strong>:
<ul>
<li><p>Suppose <span class="math inline">\(\hat{\theta}_n\)</span> is the MLE for <span class="math inline">\(\theta\)</span> based on <span class="math inline">\(n\)</span> independent observations.</p></li>
<li>
<p>Then, for large <span class="math inline">\(n\)</span>:</p>
<p><span class="math display">\[
\hat{\theta}_n \dot{\sim} N(\theta, \mathbf{H}^{-1}),
\]</span></p>
<p>where <span class="math inline">\(\mathbf{H}\)</span> is the <a href="generalized-linear-models.html#fisher-information-matrix">Fisher Information Matrix</a>, defined as:</p>
<p><span class="math display">\[
\mathbf{H}_{ij} = -E\left(\frac{\partial^2 l(\mathbf{\theta})}{\partial \theta_i \partial \theta_j}\right).
\]</span></p>
<ul>
<li>The <a href="generalized-linear-models.html#fisher-information-matrix">Fisher Information Matrix</a> measures the amount of information in the data about <span class="math inline">\(\theta\)</span>.</li>
<li>It can be estimated by evaluating the second derivatives of the log-likelihood function at <span class="math inline">\(\hat{\theta}_n\)</span>.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="likelihood-ratio-testing" class="section level5" number="25.1.4.7.2">
<h5>
<span class="header-section-number">25.1.4.7.2</span> Likelihood Ratio Testing<a class="anchor" aria-label="anchor" href="#likelihood-ratio-testing"><i class="fas fa-link"></i></a>
</h5>
<p>MLEs allow us to construct likelihood ratio tests for hypothesis testing.</p>
<ul>
<li>
<p>Suppose we test a null hypothesis <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[
H_0: \mathbf{\theta} \in \Theta_0 \quad \text{vs.} \quad H_A: \mathbf{\theta} \in \Theta.
\]</span></p>
</li>
<li>
<p>The likelihood ratio statistic is:</p>
<p><span class="math display">\[
\Lambda = \frac{\max_{\theta \in \Theta_0} L(\mathbf{\mu}, \mathbf{\Sigma} | \mathbf{Y})}
{\max_{\theta \in \Theta} L(\mathbf{\mu}, \mathbf{\Sigma} | \mathbf{Y})}.
\]</span></p>
</li>
<li>
<p>Under large sample conditions, we use the Wilks’ theorem, which states:</p>
<p><span class="math display">\[
-2 \log \Lambda \sim \chi^2_v,
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(v\)</span> is the difference in the number of parameters between the unrestricted and restricted models.</li>
<li>This allows us to approximate the distribution of <span class="math inline">\(-2 \log \Lambda\)</span> using the chi-square distribution.</li>
</ul>
</li>
</ul>
<hr>
</div>
</div>
</div>
<div id="test-of-multivariate-normality" class="section level3" number="25.1.5">
<h3>
<span class="header-section-number">25.1.5</span> Test of Multivariate Normality<a class="anchor" aria-label="anchor" href="#test-of-multivariate-normality"><i class="fas fa-link"></i></a>
</h3>
<p>Assessing multivariate normality is essential for many statistical techniques, including multivariate regression, principal component analysis, and MANOVA. Below are key methods for testing MVN.</p>
<div id="univariate-normality-checks" class="section level4" number="25.1.5.1">
<h4>
<span class="header-section-number">25.1.5.1</span> Univariate Normality Checks<a class="anchor" aria-label="anchor" href="#univariate-normality-checks"><i class="fas fa-link"></i></a>
</h4>
<p>Before testing for multivariate normality, it is useful to check for univariate normality in each variable separately:</p>
<ul>
<li>Normality Assessment: Visual and statistical tests can be used to check normality.</li>
<li>Key Property: If any univariate distribution is not normal, then the joint multivariate distribution cannot be normal.</li>
<li>Important Caveat: Even if all univariate distributions are normal, this does not guarantee multivariate normality.</li>
</ul>
<p>Thus, <strong>univariate normality is a necessary but not sufficient condition</strong> for MVN.</p>
<hr>
</div>
<div id="sec-mardias-test-for-multivariate-normality" class="section level4" number="25.1.5.2">
<h4>
<span class="header-section-number">25.1.5.2</span> Mardia’s Test for Multivariate Normality<a class="anchor" aria-label="anchor" href="#sec-mardias-test-for-multivariate-normality"><i class="fas fa-link"></i></a>
</h4>
<p><span class="citation">Mardia (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-mardia1970measures">1970</a>)</span> proposed two measures for assessing MVN:</p>
<p><strong>1. Multivariate Skewness</strong></p>
<p>Defined as:</p>
<p><span class="math display">\[
\beta_{1,p} = E[(\mathbf{y} - \mathbf{\mu})' \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu})]^3,
\]</span></p>
<p>where <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are independent but identically distributed.</p>
<p><strong>2. Multivariate Kurtosis</strong></p>
<p>Defined as:</p>
<p><span class="math display">\[
\beta_{2,p} = E[(\mathbf{y} - \mathbf{\mu})' \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu})]^2.
\]</span></p>
<p>For a <strong>true multivariate normal distribution</strong>:</p>
<p><span class="math display">\[
\beta_{1,p} = 0, \quad \beta_{2,p} = p(p+2).
\]</span></p>
<p><strong>Sample Estimates</strong></p>
<p>For a random sample of size <span class="math inline">\(n\)</span>, we estimate:</p>
<p><span class="math display">\[
\hat{\beta}_{1,p} = \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} g^2_{ij},
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_{2,p} = \frac{1}{n} \sum_{i=1}^{n} g^2_{ii},
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(g_{ij} = (\mathbf{y}_i - \bar{\mathbf{y}})' \mathbf{S}^{-1} (\mathbf{y}_j - \bar{\mathbf{y}})\)</span>,</li>
<li>
<span class="math inline">\(g_{ii} = d_i^2\)</span>, which is the Mahalanobis distance.</li>
</ul>
<p><span class="citation">Mardia (<a href="chapter-cluster-randomization-and-interference-bias.html#ref-mardia1970measures">1970</a>)</span> derived the following large-sample approximations:</p>
<p><span class="math display">\[
\kappa_1 = \frac{n \hat{\beta}_{1,p}}{6} \dot{\sim} \chi^2_{p(p+1)(p+2)/6},
\]</span></p>
<p><span class="math display">\[
\kappa_2 = \frac{\hat{\beta}_{2,p} - p(p+2)}{\sqrt{8p(p+2)/n}} \sim N(0,1).
\]</span></p>
<p><strong>Interpretation</strong></p>
<ul>
<li>
<span class="math inline">\(\kappa_1\)</span> and <span class="math inline">\(\kappa_2\)</span> are test statistics for the null hypothesis of MVN.</li>
<li>Non-normality in means is associated with skewness (<span class="math inline">\(\beta_{1,p}\)</span>).</li>
<li>Non-normality in covariance is associated with kurtosis (<span class="math inline">\(\beta_{2,p}\)</span>).</li>
</ul>
<hr>
</div>
<div id="doornik-hansen-test" class="section level4" number="25.1.5.3">
<h4>
<span class="header-section-number">25.1.5.3</span> Doornik-Hansen Test<a class="anchor" aria-label="anchor" href="#doornik-hansen-test"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>This test transforms variables to approximate normality using skewness and kurtosis corrections <span class="citation">(<a href="chapter-cluster-randomization-and-interference-bias.html#ref-doornik2008omnibus">Doornik and Hansen 2008</a>)</span>.</li>
<li>Recommended when sample sizes are small.</li>
</ul>
</div>
<div id="chi-square-q-q-plot" class="section level4" number="25.1.5.4">
<h4>
<span class="header-section-number">25.1.5.4</span> Chi-Square Q-Q Plot<a class="anchor" aria-label="anchor" href="#chi-square-q-q-plot"><i class="fas fa-link"></i></a>
</h4>
<p>The Chi-Square Q-Q plot is a graphical method for assessing MVN:</p>
<ol style="list-style-type: decimal">
<li>
<p>Compute Mahalanobis distances:</p>
<p><span class="math display">\[
d_i^2 = (\mathbf{y}_i - \bar{\mathbf{y}})' \mathbf{S}^{-1} (\mathbf{y}_i - \bar{\mathbf{y}}).
\]</span></p>
</li>
<li>
<p>The transformed variables:</p>
<p><span class="math display">\[
\mathbf{z}_i = \mathbf{\Sigma}^{-1/2}(\mathbf{y}_i - \mathbf{\mu})
\]</span></p>
<p>are iid from <span class="math inline">\(N_p(\mathbf{0}, \mathbf{I})\)</span>, and thus:</p>
<p><span class="math display">\[
d_i^2 \sim \chi^2_p.
\]</span></p>
</li>
<li><p>Plot ordered <span class="math inline">\(d_i^2\)</span> values against the theoretical quantiles of the <span class="math inline">\(\chi^2_p\)</span> distribution.</p></li>
</ol>
<p><strong>Interpretation</strong></p>
<ul>
<li>If the data are MVN, the plot should resemble a straight line at 45°.</li>
<li>Deviations suggest non-normality, especially in the tails.</li>
</ul>
<p><strong>Limitations</strong></p>
<ul>
<li>Requires a large sample size.</li>
<li>Even when data are truly MVN, the tails may deviate.</li>
</ul>
<hr>
</div>
<div id="handling-non-normality" class="section level4" number="25.1.5.5">
<h4>
<span class="header-section-number">25.1.5.5</span> Handling Non-Normality<a class="anchor" aria-label="anchor" href="#handling-non-normality"><i class="fas fa-link"></i></a>
</h4>
<p>If data <strong>fail</strong> the multivariate normality tests, possible approaches include:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Ignoring non-normality</strong> (acceptable for large samples due to the <a href="prerequisites.html#central-limit-theorem">Central Limit Theorem</a>).</li>
<li>
<strong>Using nonparametric methods</strong> (e.g., permutation tests).</li>
<li>
<strong>Applying approximate models</strong> (e.g., <a href="sec-nonlinear-and-generalized-linear-mixed-models.html#sec-generalized-linear-mixed-models">Generalized Linear Mixed Models</a>).</li>
<li>
<strong>Transforming the data</strong> (e.g., log, Box-Cox, or rank transformations <a href="variable-transformation.html#variable-transformation">12</a>).</li>
</ol>
<hr>
<div class="sourceCode" id="cb701"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://friendly.github.io/heplots/">heplots</a></span><span class="op">)</span>      <span class="co"># Multivariate hypothesis tests</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span>        <span class="co"># Multivariate tests</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MVN</span><span class="op">)</span>          <span class="co"># Multivariate normality tests</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>    <span class="co"># Data wrangling &amp; visualization</span></span>
<span></span>
<span></span>
<span><span class="co"># Load dataset</span></span>
<span><span class="va">trees</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"images/trees.dat"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">trees</span><span class="op">)</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Nitrogen"</span>, <span class="st">"Phosphorous"</span>, <span class="st">"Potassium"</span>, <span class="st">"Ash"</span>, <span class="st">"Height"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Structure of dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">trees</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    26 obs. of  5 variables:</span></span>
<span><span class="co">#&gt;  $ Nitrogen   : num  2.2 2.1 1.52 2.88 2.18 1.87 1.52 2.37 2.06 1.84 ...</span></span>
<span><span class="co">#&gt;  $ Phosphorous: num  0.417 0.354 0.208 0.335 0.314 0.271 0.164 0.302 0.373 0.265 ...</span></span>
<span><span class="co">#&gt;  $ Potassium  : num  1.35 0.9 0.71 0.9 1.26 1.15 0.83 0.89 0.79 0.72 ...</span></span>
<span><span class="co">#&gt;  $ Ash        : num  1.79 1.08 0.47 1.48 1.09 0.99 0.85 0.94 0.8 0.77 ...</span></span>
<span><span class="co">#&gt;  $ Height     : int  351 249 171 373 321 191 225 291 284 213 ...</span></span>
<span></span>
<span><span class="co"># Summary statistics</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">trees</span><span class="op">)</span></span>
<span><span class="co">#&gt;     Nitrogen      Phosphorous       Potassium           Ash        </span></span>
<span><span class="co">#&gt;  Min.   :1.130   Min.   :0.1570   Min.   :0.3800   Min.   :0.4500  </span></span>
<span><span class="co">#&gt;  1st Qu.:1.532   1st Qu.:0.1963   1st Qu.:0.6050   1st Qu.:0.6375  </span></span>
<span><span class="co">#&gt;  Median :1.855   Median :0.2250   Median :0.7150   Median :0.9300  </span></span>
<span><span class="co">#&gt;  Mean   :1.896   Mean   :0.2506   Mean   :0.7619   Mean   :0.8873  </span></span>
<span><span class="co">#&gt;  3rd Qu.:2.160   3rd Qu.:0.2975   3rd Qu.:0.8975   3rd Qu.:0.9825  </span></span>
<span><span class="co">#&gt;  Max.   :2.880   Max.   :0.4170   Max.   :1.3500   Max.   :1.7900  </span></span>
<span><span class="co">#&gt;      Height     </span></span>
<span><span class="co">#&gt;  Min.   : 65.0  </span></span>
<span><span class="co">#&gt;  1st Qu.:122.5  </span></span>
<span><span class="co">#&gt;  Median :181.0  </span></span>
<span><span class="co">#&gt;  Mean   :196.6  </span></span>
<span><span class="co">#&gt;  3rd Qu.:276.0  </span></span>
<span><span class="co">#&gt;  Max.   :373.0</span></span>
<span></span>
<span><span class="co"># Pearson correlation matrix</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">trees</span>, method <span class="op">=</span> <span class="st">"pearson"</span><span class="op">)</span></span>
<span><span class="co">#&gt;              Nitrogen Phosphorous Potassium       Ash    Height</span></span>
<span><span class="co">#&gt; Nitrogen    1.0000000   0.6023902 0.5462456 0.6509771 0.8181641</span></span>
<span><span class="co">#&gt; Phosphorous 0.6023902   1.0000000 0.7037469 0.6707871 0.7739656</span></span>
<span><span class="co">#&gt; Potassium   0.5462456   0.7037469 1.0000000 0.6710548 0.7915683</span></span>
<span><span class="co">#&gt; Ash         0.6509771   0.6707871 0.6710548 1.0000000 0.7676771</span></span>
<span><span class="co">#&gt; Height      0.8181641   0.7739656 0.7915683 0.7676771 1.0000000</span></span>
<span></span>
<span><span class="co"># Q-Q plots for each variable</span></span>
<span><span class="va">gg</span> <span class="op">&lt;-</span> <span class="va">trees</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/everything.html">everything</a></span><span class="op">(</span><span class="op">)</span>, names_to <span class="op">=</span> <span class="st">"Var"</span>, values_to <span class="op">=</span> <span class="st">"Value"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>sample <span class="op">=</span> <span class="va">Value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_qq.html">geom_qq</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_qq.html">geom_qq_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span> <span class="op">~</span> <span class="va">Var</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">gg</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="25-multivariate_files/figure-html/unnamed-chunk-1-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb702"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Shapiro-Wilk test for univariate normality</span></span>
<span><span class="va">sw_tests</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">trees</span>, MARGIN <span class="op">=</span> <span class="fl">2</span>, FUN <span class="op">=</span> <span class="va">shapiro.test</span><span class="op">)</span></span>
<span><span class="va">sw_tests</span></span>
<span><span class="co">#&gt; $Nitrogen</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  newX[, i]</span></span>
<span><span class="co">#&gt; W = 0.96829, p-value = 0.5794</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Phosphorous</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  newX[, i]</span></span>
<span><span class="co">#&gt; W = 0.93644, p-value = 0.1104</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Potassium</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  newX[, i]</span></span>
<span><span class="co">#&gt; W = 0.95709, p-value = 0.3375</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Ash</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  newX[, i]</span></span>
<span><span class="co">#&gt; W = 0.92071, p-value = 0.04671</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Height</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  newX[, i]</span></span>
<span><span class="co">#&gt; W = 0.94107, p-value = 0.1424</span></span>
<span></span>
<span><span class="co"># Kolmogorov-Smirnov test for normality</span></span>
<span><span class="va">ks_tests</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">trees</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/ks.test.html">ks.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">.x</span><span class="op">)</span>, <span class="st">"pnorm"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ks_tests</span></span>
<span><span class="co">#&gt; $Nitrogen</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  scale(.x)</span></span>
<span><span class="co">#&gt; D = 0.12182, p-value = 0.8351</span></span>
<span><span class="co">#&gt; alternative hypothesis: two-sided</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Phosphorous</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  scale(.x)</span></span>
<span><span class="co">#&gt; D = 0.17627, p-value = 0.3944</span></span>
<span><span class="co">#&gt; alternative hypothesis: two-sided</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Potassium</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  scale(.x)</span></span>
<span><span class="co">#&gt; D = 0.10542, p-value = 0.9348</span></span>
<span><span class="co">#&gt; alternative hypothesis: two-sided</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Ash</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  scale(.x)</span></span>
<span><span class="co">#&gt; D = 0.14503, p-value = 0.6449</span></span>
<span><span class="co">#&gt; alternative hypothesis: two-sided</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Height</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  scale(.x)</span></span>
<span><span class="co">#&gt; D = 0.1107, p-value = 0.9076</span></span>
<span><span class="co">#&gt; alternative hypothesis: two-sided</span></span>
<span></span>
<span><span class="co"># Mardia's test for multivariate normality</span></span>
<span><span class="va">mardia_test</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/MVN/man/mvn.html">mvn</a></span><span class="op">(</span></span>
<span>        <span class="va">trees</span>,</span>
<span>        mvnTest <span class="op">=</span> <span class="st">"mardia"</span>,</span>
<span>        covariance <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>        multivariatePlot <span class="op">=</span> <span class="st">"qq"</span></span>
<span>    <span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="25-multivariate_files/figure-html/unnamed-chunk-1-2.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb703"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mardia_test</span><span class="op">$</span><span class="va">multivariateNormality</span></span>
<span><span class="co">#&gt;              Test         Statistic            p value Result</span></span>
<span><span class="co">#&gt; 1 Mardia Skewness  29.7248528871795   0.72054426745778    YES</span></span>
<span><span class="co">#&gt; 2 Mardia Kurtosis -1.67743173185383 0.0934580886477281    YES</span></span>
<span><span class="co">#&gt; 3             MVN              &lt;NA&gt;               &lt;NA&gt;    YES</span></span>
<span></span>
<span><span class="co"># Doornik-Hansen test</span></span>
<span><span class="va">dh_test</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/MVN/man/mvn.html">mvn</a></span><span class="op">(</span></span>
<span>        <span class="va">trees</span>,</span>
<span>        mvnTest <span class="op">=</span> <span class="st">"dh"</span>,</span>
<span>        covariance <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>        multivariatePlot <span class="op">=</span> <span class="st">"qq"</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">dh_test</span><span class="op">$</span><span class="va">multivariateNormality</span></span>
<span><span class="co">#&gt;             Test        E df      p value MVN</span></span>
<span><span class="co">#&gt; 1 Doornik-Hansen 161.9446 10 1.285352e-29  NO</span></span>
<span></span>
<span><span class="co"># Henze-Zirkler test</span></span>
<span><span class="va">hz_test</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/MVN/man/mvn.html">mvn</a></span><span class="op">(</span></span>
<span>        <span class="va">trees</span>,</span>
<span>        mvnTest <span class="op">=</span> <span class="st">"hz"</span>,</span>
<span>        covariance <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>        multivariatePlot <span class="op">=</span> <span class="st">"qq"</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">hz_test</span><span class="op">$</span><span class="va">multivariateNormality</span></span>
<span><span class="co">#&gt;            Test        HZ   p value MVN</span></span>
<span><span class="co">#&gt; 1 Henze-Zirkler 0.7591525 0.6398905 YES</span></span>
<span></span>
<span><span class="co"># Royston's test (only for 3 &lt; obs &lt; 5000)</span></span>
<span><span class="va">royston_test</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/MVN/man/mvn.html">mvn</a></span><span class="op">(</span></span>
<span>        <span class="va">trees</span>,</span>
<span>        mvnTest <span class="op">=</span> <span class="st">"royston"</span>,</span>
<span>        covariance <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>        multivariatePlot <span class="op">=</span> <span class="st">"qq"</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">royston_test</span><span class="op">$</span><span class="va">multivariateNormality</span></span>
<span><span class="co">#&gt;      Test        H    p value MVN</span></span>
<span><span class="co">#&gt; 1 Royston 9.064631 0.08199215 YES</span></span>
<span></span>
<span><span class="co"># Energy test</span></span>
<span><span class="va">estat_test</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/MVN/man/mvn.html">mvn</a></span><span class="op">(</span></span>
<span>        <span class="va">trees</span>,</span>
<span>        mvnTest <span class="op">=</span> <span class="st">"energy"</span>,</span>
<span>        covariance <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>        multivariatePlot <span class="op">=</span> <span class="st">"qq"</span></span>
<span>    <span class="op">)</span></span>
<span><span class="va">estat_test</span><span class="op">$</span><span class="va">multivariateNormality</span></span>
<span><span class="co">#&gt;          Test Statistic p value MVN</span></span>
<span><span class="co">#&gt; 1 E-statistic  1.091101   0.554 YES</span></span></code></pre></div>
</div>
</div>
<div id="mean-vector-inference" class="section level3" number="25.1.6">
<h3>
<span class="header-section-number">25.1.6</span> Mean Vector Inference<a class="anchor" aria-label="anchor" href="#mean-vector-inference"><i class="fas fa-link"></i></a>
</h3>
<div id="univariate-case" class="section level4" number="25.1.6.1">
<h4>
<span class="header-section-number">25.1.6.1</span> Univariate Case<a class="anchor" aria-label="anchor" href="#univariate-case"><i class="fas fa-link"></i></a>
</h4>
<p>In the univariate normal distribution, we test:</p>
<p><span class="math display">\[
H_0: \mu = \mu_0
\]</span></p>
<p>using the t-test statistic:</p>
<p><span class="math display">\[
T = \frac{\bar{y} - \mu_0}{s/\sqrt{n}} \sim t_{n-1}.
\]</span></p>
<p><strong>Decision Rule</strong></p>
<ul>
<li><p>If <span class="math inline">\(H_0\)</span> is true, then <span class="math inline">\(T\)</span> follows a t-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</p></li>
<li>
<p>We reject <span class="math inline">\(H_0\)</span> if:</p>
<p><span class="math display">\[
|T| &gt; t_{(1-\alpha/2, n-1)}
\]</span></p>
<p>because an extreme value suggests that observing <span class="math inline">\(\bar{y}\)</span> under <span class="math inline">\(H_0\)</span> is unlikely.</p>
</li>
</ul>
<p><strong>Alternative Formulation</strong></p>
<p>Squaring <span class="math inline">\(T\)</span>, we obtain:</p>
<p><span class="math display">\[
T^2 = \frac{(\bar{y} - \mu_0)^2}{s^2/n} = n(\bar{y} - \mu_0) (s^2)^{-1} (\bar{y} - \mu_0).
\]</span></p>
<p>Under <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[
T^2 \sim f_{(1,n-1)}.
\]</span></p>
<p>This formulation allows for a direct extension to the multivariate case.</p>
<hr>
</div>
<div id="multivariate-generalization-hotellings-t2-test" class="section level4" number="25.1.6.2">
<h4>
<span class="header-section-number">25.1.6.2</span> Multivariate Generalization: Hotelling’s <span class="math inline">\(T^2\)</span> Test<a class="anchor" aria-label="anchor" href="#multivariate-generalization-hotellings-t2-test"><i class="fas fa-link"></i></a>
</h4>
<p>For a p-dimensional mean vector, we test:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \mathbf{\mu} = \mathbf{\mu}_0, \\
&amp;H_a: \mathbf{\mu} \neq \mathbf{\mu}_0.
\end{aligned}
\]</span></p>
<p>Define the Hotelling’s <span class="math inline">\(T^2\)</span> test statistic:</p>
<p><span class="math display">\[
T^2 = n(\bar{\mathbf{y}} - \mathbf{\mu}_0)' \mathbf{S}^{-1} (\bar{\mathbf{y}} - \mathbf{\mu}_0).
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\bar{\mathbf{y}}\)</span> is the sample mean vector,</p></li>
<li><p><span class="math inline">\(\mathbf{S}\)</span> is the sample covariance matrix,</p></li>
<li><p><span class="math inline">\(T^2\)</span> can be interpreted as a generalized squared distance between <span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{\mu}_0\)</span>.</p></li>
</ul>
<p>Under multivariate normality, the test statistic follows an F-distribution:</p>
<p><span class="math display">\[
F = \frac{n-p}{(n-1)p} T^2 \sim f_{(p, n-p)}.
\]</span></p>
<p>We reject <span class="math inline">\(H_0\)</span> if:</p>
<p><span class="math display">\[
F &gt; f_{(1-\alpha, p, n-p)}.
\]</span></p>
<hr>
<p><strong>Key Properties of Hotelling’s</strong> <span class="math inline">\(T^2\)</span> Test</p>
<ol style="list-style-type: decimal">
<li>
<strong>Invariance to Measurement Scale</strong>:
<ul>
<li>
<p>If we apply a linear transformation to the data:</p>
<p><span class="math display">\[
\mathbf{z} = \mathbf{C} \mathbf{y} + \mathbf{d},
\]</span></p>
<p>where <span class="math inline">\(\mathbf{C}\)</span> and <span class="math inline">\(\mathbf{d}\)</span> do not depend on <span class="math inline">\(\mathbf{y}\)</span>, then:</p>
<p><span class="math display">\[
T^2(\mathbf{z}) = T^2(\mathbf{y}).
\]</span></p>
<p>This ensures that unit changes (e.g., inches to centimeters) do not affect the test results.</p>
</li>
</ul>
</li>
<li>
<strong>Likelihood Ratio Test</strong>:
<ul>
<li>The <span class="math inline">\(T^2\)</span> test can be derived as a likelihood ratio test for <span class="math inline">\(H_0: \mathbf{\mu} = \mathbf{\mu}_0\)</span>.</li>
</ul>
</li>
</ol>
<hr>
<div class="sourceCode" id="cb704"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>    <span class="co"># For multivariate analysis</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span>   <span class="co"># For Hotelling's T^2 test</span></span>
<span></span>
<span><span class="co"># Simulated dataset (5 variables, 30 observations)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>  <span class="co"># Sample size</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">5</span>   <span class="co"># Number of variables</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span>  <span class="co"># Population mean vector</span></span>
<span><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="co"># Identity covariance matrix</span></span>
<span></span>
<span><span class="co"># Generate multivariate normal data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span>, <span class="va">Sigma</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute sample mean and covariance</span></span>
<span><span class="va">sample_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html">colMeans</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">sample_cov</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform Hotelling's T^2 test (testing against mu_0 = rep(0, p))</span></span>
<span><span class="va">hotelling_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ICSNP/man/HotellingsT.html">HotellingsT2</a></span><span class="op">(</span><span class="va">data</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Print results</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">hotelling_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hotelling's one sample T2-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  data</span></span>
<span><span class="co">#&gt; T.2 = 0.43475, df1 = 5, df2 = 25, p-value = 0.82</span></span>
<span><span class="co">#&gt; alternative hypothesis: true location is not equal to c(0,0,0,0,0)</span></span></code></pre></div>
</div>
<div id="confidence-intervals" class="section level4" number="25.1.6.3">
<h4>
<span class="header-section-number">25.1.6.3</span> Confidence Intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals"><i class="fas fa-link"></i></a>
</h4>
<div id="confidence-region-for-the-mean-vector" class="section level5" number="25.1.6.3.1">
<h5>
<span class="header-section-number">25.1.6.3.1</span> Confidence Region for the Mean Vector<a class="anchor" aria-label="anchor" href="#confidence-region-for-the-mean-vector"><i class="fas fa-link"></i></a>
</h5>
<p>An exact <span class="math inline">\(100(1-\alpha)\%\)</span> confidence region for the population mean vector <span class="math inline">\(\mathbf{\mu}\)</span> is the set of all vectors <span class="math inline">\(\mathbf{v}\)</span> that are “close enough” to the observed mean vector <span class="math inline">\(\bar{\mathbf{y}}\)</span> such that:</p>
<p><span class="math display">\[
n(\bar{\mathbf{y}} - \mathbf{\mu}_0)' \mathbf{S}^{-1} (\bar{\mathbf{y}} - \mathbf{\mu}_0) \leq \frac{(n-1)p}{n-p} f_{(1-\alpha, p, n-p)}.
\]</span></p>
<p><strong>Interpretation</strong></p>
<ul>
<li>The confidence region consists of all mean vectors <span class="math inline">\(\mathbf{\mu}_0\)</span> for which we fail to reject <span class="math inline">\(H_0\)</span> in the Hotelling’s <span class="math inline">\(T^2\)</span> test.</li>
<li>If <span class="math inline">\(p = 2\)</span>, this confidence region forms a hyper-ellipsoid.</li>
</ul>
<p><strong>Why Use Confidence Regions?</strong></p>
<ul>
<li>They provide a joint assessment of plausible values for <span class="math inline">\(\mathbf{\mu}\)</span>.</li>
<li>However, in practice, we often prefer individual confidence intervals for each mean component.</li>
</ul>
<hr>
</div>
<div id="simultaneous-confidence-intervals" class="section level5" number="25.1.6.3.2">
<h5>
<span class="header-section-number">25.1.6.3.2</span> Simultaneous Confidence Intervals<a class="anchor" aria-label="anchor" href="#simultaneous-confidence-intervals"><i class="fas fa-link"></i></a>
</h5>
<p>We want simultaneous confidence statements, ensuring that all individual confidence intervals hold simultaneously with high probability.</p>
<p><strong>Simultaneous Confidence Intervals (General Form)</strong></p>
<p>By projecting the confidence region onto the coordinate axes, we obtain simultaneous confidence intervals:</p>
<p><span class="math display">\[
\bar{y}_{i} \pm \sqrt{\frac{(n-1)p}{n-p} f_{(1-\alpha, p, n-p)} \frac{s_{ii}}{n}}, \quad \text{for } i = 1, \dots, p.
\]</span></p>
<ul>
<li>These intervals are conservative, meaning their actual confidence level is at least <span class="math inline">\(100(1 - \alpha)\%\)</span>.</li>
</ul>
<p><strong>Simultaneous Confidence Intervals for Any Linear Combination</strong></p>
<p>For any arbitrary linear combination <span class="math inline">\(\mathbf{a'\mu}\)</span>:</p>
<p><span class="math display">\[
\mathbf{a'\bar{y}} \pm \sqrt{\frac{(n-1)p}{n-p} f_{(1-\alpha, p, n-p)} \frac{\mathbf{a'Sa}}{n}}.
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{a'\mu} = a_1 \mu_1 + \dots + a_p \mu_p\)</span> is a projection onto the axis in the direction of <span class="math inline">\(\mathbf{a}\)</span>.</p></li>
<li><p>The probability that at least one interval fails to contain the corresponding <span class="math inline">\(\mathbf{a'\mu}\)</span> is no more than <span class="math inline">\(\alpha\)</span>.</p></li>
<li>
<p>These intervals are useful for “data snooping” (similar to Scheffé’s method in <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a></p>
<p><a href="sec-analysis-of-variance-anova.html#sec-scheffe-anova">24.1.1.5.4.2</a>).</p>
</li>
</ul>
<hr>
</div>
<div id="one-at-a-time-confidence-intervals" class="section level5" number="25.1.6.3.3">
<h5>
<span class="header-section-number">25.1.6.3.3</span> One-at-a-Time Confidence Intervals<a class="anchor" aria-label="anchor" href="#one-at-a-time-confidence-intervals"><i class="fas fa-link"></i></a>
</h5>
<p>A simpler alternative is to construct <strong>separate</strong> confidence intervals for each mean component <strong>individually</strong>:</p>
<p><span class="math display">\[
\bar{y}_i \pm t_{(1 - \alpha/2, n-1)} \sqrt{\frac{s_{ii}}{n}}.
\]</span></p>
<p><strong>Limitations</strong></p>
<ul>
<li>Each interval has a probability of <span class="math inline">\(1-\alpha\)</span> of covering the corresponding <span class="math inline">\(\mu_i\)</span>.</li>
<li>They ignore the covariance structure between the <span class="math inline">\(p\)</span> variables.</li>
</ul>
<p><strong>Bonferroni Correction for Multiple Comparisons</strong></p>
<p>If we only care about <span class="math inline">\(k\)</span> specific intervals, we can adjust for multiple comparisons using the Bonferroni correction:</p>
<p><span class="math display">\[
\bar{y}_i \pm t_{(1 - \alpha/(2k), n-1)} \sqrt{\frac{s_{ii}}{n}}.
\]</span></p>
<ul>
<li>This ensures that the overall confidence level remains at <span class="math inline">\(100(1 - \alpha)\%\)</span>.</li>
<li>The method becomes more conservative as the number of comparisons <span class="math inline">\(k\)</span> increases.</li>
</ul>
<hr>
<div class="sourceCode" id="cb705"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>    <span class="co"># For multivariate analysis</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span>   <span class="co"># For Hotelling's T2 test</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>  <span class="co"># Data manipulation and plotting</span></span>
<span></span>
<span><span class="co"># Simulated dataset (5 variables, 30 observations)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span>  <span class="co"># Sample size</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">5</span>   <span class="co"># Number of variables</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span></span>
<span><span class="co"># Population mean and covariance</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span>  </span>
<span><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># Generate multivariate normal data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span>, <span class="va">Sigma</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute sample mean and covariance</span></span>
<span><span class="va">sample_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html">colMeans</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">sample_cov</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Hotelling's T^2 statistic</span></span>
<span><span class="va">T2</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">n</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/t.html">t</a></span><span class="op">(</span><span class="va">sample_mean</span> <span class="op">-</span> <span class="va">mu</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">sample_cov</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="op">(</span><span class="va">sample_mean</span> <span class="op">-</span> <span class="va">mu</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Critical value for Hotelling's T^2 test</span></span>
<span><span class="va">F_crit</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">p</span> <span class="op">/</span> <span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span>, <span class="va">p</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Confidence region check</span></span>
<span><span class="va">T2</span> <span class="op">&lt;=</span> <span class="va">F_crit</span>  <span class="co"># If TRUE, mean vector is within the confidence region</span></span>
<span><span class="co">#&gt;      [,1]</span></span>
<span><span class="co">#&gt; [1,] TRUE</span></span>
<span></span>
<span><span class="co"># Simultaneous confidence intervals</span></span>
<span><span class="va">CI_limits</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span>, <span class="va">p</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">sample_cov</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Construct confidence intervals</span></span>
<span><span class="va">simultaneous_CI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Variable <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>,</span>
<span>  Lower <span class="op">=</span> <span class="va">sample_mean</span> <span class="op">-</span> <span class="va">CI_limits</span>,</span>
<span>  Upper <span class="op">=</span> <span class="va">sample_mean</span> <span class="op">+</span> <span class="va">CI_limits</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">simultaneous_CI</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Variable      Lower     Upper</span></span>
<span><span class="co">#&gt; V1       V1 -0.9983080 0.6311472</span></span>
<span><span class="co">#&gt; V2       V2 -0.7372215 0.5494437</span></span>
<span><span class="co">#&gt; V3       V3 -0.5926088 0.6414496</span></span>
<span><span class="co">#&gt; V4       V4 -0.4140990 0.7707756</span></span>
<span><span class="co">#&gt; V5       V5 -0.7430441 0.6488366</span></span>
<span></span>
<span><span class="co"># Bonferroni-corrected one-at-a-time confidence intervals</span></span>
<span><span class="va">t_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">/</span> <span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">bonferroni_CI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Variable <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>,</span>
<span>  Lower <span class="op">=</span> <span class="va">sample_mean</span> <span class="op">-</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">sample_cov</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>,</span>
<span>  Upper <span class="op">=</span> <span class="va">sample_mean</span> <span class="op">+</span> <span class="va">t_crit</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">sample_cov</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">bonferroni_CI</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Variable      Lower     Upper</span></span>
<span><span class="co">#&gt; V1       V1 -0.7615465 0.3943857</span></span>
<span><span class="co">#&gt; V2       V2 -0.5502678 0.3624900</span></span>
<span><span class="co">#&gt; V3       V3 -0.4132989 0.4621397</span></span>
<span><span class="co">#&gt; V4       V4 -0.2419355 0.5986122</span></span>
<span><span class="co">#&gt; V5       V5 -0.5408025 0.4465950</span></span></code></pre></div>
</div>
</div>
</div>
<div id="general-hypothesis-testing" class="section level3" number="25.1.7">
<h3>
<span class="header-section-number">25.1.7</span> General Hypothesis Testing<a class="anchor" aria-label="anchor" href="#general-hypothesis-testing"><i class="fas fa-link"></i></a>
</h3>
<div id="sec-one-sample-multivariate-tests" class="section level4" number="25.1.7.1">
<h4>
<span class="header-section-number">25.1.7.1</span> One-Sample Multivariate Tests<a class="anchor" aria-label="anchor" href="#sec-one-sample-multivariate-tests"><i class="fas fa-link"></i></a>
</h4>
<p>We consider testing the hypothesis:</p>
<p><span class="math display">\[
H_0: \mathbf{C \mu} = 0
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{C}\)</span> is a <span class="math inline">\(c \times p\)</span> contrast matrix of rank <span class="math inline">\(c\)</span>, where <span class="math inline">\(c \leq p\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{\mu}\)</span> is the <span class="math inline">\(p \times 1\)</span> population mean vector.</p></li>
</ul>
<p>The test statistic for this hypothesis is:</p>
<p><span class="math display">\[
F = \frac{n - c}{(n-1)c} T^2
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
T^2 = n(\mathbf{C\bar{y}})' (\mathbf{CSC'})^{-1} (\mathbf{C\bar{y}}).
\]</span></p>
<p>This follows an F-distribution:</p>
<p><span class="math display">\[
F \sim f_{(c, n-c)}.
\]</span></p>
<hr>
<p><strong>Example: Testing Equal Means Across Variables</strong></p>
<p>We test whether all <strong>mean components are equal</strong>:</p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2 = \dots = \mu_p.
\]</span></p>
<p>This can be rewritten as:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_1 - \mu_2 &amp;= 0, \\
\mu_2 - \mu_3 &amp;= 0, \\
&amp;\vdots \\
\mu_{p-1} - \mu_p &amp;= 0.
\end{aligned}
\]</span></p>
<p>Since we are testing <span class="math inline">\(p-1\)</span> constraints, the contrast matrix <span class="math inline">\(\mathbf{C}\)</span> is a <span class="math inline">\((p-1) \times p\)</span> matrix:</p>
<p><span class="math display">\[
\mathbf{C} =
\begin{bmatrix}
1 &amp; -1 &amp; 0 &amp; \dots &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; 1 &amp; -1
\end{bmatrix}.
\]</span></p>
<p><strong>Alternatively</strong>, we can compare all other means <strong>to the first mean</strong>:</p>
<p><span class="math display">\[
H_0: \mu_1 - \mu_2 = 0, \quad \mu_1 - \mu_3 = 0, \quad \dots, \quad \mu_1 - \mu_p = 0.
\]</span></p>
<p>The contrast matrix <span class="math inline">\(\mathbf{C}\)</span> then becomes:</p>
<p><span class="math display">\[
\mathbf{C} =
\begin{bmatrix}
-1 &amp; 1 &amp; 0 &amp; \dots &amp; 0 \\
-1 &amp; 0 &amp; 1 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-1 &amp; 0 &amp; \dots &amp; 0 &amp; 1
\end{bmatrix}.
\]</span></p>
<p><strong>Key Property</strong></p>
<ul>
<li>The value of <span class="math inline">\(T^2\)</span> is invariant to these different choices of <span class="math inline">\(\mathbf{C}\)</span>.</li>
</ul>
<hr>
<p><strong>Application: Repeated Measures Design</strong></p>
<p>Repeated measures designs involve <strong>measuring each subject multiple times</strong> under different conditions or time points.</p>
<p>Let:</p>
<ul>
<li><p><span class="math inline">\(y_{ij}\)</span> be the <strong>response of subject</strong> <span class="math inline">\(i\)</span> at time <span class="math inline">\(j\)</span>, where <span class="math inline">\(i = 1, \dots, n\)</span> and <span class="math inline">\(j = 1, \dots, T\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{y}_i = (y_{i1}, ..., y_{iT})'\)</span> be a random sample from:</p></li>
</ul>
<p><span class="math display">\[
N_T (\mathbf{\mu}, \mathbf{\Sigma}).
\]</span></p>
<hr>
<p><strong>Example: Testing Equal Means Over Time</strong></p>
<p>Suppose we have:</p>
<ul>
<li><p><span class="math inline">\(n = 8\)</span> subjects,</p></li>
<li><p><span class="math inline">\(T = 6\)</span> time points.</p></li>
</ul>
<p>We test:</p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2 = \dots = \mu_6.
\]</span></p>
<p>This is equivalent to:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_1 - \mu_2 &amp;= 0, \\
\mu_2 - \mu_3 &amp;= 0, \\
&amp;\dots, \\
\mu_5 - \mu_6 &amp;= 0.
\end{aligned}
\]</span></p>
<p>The corresponding <strong>contrast matrix</strong> is:</p>
<p><span class="math display">\[
\mathbf{C} =
\begin{bmatrix}
1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; -1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1
\end{bmatrix}.
\]</span></p>
<p>If measurements occur at equally spaced time points, we can test for trend effects using orthogonal polynomials.</p>
<p>For example, testing whether quadratic and cubic trends are jointly zero, we use:</p>
<p><span class="math display">\[
\mathbf{C} =
\begin{bmatrix}
1 &amp; -1 &amp; -1 &amp; 1 \\
-1 &amp; 3 &amp; -3 &amp; 1
\end{bmatrix}.
\]</span></p>
<hr>
<div class="sourceCode" id="cb706"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>    <span class="co"># For multivariate normal data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span>   <span class="co"># For Hotelling's T^2 test</span></span>
<span></span>
<span><span class="co"># Simulated dataset (6 variables, 8 subjects)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">8</span>   <span class="co"># Number of subjects</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">6</span>   <span class="co"># Number of time points</span></span>
<span></span>
<span><span class="co"># Generate sample data</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">5</span>, <span class="va">p</span><span class="op">)</span>  <span class="co"># Population mean</span></span>
<span><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>  <span class="co"># Identity covariance matrix</span></span>
<span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">mu</span>, <span class="va">Sigma</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"Time"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute sample mean and covariance</span></span>
<span><span class="va">sample_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html">colMeans</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">sample_cov</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define contrast matrix for equal means hypothesis</span></span>
<span><span class="va">C</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0</span>, nrow <span class="op">=</span> <span class="va">p</span> <span class="op">-</span> <span class="fl">1</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">p</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">C</span><span class="op">[</span><span class="va">i</span>, <span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span>  <span class="va">C</span><span class="op">[</span><span class="va">i</span>, <span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Compute Hotelling's T^2 statistic</span></span>
<span><span class="va">T2</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">n</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/t.html">t</a></span><span class="op">(</span><span class="va">C</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">sample_mean</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">C</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">sample_cov</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/t.html">t</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="op">(</span><span class="va">C</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">sample_mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute F statistic</span></span>
<span><span class="va">c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/nrow.html">nrow</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span></span>
<span><span class="va">F_stat</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">c</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">c</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="va">T2</span></span>
<span></span>
<span><span class="co"># Critical value</span></span>
<span><span class="va">F_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="va">c</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">c</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Decision rule</span></span>
<span><span class="va">decision</span> <span class="op">&lt;-</span> <span class="va">F_stat</span> <span class="op">&gt;</span> <span class="va">F_crit</span></span>
<span></span>
<span><span class="co"># Print results</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span></span>
<span>  T2_statistic <span class="op">=</span> <span class="va">T2</span>,</span>
<span>  F_statistic <span class="op">=</span> <span class="va">F_stat</span>,</span>
<span>  F_critical_value <span class="op">=</span> <span class="va">F_crit</span>,</span>
<span>  Reject_H0 <span class="op">=</span> <span class="va">decision</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; $T2_statistic</span></span>
<span><span class="co">#&gt;          [,1]</span></span>
<span><span class="co">#&gt; [1,] 22.54896</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $F_statistic</span></span>
<span><span class="co">#&gt;          [,1]</span></span>
<span><span class="co">#&gt; [1,] 1.932768</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $F_critical_value</span></span>
<span><span class="co">#&gt; [1] 9.013455</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Reject_H0</span></span>
<span><span class="co">#&gt;       [,1]</span></span>
<span><span class="co">#&gt; [1,] FALSE</span></span></code></pre></div>
<hr>
</div>
<div id="sec-two-sample-multivariate-tests" class="section level4" number="25.1.7.2">
<h4>
<span class="header-section-number">25.1.7.2</span> Two-Sample Multivariate Tests<a class="anchor" aria-label="anchor" href="#sec-two-sample-multivariate-tests"><i class="fas fa-link"></i></a>
</h4>
<p>Consider testing the equality of two multivariate population means. Suppose we have two independent random samples:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{y}_{1i} &amp;\sim N_p (\mathbf{\mu}_1, \mathbf{\Sigma}), \quad i = 1, \dots, n_1, \\
\mathbf{y}_{2j} &amp;\sim N_p (\mathbf{\mu}_2, \mathbf{\Sigma}), \quad j = 1, \dots, n_2.
\end{aligned}
\]</span></p>
<p>We assume:</p>
<ul>
<li><p>Multivariate normality of both populations.</p></li>
<li><p>Equal variance-covariance matrices: <span class="math inline">\(\mathbf{\Sigma}_1 = \mathbf{\Sigma}_2 = \mathbf{\Sigma}\)</span>.</p></li>
<li><p>Independence between samples.</p></li>
</ul>
<hr>
<p>We summarize our data using the sufficient statistics:</p>
<ul>
<li><p>Sample means: <span class="math inline">\(\mathbf{\bar{y}}_1\)</span>, <span class="math inline">\(\mathbf{\bar{y}}_2\)</span>.</p></li>
<li><p>Sample covariance matrices: <span class="math inline">\(\mathbf{S}_1\)</span>, <span class="math inline">\(\mathbf{S}_2\)</span>.</p></li>
<li><p>Sample sizes: <span class="math inline">\(n_1, n_2\)</span>.</p></li>
</ul>
<p>Since we assume equal variance-covariance matrices, we compute a pooled estimator:</p>
<p><span class="math display">\[
\mathbf{S} = \frac{(n_1 - 1)\mathbf{S}_1 + (n_2 - 1)\mathbf{S}_2}{(n_1 -1) + (n_2 - 1)}
\]</span></p>
<p>with <span class="math inline">\(n_1 + n_2 - 2\)</span> degrees of freedom.</p>
<p>We test:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \mathbf{\mu}_1 = \mathbf{\mu}_2, \\
&amp;H_a: \mathbf{\mu}_1 \neq \mathbf{\mu}_2.
\end{aligned}
\]</span></p>
<p>That is, we check whether at least one element of <span class="math inline">\(\mathbf{\mu}_1 - \mathbf{\mu}_2\)</span> is different.</p>
<p>We use:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2\)</span> to estimate <span class="math inline">\(\mathbf{\mu}_1 - \mathbf{\mu}_2\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{S}\)</span> to estimate <span class="math inline">\(\mathbf{\Sigma}\)</span>.</p></li>
</ul>
<p>Since the two populations are <strong>independent</strong>, the covariance is:</p>
<p><span class="math display">\[
\text{Cov}(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2) = \text{Var}(\mathbf{\bar{y}}_1) + \text{Var}(\mathbf{\bar{y}}_2) = \mathbf{\Sigma} \left(\frac{1}{n_1} + \frac{1}{n_2} \right).
\]</span></p>
<p>The Hotelling’s <span class="math inline">\(T^2\)</span> statistic is:</p>
<p><span class="math display">\[
T^2 = (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)' \left\{ \mathbf{S} \left(\frac{1}{n_1} + \frac{1}{n_2} \right) \right\}^{-1} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2).
\]</span></p>
<p>which simplifies to:</p>
<p><span class="math display">\[
T^2 = \frac{n_1 n_2}{n_1 + n_2} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)' \mathbf{S}^{-1} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2).
\]</span></p>
<p>Reject <span class="math inline">\(H_0\)</span> if:</p>
<p><span class="math display">\[
T^2 \geq \frac{(n_1 + n_2 - 2)p}{n_1 + n_2 - p - 1} f_{(1- \alpha, p, n_1 + n_2 - p - 1)}
\]</span></p>
<p>or equivalently, using the F-statistic:</p>
<p><span class="math display">\[
F = \frac{n_1 + n_2 - p -1}{(n_1 + n_2 -2)p} T^2.
\]</span></p>
<p>Reject <span class="math inline">\(H_0\)</span> if:</p>
<p><span class="math display">\[
F \geq f_{(1- \alpha, p , n_1 + n_2 - p -1)}.
\]</span></p>
<hr>
<p>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence region for <span class="math inline">\(\mathbf{\mu}_1 - \mathbf{\mu}_2\)</span> consists of all vectors <span class="math inline">\(\mathbf{\delta}\)</span> satisfying:</p>
<p><span class="math display">\[
\frac{n_1 n_2}{n_1 + n_2} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2 - \mathbf{\delta})' \mathbf{S}^{-1} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2 - \mathbf{\delta}) \leq \frac{(n_1 + n_2 - 2)p}{n_1 + n_2 - p - 1} f_{(1-\alpha, p, n_1 + n_2 - p -1)}.
\]</span></p>
<p>For all linear combinations of <span class="math inline">\(\mathbf{\mu}_1 - \mathbf{\mu}_2\)</span>, the simultaneous confidence intervals:</p>
<p><span class="math display">\[
\mathbf{a'}(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2) \pm \sqrt{\frac{(n_1 + n_2 -2)p}{n_1 + n_2 - p -1} f_{(1-\alpha, p, n_1 + n_2 - p -1)} \times \mathbf{a'Sa} \left(\frac{1}{n_1} + \frac{1}{n_2}\right)}.
\]</span></p>
<p>For <span class="math inline">\(k\)</span> <strong>pairwise comparisons</strong>, Bonferroni intervals are:</p>
<p><span class="math display">\[
(\bar{y}_{1i} - \bar{y}_{2i}) \pm t_{(1-\alpha/2k, n_1 + n_2 - 2)} \sqrt{\left(\frac{1}{n_1}  + \frac{1}{n_2}\right) s_{ii}}.
\]</span></p>
<hr>
<div class="sourceCode" id="cb707"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>    <span class="co"># For multivariate analysis</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span>   <span class="co"># For Hotelling's T^2 test</span></span>
<span></span>
<span><span class="co"># Simulated dataset (p = 4 variables, two groups)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n1</span> <span class="op">&lt;-</span> <span class="fl">20</span>  <span class="co"># Sample size for group 1</span></span>
<span><span class="va">n2</span> <span class="op">&lt;-</span> <span class="fl">25</span>  <span class="co"># Sample size for group 2</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">4</span>    <span class="co"># Number of variables</span></span>
<span></span>
<span><span class="co"># Generate data for both groups</span></span>
<span><span class="va">mu1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span>  <span class="co"># Mean vector for group 1</span></span>
<span><span class="va">mu2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">p</span><span class="op">)</span>  <span class="co"># Mean vector for group 2</span></span>
<span><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>  <span class="co"># Identity covariance matrix</span></span>
<span></span>
<span><span class="va">data1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n1</span>, <span class="va">mu1</span>, <span class="va">Sigma</span><span class="op">)</span></span>
<span><span class="va">data2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n2</span>, <span class="va">mu2</span>, <span class="va">Sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute sample means and covariance matrices</span></span>
<span><span class="va">y1_bar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html">colMeans</a></span><span class="op">(</span><span class="va">data1</span><span class="op">)</span></span>
<span><span class="va">y2_bar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html">colMeans</a></span><span class="op">(</span><span class="va">data2</span><span class="op">)</span></span>
<span><span class="va">S1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data1</span><span class="op">)</span></span>
<span><span class="va">S2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute pooled covariance matrix</span></span>
<span><span class="va">S_pooled</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="va">n1</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">S1</span> <span class="op">+</span> <span class="op">(</span><span class="va">n2</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">S2</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">n1</span> <span class="op">+</span> <span class="va">n2</span> <span class="op">-</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Hotelling's T^2 statistic</span></span>
<span><span class="va">T2</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">y1_bar</span> <span class="op">-</span> <span class="va">y2_bar</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">S_pooled</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">n1</span> <span class="op">+</span> <span class="fl">1</span><span class="op">/</span><span class="va">n2</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="op">(</span><span class="va">y1_bar</span> <span class="op">-</span> <span class="va">y2_bar</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert to F-statistic</span></span>
<span><span class="va">F_stat</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="va">n1</span> <span class="op">+</span> <span class="va">n2</span> <span class="op">-</span> <span class="va">p</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="op">(</span><span class="va">n1</span> <span class="op">+</span> <span class="va">n2</span> <span class="op">-</span> <span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="va">T2</span></span>
<span><span class="va">F_crit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="va">p</span>, <span class="va">n1</span> <span class="op">+</span> <span class="va">n2</span> <span class="op">-</span> <span class="va">p</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Decision rule</span></span>
<span><span class="va">decision</span> <span class="op">&lt;-</span> <span class="va">F_stat</span> <span class="op">&gt;</span> <span class="va">F_crit</span></span>
<span></span>
<span><span class="co"># Print results</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span></span>
<span>  T2_statistic <span class="op">=</span> <span class="va">T2</span>,</span>
<span>  F_statistic <span class="op">=</span> <span class="va">F_stat</span>,</span>
<span>  F_critical_value <span class="op">=</span> <span class="va">F_crit</span>,</span>
<span>  Reject_H0 <span class="op">=</span> <span class="va">decision</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; $T2_statistic</span></span>
<span><span class="co">#&gt;          [,1]</span></span>
<span><span class="co">#&gt; [1,] 51.90437</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $F_statistic</span></span>
<span><span class="co">#&gt;          [,1]</span></span>
<span><span class="co">#&gt; [1,] 12.07078</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $F_critical_value</span></span>
<span><span class="co">#&gt; [1] 2.605975</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $Reject_H0</span></span>
<span><span class="co">#&gt;      [,1]</span></span>
<span><span class="co">#&gt; [1,] TRUE</span></span></code></pre></div>
</div>
<div id="model-assumptions-in-multivariate-tests" class="section level4" number="25.1.7.3">
<h4>
<span class="header-section-number">25.1.7.3</span> Model Assumptions in Multivariate Tests<a class="anchor" aria-label="anchor" href="#model-assumptions-in-multivariate-tests"><i class="fas fa-link"></i></a>
</h4>
<div id="effects-of-unequal-covariance-matrices" class="section level5" number="25.1.7.3.1">
<h5>
<span class="header-section-number">25.1.7.3.1</span> Effects of Unequal Covariance Matrices<a class="anchor" aria-label="anchor" href="#effects-of-unequal-covariance-matrices"><i class="fas fa-link"></i></a>
</h5>
<p>We assume that the two population covariance matrices are equal (<span class="math inline">\(\mathbf{\Sigma}_1 = \mathbf{\Sigma}_2\)</span>), but in reality, this assumption may not hold.</p>
<p><strong>Impact on Type I Error and Power</strong></p>
<ul>
<li>If <span class="math inline">\(n_1 = n_2\)</span> (large samples), the impact on Type I error rate and power is minimal.</li>
<li>If <span class="math inline">\(n_1 &gt; n_2\)</span> and eigenvalues of <span class="math inline">\(\mathbf{\Sigma}_1 \mathbf{\Sigma}_2^{-1}\)</span> are less than 1, the Type I error is inflated.</li>
<li>If <span class="math inline">\(n_1 &gt; n_2\)</span> and some eigenvalues of <span class="math inline">\(\mathbf{\Sigma}_1 \mathbf{\Sigma}_2^{-1}\)</span> are greater than 1, the Type I error is too small, reducing power.</li>
</ul>
<hr>
</div>
<div id="effects-of-non-normality" class="section level5" number="25.1.7.3.2">
<h5>
<span class="header-section-number">25.1.7.3.2</span> Effects of Non-Normality<a class="anchor" aria-label="anchor" href="#effects-of-non-normality"><i class="fas fa-link"></i></a>
</h5>
<p>Multivariate tests often assume normality, but real-world data may not follow a normal distribution.</p>
<p><strong>Impact on Test Performance</strong></p>
<ul>
<li>
<a href="sec-multivariate-methods.html#sec-two-sample-multivariate-tests">Two-sample</a> Hotelling’s <span class="math inline">\(T^2\)</span> test is robust to moderate departures from normality if both populations have similar distributions.</li>
<li>
<a href="sec-multivariate-methods.html#sec-one-sample-multivariate-tests">One-sample</a> Hotelling’s <span class="math inline">\(T^2\)</span> test is more sensitive to lack of normality, especially when the distribution is skewed.</li>
</ul>
<p><strong>Intuition</strong></p>
<ul>
<li>A <a href="sec-multivariate-methods.html#sec-one-sample-multivariate-tests">one-sample</a> test depends on the distribution of individual variables, making it more sensitive to normality violations.</li>
<li>A <a href="sec-multivariate-methods.html#sec-two-sample-multivariate-tests">two-sample</a> test depends on the distribution of differences, which may be less sensitive to non-normality if both groups have similar distributions.</li>
</ul>
<p><strong>Solutions</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Transform the data</strong> (e.g., log or Box-Cox transformation <a href="variable-transformation.html#variable-transformation">12</a>) to improve normality.</p></li>
<li><p><strong>Use large samples</strong> and rely on the <a href="prerequisites.html#central-limit-theorem">Central Limit Theorem</a>.</p></li>
<li>
<p><strong>Use alternative tests</strong> that do not assume normality:</p>
<ul>
<li>
<p><strong>Wald’s Test</strong> (Chi-square-based test), which does not require:</p>
<ul>
<li>Normality,</li>
<li>Equal sample sizes,</li>
<li>Equal covariance matrices.</li>
</ul>
</li>
<li>
<p>Test:</p>
<p><span class="math display">\[
H_0: \mathbf{\mu}_1 - \mathbf{\mu}_2 = 0
\]</span></p>
<p>using:</p>
<p><span class="math display">\[
(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)' \left( \frac{1}{n_1} \mathbf{S}_1 + \frac{1}{n_2} \mathbf{S}_2 \right)^{-1} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2) \dot{\sim} \chi^2_p.
\]</span></p>
</li>
</ul>
</li>
</ol>
<hr>
</div>
<div id="testing-equality-of-covariance-matrices" class="section level5" number="25.1.7.3.3">
<h5>
<span class="header-section-number">25.1.7.3.3</span> Testing Equality of Covariance Matrices<a class="anchor" aria-label="anchor" href="#testing-equality-of-covariance-matrices"><i class="fas fa-link"></i></a>
</h5>
<p>With <span class="math inline">\(k\)</span> independent groups, each having a <span class="math inline">\(p\)</span>-dimensional vector, we test:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \mathbf{\Sigma}_1 = \mathbf{\Sigma}_2 = \dots = \mathbf{\Sigma}_k = \mathbf{\Sigma}, \\
&amp;H_a: \text{At least two are different}.
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(H_0\)</span> holds, we use a pooled covariance estimate:</p>
<p><span class="math display">\[
\mathbf{S} = \frac{\sum_{i=1}^k (n_i -1)\mathbf{S}_i}{\sum_{i=1}^k (n_i - 1)}
\]</span></p>
<p>with <span class="math inline">\(\sum_{i=1}^k (n_i -1)\)</span> degrees of freedom.</p>
<hr>
</div>
<div id="bartletts-test-for-equal-covariances" class="section level5" number="25.1.7.3.4">
<h5>
<span class="header-section-number">25.1.7.3.4</span> Bartlett’s Test for Equal Covariances<a class="anchor" aria-label="anchor" href="#bartletts-test-for-equal-covariances"><i class="fas fa-link"></i></a>
</h5>
<p>Bartlett’s test is a likelihood ratio test for equality of covariance matrices.</p>
<p>Define:</p>
<p><span class="math display">\[
N = \sum_{i=1}^k n_i.
\]</span></p>
<p>Compute:</p>
<p><span class="math display">\[
M = (N - k) \log|\mathbf{S}| - \sum_{i=1}^k (n_i - 1) \log|\mathbf{S}_i|.
\]</span></p>
<p>Correction factor:</p>
<p><span class="math display">\[
C^{-1} = 1 - \frac{2p^2 + 3p - 1}{6(p+1)(k-1)} \left\{ \sum_{i=1}^k \left(\frac{1}{n_i - 1}\right) - \frac{1}{N-k} \right\}.
\]</span></p>
<p>Reject <span class="math inline">\(H_0\)</span> if:</p>
<p><span class="math display">\[
MC^{-1} &gt; \chi^2_{1- \alpha, (k-1)p(p+1)/2}.
\]</span></p>
<p><strong>Limitations</strong></p>
<ul>
<li>Sensitive to non-normality: If data are not normal, <span class="math inline">\(MC^{-1}\)</span> often follows a right-skewed distribution (i.e., shifted to the right of the nomial <span class="math inline">\(\chi^2\)</span> distriubtion), increasing false positives.</li>
<li>Best practice: Check univariate and multivariate normality first before using Bartlett’s test.</li>
</ul>
<hr>
<div class="sourceCode" id="cb708"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span>    <span class="co"># For multivariate normal data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span>   <span class="co"># Multivariate tests</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-forge.r-project.org/projects/car/">car</a></span><span class="op">)</span>     <span class="co"># Homogeneity of variance tests</span></span>
<span></span>
<span><span class="co"># Simulated dataset (three groups, p = 4 variables)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">n1</span> <span class="op">&lt;-</span> <span class="fl">20</span>  <span class="co"># Group 1 sample size</span></span>
<span><span class="va">n2</span> <span class="op">&lt;-</span> <span class="fl">25</span>  <span class="co"># Group 2 sample size</span></span>
<span><span class="va">n3</span> <span class="op">&lt;-</span> <span class="fl">30</span>  <span class="co"># Group 3 sample size</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">4</span>    <span class="co"># Number of variables</span></span>
<span></span>
<span><span class="co"># Generate data from different covariance structures</span></span>
<span><span class="va">mu1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span>  </span>
<span><span class="va">mu2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">p</span><span class="op">)</span>  </span>
<span><span class="va">mu3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="va">p</span><span class="op">)</span>  </span>
<span></span>
<span><span class="va">Sigma1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>         <span class="co"># Identity covariance for group 1</span></span>
<span><span class="va">Sigma2</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>     <span class="co"># Scaled identity for group 2</span></span>
<span><span class="va">Sigma3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="va">p</span>, <span class="va">p</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/diag.html">diag</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="va">p</span><span class="op">)</span>  <span class="co"># Structured covariance for group 3</span></span>
<span></span>
<span><span class="va">data1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n1</span>, <span class="va">mu1</span>, <span class="va">Sigma1</span><span class="op">)</span></span>
<span><span class="va">data2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n2</span>, <span class="va">mu2</span>, <span class="va">Sigma2</span><span class="op">)</span></span>
<span><span class="va">data3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html">mvrnorm</a></span><span class="op">(</span><span class="va">n3</span>, <span class="va">mu3</span>, <span class="va">Sigma3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a combined dataset</span></span>
<span><span class="va">group_labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"Group1"</span>, <span class="va">n1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"Group2"</span>, <span class="va">n2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"Group3"</span>, <span class="va">n3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>Group <span class="op">=</span> <span class="va">group_labels</span>, <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">rbind</a></span><span class="op">(</span><span class="va">data1</span>, <span class="va">data2</span>, <span class="va">data3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute covariance matrices</span></span>
<span><span class="va">S1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data1</span><span class="op">)</span></span>
<span><span class="va">S2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data2</span><span class="op">)</span></span>
<span><span class="va">S3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">data3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Bartlett's Test for Equal Covariances</span></span>
<span><span class="va">bartlett_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/bartlett.test.html">bartlett.test</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>,<span class="op">-</span><span class="fl">1</span><span class="op">]</span>, g <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">Group</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">bartlett_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Bartlett test of homogeneity of variances</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  data[, -1]</span></span>
<span><span class="co">#&gt; Bartlett's K-squared = 0.99333, df = 3, p-value = 0.8029</span></span>
<span></span>
<span><span class="co"># Box’s M test (alternative for multivariate homogeneity)</span></span>
<span><span class="va">box_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://friendly.github.io/heplots/reference/boxM.html">boxM</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>,<span class="op">-</span><span class="fl">1</span><span class="op">]</span>, <span class="va">data</span><span class="op">$</span><span class="va">Group</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">box_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Box's M-test for Homogeneity of Covariance Matrices</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  data[, -1]</span></span>
<span><span class="co">#&gt; Chi-Sq (approx.) = 51.039, df = 20, p-value = 0.000157</span></span></code></pre></div>
<hr>
</div>
</div>
<div id="two-sample-repeated-measures-analysis" class="section level4" number="25.1.7.4">
<h4>
<span class="header-section-number">25.1.7.4</span> Two-Sample Repeated Measures Analysis<a class="anchor" aria-label="anchor" href="#two-sample-repeated-measures-analysis"><i class="fas fa-link"></i></a>
</h4>
<p>Define <span class="math inline">\(\mathbf{y}_{hi}\)</span> as the <span class="math inline">\(t\)</span>-dimensional response vector for subject <span class="math inline">\(i\)</span> in group <span class="math inline">\(h\)</span>:</p>
<p><span class="math display">\[
\mathbf{y}_{hi} = (y_{hi1}, y_{hi2}, ..., y_{hit})'
\]</span></p>
<p>Assume:</p>
<ul>
<li><p><strong>Group 1</strong>: <span class="math inline">\(\mathbf{y}_{11}, ..., \mathbf{y}_{1n_1} \sim N_t(\mathbf{\mu}_1, \mathbf{\Sigma})\)</span> (i.e., iid from a common distribution).</p></li>
<li><p><strong>Group 2</strong>: <span class="math inline">\(\mathbf{y}_{21}, ..., \mathbf{y}_{2n_2} \sim N_t(\mathbf{\mu}_2, \mathbf{\Sigma})\)</span>.</p></li>
</ul>
<p>We test whether the mean response vectors are <strong>equal across groups</strong>:</p>
<p><span class="math display">\[
H_0: \mathbf{C}(\mathbf{\mu}_1 - \mathbf{\mu}_2) = \mathbf{0}_c.
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{C}\)</span> is a contrast matrix of dimensions <span class="math inline">\(c \times t\)</span> (rank <span class="math inline">\(c\)</span>, where <span class="math inline">\(c \leq t\)</span>).</p></li>
<li><p>If <span class="math inline">\(H_0\)</span> is true, the two groups have the same mean structure.</p></li>
</ul>
<hr>
<p>The <strong>Hotelling’s</strong> <span class="math inline">\(T^2\)</span> statistic for repeated measures is:</p>
<p><span class="math display">\[
T^2 = \frac{n_1 n_2}{n_1 + n_2} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)' \mathbf{C}' (\mathbf{CSC'})^{-1} \mathbf{C} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2).
\]</span></p>
<p>where <span class="math inline">\(\mathbf{S}\)</span> is the pooled covariance matrix. The corresponding F-statistic follows:</p>
<p><span class="math display">\[
F = \frac{n_1 + n_2 - c - 1}{(n_1 + n_2 - 2)c} T^2 \sim f_{(c, n_1 + n_2 - c - 1)}.
\]</span></p>
<p>under the null hypothesis.</p>
<hr>
<p>If we reject <span class="math inline">\(H_0: \mathbf{\mu}_1 = \mathbf{\mu}_2\)</span>, we may test whether the <strong>profiles are parallel</strong>:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_{11} - \mu_{21} &amp;= \mu_{12} - \mu_{22}, \\
&amp;\vdots \\
\mu_{1t-1} - \mu_{2t-1} &amp;= \mu_{1t} - \mu_{2t}.
\end{aligned}
\]</span></p>
<p>This is expressed as:</p>
<p><span class="math display">\[
H_0: \mathbf{C}(\mu_1 - \mu_2) = \mathbf{0}_c,
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(c = t - 1\)</span> (one fewer than the number of time points).</li>
<li>The contrast matrix <span class="math inline">\(\mathbf{C}\)</span> is:</li>
</ul>
<p><span class="math display">\[
\mathbf{C} =
\begin{bmatrix}
1 &amp; -1 &amp; 0 &amp; \dots &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \dots &amp; -1
\end{bmatrix}_{(t-1) \times t}.
\]</span></p>
<hr>
<ol style="list-style-type: decimal">
<li>
<strong>One-Sample Hotelling’s</strong> <span class="math inline">\(T^2\)</span> Test</li>
</ol>
<div class="sourceCode" id="cb709"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ICSNP</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Data: Measurements on 3 variables</span></span>
<span><span class="va">plants</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    y1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2.11</span>, <span class="fl">2.36</span>, <span class="fl">2.13</span>, <span class="fl">2.78</span>, <span class="fl">2.17</span><span class="op">)</span>,</span>
<span>    y2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10.1</span>, <span class="fl">35.0</span>, <span class="fl">2.0</span>, <span class="fl">6.0</span>, <span class="fl">2.0</span><span class="op">)</span>,</span>
<span>    y3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3.4</span>, <span class="fl">4.1</span>, <span class="fl">1.9</span>, <span class="fl">3.8</span>, <span class="fl">1.7</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Center the data with hypothesized means</span></span>
<span><span class="va">plants_ctr</span> <span class="op">&lt;-</span> <span class="va">plants</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/transmute.html">transmute</a></span><span class="op">(</span>y1_ctr <span class="op">=</span> <span class="va">y1</span> <span class="op">-</span> <span class="fl">2.85</span>,</span>
<span>              y2_ctr <span class="op">=</span> <span class="va">y2</span> <span class="op">-</span> <span class="fl">15.0</span>,</span>
<span>              y3_ctr <span class="op">=</span> <span class="va">y3</span> <span class="op">-</span> <span class="fl">6.0</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform Wilks' Lambda test for one-sample Hotelling's T^2</span></span>
<span><span class="va">onesamp_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">plants_ctr</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span>, test <span class="op">=</span> <span class="st">"Wilks"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">onesamp_fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; Analysis of Variance Table</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             Df    Wilks approx F num Df den Df  Pr(&gt;F)  </span></span>
<span><span class="co">#&gt; (Intercept)  1 0.054219   11.629      3      2 0.08022 .</span></span>
<span><span class="co">#&gt; Residuals    4                                          </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<ul>
<li><p>If the p-value is large, we fail to reject <span class="math inline">\(H_0\)</span> and conclude that the hypothesized mean vector is plausible.</p></li>
<li><p>If the p-value is small, we reject <span class="math inline">\(H_0\)</span> and infer that the sample mean significantly differs from the hypothesized values.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Paired-Sample Hotelling’s</strong> <span class="math inline">\(T^2\)</span> <strong>Test</strong>
</li>
</ol>
<p>Used when each subject has two sets of paired measurements.</p>
<div class="sourceCode" id="cb710"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Data: Commercial vs. State Lab Waste Analysis</span></span>
<span><span class="va">waste</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    case <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">11</span>,</span>
<span>    com_y1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">6</span>, <span class="fl">18</span>, <span class="fl">8</span>, <span class="fl">11</span>, <span class="fl">34</span>, <span class="fl">28</span>, <span class="fl">71</span>, <span class="fl">43</span>, <span class="fl">33</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>    com_y2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">27</span>, <span class="fl">23</span>, <span class="fl">64</span>, <span class="fl">44</span>, <span class="fl">30</span>, <span class="fl">75</span>, <span class="fl">26</span>, <span class="fl">124</span>, <span class="fl">54</span>, <span class="fl">30</span>, <span class="fl">14</span><span class="op">)</span>,</span>
<span>    state_y1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">28</span>, <span class="fl">36</span>, <span class="fl">35</span>, <span class="fl">15</span>, <span class="fl">44</span>, <span class="fl">42</span>, <span class="fl">54</span>, <span class="fl">34</span>, <span class="fl">29</span>, <span class="fl">39</span><span class="op">)</span>,</span>
<span>    state_y2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">15</span>, <span class="fl">13</span>, <span class="fl">22</span>, <span class="fl">29</span>, <span class="fl">31</span>, <span class="fl">64</span>, <span class="fl">30</span>, <span class="fl">64</span>, <span class="fl">56</span>, <span class="fl">20</span>, <span class="fl">21</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute differences between commercial and state labs</span></span>
<span><span class="va">waste_diff</span> <span class="op">&lt;-</span> <span class="va">waste</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/transmute.html">transmute</a></span><span class="op">(</span>y1_diff <span class="op">=</span> <span class="va">com_y1</span> <span class="op">-</span> <span class="va">state_y1</span>,</span>
<span>              y2_diff <span class="op">=</span> <span class="va">com_y2</span> <span class="op">-</span> <span class="va">state_y2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform Paired Hotelling’s T^2 test</span></span>
<span><span class="va">paired_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ICSNP/man/HotellingsT.html">HotellingsT2</a></span><span class="op">(</span><span class="va">waste_diff</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">paired_fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hotelling's one sample T2-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  waste_diff</span></span>
<span><span class="co">#&gt; T.2 = 6.1377, df1 = 2, df2 = 9, p-value = 0.02083</span></span>
<span><span class="co">#&gt; alternative hypothesis: true location is not equal to c(0,0)</span></span></code></pre></div>
<ul>
<li><p>Reject <span class="math inline">\(H_0\)</span>: Measurements from the two labs significantly differ.</p></li>
<li><p>Fail to reject <span class="math inline">\(H_0\)</span>: No significant difference between the two labs.</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>
<strong>Independent-Sample Hotelling’s</strong> <span class="math inline">\(T^2\)</span> <strong>Test with Bartlett’s Test</strong>
</li>
</ol>
<p>Used when comparing <strong>two independent groups</strong>.</p>
<div class="sourceCode" id="cb711"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Read steel strength data</span></span>
<span><span class="va">steel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"images/steel.dat"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">steel</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Temp"</span>, <span class="st">"Yield"</span>, <span class="st">"Strength"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Scatter plot of Yield vs Strength</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">steel</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Yield</span>, y <span class="op">=</span> <span class="va">Strength</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="va">Temp</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">33</span>, y <span class="op">=</span> <span class="fl">57.5</span>, xend <span class="op">=</span> <span class="fl">42</span>, yend <span class="op">=</span> <span class="fl">65</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="25-multivariate_files/figure-html/unnamed-chunk-9-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb712"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Bartlett's test for equality of covariances</span></span>
<span><span class="va">bart_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://friendly.github.io/heplots/reference/boxM.html">boxM</a></span><span class="op">(</span><span class="va">steel</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, <span class="va">steel</span><span class="op">$</span><span class="va">Temp</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">bart_test</span><span class="op">)</span>  <span class="co"># If p &gt; 0.05, fail to reject equal covariances</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Box's M-test for Homogeneity of Covariance Matrices</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  steel[, -1]</span></span>
<span><span class="co">#&gt; Chi-Sq (approx.) = 0.38077, df = 3, p-value = 0.9442</span></span>
<span></span>
<span><span class="co"># Multivariate analysis of variance (MANOVA) using Wilks' Lambda</span></span>
<span><span class="va">twosamp_fit</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">Yield</span>, <span class="va">Strength</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Temp</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">steel</span><span class="op">)</span>, </span>
<span>          test <span class="op">=</span> <span class="st">"Wilks"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">twosamp_fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; Analysis of Variance Table</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              Df    Wilks approx F num Df den Df    Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; (Intercept)   1 0.001177   3818.1      2      9 6.589e-14 ***</span></span>
<span><span class="co">#&gt; factor(Temp)  1 0.294883     10.8      2      9  0.004106 ** </span></span>
<span><span class="co">#&gt; Residuals    10                                              </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="co"># Independent-Sample Hotelling's T^2 Test</span></span>
<span><span class="va">twosamp_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ICSNP/man/HotellingsT.html">HotellingsT2</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">steel</span><span class="op">$</span><span class="va">Yield</span>, <span class="va">steel</span><span class="op">$</span><span class="va">Strength</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">steel</span><span class="op">$</span><span class="va">Temp</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://www.math.uzh.ch/pages/spam/reference/print.html">print</a></span><span class="op">(</span><span class="va">twosamp_fit2</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hotelling's two sample T2-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  cbind(steel$Yield, steel$Strength) by factor(steel$Temp)</span></span>
<span><span class="co">#&gt; T.2 = 10.76, df1 = 2, df2 = 9, p-value = 0.004106</span></span>
<span><span class="co">#&gt; alternative hypothesis: true location difference is not equal to c(0,0)</span></span></code></pre></div>
<ul>
<li><p>Reject <span class="math inline">\(H_0\)</span>: The two temperature groups have significantly different mean vectors.</p></li>
<li><p>Fail to reject <span class="math inline">\(H_0\)</span>: No significant difference between groups.</p></li>
</ul>
<p><strong>Summary of Repeated Measures Hypothesis Testing</strong></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="30%">
<col width="46%">
<col width="23%">
</colgroup>
<thead><tr class="header">
<th><strong>Test</strong></th>
<th><strong>Hypothesis</strong></th>
<th><strong>Application</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<strong>One-Sample Hotelling’s</strong> <span class="math inline">\(T^2\)</span>
</td>
<td><span class="math inline">\(H_0: \mathbf{\mu} = \mathbf{\mu}_0\)</span></td>
<td>Single group mean vector test</td>
</tr>
<tr class="even">
<td>
<strong>Paired-Sample Hotelling’s</strong> <span class="math inline">\(T^2\)</span>
</td>
<td><span class="math inline">\(H_0: \mathbf{\mu}_d = 0\)</span></td>
<td>Paired measurements comparison</td>
</tr>
<tr class="odd">
<td>
<strong>Independent-Sample Hotelling’s</strong> <span class="math inline">\(T^2\)</span>
</td>
<td><span class="math inline">\(H_0: \mathbf{\mu}_1 = \mathbf{\mu}_2\)</span></td>
<td>Two-group mean vector test</td>
</tr>
<tr class="even">
<td><strong>Parallel Profiles Test</strong></td>
<td><span class="math inline">\(H_0: \mathbf{C}(\mathbf{\mu}_1 - \mathbf{\mu}_2) = \mathbf{0}\)</span></td>
<td>Testing parallel time trends</td>
</tr>
</tbody>
</table></div>
<hr>
</div>
</div>
</div>
<div id="sec-multivariate-analysis-of-variance" class="section level2" number="25.2">
<h2>
<span class="header-section-number">25.2</span> Multivariate Analysis of Variance<a class="anchor" aria-label="anchor" href="#sec-multivariate-analysis-of-variance"><i class="fas fa-link"></i></a>
</h2>
<p>Multivariate Analysis of Variance (MANOVA) is an extension of the univariate Analysis of Variance (<a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a>) that allows researchers to examine multiple dependent variables simultaneously. Unlike <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a>, which evaluates differences in means for a single dependent variable across groups, MANOVA assesses whether there are statistically significant differences among groups across two or more correlated dependent variables.</p>
<p>By considering multiple dependent variables at once, MANOVA accounts for interdependencies between them, reducing the likelihood of Type I errors that may arise from conducting multiple separate <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a> tests. It is particularly useful in fields such as psychology, marketing, and social sciences, where multiple outcome measures are often interrelated.</p>
<p>This technique is commonly applied in experimental and observational studies where researchers seek to determine the impact of categorical independent variables on multiple continuous dependent variables.</p>
<div id="one-way-manova" class="section level3" number="25.2.1">
<h3>
<span class="header-section-number">25.2.1</span> One-Way MANOVA<a class="anchor" aria-label="anchor" href="#one-way-manova"><i class="fas fa-link"></i></a>
</h3>
<p>One-way MANOVA extends the univariate one-way <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a> to multiple dependent variables. It is used to compare treatment means across <span class="math inline">\(h\)</span> different populations when the response consists of multiple correlated variables.</p>
<p>Let the populations be indexed by <span class="math inline">\(i = 1, 2, \dots, h\)</span>, and the observations within each population be indexed by <span class="math inline">\(j = 1, 2, \dots, n_i\)</span>. We assume:</p>
<p>Population 1: <span class="math inline">\(\mathbf{y}_{11}, \mathbf{y}_{12}, \dots, \mathbf{y}_{1n_1} \sim \text{i.i.d. } N_p (\boldsymbol{\mu}_1, \boldsymbol{\Sigma})\)</span></p>
<p><span class="math inline">\(\vdots\)</span></p>
<p>Population <span class="math inline">\(h\)</span>: <span class="math inline">\(\mathbf{y}_{h1}, \mathbf{y}_{h2}, \dots, \mathbf{y}_{hn_h} \sim \text{i.i.d. } N_p (\boldsymbol{\mu}_h, \boldsymbol{\Sigma})\)</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{y}_{ij}\)</span> is a <span class="math inline">\(p\)</span>-dimensional response vector for the <span class="math inline">\(j\)</span>th observation in the <span class="math inline">\(i\)</span>th group.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\mu}_i\)</span> is the population mean vector for the <span class="math inline">\(i\)</span>th group.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\Sigma}\)</span> is the common covariance matrix across all groups.</p></li>
</ul>
<p><strong>Assumptions</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Independence</strong>: Observations within and across groups are independent.</li>
<li>
<strong>Multivariate Normality</strong>: Each population follows a <span class="math inline">\(p\)</span>-variate normal distribution.</li>
<li>
<strong>Homogeneity of Covariance Matrices</strong>: The covariance matrix <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is the same for all groups.</li>
</ol>
<p>For each group <span class="math inline">\(i\)</span>, we can compute:</p>
<ul>
<li><p>Sample mean vector: <span class="math inline">\(\mathbf{\bar{y}}_i = \frac{1}{n_i} \sum_{j=1}^{n_i} \mathbf{y}_{ij}\)</span></p></li>
<li><p>Sample covariance matrix: <span class="math inline">\(\mathbf{S}_i = \frac{1}{n_i - 1} \sum_{j=1}^{n_i} (\mathbf{y}_{ij} - \mathbf{\bar{y}}_i)(\mathbf{y}_{ij} - \mathbf{\bar{y}}_i)'\)</span></p></li>
<li><p>Pooled covariance matrix: <span class="math display">\[
  \mathbf{S} = \frac{1}{\sum_{i=1}^{h} (n_i - 1)} \sum_{i=1}^{h} (n_i - 1) \mathbf{S}_i
  \]</span></p></li>
</ul>
<div id="effects-model-formulation" class="section level4" number="25.2.1.1">
<h4>
<span class="header-section-number">25.2.1.1</span> Effects Model Formulation<a class="anchor" aria-label="anchor" href="#effects-model-formulation"><i class="fas fa-link"></i></a>
</h4>
<p>Similar to the univariate one-way <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a>, the effects model can be written as:</p>
<p><span class="math display">\[
\boldsymbol{\mu}_i = \boldsymbol{\mu} + \boldsymbol{\tau}_i
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{\mu}_i\)</span> is the mean vector for group <span class="math inline">\(i\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\mu}\)</span> is the overall mean effect.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\tau}_i\)</span> is the treatment effect for group <span class="math inline">\(i\)</span>.</p></li>
</ul>
<p>The observational model is:</p>
<p><span class="math display">\[
\mathbf{y}_{ij} = \boldsymbol{\mu} + \boldsymbol{\tau}_i + \boldsymbol{\epsilon}_{ij}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\epsilon}_{ij} \sim N_p(\mathbf{0}, \boldsymbol{\Sigma})\)</span> represents the residual variation.</p>
<p>Since the model is overparameterized, we impose the constraint:</p>
<p><span class="math display">\[
\sum_{i=1}^h n_i \boldsymbol{\tau}_i = \mathbf{0}
\]</span></p>
<p>or equivalently, we may set <span class="math inline">\(\boldsymbol{\tau}_h = \mathbf{0}\)</span>.</p>
<hr>
<p>Analogous to univariate <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a>, the total variability is partitioned as:</p>
<p><span class="math display">\[
\sum_{i = 1}^h \sum_{j = 1}^{n_i} (\mathbf{y}_{ij} - \mathbf{\bar{y}})(\mathbf{y}_{ij} - \mathbf{\bar{y}})' =
\sum_{i = 1}^h n_i (\mathbf{\bar{y}}_i - \mathbf{\bar{y}})(\mathbf{\bar{y}}_i - \mathbf{\bar{y}})' +
\sum_{i=1}^h \sum_{j = 1}^{n_i} (\mathbf{y}_{ij} - \mathbf{\bar{y}}_i)(\mathbf{y}_{ij} - \mathbf{\bar{y}}_i)'
\]</span></p>
<p>where:</p>
<ul>
<li><p><strong>LHS</strong>: Total corrected sums of squares and cross-products (SSCP) matrix.</p></li>
<li>
<p><strong>RHS</strong>:</p>
<ul>
<li><p>First term: Between-groups SSCP matrix (denoted <span class="math inline">\(\mathbf{H}\)</span>).</p></li>
<li><p>Second term: Within-groups (residual) SSCP matrix (denoted <span class="math inline">\(\mathbf{E}\)</span>).</p></li>
</ul>
</li>
</ul>
<p>The total within-group variation is:</p>
<p><span class="math display">\[
\mathbf{E} = (n_1 - 1)\mathbf{S}_1  + \dots + (n_h -1) \mathbf{S}_h = (\sum_{i=1}^h n_i - h) \mathbf{S}
\]</span></p>
<div class="inline-table"><table class="table table-sm">
<caption>MANOVA Table</caption>
<thead><tr class="header">
<th>Source</th>
<th>SSCP</th>
<th>df</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Treatment</td>
<td><span class="math inline">\(\mathbf{H}\)</span></td>
<td><span class="math inline">\(h -1\)</span></td>
</tr>
<tr class="even">
<td>Residual (error)</td>
<td><span class="math inline">\(\mathbf{E}\)</span></td>
<td><span class="math inline">\(\sum_{i= 1}^h n_i - h\)</span></td>
</tr>
<tr class="odd">
<td>Total Corrected</td>
<td><span class="math inline">\(\mathbf{H + E}\)</span></td>
<td><span class="math inline">\(\sum_{i=1}^h n_i -1\)</span></td>
</tr>
</tbody>
</table></div>
<div id="hypothesis-testing-1" class="section level5" number="25.2.1.1.1">
<h5>
<span class="header-section-number">25.2.1.1.1</span> Hypothesis Testing<a class="anchor" aria-label="anchor" href="#hypothesis-testing-1"><i class="fas fa-link"></i></a>
</h5>
<p>The null hypothesis states:</p>
<p><span class="math display">\[
H_0: \boldsymbol{\tau}_1 = \boldsymbol{\tau}_2 = \dots = \boldsymbol{\tau}_h = \mathbf{0}
\]</span></p>
<p>which implies that all group mean vectors are equal.</p>
<p>To test <span class="math inline">\(H_0\)</span>, we assess the relative sizes of <span class="math inline">\(\mathbf{E}\)</span> and <span class="math inline">\(\mathbf{H + E}\)</span> using Wilks’ Lambda:</p>
<p>Wilks’ Lambda is defined as:</p>
<p><span class="math display">\[
\Lambda^* = \frac{|\mathbf{E}|}{|\mathbf{H + E}|}
\]</span></p>
<p>Properties:</p>
<ol style="list-style-type: decimal">
<li>In the univariate case, Wilks’ Lambda reduces to the F-statistic.</li>
<li>The exact distribution of <span class="math inline">\(\Lambda^*\)</span> is known in special cases.</li>
<li>For large samples, we reject <span class="math inline">\(H_0\)</span> if:</li>
</ol>
<p><span class="math display">\[
-\left( \sum_{i=1}^h n_i - 1 - \frac{p+h}{2} \right) \log(\Lambda^*) &gt; \chi^2_{(1-\alpha, p(h-1))}
\]</span></p>
<div class="sourceCode" id="cb713"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit MANOVA model</span></span>
<span><span class="va">manova_fit</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/manova.html">manova</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">Sepal.Length</span>, <span class="va">Sepal.Width</span>, <span class="va">Petal.Length</span>, <span class="va">Petal.Width</span><span class="op">)</span> <span class="op">~</span> <span class="va">Species</span>,</span>
<span>           data <span class="op">=</span> <span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summary of the MANOVA test</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">manova_fit</span>, test <span class="op">=</span> <span class="st">"Wilks"</span><span class="op">)</span></span>
<span><span class="co">#&gt;            Df    Wilks approx F num Df den Df    Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; Species     2 0.023439   199.15      8    288 &lt; 2.2e-16 ***</span></span>
<span><span class="co">#&gt; Residuals 147                                              </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
</div>
</div>
<div id="testing-general-hypotheses-in-manova" class="section level4" number="25.2.1.2">
<h4>
<span class="header-section-number">25.2.1.2</span> Testing General Hypotheses in MANOVA<a class="anchor" aria-label="anchor" href="#testing-general-hypotheses-in-manova"><i class="fas fa-link"></i></a>
</h4>
<p>We consider <span class="math inline">\(h\)</span> different treatments, where the <span class="math inline">\(i\)</span>-th treatment is applied to <span class="math inline">\(n_i\)</span> subjects, each observed for <span class="math inline">\(p\)</span> repeated measures. This results in a <span class="math inline">\(p\)</span>-dimensional observation vector for each subject in a random sample from each of the <span class="math inline">\(h\)</span> different treatment populations.</p>
<p>The general MANOVA model can be written as:</p>
<p><span class="math display">\[
\mathbf{y}_{ij} = \boldsymbol{\mu} + \boldsymbol{\tau}_i + \boldsymbol{\epsilon}_{ij}, \quad i = 1, \dots, h; \quad j = 1, \dots, n_i
\]</span></p>
<p>Equivalently, in matrix notation:</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{XB} + \boldsymbol{\epsilon}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{Y}_{(n \times p)}\)</span> is the matrix of response variables.</p></li>
<li><p><span class="math inline">\(\mathbf{X}_{(n \times h)}\)</span> is the design matrix. - <span class="math inline">\(\mathbf{B}_{(h \times p)}\)</span> contains the treatment effects.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\epsilon}_{(n \times p)}\)</span> is the error matrix.</p></li>
</ul>
<p>The response matrix:</p>
<p><span class="math display">\[
\mathbf{Y}_{(n \times p)} =
\begin{bmatrix}
\mathbf{y}_{11}' \\
\vdots \\
\mathbf{y}_{1n_1}' \\
\vdots \\
\mathbf{y}_{hn_h}'
\end{bmatrix}
\]</span></p>
<p>The coefficient matrix:</p>
<p><span class="math display">\[
\mathbf{B}_{(h \times p)} =
\begin{bmatrix}
\boldsymbol{\mu}' \\
\boldsymbol{\tau}_1' \\
\vdots \\
\boldsymbol{\tau}_{h-1}'
\end{bmatrix}
\]</span></p>
<p>The error matrix:</p>
<p><span class="math display">\[
\boldsymbol{\epsilon}_{(n \times p)} =
\begin{bmatrix}
\boldsymbol{\epsilon}_{11}' \\
\vdots \\
\boldsymbol{\epsilon}_{1n_1}' \\
\vdots \\
\boldsymbol{\epsilon}_{hn_h}'
\end{bmatrix}
\]</span></p>
<p>The design matrix <span class="math inline">\(\mathbf{X}\)</span> encodes the treatment assignments:</p>
<p><span class="math display">\[
\mathbf{X}_{(n \times h)} =
\begin{bmatrix}
1 &amp; 1 &amp; 0 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp;  &amp; \vdots \\
1 &amp; 1 &amp; 0 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \dots &amp; \vdots \\
1 &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
1 &amp; 0 &amp; 0 &amp; \dots &amp; 0
\end{bmatrix}
\]</span></p>
<div id="estimation-1" class="section level5" number="25.2.1.2.1">
<h5>
<span class="header-section-number">25.2.1.2.1</span> Estimation<a class="anchor" aria-label="anchor" href="#estimation-1"><i class="fas fa-link"></i></a>
</h5>
<p>The least squares estimate of <span class="math inline">\(\mathbf{B}\)</span> is given by:</p>
<p><span class="math display">\[
\hat{\mathbf{B}} = (\mathbf{X'X})^{-1} \mathbf{X'Y}
\]</span></p>
<p>Since the rows of <span class="math inline">\(\mathbf{Y}\)</span> are independent, we assume:</p>
<p><span class="math display">\[
\operatorname{Var}(\mathbf{Y}) = \mathbf{I}_n \otimes \boldsymbol{\Sigma}
\]</span></p>
<p>where <span class="math inline">\(\otimes\)</span> denotes the Kronecker product, resulting in an <span class="math inline">\(np \times np\)</span> covariance matrix.</p>
</div>
<div id="hypothesis-testing-2" class="section level5" number="25.2.1.2.2">
<h5>
<span class="header-section-number">25.2.1.2.2</span> Hypothesis Testing<a class="anchor" aria-label="anchor" href="#hypothesis-testing-2"><i class="fas fa-link"></i></a>
</h5>
<p>The general hypothesis in MANOVA can be written as:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;H_0: \mathbf{LBM} = 0 \\
&amp;H_a: \mathbf{LBM} \neq 0
\end{aligned}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{L}\)</span> is a <span class="math inline">\((g \times h)\)</span> matrix of full row rank (<span class="math inline">\(g \le h\)</span>), specifying comparisons across groups.</p></li>
<li><p><span class="math inline">\(\mathbf{M}\)</span> is a <span class="math inline">\((p \times u)\)</span> matrix of full column rank (<span class="math inline">\(u \le p\)</span>), specifying comparisons across traits.</p></li>
</ul>
<p>To evaluate the effect of treatments in the MANOVA framework, we compute the treatment corrected sums of squares and cross-product (SSCP) matrix:</p>
<p><span class="math display">\[
\mathbf{H} = \mathbf{M'Y'X(X'X)^{-1}L'[L(X'X)^{-1}L']^{-1}L(X'X)^{-1}X'YM}
\]</span></p>
<p>If we are testing the null hypothesis:</p>
<p><span class="math display">\[
H_0: \mathbf{LBM} = \mathbf{D}
\]</span></p>
<p>then the corresponding SSCP matrix is:</p>
<p><span class="math display">\[
\mathbf{H} = (\mathbf{\hat{LBM}} - \mathbf{D})'[\mathbf{X(X'X)^{-1}L}]^{-1}(\mathbf{\hat{LBM}} - \mathbf{D})
\]</span></p>
<p>Similarly, the residual (error) SSCP matrix is given by:</p>
<p><span class="math display">\[
\mathbf{E} = \mathbf{M'Y'[I - X(X'X)^{-1}X']Y M}
\]</span></p>
<p>which can also be expressed as:</p>
<p><span class="math display">\[
\mathbf{E} = \mathbf{M'[Y'Y - \hat{B}'(X'X)^{-1} \hat{B}]M}
\]</span></p>
<p>These matrices, <span class="math inline">\(\mathbf{H}\)</span> and <span class="math inline">\(\mathbf{E}\)</span>, serve as the basis for assessing the relative treatment effect in a multivariate setting.</p>
<hr>
</div>
<div id="test-statistics-in-manova" class="section level5" number="25.2.1.2.3">
<h5>
<span class="header-section-number">25.2.1.2.3</span> Test Statistics in MANOVA<a class="anchor" aria-label="anchor" href="#test-statistics-in-manova"><i class="fas fa-link"></i></a>
</h5>
<p>To test whether treatment effects significantly impact the multivariate response, we examine the eigenvalues of <span class="math inline">\(\mathbf{HE}^{-1}\)</span>, leading to several common test statistics:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Wilks’ Lambda</strong>: <span class="math display">\[
\Lambda^* = \frac{|\mathbf{E}|}{|\mathbf{H} + \mathbf{E}|}
\]</span> A smaller <span class="math inline">\(\Lambda^*\)</span> indicates a greater difference among group mean vectors. The degrees of freedom depend on the ranks of <span class="math inline">\(\mathbf{L}, \mathbf{M},\)</span> and <span class="math inline">\(\mathbf{X}\)</span>.</p></li>
<li><p><strong>Lawley-Hotelling Trace</strong>: <span class="math display">\[
U = \operatorname{tr}(\mathbf{HE}^{-1})
\]</span> This statistic sums the eigenvalues of <span class="math inline">\(\mathbf{HE}^{-1}\)</span>, capturing the overall treatment effect.</p></li>
<li><p><strong>Pillai’s Trace</strong>: <span class="math display">\[
V = \operatorname{tr}(\mathbf{H}(\mathbf{H} + \mathbf{E})^{-1})
\]</span> This test is known for its robustness against violations of MANOVA assumptions.</p></li>
<li><p><strong>Roy’s Maximum Root</strong>: The largest eigenvalue of <span class="math inline">\(\mathbf{HE}^{-1}\)</span>. It focuses on the strongest treatment effect present in the data.</p></li>
</ol>
<p>For large <span class="math inline">\(n\)</span>, under <span class="math inline">\(H_0\)</span>:</p>
<p><span class="math display">\[
-\left(n - 1 - \frac{p + h}{2} \right) \ln \Lambda^* \sim \chi^2_{p(h-1)}
\]</span></p>
<p>In certain cases, specific values of <span class="math inline">\(p\)</span> and <span class="math inline">\(h\)</span> allow for an exact <span class="math inline">\(F\)</span>-distribution under <span class="math inline">\(H_0\)</span>.</p>
<div class="sourceCode" id="cb714"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## One-Way MANOVA</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-forge.r-project.org/projects/car/">car</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rvlenth.github.io/emmeans/">emmeans</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">profileR</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Read in the data</span></span>
<span><span class="va">gpagmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"images/gpagmat.dat"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Change the variable names</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">gpagmat</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"y1"</span>, <span class="st">"y2"</span>, <span class="st">"admit"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check the structure of the dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">gpagmat</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    85 obs. of  3 variables:</span></span>
<span><span class="co">#&gt;  $ y1   : num  2.96 3.14 3.22 3.29 3.69 3.46 3.03 3.19 3.63 3.59 ...</span></span>
<span><span class="co">#&gt;  $ y2   : int  596 473 482 527 505 693 626 663 447 588 ...</span></span>
<span><span class="co">#&gt;  $ admit: int  1 1 1 1 1 1 1 1 1 1 ...</span></span>
<span></span>
<span><span class="co"># Plot the data</span></span>
<span><span class="va">gg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gpagmat</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">y1</span>, y <span class="op">=</span> <span class="va">y2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="va">admit</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">admit</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_colour_discrete.html">scale_color_discrete</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Admission"</span>,</span>
<span>                         labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Admit"</span>, <span class="st">"Do not admit"</span>, <span class="st">"Borderline"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"GPA"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"GMAT"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit a one-way MANOVA model</span></span>
<span><span class="va">oneway_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/manova.html">manova</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y1</span>, <span class="va">y2</span><span class="op">)</span> <span class="op">~</span> <span class="va">admit</span>, data <span class="op">=</span> <span class="va">gpagmat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># MANOVA test using Wilks' Lambda</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">oneway_fit</span>, test <span class="op">=</span> <span class="st">"Wilks"</span><span class="op">)</span></span>
<span><span class="co">#&gt;           Df  Wilks approx F num Df den Df    Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; admit      1 0.6126   25.927      2     82 1.881e-09 ***</span></span>
<span><span class="co">#&gt; Residuals 83                                            </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Since the Wilks’ Lambda test results in a small <span class="math inline">\(p\)</span>-value, we reject the null hypothesis of equal multivariate mean vectors among the three admission groups.</p>
<p><strong>Repeated Measures MANOVA</strong></p>
<div class="sourceCode" id="cb715"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create dataset for repeated measures example</span></span>
<span><span class="va">stress</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    subject <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">8</span>,</span>
<span>    begin <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">5</span>, <span class="fl">6</span>, <span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    middle <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">3</span>, <span class="fl">7</span>, <span class="fl">4</span>, <span class="fl">7</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>    final <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">7</span>, <span class="fl">4</span>, <span class="fl">7</span>, <span class="fl">6</span>, <span class="fl">7</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><strong>Choosing the Correct Model</strong></p>
<ul>
<li><p>If time (with three levels) is treated as an independent variable, we use <strong>univariate ANOVA</strong> (which requires the sphericity assumption, meaning the variances of all differences must be equal).</p></li>
<li><p>If each time point is treated as a separate variable, we use <strong>MANOVA</strong> (which does not require the sphericity assumption).</p></li>
</ul>
<div class="sourceCode" id="cb716"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit the MANOVA model for repeated measures</span></span>
<span><span class="va">stress_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">begin</span>, <span class="va">middle</span>, <span class="va">final</span><span class="op">)</span> <span class="op">~</span> <span class="fl">1</span>, data <span class="op">=</span> <span class="va">stress</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define the within-subject factor</span></span>
<span><span class="va">idata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"begin"</span>, <span class="st">"middle"</span>, <span class="st">"final"</span><span class="op">)</span>,</span>
<span>    levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"begin"</span>, <span class="st">"middle"</span>, <span class="st">"final"</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform repeated measures MANOVA</span></span>
<span><span class="va">repeat_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/car/man/Anova.html">Anova</a></span><span class="op">(</span></span>
<span>    <span class="va">stress_mod</span>,</span>
<span>    idata <span class="op">=</span> <span class="va">idata</span>,</span>
<span>    idesign <span class="op">=</span> <span class="op">~</span> <span class="va">time</span>,</span>
<span>    icontrasts <span class="op">=</span> <span class="st">"contr.poly"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summarize results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">repeat_fit</span><span class="op">)</span> </span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Type III Repeated Measures MANOVA Tests:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ------------------------------------------</span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Term: (Intercept) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Response transformation matrix:</span></span>
<span><span class="co">#&gt;        (Intercept)</span></span>
<span><span class="co">#&gt; begin            1</span></span>
<span><span class="co">#&gt; middle           1</span></span>
<span><span class="co">#&gt; final            1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;             (Intercept)</span></span>
<span><span class="co">#&gt; (Intercept)        1352</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: (Intercept)</span></span>
<span><span class="co">#&gt;                  Df test stat approx F num Df den Df     Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; Pillai            1  0.896552 60.66667      1      7 0.00010808 ***</span></span>
<span><span class="co">#&gt; Wilks             1  0.103448 60.66667      1      7 0.00010808 ***</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  1  8.666667 60.66667      1      7 0.00010808 ***</span></span>
<span><span class="co">#&gt; Roy               1  8.666667 60.66667      1      7 0.00010808 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ------------------------------------------</span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Term: time </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Response transformation matrix:</span></span>
<span><span class="co">#&gt;               time.L     time.Q</span></span>
<span><span class="co">#&gt; begin  -7.071068e-01  0.4082483</span></span>
<span><span class="co">#&gt; middle -7.850462e-17 -0.8164966</span></span>
<span><span class="co">#&gt; final   7.071068e-01  0.4082483</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;           time.L   time.Q</span></span>
<span><span class="co">#&gt; time.L 18.062500 6.747781</span></span>
<span><span class="co">#&gt; time.Q  6.747781 2.520833</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: time</span></span>
<span><span class="co">#&gt;                  Df test stat approx F num Df den Df   Pr(&gt;F)  </span></span>
<span><span class="co">#&gt; Pillai            1 0.7080717 7.276498      2      6 0.024879 *</span></span>
<span><span class="co">#&gt; Wilks             1 0.2919283 7.276498      2      6 0.024879 *</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  1 2.4254992 7.276498      2      6 0.024879 *</span></span>
<span><span class="co">#&gt; Roy               1 2.4254992 7.276498      2      6 0.024879 *</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Univariate Type III Repeated-Measures ANOVA Assuming Sphericity</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             Sum Sq num Df Error SS den Df F value    Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; (Intercept) 450.67      1    52.00      7 60.6667 0.0001081 ***</span></span>
<span><span class="co">#&gt; time         20.58      2    24.75     14  5.8215 0.0144578 *  </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Mauchly Tests for Sphericity</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      Test statistic p-value</span></span>
<span><span class="co">#&gt; time         0.7085 0.35565</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Greenhouse-Geisser and Huynh-Feldt Corrections</span></span>
<span><span class="co">#&gt;  for Departure from Sphericity</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;       GG eps Pr(&gt;F[GG])  </span></span>
<span><span class="co">#&gt; time 0.77429    0.02439 *</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;         HF eps Pr(&gt;F[HF])</span></span>
<span><span class="co">#&gt; time 0.9528433 0.01611634</span></span></code></pre></div>
<p>The results indicate that we cannot reject the null hypothesis of sphericity, meaning that univariate ANOVA is also appropriate. The linear time effect is significant, but the quadratic time effect is not.</p>
<p><strong>Polynomial Contrasts for Time Effects</strong></p>
<p>To further explore the effect of time, we examine polynomial contrasts.</p>
<div class="sourceCode" id="cb717"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Check the reference for the marginal means</span></span>
<span><span class="fu"><a href="https://rvlenth.github.io/emmeans/reference/ref_grid.html">ref_grid</a></span><span class="op">(</span><span class="va">stress_mod</span>, mult.name <span class="op">=</span> <span class="st">"time"</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'emmGrid' object with variables:</span></span>
<span><span class="co">#&gt;     1 = 1</span></span>
<span><span class="co">#&gt;     time = multivariate response levels: begin, middle, final</span></span>
<span></span>
<span><span class="co"># Compute marginal means for time levels</span></span>
<span><span class="va">contr_means</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rvlenth.github.io/emmeans/reference/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">stress_mod</span>, <span class="op">~</span> <span class="va">time</span>, mult.name <span class="op">=</span> <span class="st">"time"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Test for polynomial trends</span></span>
<span><span class="fu"><a href="https://rvlenth.github.io/emmeans/reference/contrast.html">contrast</a></span><span class="op">(</span><span class="va">contr_means</span>, method <span class="op">=</span> <span class="st">"poly"</span><span class="op">)</span></span>
<span><span class="co">#&gt;  contrast  estimate    SE df t.ratio p.value</span></span>
<span><span class="co">#&gt;  linear        2.12 0.766  7   2.773  0.0276</span></span>
<span><span class="co">#&gt;  quadratic     1.38 0.944  7   1.457  0.1885</span></span></code></pre></div>
<p>The results confirm that there is a <strong>significant linear trend</strong> over time but <strong>no quadratic trend</strong>.</p>
<p><strong>MANOVA for Drug Treatments</strong></p>
<p>We now analyze a multivariate response for different drug treatments.</p>
<div class="sourceCode" id="cb718"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Read in the dataset</span></span>
<span><span class="va">heart</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"images/heart.dat"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Assign variable names</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">heart</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"drug"</span>, <span class="st">"y1"</span>, <span class="st">"y2"</span>, <span class="st">"y3"</span>, <span class="st">"y4"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a subject ID nested within drug groups</span></span>
<span><span class="va">heart</span> <span class="op">&lt;-</span> <span class="va">heart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">drug</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>subject <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/row_number.html">row_number</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check dataset structure</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">heart</span><span class="op">)</span></span>
<span><span class="co">#&gt; tibble [24 × 6] (S3: tbl_df/tbl/data.frame)</span></span>
<span><span class="co">#&gt;  $ drug   : chr [1:24] "ax23" "ax23" "ax23" "ax23" ...</span></span>
<span><span class="co">#&gt;  $ y1     : int [1:24] 72 78 71 72 66 74 62 69 85 82 ...</span></span>
<span><span class="co">#&gt;  $ y2     : int [1:24] 86 83 82 83 79 83 73 75 86 86 ...</span></span>
<span><span class="co">#&gt;  $ y3     : int [1:24] 81 88 81 83 77 84 78 76 83 80 ...</span></span>
<span><span class="co">#&gt;  $ y4     : int [1:24] 77 82 75 69 66 77 70 70 80 84 ...</span></span>
<span><span class="co">#&gt;  $ subject: int [1:24] 1 2 3 4 5 6 7 8 1 2 ...</span></span>
<span></span>
<span><span class="co"># Create means summary for a profile plot</span></span>
<span><span class="va">heart_means</span> <span class="op">&lt;-</span> <span class="va">heart</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">drug</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise_all.html">summarize_at</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/vars.html">vars</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">starts_with</a></span><span class="op">(</span><span class="st">"y"</span><span class="op">)</span><span class="op">)</span>, <span class="va">mean</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span><span class="op">-</span><span class="va">drug</span>, names_to <span class="op">=</span> <span class="st">"time"</span>, values_to <span class="op">=</span> <span class="st">"mean"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">time</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate the profile plot</span></span>
<span><span class="va">gg_profile</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">heart_means</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">time</span>, y <span class="op">=</span> <span class="va">mean</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>col <span class="op">=</span> <span class="va">drug</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>col <span class="op">=</span> <span class="va">drug</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Profile Plot"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Response"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html">scale_x_discrete</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Time"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">gg_profile</span></span></code></pre></div>
<div class="inline-figure"><img src="25-multivariate_files/figure-html/unnamed-chunk-15-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb719"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Fit the MANOVA model</span></span>
<span><span class="va">heart_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y1</span>, <span class="va">y2</span>, <span class="va">y3</span>, <span class="va">y4</span><span class="op">)</span> <span class="op">~</span> <span class="va">drug</span>, data <span class="op">=</span> <span class="va">heart</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform MANOVA test</span></span>
<span><span class="va">man_fit</span> <span class="op">&lt;-</span> <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/Anova.html">Anova</a></span><span class="op">(</span><span class="va">heart_mod</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summarize results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">man_fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Type II MANOVA Tests:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for error:</span></span>
<span><span class="co">#&gt;        y1      y2      y3     y4</span></span>
<span><span class="co">#&gt; y1 641.00 601.750 535.250 426.00</span></span>
<span><span class="co">#&gt; y2 601.75 823.875 615.500 534.25</span></span>
<span><span class="co">#&gt; y3 535.25 615.500 655.875 555.25</span></span>
<span><span class="co">#&gt; y4 426.00 534.250 555.250 674.50</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ------------------------------------------</span></span>
<span><span class="co">#&gt;  </span></span>
<span><span class="co">#&gt; Term: drug </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;        y1       y2       y3    y4</span></span>
<span><span class="co">#&gt; y1 567.00 335.2500  42.7500 387.0</span></span>
<span><span class="co">#&gt; y2 335.25 569.0833 404.5417 367.5</span></span>
<span><span class="co">#&gt; y3  42.75 404.5417 391.0833 171.0</span></span>
<span><span class="co">#&gt; y4 387.00 367.5000 171.0000 316.0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: drug</span></span>
<span><span class="co">#&gt;                  Df test stat  approx F num Df den Df     Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; Pillai            2  1.283456  8.508082      8     38 1.5010e-06 ***</span></span>
<span><span class="co">#&gt; Wilks             2  0.079007 11.509581      8     36 6.3081e-08 ***</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  2  7.069384 15.022441      8     34 3.9048e-09 ***</span></span>
<span><span class="co">#&gt; Roy               2  6.346509 30.145916      4     19 5.4493e-08 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Since we obtain a small <span class="math inline">\(p\)</span>-value, we reject the null hypothesis of no difference in means between the treatments.</p>
<p><strong>Contrasts Between Treatment Groups</strong></p>
<p>To further investigate group differences, we define <strong>contrast matrices.</strong></p>
<div class="sourceCode" id="cb720"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convert drug variable to a factor</span></span>
<span><span class="va">heart</span><span class="op">$</span><span class="va">drug</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">heart</span><span class="op">$</span><span class="va">drug</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define contrast matrix L</span></span>
<span><span class="va">L</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span>,</span>
<span>              <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>,<span class="op">-</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">3</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">colnames</a></span><span class="op">(</span><span class="va">L</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"bww9:ctrl"</span>, <span class="st">"ax23:rest"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/row_colnames.html">rownames</a></span><span class="op">(</span><span class="va">L</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/unique.html">unique</a></span><span class="op">(</span><span class="va">heart</span><span class="op">$</span><span class="va">drug</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Assign contrasts</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">heart</span><span class="op">$</span><span class="va">drug</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">L</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">heart</span><span class="op">$</span><span class="va">drug</span><span class="op">)</span></span>
<span><span class="co">#&gt;      bww9:ctrl ax23:rest</span></span>
<span><span class="co">#&gt; ax23         0         2</span></span>
<span><span class="co">#&gt; bww9         1        -1</span></span>
<span><span class="co">#&gt; ctrl        -1        -1</span></span></code></pre></div>
<p><strong>Hypothesis Testing with Contrast Matrices</strong></p>
<p>Instead of setting contrasts in <code>heart$drug</code>, we use a contrast matrix <span class="math inline">\(\mathbf{M}\)</span></p>
<div class="sourceCode" id="cb721"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define contrast matrix M for further testing</span></span>
<span><span class="va">M</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span>,</span>
<span>              <span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>,</span>
<span>              <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Update model for contrast testing</span></span>
<span><span class="va">heart_mod2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">heart_mod</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display model coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">heart_mod2</span><span class="op">)</span></span>
<span><span class="co">#&gt;                  y1         y2        y3    y4</span></span>
<span><span class="co">#&gt; (Intercept)   75.00 78.9583333 77.041667 74.75</span></span>
<span><span class="co">#&gt; drugbww9:ctrl  4.50  5.8125000  3.562500  4.25</span></span>
<span><span class="co">#&gt; drugax23:rest -2.25  0.7708333  1.979167 -0.75</span></span></code></pre></div>
<p>Comparing Drug <code>bww9</code> vs Control</p>
<div class="sourceCode" id="cb722"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bww9vctrl</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">heart_mod2</span>,</span>
<span>                          hypothesis.matrix <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>                          P <span class="op">=</span> <span class="va">M</span><span class="op">)</span></span>
<span><span class="va">bww9vctrl</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Response transformation matrix:</span></span>
<span><span class="co">#&gt;    [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt; y1    1    0    0</span></span>
<span><span class="co">#&gt; y2   -1    1    0</span></span>
<span><span class="co">#&gt; y3    0   -1    1</span></span>
<span><span class="co">#&gt; y4    0    0   -1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;          [,1]   [,2]     [,3]</span></span>
<span><span class="co">#&gt; [1,]  27.5625 -47.25  14.4375</span></span>
<span><span class="co">#&gt; [2,] -47.2500  81.00 -24.7500</span></span>
<span><span class="co">#&gt; [3,]  14.4375 -24.75   7.5625</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for error:</span></span>
<span><span class="co">#&gt;          [,1]     [,2]    [,3]</span></span>
<span><span class="co">#&gt; [1,]  261.375 -141.875  28.000</span></span>
<span><span class="co">#&gt; [2,] -141.875  248.750 -19.375</span></span>
<span><span class="co">#&gt; [3,]   28.000  -19.375 219.875</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: </span></span>
<span><span class="co">#&gt;                  Df test stat approx F num Df den Df Pr(&gt;F)</span></span>
<span><span class="co">#&gt; Pillai            1 0.2564306 2.184141      3     19 0.1233</span></span>
<span><span class="co">#&gt; Wilks             1 0.7435694 2.184141      3     19 0.1233</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  1 0.3448644 2.184141      3     19 0.1233</span></span>
<span><span class="co">#&gt; Roy               1 0.3448644 2.184141      3     19 0.1233</span></span>
<span></span>
<span><span class="va">bww9vctrl</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">heart_mod</span>,</span>
<span>                          hypothesis.matrix <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>,<span class="op">-</span><span class="fl">1</span><span class="op">)</span>,</span>
<span>                          P <span class="op">=</span> <span class="va">M</span><span class="op">)</span></span>
<span><span class="va">bww9vctrl</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Response transformation matrix:</span></span>
<span><span class="co">#&gt;    [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt; y1    1    0    0</span></span>
<span><span class="co">#&gt; y2   -1    1    0</span></span>
<span><span class="co">#&gt; y3    0   -1    1</span></span>
<span><span class="co">#&gt; y4    0    0   -1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;          [,1]   [,2]     [,3]</span></span>
<span><span class="co">#&gt; [1,]  27.5625 -47.25  14.4375</span></span>
<span><span class="co">#&gt; [2,] -47.2500  81.00 -24.7500</span></span>
<span><span class="co">#&gt; [3,]  14.4375 -24.75   7.5625</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for error:</span></span>
<span><span class="co">#&gt;          [,1]     [,2]    [,3]</span></span>
<span><span class="co">#&gt; [1,]  261.375 -141.875  28.000</span></span>
<span><span class="co">#&gt; [2,] -141.875  248.750 -19.375</span></span>
<span><span class="co">#&gt; [3,]   28.000  -19.375 219.875</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: </span></span>
<span><span class="co">#&gt;                  Df test stat approx F num Df den Df Pr(&gt;F)</span></span>
<span><span class="co">#&gt; Pillai            1 0.2564306 2.184141      3     19 0.1233</span></span>
<span><span class="co">#&gt; Wilks             1 0.7435694 2.184141      3     19 0.1233</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  1 0.3448644 2.184141      3     19 0.1233</span></span>
<span><span class="co">#&gt; Roy               1 0.3448644 2.184141      3     19 0.1233</span></span></code></pre></div>
<p>Since the <span class="math inline">\(p\)</span>-value is not significant, we conclude that there is no significant difference between the control and <code>bww9</code> drug treatment.</p>
<p><strong>Comparing Drug <code>ax23</code> vs Rest</strong></p>
<div class="sourceCode" id="cb723"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">axx23vrest</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">heart_mod2</span>,</span>
<span>                          hypothesis.matrix <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>                          P <span class="op">=</span> <span class="va">M</span><span class="op">)</span></span>
<span><span class="va">axx23vrest</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Response transformation matrix:</span></span>
<span><span class="co">#&gt;    [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt; y1    1    0    0</span></span>
<span><span class="co">#&gt; y2   -1    1    0</span></span>
<span><span class="co">#&gt; y3    0   -1    1</span></span>
<span><span class="co">#&gt; y4    0    0   -1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;           [,1]       [,2]      [,3]</span></span>
<span><span class="co">#&gt; [1,]  438.0208  175.20833 -395.7292</span></span>
<span><span class="co">#&gt; [2,]  175.2083   70.08333 -158.2917</span></span>
<span><span class="co">#&gt; [3,] -395.7292 -158.29167  357.5208</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for error:</span></span>
<span><span class="co">#&gt;          [,1]     [,2]    [,3]</span></span>
<span><span class="co">#&gt; [1,]  261.375 -141.875  28.000</span></span>
<span><span class="co">#&gt; [2,] -141.875  248.750 -19.375</span></span>
<span><span class="co">#&gt; [3,]   28.000  -19.375 219.875</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: </span></span>
<span><span class="co">#&gt;                  Df test stat approx F num Df den Df     Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; Pillai            1  0.855364 37.45483      3     19 3.5484e-08 ***</span></span>
<span><span class="co">#&gt; Wilks             1  0.144636 37.45483      3     19 3.5484e-08 ***</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  1  5.913921 37.45483      3     19 3.5484e-08 ***</span></span>
<span><span class="co">#&gt; Roy               1  5.913921 37.45483      3     19 3.5484e-08 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span></span>
<span><span class="va">axx23vrest</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/linearHypothesis.html">linearHypothesis</a></span><span class="op">(</span><span class="va">heart_mod</span>,</span>
<span>                          hypothesis.matrix <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>                          P <span class="op">=</span> <span class="va">M</span><span class="op">)</span></span>
<span><span class="va">axx23vrest</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Response transformation matrix:</span></span>
<span><span class="co">#&gt;    [,1] [,2] [,3]</span></span>
<span><span class="co">#&gt; y1    1    0    0</span></span>
<span><span class="co">#&gt; y2   -1    1    0</span></span>
<span><span class="co">#&gt; y3    0   -1    1</span></span>
<span><span class="co">#&gt; y4    0    0   -1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for the hypothesis:</span></span>
<span><span class="co">#&gt;           [,1]       [,2]      [,3]</span></span>
<span><span class="co">#&gt; [1,]  402.5208  127.41667 -390.9375</span></span>
<span><span class="co">#&gt; [2,]  127.4167   40.33333 -123.7500</span></span>
<span><span class="co">#&gt; [3,] -390.9375 -123.75000  379.6875</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sum of squares and products for error:</span></span>
<span><span class="co">#&gt;          [,1]     [,2]    [,3]</span></span>
<span><span class="co">#&gt; [1,]  261.375 -141.875  28.000</span></span>
<span><span class="co">#&gt; [2,] -141.875  248.750 -19.375</span></span>
<span><span class="co">#&gt; [3,]   28.000  -19.375 219.875</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Multivariate Tests: </span></span>
<span><span class="co">#&gt;                  Df test stat approx F num Df den Df     Pr(&gt;F)    </span></span>
<span><span class="co">#&gt; Pillai            1  0.842450 33.86563      3     19 7.9422e-08 ***</span></span>
<span><span class="co">#&gt; Wilks             1  0.157550 33.86563      3     19 7.9422e-08 ***</span></span>
<span><span class="co">#&gt; Hotelling-Lawley  1  5.347205 33.86563      3     19 7.9422e-08 ***</span></span>
<span><span class="co">#&gt; Roy               1  5.347205 33.86563      3     19 7.9422e-08 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Since we obtain a significant <span class="math inline">\(p\)</span>-value, we conclude that the <code>ax23</code> drug treatment significantly differs from the rest of the treatments.</p>
<hr>
</div>
</div>
</div>
<div id="sec-profile-analysis" class="section level3" number="25.2.2">
<h3>
<span class="header-section-number">25.2.2</span> Profile Analysis<a class="anchor" aria-label="anchor" href="#sec-profile-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>Profile analysis is a multivariate extension of repeated measures <a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">ANOVA</a> used to examine similarities between treatment effects in longitudinal data. The null hypothesis states that all treatments have the same average effect:</p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2 = \dots = \mu_h
\]</span></p>
<p>which is equivalent to testing:</p>
<p><span class="math display">\[
H_0: \tau_1 = \tau_2 = \dots = \tau_h
\]</span></p>
<p>This analysis helps determine the exact nature of similarities and differences between treatments by sequentially testing the following hypotheses:</p>
<ol style="list-style-type: decimal">
<li>
<a href="sec-multivariate-methods.html#sec-parallel-profile-hypothesis">Are the profiles parallel?</a> No interaction between treatment and time.</li>
<li>
<a href="sec-multivariate-methods.html#sec-coincidental-profiles">Are the profiles coincidental?</a> Identical profiles across treatments.</li>
<li>
<a href="sec-multivariate-methods.html#sec-horizontal-profiles">Are the profiles horizontal?</a> No differences across any time points.</li>
</ol>
<p>If the <strong>parallelism assumption is rejected</strong>, we can further investigate:</p>
<ul>
<li><p>Differences among groups at specific time points.</p></li>
<li><p>Differences among time points within a particular group.</p></li>
<li><p>Differences within subsets of time points across groups.</p></li>
</ul>
<hr>
<p><strong>Example: Profile Analysis Setup</strong></p>
<p>Consider an example with:</p>
<ul>
<li><p>4 time points (<span class="math inline">\(p = 4\)</span>)</p></li>
<li><p>3 treatments (<span class="math inline">\(h = 3\)</span>)</p></li>
</ul>
<p>We analyze whether the profiles for each treatment group are identical except for a mean shift (i.e., they are parallel).</p>
<hr>
<div id="sec-parallel-profile-hypothesis" class="section level4" number="25.2.2.1">
<h4>
<span class="header-section-number">25.2.2.1</span> Parallel Profile Hypothesis<a class="anchor" aria-label="anchor" href="#sec-parallel-profile-hypothesis"><i class="fas fa-link"></i></a>
</h4>
<p>We test whether the differences in treatment means remain constant across time:</p>
<p><span class="math display">\[
\begin{aligned}
H_0: \mu_{11} - \mu_{21} &amp;= \mu_{12} - \mu_{22} = \dots = \mu_{1t} - \mu_{2t} \\
\mu_{11} - \mu_{31} &amp;= \mu_{12} - \mu_{32} = \dots = \mu_{1t} - \mu_{3t} \\
&amp;\vdots
\end{aligned}
\]</span></p>
<p>for <span class="math inline">\(h-1\)</span> equations. Equivalently, in matrix form:</p>
<p><span class="math display">\[
H_0: \mathbf{LBM} = 0
\]</span></p>
<p>where the cell means parameterization of <span class="math inline">\(\mathbf{B}\)</span> is:</p>
<p><span class="math display">\[
\mathbf{LBM} =
\left[
\begin{array}
{ccc}
1 &amp; -1 &amp; 0 \\
1 &amp; 0 &amp; -1
\end{array}
\right]
\left[
\begin{array}
{ccc}
\mu_{11} &amp; \dots &amp; \mu_{14} \\
\mu_{21} &amp; \dots &amp; \mu_{24} \\
\mu_{31} &amp; \dots &amp; \mu_{34}
\end{array}
\right]
\left[
\begin{array}
{ccc}
1 &amp; 1 &amp; 1 \\
-1 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; -1
\end{array}
\right]
= \mathbf{0}
\]</span></p>
<p>where:</p>
<ul>
<li><p>The first matrix compares treatments at each time point.</p></li>
<li><p>The second matrix contains the mean responses for each treatment across time.</p></li>
<li><p>The third matrix compares time points within each treatment.</p></li>
</ul>
<hr>
<p>The first multiplication, <span class="math inline">\(\mathbf{LB}\)</span>, results in:</p>
<p><span class="math display">\[
\left[
\begin{array}
{cccc}
\mu_{11} - \mu_{21} &amp; \mu_{12} - \mu_{22} &amp; \mu_{13} - \mu_{23} &amp; \mu_{14} - \mu_{24}\\
\mu_{11} - \mu_{31} &amp; \mu_{12} - \mu_{32} &amp; \mu_{13} - \mu_{33} &amp; \mu_{14} - \mu_{34}
\end{array}
\right]
\]</span></p>
<p>This represents differences in treatment means at each time point.</p>
<p>Multiplying by <span class="math inline">\(\mathbf{M}\)</span> compares these differences across time:</p>
<p><span class="math display">\[
\left[
\begin{array}
{ccc}
(\mu_{11} - \mu_{21}) - (\mu_{12} - \mu_{22}) &amp; (\mu_{11} - \mu_{21}) - (\mu_{13} - \mu_{23}) &amp; (\mu_{11} - \mu_{21}) - (\mu_{14} - \mu_{24}) \\
(\mu_{11} - \mu_{31}) - (\mu_{12} - \mu_{32}) &amp; (\mu_{11} - \mu_{31}) - (\mu_{13} - \mu_{33}) &amp; (\mu_{11} - \mu_{31}) - (\mu_{14} - \mu_{34})
\end{array}
\right]
\]</span></p>
<p>This matrix captures the changes in treatment differences over time.</p>
<hr>
<p>Instead of using the cell means parameterization, we can express the model in terms of effects:</p>
<p><span class="math display">\[
\mathbf{LBM} =
\left[
\begin{array}
{cccc}
0 &amp; 1 &amp; -1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; -1
\end{array}
\right]
\left[
\begin{array}
{c}
\mu' \\
\tau'_1 \\
\tau_2' \\
\tau_3'
\end{array}
\right]
\left[
\begin{array}
{ccc}
1 &amp; 1 &amp; 1 \\
-1 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; -1
\end{array}
\right]
= \mathbf{0}
\]</span></p>
<p>where:</p>
<ul>
<li><p>The first matrix compares treatment effects.</p></li>
<li><p>The second matrix contains overall mean and treatment effects.</p></li>
<li><p>The third matrix compares time points within each treatment.</p></li>
</ul>
<p>In both parameterizations:</p>
<ul>
<li><p><span class="math inline">\(\operatorname{rank}(\mathbf{L}) = h-1\)</span></p></li>
<li><p><span class="math inline">\(\operatorname{rank}(\mathbf{M}) = p-1\)</span></p></li>
</ul>
<p>indicating that we are testing for differences across treatments (<span class="math inline">\(\mathbf{L}\)</span>) and time points (<span class="math inline">\(\mathbf{M}\)</span>).</p>
<hr>
<p>Different choices of <span class="math inline">\(\mathbf{L}\)</span> and <span class="math inline">\(\mathbf{M}\)</span> still lead to the same hypothesis:</p>
<p><span class="math display">\[
\mathbf{L} =
\left[
\begin{array}
{cccc}
0 &amp; 1 &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 1 &amp; -1
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{M} =
\left[
\begin{array}
{ccc}
1 &amp; 0 &amp; 0 \\
-1 &amp; 1 &amp; 0 \\
0 &amp; -1 &amp; 1 \\
0 &amp; 0 &amp; -1
\end{array}
\right]
\]</span></p>
<p>This choice yields the same profile comparison structure.</p>
<hr>
</div>
<div id="sec-coincidental-profiles" class="section level4" number="25.2.2.2">
<h4>
<span class="header-section-number">25.2.2.2</span> Coincidental Profiles<a class="anchor" aria-label="anchor" href="#sec-coincidental-profiles"><i class="fas fa-link"></i></a>
</h4>
<p>Once we establish that the profiles are <strong>parallel</strong> (i.e., we fail to reject the parallel profile test), we next ask:</p>
<p><strong>Are the profiles identical?</strong></p>
<p>If the sums of the components of <span class="math inline">\(\boldsymbol{\mu}_i\)</span> are equal across all treatments, then the profiles are <strong>coincidental</strong> (i.e., identical across groups).</p>
<p><strong>Hypothesis for Coincidental Profiles</strong></p>
<p><span class="math display">\[
H_0: \mathbf{1'}_p \boldsymbol{\mu}_1 = \mathbf{1'}_p \boldsymbol{\mu}_2 = \dots = \mathbf{1'}_p \boldsymbol{\mu}_h
\]</span></p>
<p>Equivalently, in matrix notation:</p>
<p><span class="math display">\[
H_0: \mathbf{LBM} = \mathbf{0}
\]</span></p>
<p>where, under the <strong>cell means parameterization</strong>:</p>
<p><span class="math display">\[
\mathbf{L} =
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\
0 &amp; 1 &amp; -1
\end{bmatrix}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\mathbf{M} =
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1
\end{bmatrix}'
\]</span></p>
<p>Multiplying <span class="math inline">\(\mathbf{LBM}\)</span> yields:</p>
<p><span class="math display">\[
\begin{bmatrix}
(\mu_{11} + \mu_{12} + \mu_{13} + \mu_{14}) - (\mu_{31} + \mu_{32} + \mu_{33} + \mu_{34}) \\
(\mu_{21} + \mu_{22} + \mu_{23} + \mu_{24}) - (\mu_{31} + \mu_{32} + \mu_{33} + \mu_{34})
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0
\end{bmatrix}
\]</span></p>
<p>Thus, rejecting this hypothesis suggests that the treatments do not have identical effects over time.</p>
<p>As in previous cases, different choices of <span class="math inline">\(\mathbf{L}\)</span> and <span class="math inline">\(\mathbf{M}\)</span> can yield the same result.</p>
<hr>
</div>
<div id="sec-horizontal-profiles" class="section level4" number="25.2.2.3">
<h4>
<span class="header-section-number">25.2.2.3</span> Horizontal Profiles<a class="anchor" aria-label="anchor" href="#sec-horizontal-profiles"><i class="fas fa-link"></i></a>
</h4>
<p>If we fail to reject the null hypothesis that all <span class="math inline">\(h\)</span> profiles are the same (i.e., we confirm parallel and coincidental profiles), we then ask:</p>
<p><strong>Are all elements of the common profile equal across time?</strong></p>
<p>This question tests whether the profiles are horizontal, meaning no differences between any time points.</p>
<p><strong>Hypothesis for Horizontal Profiles</strong></p>
<p><span class="math display">\[
H_0: \mathbf{LBM} = \mathbf{0}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\mathbf{L} =
\begin{bmatrix}
1 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\mathbf{M} =
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
-1 &amp; 1 &amp; 0 \\
0 &amp; -1 &amp; 1 \\
0 &amp; 0 &amp; -1
\end{bmatrix}
\]</span></p>
<p>Multiplication yields:</p>
<p><span class="math display">\[
\begin{bmatrix}
(\mu_{11} - \mu_{12}) &amp; (\mu_{12} - \mu_{13}) &amp; (\mu_{13} - \mu_{14})
\end{bmatrix}
=
\begin{bmatrix}
0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>Thus, rejecting this hypothesis suggests that at least one time point differs significantly from the others in the common profile.</p>
<hr>
</div>
<div id="summary-of-profile-tests" class="section level4" number="25.2.2.4">
<h4>
<span class="header-section-number">25.2.2.4</span> Summary of Profile Tests<a class="anchor" aria-label="anchor" href="#summary-of-profile-tests"><i class="fas fa-link"></i></a>
</h4>
<p>If we fail to reject all three hypotheses, we conclude that:</p>
<ul>
<li><p>There are no significant differences between treatments.</p></li>
<li><p>There are no significant differences between time points.</p></li>
</ul>
<p>The three profile tests correspond to well-known univariate ANOVA components:</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="34%">
<col width="65%">
</colgroup>
<thead><tr class="header">
<th>Test</th>
<th>Equivalent test for</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Parallel profiles</strong></td>
<td>Interaction effect (treatment × time)</td>
</tr>
<tr class="even">
<td><strong>Coincidental profiles</strong></td>
<td>Main effect of treatment (between-subjects factor)</td>
</tr>
<tr class="odd">
<td><strong>Horizontal profiles</strong></td>
<td>Main effect of time (repeated measures factor)</td>
</tr>
</tbody>
</table></div>
<div class="sourceCode" id="cb724"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Profile analysis for heart dataset</span></span>
<span><span class="va">profile_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/profileR/man/pbg.html">pbg</a></span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">heart</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span>,   <span class="co"># Response variables</span></span>
<span>    group <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">heart</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>,    <span class="co"># Treatment group</span></span>
<span>    original.names <span class="op">=</span> <span class="cn">TRUE</span>,            <span class="co"># Keep original variable names</span></span>
<span>    profile.plot <span class="op">=</span> <span class="cn">FALSE</span>              <span class="co"># Disable automatic plotting</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summary of profile analysis results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">profile_fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; pbg(data = as.matrix(heart[, 2:5]), group = as.matrix(heart[, </span></span>
<span><span class="co">#&gt;     1]), original.names = TRUE, profile.plot = FALSE)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Hypothesis Tests:</span></span>
<span><span class="co">#&gt; $`Ho: Profiles are parallel`</span></span>
<span><span class="co">#&gt;   Multivariate.Test Statistic  Approx.F num.df den.df      p.value</span></span>
<span><span class="co">#&gt; 1             Wilks 0.1102861 12.737599      6     38 7.891497e-08</span></span>
<span><span class="co">#&gt; 2            Pillai 1.0891707  7.972007      6     40 1.092397e-05</span></span>
<span><span class="co">#&gt; 3  Hotelling-Lawley 6.2587852 18.776356      6     36 9.258571e-10</span></span>
<span><span class="co">#&gt; 4               Roy 5.9550887 39.700592      3     20 1.302458e-08</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Ho: Profiles have equal levels`</span></span>
<span><span class="co">#&gt;             Df Sum Sq Mean Sq F value  Pr(&gt;F)   </span></span>
<span><span class="co">#&gt; group        2  328.7  164.35   5.918 0.00915 **</span></span>
<span><span class="co">#&gt; Residuals   21  583.2   27.77                   </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $`Ho: Profiles are flat`</span></span>
<span><span class="co">#&gt;          F df1 df2      p-value</span></span>
<span><span class="co">#&gt; 1 14.30928   3  19 4.096803e-05</span></span></code></pre></div>
</div>
</div>
</div>
<div id="statistical-test-selection-for-comparing-means" class="section level2" number="25.3">
<h2>
<span class="header-section-number">25.3</span> Statistical Test Selection for Comparing Means<a class="anchor" aria-label="anchor" href="#statistical-test-selection-for-comparing-means"><i class="fas fa-link"></i></a>
</h2>
<div class="inline-figure"><img src="images/MANOVA_summary.PNG" title="MANOVA summary" style="display: block; margin: 1em auto;width:100.0%"></div>

</div>
</div>



<div class="chapter-nav">
<div class="prev"><a href="sec-analysis-of-variance-anova.html"><span class="header-section-number">24</span> Analysis of Variance</a></div>
<div class="next"><a href="sec-quasi-experimental.html"><span class="header-section-number">26</span> Quasi-Experimental Methods</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#sec-multivariate-methods"><span class="header-section-number">25</span> Multivariate Methods</a></li>
<li>
<a class="nav-link" href="#basic-understanding"><span class="header-section-number">25.1</span> Basic Understanding</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#multivariate-random-vectors"><span class="header-section-number">25.1.1</span> Multivariate Random Vectors</a></li>
<li><a class="nav-link" href="#sec-covariance-matrix-multivariate"><span class="header-section-number">25.1.2</span> Covariance Matrix</a></li>
<li><a class="nav-link" href="#equalities-in-expectation-and-variance"><span class="header-section-number">25.1.3</span> Equalities in Expectation and Variance</a></li>
<li><a class="nav-link" href="#multivariate-normal-distribution-1"><span class="header-section-number">25.1.4</span> Multivariate Normal Distribution</a></li>
<li><a class="nav-link" href="#test-of-multivariate-normality"><span class="header-section-number">25.1.5</span> Test of Multivariate Normality</a></li>
<li><a class="nav-link" href="#mean-vector-inference"><span class="header-section-number">25.1.6</span> Mean Vector Inference</a></li>
<li><a class="nav-link" href="#general-hypothesis-testing"><span class="header-section-number">25.1.7</span> General Hypothesis Testing</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sec-multivariate-analysis-of-variance"><span class="header-section-number">25.2</span> Multivariate Analysis of Variance</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#one-way-manova"><span class="header-section-number">25.2.1</span> One-Way MANOVA</a></li>
<li><a class="nav-link" href="#sec-profile-analysis"><span class="header-section-number">25.2.2</span> Profile Analysis</a></li>
</ul>
</li>
<li><a class="nav-link" href="#statistical-test-selection-for-comparing-means"><span class="header-section-number">25.3</span> Statistical Test Selection for Comparing Means</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/25-multivariate.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/25-multivariate.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>
</div>
  

  

</div>
 <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-06-05.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
