<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Descriptive Statistics | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="When you have an area of interest to research, a problem to solve, or a relationship to investigate, theoretical and empirical processes will help you. Estimand: Defined as “a quantity of...">
<meta name="generator" content="bookdown 0.35 with bs4_book()">
<meta property="og:title" content="Chapter 3 Descriptive Statistics | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/descriptive-statistics.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="When you have an area of interest to research, a problem to solve, or a relationship to investigate, theoretical and empirical processes will help you. Estimand: Defined as “a quantity of...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Descriptive Statistics | A Guide on Data Analysis">
<meta name="twitter:description" content="When you have an area of interest to research, a problem to solve, or a relationship to investigate, theoretical and empirical processes will help you. Estimand: Defined as “a quantity of...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="active" href="descriptive-statistics.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-Linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="sec-linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="sec-nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="model-specification-4.html"><span class="header-section-number">10</span> Model Specification</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">11</span> Imputation (Missing Data)</a></li>
<li><a class="" href="data.html"><span class="header-section-number">12</span> Data</a></li>
<li><a class="" href="variable-transformation.html"><span class="header-section-number">13</span> Variable Transformation</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">14</span> Hypothesis Testing</a></li>
<li><a class="" href="marginal-effects.html"><span class="header-section-number">15</span> Marginal Effects</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">16</span> Prediction and Estimation</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">17</span> Moderation</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="" href="causal-inference.html"><span class="header-section-number">18</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="experimental-design.html"><span class="header-section-number">19</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">20</span> Sampling</a></li>
<li><a class="" href="sec-analysis-of-variance-anova.html"><span class="header-section-number">21</span> Analysis of Variance (ANOVA)</a></li>
<li><a class="" href="multivariate-methods.html"><span class="header-section-number">22</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="quasi-experimental.html"><span class="header-section-number">23</span> Quasi-experimental</a></li>
<li><a class="" href="regression-discontinuity.html"><span class="header-section-number">24</span> Regression Discontinuity</a></li>
<li><a class="" href="synthetic-difference-in-differences.html"><span class="header-section-number">25</span> Synthetic Difference-in-Differences</a></li>
<li><a class="" href="difference-in-differences.html"><span class="header-section-number">26</span> Difference-in-differences</a></li>
<li><a class="" href="changes-in-changes.html"><span class="header-section-number">27</span> Changes-in-Changes</a></li>
<li><a class="" href="synthetic-control.html"><span class="header-section-number">28</span> Synthetic Control</a></li>
<li><a class="" href="event-studies.html"><span class="header-section-number">29</span> Event Studies</a></li>
<li><a class="" href="instrumental-variables.html"><span class="header-section-number">30</span> Instrumental Variables</a></li>
<li><a class="" href="matching-methods.html"><span class="header-section-number">31</span> Matching Methods</a></li>
<li><a class="" href="interrupted-time-series.html"><span class="header-section-number">32</span> Interrupted Time Series</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">33</span> Endogeneity</a></li>
<li><a class="" href="other-biases.html"><span class="header-section-number">34</span> Other Biases</a></li>
<li><a class="" href="controls.html"><span class="header-section-number">35</span> Controls</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">36</span> Mediation</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">37</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">38</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">39</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">40</span> Sensitivity Analysis/ Robustness Check</a></li>
<li><a class="" href="replication-and-synthetic-data.html"><span class="header-section-number">41</span> Replication and Synthetic Data</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="descriptive-statistics" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Descriptive Statistics<a class="anchor" aria-label="anchor" href="#descriptive-statistics"><i class="fas fa-link"></i></a>
</h1>
<p>When you have an area of interest to research, a problem to solve, or a relationship to investigate, theoretical and empirical processes will help you.</p>
<p><strong>Estimand</strong>: Defined as “a quantity of scientific interest that can be calculated in the population and does not change its value depending on the data collection design used to measure it (i.e., it does not vary with sample size, survey design, the number of non-respondents, or follow-up efforts).” <span class="citation">(<a href="references.html#ref-Rubin_1996">Rubin 1996</a>)</span></p>
<p>Examples of estimands include:</p>
<ul>
<li>Population means</li>
<li>Population variances</li>
<li>Correlations</li>
<li>Factor loadings</li>
<li>Regression coefficients</li>
</ul>
<hr>
<div id="numerical-measures" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Numerical Measures<a class="anchor" aria-label="anchor" href="#numerical-measures"><i class="fas fa-link"></i></a>
</h2>
<p>There are differences between a population and a sample:</p>
<div class="inline-table"><table style="width:99%;" class="table table-sm">
<colgroup>
<col width="9%">
<col width="26%">
<col width="38%">
<col width="24%">
</colgroup>
<thead><tr class="header">
<th><strong>Measures of</strong></th>
<th><strong>Category</strong></th>
<th><strong>Population</strong></th>
<th><strong>Sample</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td>What is it?</td>
<td>Reality</td>
<td>A small fraction of reality (inference)</td>
</tr>
<tr class="even">
<td></td>
<td>Characteristics described by</td>
<td>Parameters</td>
<td>Statistics</td>
</tr>
<tr class="odd">
<td><strong>Central Tendency</strong></td>
<td>Mean</td>
<td><span class="math inline">\(\mu = E(Y)\)</span></td>
<td><span class="math inline">\(\hat{\mu} = \overline{y}\)</span></td>
</tr>
<tr class="even">
<td><strong>Central Tendency</strong></td>
<td>Median</td>
<td>50th percentile</td>
<td><span class="math inline">\(y_{(\frac{n+1}{2})}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Dispersion</strong></td>
<td>Variance</td>
<td><span class="math display">\[\sigma^2 = var(Y) = E[(Y-\mu)^2]\]</span></td>
<td><span class="math inline">\(s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (y_i - \overline{y})^2\)</span></td>
</tr>
<tr class="even">
<td><strong>Dispersion</strong></td>
<td>Coefficient of Variation</td>
<td><span class="math inline">\(\frac{\sigma}{\mu}\)</span></td>
<td><span class="math inline">\(\frac{s}{\overline{y}}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Dispersion</strong></td>
<td>Interquartile Range</td>
<td>Difference between 25th and 75th percentiles; robust to outliers</td>
<td></td>
</tr>
<tr class="even">
<td><strong>Shape</strong></td>
<td>
<p>Skewness</p>
<p>Standardized 3rd central moment (unitless)</p>
</td>
<td><span class="math inline">\(g_1 = \frac{\mu_3}{\sigma^3}\)</span></td>
<td><span class="math inline">\(\hat{g_1} = \frac{m_3}{m_2^{3/2}}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Shape</strong></td>
<td>Central moments</td>
<td>
<span class="math inline">\(\mu=E(Y)\)</span>, <span class="math inline">\(\mu_2 = \sigma^2 = E[(Y-\mu)^2]\)</span>, <span class="math inline">\(\mu_3 = E[(Y-\mu)^3]\)</span>, <span class="math inline">\(\mu_4 = E[(Y-\mu)^4]\)</span>
</td>
<td>
<p><span class="math inline">\(m_2 = \frac{1}{n} \sum_{i=1}^{n} (y_i - \overline{y})^2\)</span></p>
<p><span class="math inline">\(m_3 = \frac{1}{n} \sum_{i=1}^{n} (y_i - \overline{y})^3\)</span></p>
</td>
</tr>
<tr class="even">
<td><strong>Shape</strong></td>
<td>
<p>Kurtosis</p>
<p>(peakedness and tail thickness) Standardized 4th central moment</p>
</td>
<td><span class="math inline">\(g_2^* = \frac{E[(Y-\mu)^4]}{\sigma^4}\)</span></td>
<td><span class="math inline">\(\hat{g_2} = \frac{m_4}{m_2^2} - 3\)</span></td>
</tr>
</tbody>
</table></div>
<hr>
<p><strong>Notes</strong>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Order Statistics</strong>: <span class="math inline">\(y_{(1)}, y_{(2)}, \ldots, y_{(n)}\)</span>, where <span class="math inline">\(y_{(1)} &lt; y_{(2)} &lt; \ldots &lt; y_{(n)}\)</span>.</p></li>
<li>
<p><strong>Coefficient of Variation</strong>:</p>
<ul>
<li>Defined as the standard deviation divided by the mean.</li>
<li>A stable, unitless statistic useful for comparison.</li>
</ul>
</li>
<li>
<p><strong>Symmetry</strong>:</p>
<ul>
<li>
<strong>Symmetric distributions</strong>: Mean = Median; Skewness = 0.</li>
<li>
<strong>Skewed Right</strong>: Mean &gt; Median; Skewness &gt; 0.</li>
<li>
<strong>Skewed Left</strong>: Mean &lt; Median; Skewness &lt; 0.</li>
</ul>
</li>
<li>
<p><strong>Central Moments</strong>:</p>
<ul>
<li><span class="math inline">\(\mu = E(Y)\)</span></li>
<li><span class="math inline">\(\mu_2 = \sigma^2 = E[(Y-\mu)^2]\)</span></li>
<li><span class="math inline">\(\mu_3 = E[(Y-\mu)^3]\)</span></li>
<li><span class="math inline">\(\mu_4 = E[(Y-\mu)^4]\)</span></li>
</ul>
</li>
</ol>
<p><strong>Skewness (</strong><span class="math inline">\(\hat{g_1}\)</span><strong>)</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Sampling Distribution</strong>:<br>
For samples drawn from a normal population:
<ul>
<li>
<span class="math inline">\(\hat{g_1}\)</span> is approximately distributed as <span class="math inline">\(N(0, \frac{6}{n})\)</span> when <span class="math inline">\(n &gt; 150\)</span>.</li>
</ul>
</li>
<li>
<strong>Inference</strong>:
<ul>
<li>
<strong>Large Samples</strong>: Inference on skewness can be based on the standard normal distribution.<br>
The 95% confidence interval for <span class="math inline">\(g_1\)</span> is given by: <span class="math display">\[
\hat{g_1} \pm 1.96 \sqrt{\frac{6}{n}}
\]</span>
</li>
<li>
<strong>Small Samples</strong>: For small samples, consult special tables such as:
<ul>
<li>
<span class="citation">Snedecor and Cochran (<a href="references.html#ref-snedecor1989statistical">1989</a>)</span>, Table A 19(i)</li>
<li>Monte Carlo test results</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>Kurtosis (</strong><span class="math inline">\(\hat{g_2}\)</span><strong>)</strong></p>
<ol style="list-style-type: decimal">
<li>
<strong>Definitions and Relationships</strong>:
<ul>
<li>A normal distribution has kurtosis <span class="math inline">\(g_2^* = 3\)</span>.<br>
Kurtosis is often redefined as: <span class="math display">\[
g_2 = \frac{E[(Y - \mu)^4]}{\sigma^4} - 3
\]</span> where the 4th central moment is estimated by: <span class="math display">\[
m_4 = \frac{\sum_{i=1}^n (y_i - \overline{y})^4}{n}
\]</span>
</li>
</ul>
</li>
<li>
<strong>Sampling Distribution</strong>:<br>
For large samples (<span class="math inline">\(n &gt; 1000\)</span>):
<ul>
<li>
<span class="math inline">\(\hat{g_2}\)</span> is approximately distributed as <span class="math inline">\(N(0, \frac{24}{n})\)</span>.</li>
</ul>
</li>
<li>
<strong>Inference</strong>:
<ul>
<li>
<strong>Large Samples</strong>: Inference for kurtosis can use standard normal tables.</li>
<li>
<strong>Small Samples</strong>: Refer to specialized tables such as:
<ul>
<li>
<span class="citation">Snedecor and Cochran (<a href="references.html#ref-snedecor1989statistical">1989</a>)</span>, Table A 19(ii)</li>
<li><span class="citation">Geary (<a href="references.html#ref-geary1936moments">1936</a>)</span></li>
</ul>
</li>
</ul>
</li>
</ol>
<div class="inline-table"><table style="width:99%;" class="table table-sm">
<colgroup>
<col width="26%">
<col width="20%">
<col width="53%">
</colgroup>
<thead><tr class="header">
<th><strong>Kurtosis Value</strong></th>
<th><strong>Tail Behavior</strong></th>
<th><strong>Comparison to Normal Distribution</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<span class="math inline">\(g_2 &gt; 0\)</span> (Leptokurtic)</td>
<td>Heavier Tails</td>
<td>Examples: <span class="math inline">\(t\)</span>-distributions</td>
</tr>
<tr class="even">
<td>
<span class="math inline">\(g_2 &lt; 0\)</span> (Platykurtic)</td>
<td>Lighter Tails</td>
<td>Examples: Uniform or certain bounded distributions</td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(g_2 = 0\)</span> (Mesokurtic)</td>
<td>Normal Tails</td>
<td>Exactly matches the normal distribution</td>
</tr>
</tbody>
</table></div>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate random data from a normal distribution</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load the e1071 package for skewness and kurtosis functions</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">e1071</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate skewness</span></span>
<span><span class="va">skewness_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/e1071/man/skewness.html">skewness</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Skewness:"</span>, <span class="va">skewness_value</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Skewness: 0.362615</span></span>
<span></span>
<span><span class="co"># Calculate kurtosis</span></span>
<span><span class="va">kurtosis_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/e1071/man/kurtosis.html">kurtosis</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Kurtosis:"</span>, <span class="va">kurtosis_value</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Kurtosis: -0.3066409</span></span></code></pre></div>
</div>
<div id="graphical-measures" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Graphical Measures<a class="anchor" aria-label="anchor" href="#graphical-measures"><i class="fas fa-link"></i></a>
</h2>
<p>The following table summarizes key graphical measures along with guidance on when and why to use each. More detailed explanations, visual examples, and sample code will be discussed after this table.</p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="13%">
<col width="44%">
<col width="41%">
</colgroup>
<thead><tr class="header">
<th><strong>Graph Type</strong></th>
<th><strong>When to Use</strong></th>
<th><strong>Why It's Useful</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Histogram</strong></td>
<td>- Exploring the distribution (shape, center, spread) of a single continuous variable</td>
<td>- Quickly identifies frequency, modes, skewness, and potential outliers<br>
- Provides an overview of data "shape"</td>
</tr>
<tr class="even">
<td><strong>Box-and-Whisker Plot</strong></td>
<td>- Comparing the same continuous variable across multiple categories<br>
- Identifying median, IQR, and outliers</td>
<td>- Shows distribution at a glance (median, quartiles)<br>
- Highlights outliers and potential group differences</td>
</tr>
<tr class="odd">
<td><strong>Stem-and-Leaf Plot</strong></td>
<td>- Small, single-variable datasets where you want a textual yet visual distribution view</td>
<td>- Reveals the distribution while preserving actual data values<br>
- Easy to spot clusters and gaps for small datasets</td>
</tr>
<tr class="even">
<td><strong>Notched Boxplot</strong></td>
<td>- Similar to a standard boxplot but with confidence intervals around the median</td>
<td>- If notches don't overlap, it suggests the medians differ significantly<br>
- Helps clarify whether differences in medians are likely meaningful</td>
</tr>
<tr class="odd">
<td><strong>Bagplot (2D Boxplot)</strong></td>
<td>- Bivariate data where you want a 2D "boxplot"-style overview<br>
- Identifying outliers in two-dimensional space</td>
<td>- Depicts both central region ("bag") and potential outliers<br>
- Ideal for discovering clusters or unusual points in two continuous variables</td>
</tr>
<tr class="even">
<td><strong>Boxplot Matrix</strong></td>
<td>- Multiple continuous variables that you want to compare side-by-side</td>
<td>- Quickly compares distributions of many variables simultaneously<br>
- Helpful for spotting differences in median, spread, and outliers</td>
</tr>
<tr class="odd">
<td><strong>Violin Plot</strong></td>
<td>- Same use case as boxplot but you want <em>more detail</em> on the distribution's shape</td>
<td>- Combines boxplot features with a density plot<br>
- Shows where data are concentrated or sparse within each category</td>
</tr>
<tr class="even">
<td><strong>Scatterplot</strong></td>
<td>- Two continuous variables to check for relationships, trends, or outliers</td>
<td>- Visualizes correlation or non-linear patterns<br>
- Aids in identifying clusters or extreme values</td>
</tr>
<tr class="odd">
<td><strong>Pairwise Scatterplots</strong></td>
<td>- Initial exploration of <em>several</em> variables at once</td>
<td>- Enables a quick scan of relationships between <em>all</em> variable pairs<br>
- Useful for identifying multivariate patterns or potential correlation structures</td>
</tr>
</tbody>
</table></div>
<p><strong>Tips for Selecting the Right Plot:</strong></p>
<ul>
<li><p><strong>Focus on Your Question</strong>: Are you comparing groups, investigating correlations, or just exploring the overall shape of the data?</p></li>
<li><p><strong>Match the Plot to Your Data Type</strong>: Continuous vs. categorical data often dictates your choice of chart.</p></li>
<li><p><strong>Mind the Data Size</strong>: Some plots become cluttered or lose clarity with very large datasets (e.g., stem-and-leaf), while others may be less informative with very few data points.</p></li>
</ul>
<div id="shape" class="section level3" number="3.2.1">
<h3>
<span class="header-section-number">3.2.1</span> Shape<a class="anchor" aria-label="anchor" href="#shape"><i class="fas fa-link"></i></a>
</h3>
<p>Properly labeling your graphs is essential to ensure that viewers can easily understand the data presented. Below are several examples of graphical measures used to assess the shape of a dataset.</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate random data for demonstration purposes</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Histogram: A graphical representation of the distribution of a dataset.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span></span>
<span>    <span class="va">data</span>,</span>
<span>    labels <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    col <span class="op">=</span> <span class="st">"grey"</span>,</span>
<span>    breaks <span class="op">=</span> <span class="fl">12</span>,</span>
<span>    main <span class="op">=</span> <span class="st">"Histogram of Random Data"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"Value"</span>,</span>
<span>    ylab <span class="op">=</span> <span class="st">"Frequency"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-2-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Interactive Histogram: Using 'highcharter' for a more interactive visualization.</span></span>
<span><span class="co"># pacman::p_load("highcharter")</span></span>
<span><span class="co"># hchart(data, type = "column", name = "Random Data Distribution")</span></span>
<span></span>
<span><span class="co"># Box-and-Whisker Plot: Useful for visualizing the distribution and identifying outliers.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html">boxplot</a></span><span class="op">(</span></span>
<span>    <span class="va">count</span> <span class="op">~</span> <span class="va">spray</span>,</span>
<span>    data <span class="op">=</span> <span class="va">InsectSprays</span>,</span>
<span>    col <span class="op">=</span> <span class="st">"lightgray"</span>,</span>
<span>    main <span class="op">=</span> <span class="st">"Boxplot of Insect Sprays"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"Spray Type"</span>,</span>
<span>    ylab <span class="op">=</span> <span class="st">"Count"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-2-2.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Notched Boxplot: The notches indicate a confidence interval around the median.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html">boxplot</a></span><span class="op">(</span></span>
<span>    <span class="va">len</span> <span class="op">~</span> <span class="va">supp</span> <span class="op">*</span> <span class="va">dose</span>,</span>
<span>    data <span class="op">=</span> <span class="va">ToothGrowth</span>,</span>
<span>    notch <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gold"</span>, <span class="st">"darkgreen"</span><span class="op">)</span>,</span>
<span>    main <span class="op">=</span> <span class="st">"Tooth Growth by Supplement and Dose"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"Supplement and Dose"</span>,</span>
<span>    ylab <span class="op">=</span> <span class="st">"Length"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-2-3.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># If the notches of two boxes do not overlap, this suggests that the medians differ significantly.</span></span>
<span></span>
<span><span class="co"># Stem-and-Leaf Plot: Provides a quick way to visualize the distribution of data.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/stem.html">stem</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   The decimal point is at the |</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   -2 | 4321000</span></span>
<span><span class="co">#&gt;   -1 | 87665</span></span>
<span><span class="co">#&gt;   -1 | 44433222111000</span></span>
<span><span class="co">#&gt;   -0 | 998888886666665555</span></span>
<span><span class="co">#&gt;   -0 | 433322221100</span></span>
<span><span class="co">#&gt;    0 | 0112233333344</span></span>
<span><span class="co">#&gt;    0 | 5666677888999999</span></span>
<span><span class="co">#&gt;    1 | 0111122344</span></span>
<span><span class="co">#&gt;    1 | 699</span></span>
<span><span class="co">#&gt;    2 | 34</span></span>
<span></span>
<span><span class="co"># Bagplot - A 2D Boxplot Extension: Visualizes the spread and identifies outliers in two-dimensional data.</span></span>
<span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">aplpack</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/attach.html">attach</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span></span>
<span><span class="fu">bagplot</span><span class="op">(</span><span class="va">wt</span>,</span>
<span>        <span class="va">mpg</span>,</span>
<span>        xlab <span class="op">=</span> <span class="st">"Car Weight"</span>,</span>
<span>        ylab <span class="op">=</span> <span class="st">"Miles Per Gallon"</span>,</span>
<span>        main <span class="op">=</span> <span class="st">"Bagplot of Car Weight vs. Miles Per Gallon"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-2-4.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/detach.html">detach</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span></span></code></pre></div>
<p>Below are some advanced plot types that can provide deeper insights into data:</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># boxplot.matrix(): Creates boxplots for each column in a matrix. Useful for comparing multiple variables.</span></span>
<span><span class="fu">graphics</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.matrix.html">boxplot.matrix</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span></span>
<span>        Uni05 <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span> <span class="op">/</span> <span class="fl">21</span>,</span>
<span>        Norm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>,</span>
<span>        T5 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">rt</a></span><span class="op">(</span><span class="fl">100</span>, df <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>,</span>
<span>        Gam2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">rgamma</a></span><span class="op">(</span><span class="fl">100</span>, shape <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">)</span>,</span>
<span>    main <span class="op">=</span> <span class="st">"Boxplot Marix"</span>,</span>
<span>    notch <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    col <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-3-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Violin Plot (vioplot()): Combines a boxplot with a density plot, providing more information about the distribution.</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/TomKellyGenetics/vioplot">"vioplot"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/vioplot/man/vioplot.html">vioplot</a></span><span class="op">(</span><span class="va">data</span>, col <span class="op">=</span> <span class="st">"lightblue"</span>, main <span class="op">=</span> <span class="st">"Violin Plot Example"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-3-2.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="scatterplot" class="section level3" number="3.2.2">
<h3>
<span class="header-section-number">3.2.2</span> Scatterplot<a class="anchor" aria-label="anchor" href="#scatterplot"><i class="fas fa-link"></i></a>
</h3>
<p>Scatterplots are useful for visualizing relationships between two continuous variables. They help identify patterns, correlations, and outliers.</p>
<p>Pairwise Scatterplots: Visualizes relationships between all pairs of variables in a dataset. This is especially useful for exploring potential correlations.</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">mtcars</span>,</span>
<span>      main <span class="op">=</span> <span class="st">"Pairwise Scatterplots"</span>,</span>
<span>      pch <span class="op">=</span> <span class="fl">19</span>,</span>
<span>      col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-4-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="normality-assessment" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Normality Assessment<a class="anchor" aria-label="anchor" href="#normality-assessment"><i class="fas fa-link"></i></a>
</h2>
<p>The Normal (Gaussian) distribution plays a critical role in statistical analyses due to its theoretical and practical applications. Many statistical methods assume normality in the data, making it essential to assess whether our variable of interest follows a normal distribution. To achieve this, we utilize both <a href="descriptive-statistics.html#numerical-measures">Numerical Measures</a> and <a href="descriptive-statistics.html#graphical-assessment">Graphical Assessment</a>.</p>
<div id="graphical-assessment" class="section level3" number="3.3.1">
<h3>
<span class="header-section-number">3.3.1</span> Graphical Assessment<a class="anchor" aria-label="anchor" href="#graphical-assessment"><i class="fas fa-link"></i></a>
</h3>
<p>Graphical methods provide an intuitive way to visually inspect the normality of a dataset. One of the most common methods is the <strong>Q-Q plot</strong> (quantile-quantile plot). The Q-Q plot compares the quantiles of the sample data to the quantiles of a theoretical normal distribution. Deviations from the line indicate departures from normality.</p>
<p>Below is an example of using the <code>qqnorm</code> and <code>qqline</code> functions in R to assess the normality of the <code>precip</code> dataset, which contains precipitation data (in inches per year) for 70 U.S. cities:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load the required package</span></span>
<span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="st">"car"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate a Q-Q plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">precip</span>,</span>
<span>       ylab <span class="op">=</span> <span class="st">"Precipitation [in/yr] for 70 US cities"</span>,</span>
<span>       main <span class="op">=</span> <span class="st">"Q-Q Plot of Precipitation Data"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqline</a></span><span class="op">(</span><span class="va">precip</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;"></div>
<p><strong>Interpretation</strong></p>
<ul>
<li><p><strong>Theoretical Line</strong>: The red line represents the expected relationship if the data were perfectly normally distributed.</p></li>
<li><p><strong>Data Points</strong>: The dots represent the actual empirical data.</p></li>
</ul>
<p>If the points closely align with the theoretical line, we can conclude that the data likely follow a normal distribution. However, noticeable deviations from the line, particularly systematic patterns (e.g., curves or s-shaped patterns), indicate potential departures from normality.</p>
<p>Tips</p>
<ol style="list-style-type: decimal">
<li><p><strong>Small Deviations</strong>: Minor deviations from the line in small datasets are not uncommon and may not significantly impact analyses that assume normality.</p></li>
<li><p><strong>Systematic Patterns</strong>: Look for clear trends, such as clusters or s-shaped curves, which suggest skewness or heavy tails.</p></li>
<li><p><strong>Complementary Tests</strong>: Always pair graphical methods with numerical measures (e.g., Shapiro-Wilk test) to make a robust conclusion.</p></li>
</ol>
<p>When interpreting a Q-Q plot, it is helpful to see both ideal and non-ideal scenarios. Below is an illustrative example:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Normal Data</strong>: Points fall closely along the line.</p></li>
<li><p><strong>Skewed Data</strong>: Points systematically deviate from the line, curving upward or downward.</p></li>
<li><p><strong>Heavy Tails</strong>: Points deviate at the extremes (ends) of the distribution.</p></li>
</ol>
<p>By combining visual inspection and numerical measures, we can better understand the nature of our data and its alignment with the assumption of normality.</p>
</div>
<div id="summary-statistics" class="section level3" number="3.3.2">
<h3>
<span class="header-section-number">3.3.2</span> Summary Statistics<a class="anchor" aria-label="anchor" href="#summary-statistics"><i class="fas fa-link"></i></a>
</h3>
<p>While graphical assessments, such as Q-Q plots, provide a visual indication of normality, they may not always offer a definitive conclusion. To supplement graphical methods, statistical tests are often employed. These tests provide quantitative evidence to support or refute the assumption of normality. The most common methods can be classified into two categories:</p>
<ul>
<li>
<p><a href="descriptive-statistics.html#methods-based-on-normal-probability-plot">Methods Based on Normal Probability Plot</a></p>
<ul>
<li><a href="descriptive-statistics.html#correlation-coefficient-with-normal-probability-plots">Correlation Coefficient with Normal Probability Plots</a></li>
<li><a href="descriptive-statistics.html#shapiro-wilk-test">Shapiro-Wilk Test</a></li>
</ul>
</li>
<li>
<p><a href="descriptive-statistics.html#methods-based-on-empirical-cumulative-distribution-function">Methods based on empirical cumulative distribution function</a></p>
<ul>
<li><a href="descriptive-statistics.html#anderson-darling-test">Anderson-Darling Test</a></li>
<li><a href="descriptive-statistics.html#kolmogorov-smirnov-test">Kolmogorov-Smirnov Test</a></li>
<li><a href="descriptive-statistics.html#cramer-von-mises-test">Cramer-von Mises Test</a></li>
<li><a href="descriptive-statistics.html#jarquebera-test">Jarque–Bera Test</a></li>
</ul>
</li>
</ul>
<div id="methods-based-on-normal-probability-plot" class="section level4" number="3.3.2.1">
<h4>
<span class="header-section-number">3.3.2.1</span> Methods Based on Normal Probability Plot<a class="anchor" aria-label="anchor" href="#methods-based-on-normal-probability-plot"><i class="fas fa-link"></i></a>
</h4>
<div id="correlation-coefficient-with-normal-probability-plots" class="section level5" number="3.3.2.1.1">
<h5>
<span class="header-section-number">3.3.2.1.1</span> Correlation Coefficient with Normal Probability Plots<a class="anchor" aria-label="anchor" href="#correlation-coefficient-with-normal-probability-plots"><i class="fas fa-link"></i></a>
</h5>
<p>As described by <span class="citation">Looney and Gulledge Jr (<a href="references.html#ref-Looney_1985">1985</a>)</span> and <span class="citation">Samuel S. Shapiro and Francia (<a href="references.html#ref-Shapiro_1972">1972</a>)</span>, this method evaluates the linearity of a normal probability plot by calculating the correlation coefficient between the ordered sample values <span class="math inline">\(y_{(i)}\)</span> and their theoretical normal quantiles <span class="math inline">\(m_i^*\)</span>. A perfectly linear relationship suggests that the data follow a normal distribution.</p>
<p>The correlation coefficient, denoted <span class="math inline">\(W^*\)</span>, is given by:</p>
<p><span class="math display">\[
W^* = \frac{\sum_{i=1}^{n}(y_{(i)}-\bar{y})(m_i^* - 0)}{\sqrt{\sum_{i=1}^{n}(y_{(i)}-\bar{y})^2 \cdot \sum_{i=1}^{n}(m_i^* - 0)^2}}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\bar{y}\)</span> is the sample mean,</p></li>
<li><p><span class="math inline">\(\bar{m^*} = 0\)</span> under the null hypothesis of normality.</p></li>
</ul>
<p>The <strong>Pearson product-moment correlation formula</strong> can also be used to evaluate this relationship:</p>
<p><span class="math display">\[
\hat{\rho} = \frac{\sum_{i=1}^{n}(y_i - \bar{y})(x_i - \bar{x})}{\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2 \cdot \sum_{i=1}^{n}(x_i - \bar{x})^2}}
\]</span></p>
<ul>
<li>
<strong>Interpretation</strong>:
<ul>
<li>When the correlation is 1, the plot is exactly linear, and normality is assumed.</li>
<li>The closer the correlation is to 0, the stronger the evidence to reject normality.</li>
<li>Inference on <span class="math inline">\(W^*\)</span> requires reference to special tables <span class="citation">(<a href="references.html#ref-Looney_1985">Looney and Gulledge Jr 1985</a>)</span>.</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/alexkowa/EnvStats">"EnvStats"</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform Probability Plot Correlation Coefficient (PPCC) Test</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest</a></span><span class="op">(</span><span class="va">data</span>, test <span class="op">=</span> <span class="st">"ppcc"</span><span class="op">)</span><span class="op">$</span><span class="va">p.value</span> <span class="co"># Probability Plot Correlation Coefficient</span></span>
<span><span class="co">#&gt; [1] 0.3701575</span></span></code></pre></div>
</div>
<div id="shapiro-wilk-test" class="section level5" number="3.3.2.1.2">
<h5>
<span class="header-section-number">3.3.2.1.2</span> Shapiro-Wilk Test<a class="anchor" aria-label="anchor" href="#shapiro-wilk-test"><i class="fas fa-link"></i></a>
</h5>
<p>The Shapiro-Wilk test <span class="citation">(<a href="references.html#ref-Shapiro_1965">Samuel Sanford Shapiro and Wilk 1965</a>)</span> is one of the most widely used tests for assessing normality, especially for sample sizes <span class="math inline">\(n &lt; 2000\)</span>. This test evaluates how well the data’s order statistics match a theoretical normal distribution. The test statistic, <span class="math inline">\(W\)</span>, is computed as:</p>
<p><span class="math display">\[
W=\frac{\sum_{i=1}^{n}a_i x_{(i)}}{\sum_{i=1}^{n}(x_{(i)}-\bar{x})^2}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(n\)</span>: The sample size.</p></li>
<li><p><span class="math inline">\(x_{(i)}\)</span>: The <span class="math inline">\(i\)</span>-th smallest value in the sample (the ordered data).</p></li>
<li><p><span class="math inline">\(\bar{x}\)</span>: The sample mean.</p></li>
<li><p><span class="math inline">\(a_i\)</span>: Weights derived from the expected values and variances of the order statistics of a normal distribution, precomputed based on the sample size <span class="math inline">\(n\)</span>.</p></li>
</ul>
<p><strong>Sensitive</strong> to:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Symmetry</strong>
<ul>
<li>The Shapiro-Wilk test assesses whether a sample is drawn from a normal distribution, which assumes <strong>symmetry</strong> around the mean.</li>
<li>If the data exhibit skewness (a lack of symmetry), the test is likely to reject the null hypothesis of normality.</li>
</ul>
</li>
<li>
<strong>Heavy Tails</strong>
<ul>
<li>Heavy tails refer to distributions where extreme values (outliers) are more likely compared to a normal distribution.</li>
<li>The Shapiro-Wilk test is also sensitive to such departures from normality because heavy tails affect the spread and variance, which are central to the calculation of the test statistic <span class="math inline">\(W\)</span>.</li>
</ul>
</li>
</ol>
<p>Hence, the Shapiro-Wilk test’s sensitivity to these deviations makes it a powerful tool for detecting non-normality only in small to moderate-sized samples. However:</p>
<ul>
<li><p>It is generally more sensitive to <strong>symmetry</strong> (skewness) than to <strong>tail behavior</strong> (kurtosis).</p></li>
<li>
<p>In very large samples, even small deviations in symmetry or tail behavior may cause the test to reject the null hypothesis, even if the data is practically “normal” for the intended analysis.</p>
<ul>
<li><p>Small sample sizes may lack power to detect deviations from normality.</p></li>
<li><p>Large sample sizes may detect minor deviations that are not practically significant.</p></li>
</ul>
</li>
</ul>
<p><strong>Key Steps</strong>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Sort the Data:</strong> Arrange the sample data in ascending order, yielding <span class="math inline">\(x_{(1)}, x_{(2)}, \dots, x_{(n)}\)</span>.</p></li>
<li><p><strong>Compute Weights:</strong> The weights <span class="math inline">\(a_i\)</span> are determined using a covariance matrix of the normal order statistics. These are optimized to maximize the power of the test.</p></li>
<li><p><strong>Calculate</strong> <span class="math inline">\(W\)</span>: Use the formula to determine <span class="math inline">\(W\)</span>, which ranges from 0 to 1.</p></li>
</ol>
<p><strong>Decision Rule</strong>:</p>
<ul>
<li><p><strong>Null Hypothesis</strong> (<span class="math inline">\(H_0\)</span>): The data follows a normal distribution.</p></li>
<li><p><strong>Alternative Hypothesis</strong> (<span class="math inline">\(H_1\)</span>): The data does not follow a normal distribution.</p></li>
<li>
<p>A small <span class="math inline">\(W\)</span> value, along with a <span class="math inline">\(p\)</span>-value below a chosen significance level (e.g., 0.05), leads to rejection of <span class="math inline">\(H_0\)</span>.</p>
<ul>
<li><p>Under normality, <span class="math inline">\(W\)</span> approaches 1.</p></li>
<li><p>Smaller values of <span class="math inline">\(W\)</span> indicate deviations from normality.</p></li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Perform Shapiro-Wilk Test (Default for gofTest)</span></span>
<span><span class="fu">EnvStats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>, test <span class="op">=</span> <span class="st">"sw"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Results of Goodness-of-Fit Test</span></span>
<span><span class="co">#&gt; -------------------------------</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test Method:                     Shapiro-Wilk GOF</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Hypothesized Distribution:       Normal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimated Parameter(s):          mean = 20.090625</span></span>
<span><span class="co">#&gt;                                  sd   =  6.026948</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Estimation Method:               mvue</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Data:                            mtcars$mpg</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Sample Size:                     32</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test Statistic:                  W = 0.9475647</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test Statistic Parameter:        n = 32</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; P-value:                         0.1228814</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Alternative Hypothesis:          True cdf does not equal the</span></span>
<span><span class="co">#&gt;                                  Normal Distribution.</span></span></code></pre></div>
</div>
</div>
<div id="methods-based-on-empirical-cumulative-distribution-function" class="section level4" number="3.3.2.2">
<h4>
<span class="header-section-number">3.3.2.2</span> Methods Based on Empirical Cumulative Distribution Function<a class="anchor" aria-label="anchor" href="#methods-based-on-empirical-cumulative-distribution-function"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>Empirical Cumulative Distribution Function (ECDF)</strong> is a way to represent the distribution of a sample dataset in cumulative terms. It answers the question:</p>
<blockquote>
<p>“What fraction of the observations in my dataset are less than or equal to a given value <span class="math inline">\(x\)</span>?”</p>
</blockquote>
<p>The ECDF is defined as:</p>
<p><span class="math display">\[
F_n(x) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}(X_i \leq x)
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(F_(x)\)</span>: ECDF at value <span class="math inline">\(x\)</span>.</p></li>
<li><p><span class="math inline">\(n\)</span>: Total number of data points.</p></li>
<li><p><span class="math inline">\(\mathbb{I}(X_i \leq x)\)</span>: Indicator function, equal to 1 if <span class="math inline">\(X_i \leq x\)</span>, otherwise 0.</p></li>
</ul>
<p>This method is especially useful for large sample sizes and can be applied to distributions beyond the normal (Gaussian) distribution.</p>
<p>Properties of the ECDF</p>
<ol style="list-style-type: decimal">
<li>
<strong>Step Function</strong>: The ECDF is a step function that increases by <span class="math inline">\(1/n\)</span> at each data point.</li>
<li>
<strong>Non-decreasing</strong>: As <span class="math inline">\(x\)</span> increases, <span class="math inline">\(F_n(x)\)</span> never decreases.</li>
<li>
<strong>Range</strong>: The ECDF starts at 0 and ends at 1:
<ul>
<li>
<span class="math inline">\(F_n(x) = 0\)</span> for <span class="math inline">\(x &lt; \min(X)\)</span>.</li>
<li>
<span class="math inline">\(F_n(x) = 1\)</span> for <span class="math inline">\(x \geq \max(X)\)</span>.</li>
</ul>
</li>
<li>
<strong>Convergence</strong>: As <span class="math inline">\(n \to \infty\)</span>, the ECDF approaches the true cumulative distribution function (CDF) of the population.</li>
</ol>
<p>Let’s consider a sample dataset <span class="math inline">\(\{3, 7, 7, 10, 15\}\)</span>. The ECDF at different values of <span class="math inline">\(x\)</span> is calculated as:</p>
<div class="inline-table"><table style="width:98%;" class="table table-sm">
<colgroup>
<col width="14%">
<col width="46%">
<col width="18%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th>
<span class="math inline">\(\mathbb{I}(X_i \leq x)\)</span> for each <span class="math inline">\(X_i\)</span>
</th>
<th>Count <span class="math inline">\(\leq x\)</span>
</th>
<th>ECDF <span class="math inline">\(F_n(x)\)</span>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x = 5\)</span></td>
<td><span class="math inline">\(\{1, 0, 0, 0, 0\}\)</span></td>
<td>1</td>
<td><span class="math inline">\(1/5 = 0.2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x = 7\)</span></td>
<td><span class="math inline">\(\{1, 1, 1, 0, 0\}\)</span></td>
<td>3</td>
<td><span class="math inline">\(3/5 = 0.6\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x = 12\)</span></td>
<td><span class="math inline">\(\{1, 1, 1, 1, 0\}\)</span></td>
<td>4</td>
<td><span class="math inline">\(4/5 = 0.8\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x = 15\)</span></td>
<td><span class="math inline">\(\{1, 1, 1, 1, 1\}\)</span></td>
<td>5</td>
<td><span class="math inline">\(5/5 = 1.0\)</span></td>
</tr>
</tbody>
</table></div>
<p>Applications of the ECDF</p>
<ol style="list-style-type: decimal">
<li><p><strong>Goodness-of-fit Tests</strong>: Compare the ECDF to a theoretical CDF (e.g., using the Kolmogorov-Smirnov test).</p></li>
<li><p><strong>Outlier Detection</strong>: Analyze cumulative trends to spot unusual data points.</p></li>
<li><p><strong>Visual Data Exploration</strong>: Use the ECDF to understand the spread, skewness, and distribution of the data.</p></li>
<li><p><strong>Comparing Distributions</strong>: Compare the ECDFs of two datasets to assess differences in their distributions.</p></li>
</ol>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load required libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Sample dataset</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">7</span>, <span class="fl">7</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ECDF calculation</span></span>
<span><span class="va">ecdf_function</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">ecdf</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate a data frame for plotting</span></span>
<span><span class="va">ecdf_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                        ecdf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>                          <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data</span> <span class="op">&lt;=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display ECDF values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">ecdf_data</span><span class="op">)</span></span>
<span><span class="co">#&gt;    x ecdf</span></span>
<span><span class="co">#&gt; 1  3  0.2</span></span>
<span><span class="co">#&gt; 2  7  0.6</span></span>
<span><span class="co">#&gt; 3 10  0.8</span></span>
<span><span class="co">#&gt; 4 15  1.0</span></span>
<span></span>
<span><span class="co"># Plot the ECDF</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">ecdf_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">ecdf</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_step</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Empirical Cumulative Distribution Function"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Data Values"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Cumulative Proportion"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Alternatively</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">plot.ecdf</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>,</span>
<span>          verticals <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>          do.points <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-9-1.png" width="90%" style="display: block; margin: auto;"></div>
<div id="anderson-darling-test" class="section level5" number="3.3.2.2.1">
<h5>
<span class="header-section-number">3.3.2.2.1</span> Anderson-Darling Test<a class="anchor" aria-label="anchor" href="#anderson-darling-test"><i class="fas fa-link"></i></a>
</h5>
<p>The <strong>Anderson-Darling test</strong> statistic <span class="citation">(<a href="references.html#ref-Anderson_1952">T. W. Anderson and Darling 1952</a>)</span> is given by:</p>
<p><span class="math display">\[
A^2 = \int_{-\infty}^{\infty} \frac{\left(F_n(t) - F(t)\right)^2}{F(t)(1 - F(t))} dF(t)
\]</span></p>
<p>This test calculates a weighted average of squared deviations between the empirical cumulative distribution function (CDF), <span class="math inline">\(F_n(t)\)</span>, and the theoretical CDF, <span class="math inline">\(F(t)\)</span>. More weight is given to deviations in the tails of the distribution, which makes the test particularly sensitive to these regions.</p>
<p>For a sample of size <span class="math inline">\(n\)</span>, with ordered observations <span class="math inline">\(y_{(1)}, y_{(2)}, \dots, y_{(n)}\)</span>, the Anderson-Darling test statistic can also be written as:</p>
<p><span class="math display">\[
A^2 = -n - \frac{1}{n} \sum_{i=1}^n \left[ (2i - 1) \ln(F(y_{(i)})) + (2n + 1 - 2i) \ln(1 - F(y_{(i)})) \right]
\]</span></p>
<p>For the <strong>normal distribution</strong>, the test statistic is further simplified. Using the transformation:</p>
<p><span class="math display">\[
p_i = \Phi\left(\frac{y_{(i)} - \bar{y}}{s}\right),
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(p_i\)</span> is the cumulative probability under the standard normal distribution,</p></li>
<li><p><span class="math inline">\(y_{(i)}\)</span> are the ordered sample values,</p></li>
<li><p><span class="math inline">\(\bar{y}\)</span> is the sample mean,</p></li>
<li><p><span class="math inline">\(s\)</span> is the sample standard deviation,</p></li>
</ul>
<p>the formula becomes:</p>
<p><span class="math display">\[
A^2 = -n - \frac{1}{n} \sum_{i=1}^n \left[ (2i - 1) \ln(p_i) + (2n + 1 - 2i) \ln(1 - p_i) \right].
\]</span></p>
<p>Key Features of the Test</p>
<ol style="list-style-type: decimal">
<li><p><strong>CDF-Based Weighting</strong>: The Anderson-Darling test gives more weight to deviations in the tails, which makes it particularly sensitive to detecting non-normality in these regions.</p></li>
<li><p><strong>Sensitivity</strong>: Compared to other goodness-of-fit tests, such as the <a href="descriptive-statistics.html#kolmogorov-smirnov-test">Kolmogorov-Smirnov Test</a>, the Anderson-Darling test is better at identifying differences in the tails of the distribution.</p></li>
<li><p><strong>Integral Form</strong>: The test statistic can also be expressed as an integral over the theoretical CDF: <span class="math display">\[
A^2 = n \int_{-\infty}^\infty \frac{\left[F_n(t) - F(t)\right]^2}{F(t)(1 - F(t))} dF(t),
\]</span> where <span class="math inline">\(F_n(t)\)</span> is the empirical CDF, and <span class="math inline">\(F(t)\)</span> is the specified theoretical CDF.</p></li>
<li>
<p><strong>Applications</strong>:</p>
<ul>
<li>Testing for normality or other distributions (e.g., exponential, Weibull).</li>
<li>Validating assumptions in statistical models.</li>
<li>Comparing data to theoretical distributions.</li>
</ul>
</li>
</ol>
<p>Hypothesis Testing</p>
<ul>
<li>
<strong>Null Hypothesis (</strong><span class="math inline">\(H_0\)</span>): The data follows the specified distribution (e.g., normal distribution).</li>
<li>
<strong>Alternative Hypothesis (</strong><span class="math inline">\(H_1\)</span>): The data does not follow the specified distribution.</li>
<li>The null hypothesis is rejected if <span class="math inline">\(A^2\)</span> is too large, indicating a poor fit to the specified distribution.</li>
</ul>
<p>Critical values for the test statistic are provided by <span class="citation">(<a href="references.html#ref-Marsaglia_2004">Marsaglia and Marsaglia 2004</a>)</span> and <span class="citation">(<a href="references.html#ref-Stephens_1974">Stephens 1974</a>)</span>.</p>
<p>Applications to Other Distributions</p>
<p>The Anderson-Darling test can be applied to various distributions by using specific transformation methods. Examples include:</p>
<ul>
<li><p><strong>Exponential</strong></p></li>
<li><p><strong>Logistic</strong></p></li>
<li><p><strong>Gumbel</strong></p></li>
<li><p><strong>Extreme-value</strong></p></li>
<li><p><strong>Weibull</strong> (after logarithmic transformation: <span class="math inline">\(\log(\text{Weibull}) = \text{Gumbel}\)</span>)</p></li>
<li><p><strong>Gamma</strong></p></li>
<li><p><strong>Cauchy</strong></p></li>
<li><p><strong>von Mises</strong></p></li>
<li><p><strong>Log-normal (two-parameter)</strong></p></li>
</ul>
<p>For more details on transformations and critical values, consult <span class="citation">(<a href="references.html#ref-Stephens_1974">Stephens 1974</a>)</span>.</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Perform Anderson-Darling Test</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">nortest</span><span class="op">)</span></span>
<span><span class="va">ad_test_result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nortest/man/ad.test.html">ad.test</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Output the test statistic and p-value</span></span>
<span><span class="va">ad_test_result</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Anderson-Darling normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  mtcars$mpg</span></span>
<span><span class="co">#&gt; A = 0.57968, p-value = 0.1207</span></span></code></pre></div>
<p>Alternatively, for a broader range of distributions, use the <code>gofTest</code> function from the <code>gof</code> package:</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># General goodness-of-fit test with Anderson-Darling</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/alexkowa/EnvStats">EnvStats</a></span><span class="op">)</span></span>
<span><span class="va">gof_test_result</span> <span class="op">&lt;-</span> <span class="fu">EnvStats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">mpg</span>, test <span class="op">=</span> <span class="st">"ad"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract the p-value</span></span>
<span><span class="va">gof_test_result</span><span class="op">$</span><span class="va">p.value</span></span>
<span><span class="co">#&gt; [1] 0.1207371</span></span></code></pre></div>
</div>
<div id="kolmogorov-smirnov-test" class="section level5" number="3.3.2.2.2">
<h5>
<span class="header-section-number">3.3.2.2.2</span> Kolmogorov-Smirnov Test<a class="anchor" aria-label="anchor" href="#kolmogorov-smirnov-test"><i class="fas fa-link"></i></a>
</h5>
<p>The <strong>Kolmogorov-Smirnov (K-S) test</strong> is a nonparametric test that compares the empirical cumulative distribution function (ECDF) of a sample to a theoretical cumulative distribution function (CDF), or compares the ECDFs of two samples. It is used to assess whether a sample comes from a specific distribution (one-sample test) or to compare two samples (two-sample test).</p>
<p>The test statistic <span class="math inline">\(D_n\)</span> for the one-sample test is defined as:</p>
<p><span class="math display">\[
D_n = \sup_x \left| F_n(x) - F(x) \right|,
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(F_n(x)\)</span> is the empirical CDF of the sample,</p></li>
<li><p><span class="math inline">\(F(x)\)</span> is the theoretical CDF under the null hypothesis,</p></li>
<li><p><span class="math inline">\(\sup_x\)</span> denotes the supremum (largest value) over all possible values of <span class="math inline">\(x\)</span>.</p></li>
</ul>
<p>For the two-sample K-S test, the statistic is:</p>
<p><span class="math display">\[
D_{n,m} = \sup_x \left| F_{n,1}(x) - F_{m,2}(x) \right|,
\]</span></p>
<p>where <span class="math inline">\(F_{n,1}(x)\)</span> and <span class="math inline">\(F_{m,2}(x)\)</span> are the empirical CDFs of the two samples, with sizes <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span>, respectively.</p>
<p>Hypotheses</p>
<ul>
<li>
<strong>Null hypothesis (</strong><span class="math inline">\(H_0\)</span>): The sample comes from the specified distribution (one-sample) or the two samples are drawn from the same distribution (two-sample).</li>
<li>
<strong>Alternative hypothesis (</strong><span class="math inline">\(H_1\)</span>): The sample does not come from the specified distribution (one-sample) or the two samples are drawn from different distributions (two-sample).</li>
</ul>
<p>Properties</p>
<ol style="list-style-type: decimal">
<li><p><strong>Based on the Largest Deviation</strong>: The K-S test is sensitive to the largest absolute difference between the empirical and expected CDFs, making it effective for detecting shifts in location or scale.</p></li>
<li><p><strong>Distribution-Free</strong>: The test does not assume a specific distribution for the data under the null hypothesis. Its significance level is determined from the distribution of the test statistic under the null hypothesis.</p></li>
<li>
<p><strong>Limitations</strong>:</p>
<ul>
<li>The test is more sensitive near the center of the distribution than in the tails.</li>
<li>It may not perform well with discrete data or small sample sizes.</li>
</ul>
</li>
<li>
<p><strong>Related Tests</strong>:</p>
<ul>
<li>
<strong>Kuiper’s Test</strong>: A variation of the K-S test that is sensitive to deviations in both the center and tails of the distribution. The Kuiper test statistic is: <span class="math display">\[
V_n = D^+ + D^-,
\]</span> where <span class="math inline">\(D^+\)</span> and <span class="math inline">\(D^-\)</span> are the maximum positive and negative deviations of the empirical CDF from the theoretical CDF.</li>
</ul>
</li>
</ol>
<p>Applications</p>
<ul>
<li>Testing for normality or other specified distributions.</li>
<li>Comparing two datasets to determine if they are drawn from the same distribution.</li>
</ul>
<p>To perform a one-sample K-S test in R, use the <code><a href="https://rdrr.io/r/stats/ks.test.html">ks.test()</a></code> function. To check the goodness of fit for a specific distribution, the <code><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest()</a></code> function from a package like <code>DescTools</code> can also be used.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># One-sample Kolmogorov-Smirnov test for normality</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span>  <span class="co"># Generate random normal data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/ks.test.html">ks.test</a></span><span class="op">(</span><span class="va">data</span>, <span class="st">"pnorm"</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Exact one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  data</span></span>
<span><span class="co">#&gt; D = 0.098643, p-value = 0.6785</span></span>
<span><span class="co">#&gt; alternative hypothesis: two-sided</span></span>
<span></span>
<span><span class="co"># Goodness-of-fit test using gofTest</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://andrisignorell.github.io/DescTools/">DescTools</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest</a></span><span class="op">(</span><span class="va">data</span>, test <span class="op">=</span> <span class="st">"ks"</span><span class="op">)</span><span class="op">$</span><span class="va">p.value</span>  <span class="co"># Kolmogorov-Smirnov test p-value</span></span>
<span><span class="co">#&gt; [1] 0.6785444</span></span></code></pre></div>
<ul>
<li>
<p><strong>Advantages</strong>:</p>
<ul>
<li><p>Simple and widely applicable.</p></li>
<li><p>Distribution-free under the null hypothesis.</p></li>
</ul>
</li>
<li>
<p><strong>Limitations</strong>:</p>
<ul>
<li><p>Sensitive to sample size: small deviations may lead to significance in large samples.</p></li>
<li><p>Reduced sensitivity to differences in the tails compared to the Anderson-Darling test.</p></li>
</ul>
</li>
</ul>
<p>The Kolmogorov-Smirnov test provides a general-purpose method for goodness-of-fit testing and sample comparison, with particular utility in detecting central deviations.</p>
</div>
<div id="cramer-von-mises-test" class="section level5" number="3.3.2.2.3">
<h5>
<span class="header-section-number">3.3.2.2.3</span> Cramer-von Mises Test<a class="anchor" aria-label="anchor" href="#cramer-von-mises-test"><i class="fas fa-link"></i></a>
</h5>
<p>The <strong>Cramer-von Mises (CVM) test</strong> is a nonparametric goodness-of-fit test that evaluates the agreement between the empirical cumulative distribution function (ECDF) of a sample and a specified theoretical cumulative distribution function (CDF). Unlike the <a href="descriptive-statistics.html#kolmogorov-smirnov-test">Kolmogorov-Smirnov test</a>, which focuses on the largest discrepancy, the Cramer-von Mises test considers the <strong>average squared discrepancy</strong> across the entire distribution. Unlike the <a href="descriptive-statistics.html#anderson-darling-test">Anderson-Darling test</a>, it weights all parts of the distribution equally.</p>
<p>The test statistic <span class="math inline">\(W^2\)</span> for the one-sample Cramer-von Mises test is defined as:</p>
<p><span class="math display">\[
W^2 = n \int_{-\infty}^\infty \left[ F_n(t) - F(t) \right]^2 dF(t),
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(F_n(t)\)</span> is the empirical CDF,</p></li>
<li><p><span class="math inline">\(F(t)\)</span> is the specified theoretical CDF under the null hypothesis,</p></li>
<li><p><span class="math inline">\(n\)</span> is the sample size.</p></li>
</ul>
<p>In practice, <span class="math inline">\(W^2\)</span> is computed using the ordered sample values <span class="math inline">\(y_{(1)}, y_{(2)}, \dots, y_{(n)}\)</span> as:</p>
<p><span class="math display">\[
W^2 = \sum_{i=1}^n \left( F(y_{(i)}) - \frac{2i - 1}{2n} \right)^2 + \frac{1}{12n},
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(F(y_{(i)})\)</span> is the theoretical CDF evaluated at the ordered sample values <span class="math inline">\(y_{(i)}\)</span>.</li>
</ul>
<p>Hypotheses</p>
<ul>
<li>
<strong>Null hypothesis (H0)</strong>: The sample data follow the specified distribution.</li>
<li>
<strong>Alternative hypothesis (H1)</strong>: The sample data do not follow the specified distribution.</li>
</ul>
<p>Properties</p>
<ol style="list-style-type: decimal">
<li><p><strong>Focus on Average Discrepancy</strong>: The Cramer-von Mises test measures the overall goodness-of-fit by considering the squared deviations across all points in the distribution, ensuring equal weighting of discrepancies.</p></li>
<li><p><strong>Comparison to Anderson-Darling</strong>: Unlike the Anderson-Darling test, which gives more weight to deviations in the tails, the CVM test weights all parts of the distribution equally.</p></li>
<li><p><strong>Integral Representation</strong>: The statistic is expressed as an integral over the squared differences between the empirical and theoretical CDFs.</p></li>
<li><p><strong>Two-Sample Test</strong>: The Cramer-von Mises framework can also be extended to compare two empirical CDFs. The two-sample statistic is based on the pooled empirical CDF.</p></li>
</ol>
<p>Applications</p>
<ul>
<li>Assessing goodness-of-fit for a theoretical distribution (e.g., normal, exponential, Weibull).</li>
<li>Comparing two datasets to determine if they are drawn from similar distributions.</li>
<li>Validating model assumptions.</li>
</ul>
<p>To perform a Cramer-von Mises test in R, the <code><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest()</a></code> function from the <code>DescTools</code> package can be used. Below is an example:</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Generate random normal data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform the Cramer-von Mises test</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://andrisignorell.github.io/DescTools/">DescTools</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/EnvStats/man/gofTest.html">gofTest</a></span><span class="op">(</span><span class="va">data</span>, test <span class="op">=</span> <span class="st">"cvm"</span><span class="op">)</span><span class="op">$</span><span class="va">p.value</span>  <span class="co"># Cramer-von Mises test p-value</span></span>
<span><span class="co">#&gt; [1] 0.04846959</span></span></code></pre></div>
<ul>
<li>
<p><strong>Advantages</strong>:</p>
<ul>
<li><p>Considers discrepancies across the entire distribution.</p></li>
<li><p>Robust to outliers due to equal weighting.</p></li>
<li><p>Simple to compute and interpret.</p></li>
</ul>
</li>
<li>
<p><strong>Limitations</strong>:</p>
<ul>
<li><p>Less sensitive to deviations in the tails compared to the Anderson-Darling test.</p></li>
<li><p>May be less powerful than the Kolmogorov-Smirnov test in detecting central shifts.</p></li>
</ul>
</li>
</ul>
</div>
<div id="jarquebera-test" class="section level5" number="3.3.2.2.4">
<h5>
<span class="header-section-number">3.3.2.2.4</span> Jarque-Bera Test<a class="anchor" aria-label="anchor" href="#jarquebera-test"><i class="fas fa-link"></i></a>
</h5>
<p>The <strong>Jarque-Bera (JB) test</strong> <span class="citation">(<a href="references.html#ref-Bera_1981">Bera and Jarque 1981</a>)</span> is a goodness-of-fit test used to check whether a dataset follows a normal distribution. It is based on the <strong>skewness</strong> and <strong>kurtosis</strong> of the data, which measure the asymmetry and the “tailedness” of the distribution, respectively.</p>
<p>The Jarque-Bera test statistic is defined as:</p>
<p><span class="math display">\[
JB = \frac{n}{6}\left(S^2 + \frac{(K - 3)^2}{4}\right),
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(n\)</span> is the sample size,</p></li>
<li><p><span class="math inline">\(S\)</span> is the sample skewness,</p></li>
<li><p><span class="math inline">\(K\)</span> is the sample kurtosis.</p></li>
</ul>
<p>Skewness (<span class="math inline">\(S\)</span>) is calculated as:</p>
<p><span class="math display">\[
S = \frac{\hat{\mu}_3}{\hat{\sigma}^3} = \frac{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^3}{\left(\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2\right)^{3/2}},
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(\hat{\mu}_3\)</span> is the third central moment,</p></li>
<li><p><span class="math inline">\(\hat{\sigma}\)</span> is the standard deviation,</p></li>
<li><p><span class="math inline">\(\bar{x}\)</span> is the sample mean.</p></li>
</ul>
<p>Kurtosis (<span class="math inline">\(K\)</span>) is calculated as:</p>
<p><span class="math display">\[
K = \frac{\hat{\mu}_4}{\hat{\sigma}^4} = \frac{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^4}{\left(\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2\right)^2},
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\hat{\mu}_4\)</span> is the fourth central moment.</li>
</ul>
<p>Hypothesis</p>
<ul>
<li>
<strong>Null hypothesis (</strong><span class="math inline">\(H_0\)</span>): The data follow a normal distribution, implying:
<ul>
<li>Skewness <span class="math inline">\(S = 0\)</span>,</li>
<li>Excess kurtosis <span class="math inline">\(K - 3 = 0\)</span>.</li>
</ul>
</li>
<li>
<strong>Alternative hypothesis (</strong><span class="math inline">\(H_1\)</span>): The data do not follow a normal distribution.</li>
</ul>
<p><strong>Distribution of the JB Statistic</strong></p>
<p>Under the null hypothesis, the Jarque-Bera statistic asymptotically follows a chi-squared distribution with 2 degrees of freedom:</p>
<p><span class="math display">\[
JB \sim \chi^2_2.
\]</span></p>
<p>Properties</p>
<ol style="list-style-type: decimal">
<li>
<strong>Sensitivity</strong>:
<ul>
<li>Skewness (<span class="math inline">\(S\)</span>) captures asymmetry in the data.</li>
<li>Kurtosis (<span class="math inline">\(K\)</span>) measures how heavy-tailed or light-tailed the distribution is compared to a normal distribution.</li>
</ul>
</li>
<li>
<strong>Limitations</strong>:
<ul>
<li>The test is sensitive to large sample sizes; even small deviations from normality may result in rejection of <span class="math inline">\(H_0\)</span>.</li>
<li>Assumes that the data are independently and identically distributed.</li>
</ul>
</li>
</ol>
<p>Applications</p>
<ul>
<li>Testing normality in regression residuals.</li>
<li>Validating distributional assumptions in econometrics and time series analysis.</li>
</ul>
<p>The Jarque-Bera test can be performed in R using the <code>tseries</code> package:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">tseries</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate a sample dataset</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>  <span class="co"># Normally distributed data</span></span>
<span></span>
<span><span class="co"># Perform the Jarque-Bera test</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tseries/man/jarque.bera.test.html">jarque.bera.test</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Jarque Bera Test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  data</span></span>
<span><span class="co">#&gt; X-squared = 0.89476, df = 2, p-value = 0.6393</span></span></code></pre></div>
</div>
</div>
</div>
</div>
<div id="bivariate-statistics" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Bivariate Statistics<a class="anchor" aria-label="anchor" href="#bivariate-statistics"><i class="fas fa-link"></i></a>
</h2>
<p>Bivariate statistics involve the analysis of relationships between two variables. Understanding these relationships can provide insights into patterns, associations, or (suggestive of) causal connections. Below, we explore the correlation between different types of variables:</p>
<ul>
<li>
<a href="descriptive-statistics.html#two-continuous">Two Continuous</a> <strong>Variables</strong>
</li>
<li>
<a href="descriptive-statistics.html#two-discrete">Two Discrete</a> <strong>Variables</strong>
</li>
<li>
<a href="descriptive-statistics.html#categorical-and-continuous">Categorical and Continuous</a> <strong>Variables</strong>
</li>
</ul>
<p>Before delving into the analysis, it is critical to consider the following:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Is the relationship linear or non-linear?</strong>
<ul>
<li>Linear relationships can be modeled with simpler statistical methods such as Pearson’s correlation, while non-linear relationships may require alternative approaches, such as Spearman’s rank correlation or regression with transformations.</li>
</ul>
</li>
<li>
<strong>If the variable is continuous, is it normal and homoskedastic?</strong>
<ul>
<li>For parametric methods like Pearson’s correlation, assumptions such as normality and homoskedasticity (equal variance) must be met. When these assumptions fail, non-parametric methods like Spearman’s correlation or robust alternatives are preferred.</li>
</ul>
</li>
<li>
<strong>How big is your dataset?</strong>
<ul>
<li>Large datasets can reveal subtle patterns but may lead to statistically significant results that are not practically meaningful. For smaller datasets, careful selection of statistical methods is essential to ensure reliability and validity.</li>
</ul>
</li>
</ol>
<div class="inline-table"><table style="width:99%;" class="table table-sm">
<colgroup>
<col width="14%">
<col width="47%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>Categorical</th>
<th>Continuous</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Categorical</strong></td>
<td>
<p><a href="descriptive-statistics.html#chi-squared-test">Chi-squared Test</a></p>
<p><a href="descriptive-statistics.html#phi-coefficient">Phi Coefficient</a></p>
<p><a href="descriptive-statistics.html#cramers-v">Cramer’s V</a></p>
<p><a href="descriptive-statistics.html#tschuprows-t">Tschuprow’s T</a></p>
<p><a href="descriptive-statistics.html#spearmans-rank-correlation">Spearman’s Rank Correlation</a></p>
<p><a href="descriptive-statistics.html#kendalls-tau">Kendall’s Tau</a></p>
<p><a href="descriptive-statistics.html#gamma-statistic">Gamma Statistic</a></p>
<p><a href="descriptive-statistics.html#freemans-theta">Freeman’s Theta</a></p>
<p><a href="descriptive-statistics.html#epsilon-squared">Epsilon-squared</a></p>
<p><a href="descriptive-statistics.html#goodman-kruskals-gamma">Goodman Kruskal’s Gamma</a></p>
<p><a href="descriptive-statistics.html#somers-d">Somers’ D</a></p>
<p><a href="descriptive-statistics.html#kendalls-tau-b">Kendall’s Tau-b</a></p>
<p><a href="descriptive-statistics.html#yules-q-and-y">Yule’s Q and Y</a></p>
<p><a href="descriptive-statistics.html#tetrachoric-correlation">Tetrachoric Correlation</a></p>
<p><a href="descriptive-statistics.html#polychoric-correlation">Polychoric Correlation</a></p>
</td>
<td></td>
</tr>
<tr class="even">
<td><strong>Continuous</strong></td>
<td>
<p><a href="descriptive-statistics.html#point-biserial-correlation">Point-Biserial Correlation</a></p>
<p><a href="descriptive-statistics.html#logistic-regression">Logistic Regression</a></p>
</td>
<td>
<p><a href="#pearson-correlation-1">Pearson Correlation</a></p>
<p><a href="descriptive-statistics.html#spearman-correlation">Spearman Correlation</a></p>
</td>
</tr>
</tbody>
</table></div>
<div id="two-continuous" class="section level3" number="3.4.1">
<h3>
<span class="header-section-number">3.4.1</span> Two Continuous<a class="anchor" aria-label="anchor" href="#two-continuous"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">100</span> <span class="co"># (sample size)</span></span>
<span></span>
<span><span class="va">data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">20</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span>,</span>
<span>                  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">30</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div id="pearson-correlation" class="section level4" number="3.4.1.1">
<h4>
<span class="header-section-number">3.4.1.1</span> Pearson Correlation<a class="anchor" aria-label="anchor" href="#pearson-correlation"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Pearson correlation</strong> quantifies the strength and direction of a <strong>linear relationship</strong> between two continuous variables.</p>
<p>Formula:</p>
<p><span class="math display">\[
r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \cdot \sum (y_i - \bar{y})^2}}
\]</span> where</p>
<ul>
<li><p><span class="math inline">\(x_i, y_i\)</span>: Individual data points of variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
<li><p><span class="math inline">\(\bar{x}, \bar{y}\)</span>: Means of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li>The relationship between variables is <strong>linear</strong>.</li>
<li>Variables are <strong>normally distributed</strong>.</li>
<li>Data exhibits <strong>homoscedasticity</strong> (equal variance of <span class="math inline">\(Y\)</span> for all values of <span class="math inline">\(X\)</span>).</li>
</ol>
<p>Use Case:</p>
<ul>
<li>Use when the relationship is expected to be linear, and assumptions of normality and homoscedasticity are met.</li>
</ul>
<p>Interpretation:</p>
<ul>
<li>
<span class="math inline">\(r = +1\)</span>: Perfect positive linear relationship.</li>
<li>
<span class="math inline">\(r = -1\)</span>: Perfect negative linear relationship.</li>
<li>
<span class="math inline">\(r = 0\)</span>: No linear relationship.</li>
</ul>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Pearson correlation</span></span>
<span><span class="va">pearson_corr</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">A</span>, <span class="va">data</span><span class="op">$</span><span class="va">B</span>, method <span class="op">=</span> <span class="st">"pearson"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Pearson Correlation (r):"</span>, <span class="va">pearson_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pearson Correlation (r): 0.02394939</span></span></code></pre></div>
</div>
<div id="spearman-correlation" class="section level4" number="3.4.1.2">
<h4>
<span class="header-section-number">3.4.1.2</span> Spearman Correlation<a class="anchor" aria-label="anchor" href="#spearman-correlation"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Spearman correlation</strong> measures the strength of a <strong>monotonic relationship</strong> between two variables. It ranks the data and calculates correlation based on ranks.</p>
<p>Formula:</p>
<p><span class="math display">\[
\rho = 1 - \frac{6 \sum d_i^2}{n(n^2 -1)}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(d_i\)</span>: Difference between the ranks of <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span>.</li>
<li>
<span class="math inline">\(n\)</span>: Number of paired observations.</li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Relationship must be <strong>monotonic</strong>, not necessarily linear.</p></li>
<li><p>No assumptions about the distribution of variables.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>Use when data is ordinal or when normality and linearity assumptions are violated.</li>
</ul>
<p>Interpretation:</p>
<ul>
<li><p><span class="math inline">\(\rho = +1\)</span>: Perfect positive monotonic relationship.</p></li>
<li><p><span class="math inline">\(\rho = -1\)</span>: Perfect negative monotonic relationship.</p></li>
<li><p><span class="math inline">\(\rho = 0\)</span>: No monotonic relationship.</p></li>
</ul>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Spearman correlation</span></span>
<span><span class="va">spearman_corr</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">A</span>, <span class="va">data</span><span class="op">$</span><span class="va">B</span>, method <span class="op">=</span> <span class="st">"spearman"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Spearman Correlation (rho):"</span>, <span class="va">spearman_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Spearman Correlation (rho): 0.02304636</span></span></code></pre></div>
</div>
<div id="kendalls-tau-correlation" class="section level4" number="3.4.1.3">
<h4>
<span class="header-section-number">3.4.1.3</span> Kendall’s Tau Correlation<a class="anchor" aria-label="anchor" href="#kendalls-tau-correlation"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Kendall’s Tau</strong> measures the strength of a <strong>monotonic relationship</strong> by comparing concordant and discordant pairs.</p>
<p>Formula:</p>
<p><span class="math display">\[
\tau = \frac{(C- D)}{\binom{n}{2}}
\]</span></p>
<p>where​</p>
<ul>
<li><p><span class="math inline">\(C\)</span>: Number of concordant pairs (where ranks of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> increase or decrease together).</p></li>
<li><p><span class="math inline">\(D\)</span>: Number of discordant pairs (where one rank increases while the other decreases).</p></li>
<li><p><span class="math inline">\(\binom{n}{2}\)</span>: Total number of possible pairs.</p></li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>No specific assumptions about the data distribution.</p></li>
<li><p>Measures monotonic relationships.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>Preferred for small datasets or when data contains outliers.</li>
</ul>
<p>Interpretation:</p>
<ul>
<li><p><span class="math inline">\(\tau = +1\)</span>: Perfect positive monotonic relationship.</p></li>
<li><p><span class="math inline">\(\tau = -1\)</span>: Perfect negative monotonic relationship.</p></li>
<li><p><span class="math inline">\(\tau = 0\)</span>: No monotonic relationship.</p></li>
</ul>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Kendall's Tau correlation</span></span>
<span><span class="va">kendall_corr</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">A</span>, <span class="va">data</span><span class="op">$</span><span class="va">B</span>, method <span class="op">=</span> <span class="st">"kendall"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Kendall's Tau Correlation (tau):"</span>, <span class="va">kendall_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Kendall's Tau Correlation (tau): 0.02171284</span></span></code></pre></div>
</div>
<div id="distance-correlation" class="section level4" number="3.4.1.4">
<h4>
<span class="header-section-number">3.4.1.4</span> Distance Correlation<a class="anchor" aria-label="anchor" href="#distance-correlation"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Distance Correlation</strong> measures both <strong>linear and non-linear relationships</strong> between variables. It does not require monotonicity or linearity.</p>
<p>Formula:</p>
<p><span class="math display">\[
d Cor = \frac{d Cov(X,Y)}{\sqrt{d Var (X) \cdot d Var (Y)}}
\]</span></p>
<p>where​</p>
<ul>
<li><p><span class="math inline">\(dCov\)</span>: Distance covariance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
<li><p><span class="math inline">\(dVar\)</span>: Distance variances of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
</ul>
<p><strong>Assumptions:</strong></p>
<ul>
<li>No specific assumptions about the relationship (linear, monotonic, or otherwise).</li>
</ul>
<p>Use Case:</p>
<ul>
<li>Use for complex relationships, including non-linear patterns.</li>
</ul>
<p>Interpretation:</p>
<ul>
<li><p><span class="math inline">\(dCor = 0\)</span>: No association.</p></li>
<li><p><span class="math inline">\(dCor = 1\)</span>: Perfect association.</p></li>
</ul>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Distance correlation</span></span>
<span><span class="va">distance_corr</span> <span class="op">&lt;-</span> <span class="fu">energy</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/energy/man/dcov.html">dcor</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">A</span>, <span class="va">data</span><span class="op">$</span><span class="va">B</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Distance Correlation (dCor):"</span>, <span class="va">distance_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Distance Correlation (dCor): 0.1008934</span></span></code></pre></div>
</div>
<div id="summary-table-of-correlation-methods" class="section level4" number="3.4.1.5">
<h4>
<span class="header-section-number">3.4.1.5</span> Summary Table of Correlation Methods<a class="anchor" aria-label="anchor" href="#summary-table-of-correlation-methods"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table style="width:98%;" class="table table-sm">
<colgroup>
<col width="14%">
<col width="17%">
<col width="15%">
<col width="16%">
<col width="13%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Formula/Approach</th>
<th>Detects Relationship Type</th>
<th>Assumptions</th>
<th>Sensitivity to Outliers</th>
<th>Use Case</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Pearson</strong></td>
<td>Linear covariance</td>
<td>Linear</td>
<td>Normality, homoscedasticity</td>
<td>High</td>
<td>Linear relationships.</td>
</tr>
<tr class="even">
<td><strong>Spearman</strong></td>
<td>Ranks and monotonicity formula</td>
<td>Monotonic</td>
<td>None</td>
<td>Moderate</td>
<td>Monotonic, non-linear data.</td>
</tr>
<tr class="odd">
<td><strong>Kendall’s Tau</strong></td>
<td>Concordance/discordance ratio</td>
<td>Monotonic</td>
<td>None</td>
<td>Low</td>
<td>Small datasets, robust to outliers.</td>
</tr>
<tr class="even">
<td><strong>Distance Correlation</strong></td>
<td>Distance-based variance</td>
<td>Linear and non-linear</td>
<td>None</td>
<td>Low</td>
<td>Complex, non-linear relationships.</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="categorical-and-continuous" class="section level3" number="3.4.2">
<h3>
<span class="header-section-number">3.4.2</span> Categorical and Continuous<a class="anchor" aria-label="anchor" href="#categorical-and-continuous"><i class="fas fa-link"></i></a>
</h3>
<p>Analyzing the relationship between a <strong>categorical variable</strong> (binary or multi-class) and a <strong>continuous variable</strong> requires specialized techniques. These methods assess whether the categorical variable significantly influences the continuous variable or vice versa.</p>
<p>We focus on the following methods:</p>
<ol style="list-style-type: decimal">
<li><a href="descriptive-statistics.html#point-biserial-correlation">Point-Biserial Correlation</a></li>
<li><a href="descriptive-statistics.html#logistic-regression">Logistic Regression</a></li>
<li><a href="sec-analysis-of-variance-anova.html#sec-analysis-of-variance-anova">Analysis of Variance (ANOVA)</a></li>
<li>T-test</li>
</ol>
<div id="point-biserial-correlation" class="section level4" number="3.4.2.1">
<h4>
<span class="header-section-number">3.4.2.1</span> Point-Biserial Correlation<a class="anchor" aria-label="anchor" href="#point-biserial-correlation"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>Point-Biserial Correlation</strong> is a special case of the Pearson correlation used to assess the relationship between a <strong>binary categorical variable</strong> (coded as 0 and 1) and a continuous variable. It measures the strength and direction of the linear relationship.</p>
<p>Formula:</p>
<p><span class="math display">\[
r_{pb} = \frac{\bar{Y_1} - \bar{Y_0}}{s_Y} \sqrt{\frac{n_1 n_0}{n^2}}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(\bar{Y_1}\)</span>, <span class="math inline">\(\bar{Y_0}\)</span>: Mean of the continuous variable for the groups coded as 1 and 0, respectively.</p></li>
<li><p><span class="math inline">\(s_Y\)</span>: Standard deviation of the continuous variable.</p></li>
<li><p><span class="math inline">\(n_1, n_0\)</span>: Number of observations in each group (1 and 0).</p></li>
<li><p><span class="math inline">\(n\)</span>: Total number of observations.</p></li>
</ul>
<p>Key Properties:</p>
<ul>
<li>
<strong>Range</strong>: <span class="math inline">\(-1\)</span> to <span class="math inline">\(1\)</span>.
<ul>
<li>
<span class="math inline">\(r_{pb} = +1\)</span>: Perfect positive correlation.</li>
<li>
<span class="math inline">\(r_{pb} = -1\)</span>: Perfect negative correlation.</li>
<li>
<span class="math inline">\(r_{pb} = 0\)</span>: No linear relationship.</li>
</ul>
</li>
<li>A positive <span class="math inline">\(r_{pb}\)</span> indicates higher values of the continuous variable are associated with the 1 group, while a negative <span class="math inline">\(r_{pb}\)</span> indicates the opposite.</li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li>The binary variable is <strong>truly dichotomous</strong> (e.g., male/female, success/failure).</li>
<li>The continuous variable is approximately <strong>normally distributed</strong>.</li>
<li>Homogeneity of variance across the two groups (not strictly required but recommended).</li>
</ol>
<p>Use Case:</p>
<ul>
<li>To evaluate the linear relationship between a binary categorical variable and a continuous variable.</li>
</ul>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/drizopoulos/ltm">ltm</a></span><span class="op">)</span></span>
<span><span class="co"># Point-Biserial Correlation</span></span>
<span><span class="va">biserial_corr</span> <span class="op">&lt;-</span> <span class="fu">ltm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ltm/man/biserial.cor.html">biserial.cor</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">12.5</span>, <span class="fl">15.3</span>, <span class="fl">10.7</span>, <span class="fl">18.1</span>, <span class="fl">11.2</span>, <span class="fl">16.8</span>, <span class="fl">13.4</span>, <span class="fl">14.9</span><span class="op">)</span>, </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, </span>
<span>  use <span class="op">=</span> <span class="st">"all.obs"</span>, </span>
<span>  level <span class="op">=</span> <span class="fl">2</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Point-Biserial Correlation:"</span>, <span class="va">biserial_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Point-Biserial Correlation: 0.8792835</span></span></code></pre></div>
</div>
<div id="logistic-regression" class="section level4" number="3.4.2.2">
<h4>
<span class="header-section-number">3.4.2.2</span> Logistic Regression<a class="anchor" aria-label="anchor" href="#logistic-regression"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Logistic Regression</strong> models the relationship between a <strong>binary categorical variable</strong> (dependent variable) and one or more independent variables (which may include continuous variables). It predicts the probability of the binary outcome (e.g., success/failure, yes/no).</p>
<p>Refer to <a href="descriptive-statistics.html#logistic-regression">3.4.2.2</a> for more detail.</p>
<p>Formula:</p>
<p>The logistic regression model is represented as:</p>
<p><span class="math display">\[
\text{logit}(p) = \ln \left( \frac{p}{1 - p} \right) = \beta_0 + \beta_1 X
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(p\)</span>: Probability of the outcome being 1.</p></li>
<li><p><span class="math inline">\(\beta_0\)</span>: Intercept.</p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: Coefficient for the continuous variable <span class="math inline">\(X\)</span>.</p></li>
<li><p><span class="math inline">\(\text{logit}(p)\)</span>: Log-odds of the probability.</p></li>
</ul>
<p>Key Features:</p>
<ul>
<li><p><strong>Output</strong>: Odds ratio or probability of the binary outcome.</p></li>
<li><p>Can include multiple predictors (continuous and categorical).</p></li>
<li><p>Non-linear transformation ensures predictions are probabilities between 0 and 1.</p></li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>The dependent variable is <strong>binary</strong>.</p></li>
<li><p>Observations are <strong>independent</strong>.</p></li>
<li><p>There is a <strong>linear relationship</strong> between the logit of the dependent variable and the independent variable.</p></li>
<li><p>No <strong>multicollinearity</strong> between predictors.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>To predict the likelihood of a binary outcome based on a continuous predictor (e.g., probability of success given test scores).</li>
</ul>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulated data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, mean <span class="op">=</span> <span class="fl">50</span>, sd <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>  <span class="co"># Continuous predictor</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">55</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span>  <span class="co"># Binary outcome based on threshold</span></span>
<span></span>
<span><span class="co"># Logistic Regression</span></span>
<span><span class="va">logistic_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">logistic_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = y ~ x, family = binomial)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;        Min          1Q      Median          3Q         Max  </span></span>
<span><span class="co">#&gt; -2.770e-04  -2.100e-08  -2.100e-08   2.100e-08   2.548e-04  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)  -3749.9   495083.0  -0.008    0.994</span></span>
<span><span class="co">#&gt; x               67.9     8966.6   0.008    0.994</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 1.2217e+02  on 99  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 1.4317e-07  on 98  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 25</span></span>
<span></span>
<span><span class="co"># Predicted probabilities</span></span>
<span><span class="va">predicted_probs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">logistic_model</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">predicted_probs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;         1         2         3         4         5         6 </span></span>
<span><span class="co">#&gt; -735.6466 -511.3844  703.2134 -307.2281 -267.3187  809.3747</span></span></code></pre></div>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Visualize logistic regression curve</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, predicted <span class="op">=</span> <span class="va">predicted_probs</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">predicted</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Logistic Regression: Continuous vs Binary"</span>,</span>
<span>         x <span class="op">=</span> <span class="st">"Continuous Predictor"</span>, y <span class="op">=</span> <span class="st">"Predicted Probability"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-22-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="summary-table-of-methods-between-categorical-and-continuous" class="section level4" number="3.4.2.3">
<h4>
<span class="header-section-number">3.4.2.3</span> Summary Table of Methods (Between Categorical and Continuous)<a class="anchor" aria-label="anchor" href="#summary-table-of-methods-between-categorical-and-continuous"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table style="width:99%;" class="table table-sm">
<colgroup>
<col width="21%">
<col width="26%">
<col width="24%">
<col width="26%">
</colgroup>
<thead><tr class="header">
<th>Method</th>
<th>Type of Variable Relationship</th>
<th>Key Assumptions</th>
<th>Use Case</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Point-Biserial Correlation</strong></td>
<td>Binary Categorical vs Continuous</td>
<td>Linear, normality (continuous)</td>
<td>Assess linear association.</td>
</tr>
<tr class="even">
<td><strong>Logistic Regression</strong></td>
<td>Continuous → Binary Categorical</td>
<td>Logit-linear relationship</td>
<td>Predict probability of binary outcome.</td>
</tr>
<tr class="odd">
<td><strong>ANOVA</strong></td>
<td>Multi-level Categorical vs Continuous</td>
<td>Normality, homogeneity of variance</td>
<td>Compare means across groups.</td>
</tr>
<tr class="even">
<td><strong>T-Test</strong></td>
<td>Binary Categorical vs Continuous</td>
<td>Normality, equal variance</td>
<td>Compare means between two groups.</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="two-discrete" class="section level3" number="3.4.3">
<h3>
<span class="header-section-number">3.4.3</span> Two Discrete<a class="anchor" aria-label="anchor" href="#two-discrete"><i class="fas fa-link"></i></a>
</h3>
<p>When analyzing the relationship between two <strong>discrete variables</strong> (categorical or ordinal), various methods are available to quantify the degree of association or similarity. These methods can broadly be classified into:</p>
<ol style="list-style-type: decimal">
<li><p><a href="descriptive-statistics.html#distance-metrics">Distance Metrics</a></p></li>
<li><p><a href="descriptive-statistics.html#statistical-metrics">Statistical Metrics</a></p></li>
</ol>
<hr>
<div id="distance-metrics" class="section level4" number="3.4.3.1">
<h4>
<span class="header-section-number">3.4.3.1</span> Distance Metrics<a class="anchor" aria-label="anchor" href="#distance-metrics"><i class="fas fa-link"></i></a>
</h4>
<p>Distance metrics measure the <strong>dissimilarity</strong> between two discrete variables and are often used as a proxy for correlation in specific applications like clustering or machine learning.</p>
<div id="euclidean-distance" class="section level5" number="3.4.3.1.1">
<h5>
<span class="header-section-number">3.4.3.1.1</span> Euclidean Distance<a class="anchor" aria-label="anchor" href="#euclidean-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
\]</span></p>
<ul>
<li><p>Measures the straight-line distance between two variables in Euclidean space.</p></li>
<li><p>Sensitive to scaling; variables should be normalized for meaningful comparisons.</p></li>
</ul>
</div>
<div id="manhattan-distance" class="section level5" number="3.4.3.1.2">
<h5>
<span class="header-section-number">3.4.3.1.2</span> Manhattan Distance<a class="anchor" aria-label="anchor" href="#manhattan-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \sum_{i=1}^n |x_i - y_i|
\]</span></p>
<ul>
<li><p>Measures distance by summing the absolute differences along each dimension.</p></li>
<li><p>Also called <strong>L1 norm</strong>; often used in grid-based problems.</p></li>
</ul>
</div>
<div id="chebyshev-distance" class="section level5" number="3.4.3.1.3">
<h5>
<span class="header-section-number">3.4.3.1.3</span> Chebyshev Distance<a class="anchor" aria-label="anchor" href="#chebyshev-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \max_{i=1}^n |x_i - y_i|
\]</span></p>
<ul>
<li><p>Measures the maximum single-step distance along any dimension.</p></li>
<li><p>Useful in discrete, grid-based problems (e.g., chess moves).</p></li>
</ul>
</div>
<div id="minkowski-distance" class="section level5" number="3.4.3.1.4">
<h5>
<span class="header-section-number">3.4.3.1.4</span> Minkowski Distance<a class="anchor" aria-label="anchor" href="#minkowski-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \left( \sum_{i=1}^n |x_i - y_i|^p \right)^{1/p}
\]</span></p>
<ul>
<li>
<p>Generalized distance metric. Special cases include:</p>
<ul>
<li><p><span class="math inline">\(p = 1\)</span>: Manhattan Distance.</p></li>
<li><p><span class="math inline">\(p = 2\)</span>: Euclidean Distance.</p></li>
<li><p><span class="math inline">\(p \to \infty\)</span>: Chebyshev Distance.</p></li>
</ul>
</li>
</ul>
</div>
<div id="canberra-distance" class="section level5" number="3.4.3.1.5">
<h5>
<span class="header-section-number">3.4.3.1.5</span> Canberra Distance<a class="anchor" aria-label="anchor" href="#canberra-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \sum_{i=1}^n \frac{|x_i - y_i|}{|x_i| + |y_i|}
\]</span></p>
<ul>
<li>Emphasizes proportional differences, making it sensitive to smaller values.</li>
</ul>
</div>
<div id="hamming-distance" class="section level5" number="3.4.3.1.6">
<h5>
<span class="header-section-number">3.4.3.1.6</span> Hamming Distance<a class="anchor" aria-label="anchor" href="#hamming-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \sum_{i=1}^n I(x_i \neq y_i)
\]</span></p>
<ul>
<li><p>Counts the number of differing positions between two sequences.</p></li>
<li><p>Widely used in text similarity and binary data.</p></li>
</ul>
</div>
<div id="cosine-similarity-and-distance" class="section level5" number="3.4.3.1.7">
<h5>
<span class="header-section-number">3.4.3.1.7</span> Cosine Similarity and Distance<a class="anchor" aria-label="anchor" href="#cosine-similarity-and-distance"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
\text{Cosine Similarity} = \frac{\sum_{i=1}^n x_i y_i}{\sqrt{\sum_{i=1}^n x_i^2} \cdot \sqrt{\sum_{i=1}^n y_i^2}}
\]</span></p>
<p><span class="math display">\[
\text{Cosine Distance} = 1 - \text{Cosine Similarity}
\]</span></p>
<ul>
<li><p>Measures the angle between two vectors in a high-dimensional space.</p></li>
<li><p>Often used in text and document similarity.</p></li>
</ul>
</div>
<div id="sum-of-absolute-differences" class="section level5" number="3.4.3.1.8">
<h5>
<span class="header-section-number">3.4.3.1.8</span> Sum of Absolute Differences<a class="anchor" aria-label="anchor" href="#sum-of-absolute-differences"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \sum_{i=1}^n |x_i - y_i|
\]</span></p>
<ul>
<li>Equivalent to Manhattan Distance but without coordinate context.</li>
</ul>
</div>
<div id="sum-of-squared-differences" class="section level5" number="3.4.3.1.9">
<h5>
<span class="header-section-number">3.4.3.1.9</span> Sum of Squared Differences<a class="anchor" aria-label="anchor" href="#sum-of-squared-differences"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
d(x, y) = \sum_{i=1}^n (x_i - y_i)^2
\]</span></p>
<ul>
<li>Equivalent to squared Euclidean Distance.</li>
</ul>
</div>
<div id="mean-absolute-error" class="section level5" number="3.4.3.1.10">
<h5>
<span class="header-section-number">3.4.3.1.10</span> Mean Absolute Error<a class="anchor" aria-label="anchor" href="#mean-absolute-error"><i class="fas fa-link"></i></a>
</h5>
<p><span class="math display">\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^n |x_i - y_i|
\]</span></p>
<ul>
<li>Measures average absolute differences.</li>
</ul>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example data</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">5</span>, <span class="fl">6</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute distances</span></span>
<span><span class="va">euclidean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">manhattan</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">chebyshev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">hamming</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span> <span class="op">!=</span> <span class="va">y</span><span class="op">)</span></span>
<span><span class="va">cosine_similarity</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span> <span class="op">*</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cosine_distance</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">cosine_similarity</span></span>
<span></span>
<span><span class="co"># Display results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Euclidean Distance:"</span>, <span class="va">euclidean</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Euclidean Distance: 2.236068</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Manhattan Distance:"</span>, <span class="va">manhattan</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Manhattan Distance: 5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Chebyshev Distance:"</span>, <span class="va">chebyshev</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chebyshev Distance: 1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Hamming Distance:"</span>, <span class="va">hamming</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Hamming Distance: 5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Cosine Distance:"</span>, <span class="va">cosine_distance</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Cosine Distance: 0.005063324</span></span></code></pre></div>
</div>
</div>
<div id="statistical-metrics" class="section level4" number="3.4.3.2">
<h4>
<span class="header-section-number">3.4.3.2</span> Statistical Metrics<a class="anchor" aria-label="anchor" href="#statistical-metrics"><i class="fas fa-link"></i></a>
</h4>
<div id="chi-squared-test" class="section level5" number="3.4.3.2.1">
<h5>
<span class="header-section-number">3.4.3.2.1</span> Chi-squared Test<a class="anchor" aria-label="anchor" href="#chi-squared-test"><i class="fas fa-link"></i></a>
</h5>
<p>The <strong>Chi-Squared Test</strong> evaluates whether two categorical variables are <strong>independent</strong> by comparing observed and expected frequencies in a contingency table.</p>
<p>Formula:</p>
<p><span class="math display">\[
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(O_i\)</span>: Observed frequency in each cell of the table.</p></li>
<li><p><span class="math inline">\(E_i\)</span>: Expected frequency under the assumption of independence.</p></li>
</ul>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li><p>Construct a contingency table with observed counts.</p></li>
<li><p>Compute expected frequencies: <span class="math inline">\(E_{ij} = \frac{\text{Row Total}_i \cdot \text{Column Total}_j}{\text{Grand Total}}\)</span></p></li>
<li><p>Apply the Chi-squared formula.</p></li>
<li><p>Compare <span class="math inline">\(\chi^2\)</span> with a critical value from the <a href="prerequisites.html#chi-squared-distribution">Chi-squared distribution</a>.</p></li>
</ol>
<p>Assumptions:</p>
<ol style="list-style-type: decimal">
<li><p>Observations are <strong>independent</strong>.</p></li>
<li><p>Expected frequencies should be <span class="math inline">\(\geq 5\)</span> in at least 80% of the cells.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>Tests for <strong>independence</strong> between two nominal variables.</li>
</ul>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example data</span></span>
<span><span class="va">dt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">15</span>, <span class="fl">25</span>, <span class="fl">20</span>, <span class="fl">40</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">dt</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Group A"</span>, <span class="st">"Group B"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">dt</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Category 1"</span>, <span class="st">"Category 2"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Perform Chi-Squared Test</span></span>
<span><span class="va">chi_sq_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">dt</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">chi_sq_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pearson's Chi-squared test with Yates' continuity correction</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  dt</span></span>
<span><span class="co">#&gt; X-squared = 0.045788, df = 1, p-value = 0.8306</span></span></code></pre></div>
</div>
<div id="phi-coefficient" class="section level5" number="3.4.3.2.2">
<h5>
<span class="header-section-number">3.4.3.2.2</span> Phi Coefficient<a class="anchor" aria-label="anchor" href="#phi-coefficient"><i class="fas fa-link"></i></a>
</h5>
<p>The <strong>Phi Coefficient</strong> is a measure of association between two <strong>binary variables</strong>, derived from the Chi-squared statistic.</p>
<p>Formula:</p>
<p><span class="math display">\[
\phi = \frac{\chi^2}{n}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(n\)</span>: Total sample size.</li>
</ul>
<p>Interpretation:</p>
<ul>
<li><p><span class="math inline">\(\phi = 0\)</span>: No association.</p></li>
<li><p><span class="math inline">\(\phi = +1\)</span>: Perfect positive association.</p></li>
<li><p><span class="math inline">\(\phi = -1\)</span>: Perfect negative association.</p></li>
</ul>
<p>Use Case:</p>
<ul>
<li>Suitable for <strong>2x2 contingency tables</strong>.</li>
<li>2 binary</li>
</ul>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://personality-project.org/r/psych/">psych</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Phi Coefficient</span></span>
<span><span class="va">phi_coeff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/psych/man/phi.html">phi</a></span><span class="op">(</span><span class="va">dt</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Phi Coefficient:"</span>, <span class="va">phi_coeff</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Phi Coefficient: 0.04</span></span></code></pre></div>
</div>
<div id="cramers-v" class="section level5" number="3.4.3.2.3">
<h5>
<span class="header-section-number">3.4.3.2.3</span> Cramer’s V<a class="anchor" aria-label="anchor" href="#cramers-v"><i class="fas fa-link"></i></a>
</h5>
<p><strong>Cramer’s V</strong> generalizes the Phi coefficient to handle contingency tables with more than two rows or columns.</p>
<p>Formula:</p>
<p><span class="math display">\[
V = \sqrt{\frac{\chi^2 / n}{\min(r-1, c-1)}}
\]</span></p>
<p>where​​</p>
<ul>
<li><p><span class="math inline">\(r\)</span>: Number of rows.</p></li>
<li><p><span class="math inline">\(c\)</span>: Number of columns.</p></li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Variables are nominal.</p></li>
<li><p>Suitable for <strong>larger contingency tables</strong>.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>Measures the <strong>strength of association</strong> between nominal variables with no natural order.</li>
</ul>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/djnavarro/lsr">lsr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>,  <span class="co"># Nominal variable</span></span>
<span>  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>  <span class="co"># Nominal variable</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Cramer's V</span></span>
<span><span class="va">cramers_v</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lsr/man/cramersV.html">cramersV</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">A</span>, <span class="va">data</span><span class="op">$</span><span class="va">B</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Cramer's V:"</span>, <span class="va">cramers_v</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Cramer's V: 0.1944616</span></span></code></pre></div>
<p>Alternatively,</p>
<ul>
<li><p><code>ncchisq</code> noncentral Chi-square</p></li>
<li><p><code>nchisqadj</code> Adjusted noncentral Chi-square</p></li>
<li><p><code>fisher</code> Fisher Z transformation</p></li>
<li><p><code>fisheradj</code> bias correction Fisher z transformation</p></li>
</ul>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">DescTools</span><span class="fu">::</span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">CramerV</a></span><span class="op">(</span><span class="va">data</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span>,method <span class="op">=</span> <span class="st">"ncchisqadj"</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Cramer V    lwr.ci    upr.ci </span></span>
<span><span class="co">#&gt; 0.3472325 0.3929964 0.4033053</span></span></code></pre></div>
</div>
<div id="adjusted-cramers-v" class="section level5" number="3.4.3.2.4">
<h5>
<span class="header-section-number">3.4.3.2.4</span> Adjusted Cramer’s V<a class="anchor" aria-label="anchor" href="#adjusted-cramers-v"><i class="fas fa-link"></i></a>
</h5>
<p>Adjusted versions of Cramer’s V correct for bias, especially in small samples.</p>
<p>Adjusted formulas account for non-central Chi-squared or bias correction. Examples include:</p>
<ul>
<li><p><strong>Non-central Chi-squared</strong>: <span class="math inline">\(V_{adj} = \sqrt{\frac{\chi^2_{nc} / n}{\min(r-1, c-1)}}\)</span>​</p></li>
<li><p><strong>Bias Correction</strong>: <span class="math inline">\(V_{adj} = V - \text{Bias Term}\)</span></p></li>
</ul>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://andrisignorell.github.io/DescTools/">DescTools</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Adjusted Cramer's V</span></span>
<span><span class="va">cramers_v_adj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">CramerV</a></span><span class="op">(</span><span class="va">data</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span>, method <span class="op">=</span> <span class="st">"ncchisqadj"</span><span class="op">)</span></span>
<span><span class="va">cramers_v_adj</span></span>
<span><span class="co">#&gt;  Cramer V    lwr.ci    upr.ci </span></span>
<span><span class="co">#&gt; 0.3472325 0.3929964 0.4033053</span></span></code></pre></div>
</div>
<div id="tschuprows-t" class="section level5" number="3.4.3.2.5">
<h5>
<span class="header-section-number">3.4.3.2.5</span> Tschuprow’s T<a class="anchor" aria-label="anchor" href="#tschuprows-t"><i class="fas fa-link"></i></a>
</h5>
<p><strong>Tschuprow’s T</strong> is a symmetric measure of association for nominal variables. It differs from Cramer’s V by considering the product of rows and columns, making it less sensitive to asymmetrical tables.</p>
<p>Formula:</p>
<p><span class="math display">\[
T = \sqrt{\frac{\chi^2/n}{\sqrt{(r-1)(c-1)}}}
\]</span></p>
<p><strong>Assumptions</strong>:</p>
<ul>
<li><p>Applicable to nominal variables.</p></li>
<li><p>Suitable for contingency tables with unequal dimensions.</p></li>
</ul>
<p>Use Case:</p>
<ul>
<li>Preferred when table dimensions are <strong>highly unequal</strong>.</li>
</ul>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute Tschuprow's T</span></span>
<span><span class="va">tschuprow_t</span> <span class="op">&lt;-</span> <span class="fu">DescTools</span><span class="fu">::</span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">TschuprowT</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">A</span>, <span class="va">data</span><span class="op">$</span><span class="va">B</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Tschuprow's T:"</span>, <span class="va">tschuprow_t</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Tschuprow's T: 0.1839104</span></span></code></pre></div>
</div>
<div id="ordinal-association-rank-correlation" class="section level5" number="3.4.3.2.6">
<h5>
<span class="header-section-number">3.4.3.2.6</span> Ordinal Association (Rank correlation)<a class="anchor" aria-label="anchor" href="#ordinal-association-rank-correlation"><i class="fas fa-link"></i></a>
</h5>
<p>When at least one variable is <strong>ordinal</strong>, rank-based methods are the most appropriate as they respect the <strong>order of the categories</strong>. These methods are often used when relationships are monotonic (increasing or decreasing consistently) but not necessarily linear.</p>
<div id="spearmans-rank-correlation" class="section level6" number="3.4.3.2.6.1">
<h6>
<span class="header-section-number">3.4.3.2.6.1</span> Spearman’s Rank Correlation<a class="anchor" aria-label="anchor" href="#spearmans-rank-correlation"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Spearman’s Rank Correlation</strong> (<span class="math inline">\(\rho\)</span>) measures the strength and direction of a <strong>monotonic relationship</strong> between two variables. It transforms the data into ranks and calculates Pearson correlation on the ranks.</p>
<p>Formula:</p>
<p><span class="math display">\[
\rho = 1 - \frac{6 \sum d_i^2}{n (n^2 -1)}
\]</span></p>
<p>where​​</p>
<ul>
<li><p><span class="math inline">\(d_i\)</span>: Difference between the ranks of the paired observations.</p></li>
<li><p><span class="math inline">\(n\)</span>: Number of paired observations.</p></li>
</ul>
<p><strong>Assumptions</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Data must be <strong>ordinal</strong> or <strong>continuous</strong> but convertible to ranks.</p></li>
<li><p>Relationship is <strong>monotonic</strong>.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>Suitable for ordinal-ordinal or ordinal-continuous associations.</li>
</ul>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulating ordinal data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">ordinal_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">100</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">ordinal_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">100</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Spearman's Correlation</span></span>
<span><span class="va">spearman_corr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">ordinal_x</span>, <span class="va">ordinal_y</span>, method <span class="op">=</span> <span class="st">"spearman"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Spearman's Correlation (rho):"</span>, <span class="va">spearman_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Spearman's Correlation (rho): 0.08731195</span></span></code></pre></div>
</div>
<div id="kendalls-tau" class="section level6" number="3.4.3.2.6.2">
<h6>
<span class="header-section-number">3.4.3.2.6.2</span> Kendall’s Tau<a class="anchor" aria-label="anchor" href="#kendalls-tau"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Kendall’s Tau</strong> (<span class="math inline">\(\tau\)</span>) measures the strength of a <strong>monotonic relationship</strong> by comparing concordant and discordant pairs.</p>
<p>Formula:</p>
<p><span class="math display">\[
\tau = \frac{C - D}{C + D}
\]</span>​where</p>
<ul>
<li><p><span class="math inline">\(C\)</span>: Number of concordant pairs (ranks increase together).</p></li>
<li><p><span class="math inline">\(D\)</span>: Number of discordant pairs (one rank increases while the other decreases).</p></li>
</ul>
<p>Variants:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Kendall’s Tau-a</strong>: For data with no ties.</p></li>
<li><p><strong>Kendall’s Tau-b</strong>: Adjusted for ties in ranks.</p></li>
<li><p><strong>Kendall’s Tau-c</strong>: Adjusted for ties in large tables.</p></li>
</ol>
<p>Use Case:</p>
<ul>
<li>Ideal for small datasets or when ties are present.</li>
</ul>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Kendall's Tau</span></span>
<span><span class="va">kendall_corr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">ordinal_x</span>, <span class="va">ordinal_y</span>, method <span class="op">=</span> <span class="st">"kendall"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Kendall's Tau (tau):"</span>, <span class="va">kendall_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Kendall's Tau (tau): 0.06795076</span></span></code></pre></div>
</div>
<div id="gamma-statistic" class="section level6" number="3.4.3.2.6.3">
<h6>
<span class="header-section-number">3.4.3.2.6.3</span> Gamma Statistic<a class="anchor" aria-label="anchor" href="#gamma-statistic"><i class="fas fa-link"></i></a>
</h6>
<p>The <strong>Gamma Statistic</strong> measures the strength of association between two ordinal variables by focusing on <strong>concordant</strong> and <strong>discordant</strong> pairs, ignoring ties.</p>
<p>Formula:</p>
<p><span class="math display">\[
\gamma = \frac{C- D}{C + D}
\]</span></p>
<p>Use Case:</p>
<ul>
<li>Works well when there are <strong>many ties</strong> in the data.</li>
</ul>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">vcd</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulating ordinal data</span></span>
<span><span class="va">cont_table</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">ordinal_x</span>, <span class="va">ordinal_y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Gamma Statistic</span></span>
<span><span class="va">gamma_stat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/vcd/man/assocstats.html">assocstats</a></span><span class="op">(</span><span class="va">cont_table</span><span class="op">)</span><span class="op">$</span><span class="va">gamma</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Gamma Statistic:"</span>, <span class="va">gamma_stat</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Gamma Statistic:</span></span></code></pre></div>
</div>
<div id="freemans-theta" class="section level6" number="3.4.3.2.6.4">
<h6>
<span class="header-section-number">3.4.3.2.6.4</span> Freeman’s Theta<a class="anchor" aria-label="anchor" href="#freemans-theta"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Freeman’s Theta</strong> measures the association between an <strong>ordinal variable</strong> and a <strong>nominal variable</strong>. It quantifies how well the grouping in the nominal variable explains the ordering in the ordinal variable.</p>
<p>Use Case:</p>
<ul>
<li>Useful when analyzing relationships between ordinal predictors and nominal responses (or vice versa).</li>
</ul>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">rcompanion</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rcompanion/man/freemanTheta.html">freemanTheta</a></span><span class="op">(</span><span class="va">ordinal_x</span>, <span class="va">ordinal_y</span><span class="op">)</span></span>
<span><span class="co">#&gt; Freeman.theta </span></span>
<span><span class="co">#&gt;         0.094</span></span></code></pre></div>
</div>
<div id="epsilon-squared" class="section level6" number="3.4.3.2.6.5">
<h6>
<span class="header-section-number">3.4.3.2.6.5</span> Epsilon-squared<a class="anchor" aria-label="anchor" href="#epsilon-squared"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Epsilon-Squared</strong> (<span class="math inline">\(\epsilon^2\)</span>) measures the proportion of variance in the <strong>ordinal variable</strong> explained by a <strong>nominal variable</strong>. It is conceptually similar to the coefficient of determination (<span class="math inline">\(R^2\)</span>) in linear regression but adapted for ordinal-nominal relationships.</p>
<p>Formula:</p>
<p><span class="math display">\[
\epsilon^2 = \frac{\text{variance explained by group differences}}{\text{total variance}}
\]</span></p>
<p>where</p>
<ul>
<li><p>The numerator represents the variance between ordinal categories due to differences in nominal groups.</p></li>
<li><p>The denominator is the total variance in the ordinal variable.</p></li>
</ul>
<p>Use Case:</p>
<ul>
<li>Quantifies the effect size when analyzing how well a nominal variable explains an ordinal variable.</li>
</ul>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">ordinal_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">100</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  <span class="co"># Ordinal variable</span></span>
<span><span class="va">nominal_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">100</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co"># Nominal variable</span></span>
<span></span>
<span><span class="co"># Compute Epsilon-Squared</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://CRAN.R-project.org/package=rcompanion">rcompanion</a></span><span class="op">)</span></span>
<span><span class="va">epsilon_squared</span> <span class="op">&lt;-</span> <span class="fu">rcompanion</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rcompanion/man/epsilonSquared.html">epsilonSquared</a></span><span class="op">(</span><span class="va">ordinal_x</span>,  <span class="va">nominal_y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">epsilon_squared</span><span class="op">)</span></span>
<span><span class="co">#&gt; epsilon.squared </span></span>
<span><span class="co">#&gt;         0.00446</span></span></code></pre></div>
</div>
<div id="goodman-kruskals-gamma" class="section level6" number="3.4.3.2.6.6">
<h6>
<span class="header-section-number">3.4.3.2.6.6</span> Goodman-Kruskal’s Gamma<a class="anchor" aria-label="anchor" href="#goodman-kruskals-gamma"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Goodman-Kruskal’s Gamma</strong> measures the strength of association between two <strong>ordinal variables</strong>. It is a rank-based measure, focusing only on <strong>concordant</strong> and <strong>discordant</strong> pairs while ignoring ties.</p>
<p>Formula:</p>
<p><span class="math display">\[
\gamma = \frac{C - D}{C + D}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(C\)</span>: Number of concordant pairs (where ranks move in the same direction).</p></li>
<li><p><span class="math inline">\(D\)</span>: Number of discordant pairs (where ranks move in opposite directions).</p></li>
</ul>
<p>Use Case:</p>
<ul>
<li>Suitable for ordinal variables with many ties.</li>
</ul>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">=</span> <span class="fl">100</span> <span class="co"># (sample size)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">dt</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span>, <span class="co"># ordinal</span></span>
<span>    B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span>  <span class="co"># ordinal</span></span>
<span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">dt</span></span>
<span><span class="co">#&gt;    B</span></span>
<span><span class="co">#&gt; A    1  2  3</span></span>
<span><span class="co">#&gt;   1  7 11  9</span></span>
<span><span class="co">#&gt;   2 11  6 14</span></span>
<span><span class="co">#&gt;   3  7 11  4</span></span>
<span><span class="co">#&gt;   4  6  4 10</span></span></code></pre></div>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute Goodman-Kruskal's Gamma</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://andrisignorell.github.io/DescTools/">DescTools</a></span><span class="op">)</span></span>
<span><span class="va">goodman_kruskal_gamma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/GoodmanKruskalGamma.html">GoodmanKruskalGamma</a></span><span class="op">(</span><span class="va">dt</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Goodman-Kruskal's Gamma:"</span>, <span class="va">goodman_kruskal_gamma</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Goodman-Kruskal's Gamma: 0.006781013 -0.2290321 0.2425941</span></span></code></pre></div>
</div>
<div id="somers-d" class="section level6" number="3.4.3.2.6.7">
<h6>
<span class="header-section-number">3.4.3.2.6.7</span> Somers’ D<a class="anchor" aria-label="anchor" href="#somers-d"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Somers’ D</strong> (also called Somers’ Delta) extends Kendall’s Tau by focusing on <strong>asymmetric relationships</strong>, where one variable is a predictor and the other is a response.</p>
<p>Formula:</p>
<p><span class="math display">\[
D_{XY} = \frac{C - D}{C + D + T_Y}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(T_Y\)</span>: Tied pairs in the dependent variable.</li>
</ul>
<p>Use Case:</p>
<ul>
<li>Appropriate when there is a clear predictor-response relationship between two ordinal variables.</li>
</ul>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute Somers' D</span></span>
<span><span class="va">somers_d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/SomersDelta.html">SomersDelta</a></span><span class="op">(</span><span class="va">dt</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="va">somers_d</span></span>
<span><span class="co">#&gt;       somers       lwr.ci       upr.ci </span></span>
<span><span class="co">#&gt;  0.005115859 -0.172800185  0.183031903</span></span></code></pre></div>
</div>
<div id="kendalls-tau-b" class="section level6" number="3.4.3.2.6.8">
<h6>
<span class="header-section-number">3.4.3.2.6.8</span> Kendall’s Tau-b<a class="anchor" aria-label="anchor" href="#kendalls-tau-b"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Kendall’s Tau-b</strong> is an extension of Kendall’s Tau that accounts for <strong>ties</strong> in the data.</p>
<p>Formula:</p>
<p><span class="math display">\[
\tau_b = \frac{C - D}{\sqrt{(C + D+ T_X) (C + D + T_Y)}}
\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(T_X, T_Y\)</span>: Tied pairs in each variable.</li>
</ul>
<p>Use Case:</p>
<ul>
<li>Use when ordinal data contains ties.</li>
</ul>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute Kendall's Tau-b</span></span>
<span><span class="va">kendalls_tau_b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/KendallTauB.html">KendallTauB</a></span><span class="op">(</span><span class="va">dt</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="va">kendalls_tau_b</span></span>
<span><span class="co">#&gt;        tau_b       lwr.ci       upr.ci </span></span>
<span><span class="co">#&gt;  0.004839732 -0.163472443  0.173151906</span></span></code></pre></div>
</div>
<div id="yules-q-and-y" class="section level6" number="3.4.3.2.6.9">
<h6>
<span class="header-section-number">3.4.3.2.6.9</span> Yule’s Q and Y<a class="anchor" aria-label="anchor" href="#yules-q-and-y"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Yule’s Q</strong> and <strong>Yule’s Y</strong> are specialized measures for <strong>2x2 contingency tables</strong>. They are simplified versions of Goodman-Kruskal’s Gamma, designed for binary ordinal variables.​​</p>
<p>Use Case:</p>
<ul>
<li>Ideal for binary ordinal variables in a 2x2 table.</li>
</ul>
<p>Special version <span class="math inline">\((2 \times 2)\)</span> of the <a href="descriptive-statistics.html#goodman-kruskals-gamma">Goodman Kruskal’s Gamma</a> coefficient.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th></th>
<th>Variable 1</th>
<th></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Variable 2</strong></td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td></td>
<td>c</td>
<td>d</td>
</tr>
</tbody>
</table></div>
<p><span class="math display">\[
\text{Yule's Q} = \frac{ad - bc}{ad + bc}
\]</span></p>
<p>We typically use Yule’s <span class="math inline">\(Q\)</span> in practice while Yule’s Y has the following relationship with <span class="math inline">\(Q\)</span>.</p>
<p><span class="math display">\[
\text{Yule's Y} = \frac{\sqrt{ad} - \sqrt{bc}}{\sqrt{ad} + \sqrt{bc}}
\]</span></p>
<p><span class="math display">\[
Q = \frac{2Y}{1 + Y^2}
\]</span></p>
<p><span class="math display">\[
Y = \frac{1 = \sqrt{1-Q^2}}{Q}
\]</span></p>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create 2x2 table</span></span>
<span><span class="va">dt_binary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span>,</span>
<span>  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Yule's Q</span></span>
<span><span class="va">yules_q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">YuleQ</a></span><span class="op">(</span><span class="va">dt_binary</span><span class="op">)</span></span>
<span><span class="va">yules_q</span></span>
<span><span class="co">#&gt; [1] -0.07667474</span></span></code></pre></div>
</div>
<div id="tetrachoric-correlation" class="section level6" number="3.4.3.2.6.10">
<h6>
<span class="header-section-number">3.4.3.2.6.10</span> Tetrachoric Correlation<a class="anchor" aria-label="anchor" href="#tetrachoric-correlation"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Tetrachoric Correlation</strong> measures the association between two <strong>binary variables</strong> by assuming they represent thresholds of underlying continuous normal distributions. It is a special case of <a href="descriptive-statistics.html#polychoric-correlation">Polychoric Correlation</a> when both variables are binary</p>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulate binary data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://personality-project.org/r/psych/">psych</a></span><span class="op">)</span></span>
<span><span class="va">data_binary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span>,</span>
<span>  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Tetrachoric Correlation</span></span>
<span><span class="va">tetrachoric_corr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/psych/man/tetrachor.html">tetrachoric</a></span><span class="op">(</span><span class="va">data_binary</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">tetrachoric_corr</span><span class="op">)</span></span>
<span><span class="co">#&gt; Call: tetrachoric(x = data_binary)</span></span>
<span><span class="co">#&gt; tetrachoric correlation </span></span>
<span><span class="co">#&gt;   A    B   </span></span>
<span><span class="co">#&gt; A 1.00     </span></span>
<span><span class="co">#&gt; B 0.31 1.00</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  with tau of </span></span>
<span><span class="co">#&gt;      A      B </span></span>
<span><span class="co">#&gt;  0.126 -0.025</span></span></code></pre></div>
</div>
<div id="polychoric-correlation" class="section level6" number="3.4.3.2.6.11">
<h6>
<span class="header-section-number">3.4.3.2.6.11</span> Polychoric Correlation<a class="anchor" aria-label="anchor" href="#polychoric-correlation"><i class="fas fa-link"></i></a>
</h6>
<p><strong>Polychoric Correlation</strong> measures the association between <strong>ordinal variables</strong> by assuming they are discretized versions of latent, normally distributed continuous variables.</p>
<p>Assumptions:</p>
<ul>
<li>The ordinal variables represent categories of an underlying normal distribution.</li>
</ul>
<p>Use Case:</p>
<ul>
<li>Suitable for ordinal variables with a natural order.</li>
</ul>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulate ordinal data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-forge.r-project.org/projects/polycor/">polycor</a></span><span class="op">)</span></span>
<span><span class="va">data_ordinal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span>,</span>
<span>  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, size <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute Polychoric Correlation</span></span>
<span><span class="va">polychoric_corr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/polycor/man/polychor.html">polychor</a></span><span class="op">(</span><span class="va">data_ordinal</span><span class="op">$</span><span class="va">A</span>, <span class="va">data_ordinal</span><span class="op">$</span><span class="va">B</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Polychoric Correlation:"</span>, <span class="va">polychoric_corr</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Polychoric Correlation: 0.1908334</span></span></code></pre></div>
<div class="inline-table"><table style="width:99%;" class="table table-sm">
<colgroup>
<col width="25%">
<col width="31%">
<col width="42%">
</colgroup>
<thead><tr class="header">
<th>Metric</th>
<th>Variable Types</th>
<th>Use Case</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>Spearman’s Correlation</strong></td>
<td>Ordinal vs. Ordinal</td>
<td>Non-linear, monotonic relationships.</td>
</tr>
<tr class="even">
<td><strong>Kendall’s Tau</strong></td>
<td>Ordinal vs. Ordinal</td>
<td>Non-linear, monotonic relationships with ties.</td>
</tr>
<tr class="odd">
<td><strong>Gamma Statistic</strong></td>
<td>Ordinal vs. Ordinal</td>
<td>Handles data with many ties effectively.</td>
</tr>
<tr class="even">
<td><strong>Freeman’s Theta</strong></td>
<td>Ordinal vs. Nominal</td>
<td>Mixed data types (ordinal and nominal).</td>
</tr>
<tr class="odd">
<td><strong>Epsilon-Squared</strong></td>
<td>Ordinal vs. Nominal</td>
<td>Variance explained by nominal groups.</td>
</tr>
<tr class="even">
<td><strong>Goodman-Kruskal’s Gamma</strong></td>
<td>Ordinal vs. Ordinal</td>
<td>Strong association; ignores ties.</td>
</tr>
<tr class="odd">
<td><strong>Somers’ D</strong></td>
<td>Ordinal Predictor and Response</td>
<td>Asymmetric association.</td>
</tr>
<tr class="even">
<td><strong>Kendall’s Tau-b</strong></td>
<td>Ordinal vs. Ordinal</td>
<td>Adjusts for ties in data.</td>
</tr>
<tr class="odd">
<td><strong>Yule’s Q</strong></td>
<td>Binary Ordinal vs. Binary Ordinal</td>
<td>Special case for 2x2 tables.</td>
</tr>
<tr class="even">
<td><strong>Tetrachoric Correlation</strong></td>
<td>Binary vs. Binary</td>
<td>Binary ordinal variables.</td>
</tr>
<tr class="odd">
<td><strong>Polychoric Correlation</strong></td>
<td>Ordinal vs. Ordinal</td>
<td>Continuous latent structure.</td>
</tr>
</tbody>
</table></div>
</div>
</div>
</div>
</div>
<div id="general-approach-to-bivariate-statistics" class="section level3" number="3.4.4">
<h3>
<span class="header-section-number">3.4.4</span> General Approach to Bivariate Statistics<a class="anchor" aria-label="anchor" href="#general-approach-to-bivariate-statistics"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"mtcars"</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">=</span> <span class="va">mtcars</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">cyl</span>, <span class="va">vs</span>, <span class="va">carb</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">df_factor</span> <span class="op">=</span> <span class="va">df</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>        cyl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">cyl</span><span class="op">)</span>,</span>
<span>        vs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">vs</span><span class="op">)</span>,</span>
<span>        carb <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">carb</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="co"># summary(df)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    32 obs. of  3 variables:</span></span>
<span><span class="co">#&gt;  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...</span></span>
<span><span class="co">#&gt;  $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...</span></span>
<span><span class="co">#&gt;  $ carb: num  4 4 1 1 2 1 4 2 2 4 ...</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">df_factor</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    32 obs. of  3 variables:</span></span>
<span><span class="co">#&gt;  $ cyl : Factor w/ 3 levels "4","6","8": 2 2 1 2 3 2 3 1 1 2 ...</span></span>
<span><span class="co">#&gt;  $ vs  : Factor w/ 2 levels "0","1": 1 1 2 2 1 2 1 2 2 2 ...</span></span>
<span><span class="co">#&gt;  $ carb: Factor w/ 6 levels "1","2","3","4",..: 4 4 1 1 2 1 4 2 2 4 ...</span></span></code></pre></div>
<p>Get the correlation table for continuous variables only</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span>
<span><span class="co">#&gt;             cyl         vs       carb</span></span>
<span><span class="co">#&gt; cyl   1.0000000 -0.8108118  0.5269883</span></span>
<span><span class="co">#&gt; vs   -0.8108118  1.0000000 -0.5696071</span></span>
<span><span class="co">#&gt; carb  0.5269883 -0.5696071  1.0000000</span></span>
<span></span>
<span><span class="co"># only complete obs</span></span>
<span><span class="co"># cor(df, use = "complete.obs")</span></span></code></pre></div>
<p>Alternatively, you can also have the</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">Hmisc</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Hmisc/man/rcorr.html">rcorr</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"pearson"</span><span class="op">)</span></span>
<span><span class="co">#&gt;        cyl    vs  carb</span></span>
<span><span class="co">#&gt; cyl   1.00 -0.81  0.53</span></span>
<span><span class="co">#&gt; vs   -0.81  1.00 -0.57</span></span>
<span><span class="co">#&gt; carb  0.53 -0.57  1.00</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; n= 32 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; P</span></span>
<span><span class="co">#&gt;      cyl    vs     carb  </span></span>
<span><span class="co">#&gt; cyl         0.0000 0.0019</span></span>
<span><span class="co">#&gt; vs   0.0000        0.0007</span></span>
<span><span class="co">#&gt; carb 0.0019 0.0007</span></span></code></pre></div>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">modelsummary</span><span class="fu">::</span><span class="fu"><a href="https://modelsummary.com/man/datasummary_correlation.html">datasummary_correlation</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
cyl
</th>
<th style="text-align:right;">
vs
</th>
<th style="text-align:right;">
carb
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
cyl
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
.
</td>
<td style="text-align:right;">
.
</td>
</tr>
<tr>
<td style="text-align:left;">
vs
</td>
<td style="text-align:right;">
−.81
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
.
</td>
</tr>
<tr>
<td style="text-align:left;">
carb
</td>
<td style="text-align:right;">
.53
</td>
<td style="text-align:right;">
−.57
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggcorrplot</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ggcorrplot/man/ggcorrplot.html">ggcorrplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-46-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Comparing correlations between different types of variables (e.g., continuous vs. categorical) poses unique challenges. One key issue is ensuring that methods are appropriate for the nature of the variables being analyzed. Another challenge lies in detecting non-linear relationships, as traditional correlation measures, such as Pearson’s correlation coefficient, are designed to assess linear associations.</p>
<p>To address these challenges, a potential solution is to utilize <strong>mutual information</strong> from information theory. Mutual information quantifies how much knowing one variable reduces the uncertainty of another, providing a more general measure of association that accommodates both linear and non-linear relationships.</p>
<div id="approximating-mutual-information" class="section level4" number="3.4.4.1">
<h4>
<span class="header-section-number">3.4.4.1</span> Approximating Mutual Information<a class="anchor" aria-label="anchor" href="#approximating-mutual-information"><i class="fas fa-link"></i></a>
</h4>
<p>We can approximate mutual information using the following relationship:</p>
<p><span class="math display">\[
\downarrow \text{Prediction Error} \approx \downarrow \text{Uncertainty} \approx \uparrow \text{Association Strength}
\]</span></p>
<p>This principle underpins the <a href="https://rviews.rstudio.com/2021/04/15/an-alternative-to-the-correlation-coefficient-that-works-for-numeric-and-categorical-variables/">X2Y metric</a>, which is implemented through the following steps:</p>
<ol style="list-style-type: decimal">
<li>
<p><strong>Predict</strong> <span class="math inline">\(y\)</span> without <span class="math inline">\(x\)</span> (baseline model):</p>
<ul>
<li>If <span class="math inline">\(y\)</span> is continuous, predict the mean of <span class="math inline">\(y\)</span>.<br>
</li>
<li>If <span class="math inline">\(y\)</span> is categorical, predict the mode of <span class="math inline">\(y\)</span>.</li>
</ul>
</li>
<li><p><strong>Predict</strong> <span class="math inline">\(y\)</span> with <span class="math inline">\(x\)</span> using a model (e.g., linear regression, random forest, etc.).</p></li>
<li><p><strong>Calculate the difference in prediction error</strong> between steps 1 and 2. This difference reflects the reduction in uncertainty about <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> is included, serving as a measure of association strength.</p></li>
</ol>
</div>
<div id="generalizing-across-variable-types" class="section level4" number="3.4.4.2">
<h4>
<span class="header-section-number">3.4.4.2</span> Generalizing Across Variable Types<a class="anchor" aria-label="anchor" href="#generalizing-across-variable-types"><i class="fas fa-link"></i></a>
</h4>
<p>To construct a comprehensive framework that handles different variable combinations, such as:</p>
<ul>
<li>Continuous vs. continuous</li>
<li>Categorical vs. continuous</li>
<li>Continuous vs. categorical</li>
<li>Categorical vs. categorical</li>
</ul>
<p>a flexible modeling approach is required. <strong>Classification and Regression Trees (CART)</strong> are particularly well-suited for this purpose, as they can accommodate both continuous and categorical predictors and outcomes. However, other models, such as random forests or generalized additive models (GAMs), may also be employed.</p>
</div>
<div id="limitations-of-the-approach" class="section level4" number="3.4.4.3">
<h4>
<span class="header-section-number">3.4.4.3</span> Limitations of the Approach<a class="anchor" aria-label="anchor" href="#limitations-of-the-approach"><i class="fas fa-link"></i></a>
</h4>
<p>Despite its strengths, this approach has some limitations:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Asymmetry:</strong><br>
The measure is not symmetric, meaning <span class="math inline">\((x, y) \neq (y, x)\)</span>.</p></li>
<li><p><strong>Comparability:</strong><br>
Different variable pairs may yield metrics that are not directly comparable. For instance, continuous outcomes often use metrics like Mean Absolute Error (MAE), while categorical outcomes use measures like misclassification error.</p></li>
</ol>
<p>These limitations should be considered when interpreting results, especially in multi-variable or mixed-data contexts.</p>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ppsr</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">iris</span> <span class="op">&lt;-</span> <span class="va">iris</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ppsr::score_df(iris) # if you want a dataframe</span></span>
<span><span class="fu">ppsr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ppsr/man/score_matrix.html">score_matrix</a></span><span class="op">(</span><span class="va">iris</span>,</span>
<span>                   do_parallel <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                   n_cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;              Sepal.Length Sepal.Width Petal.Length</span></span>
<span><span class="co">#&gt; Sepal.Length   1.00000000  0.04632352    0.5491398</span></span>
<span><span class="co">#&gt; Sepal.Width    0.06790301  1.00000000    0.2376991</span></span>
<span><span class="co">#&gt; Petal.Length   0.61608360  0.24263851    1.0000000</span></span>
<span></span>
<span><span class="co"># if you want a similar correlation matrix</span></span>
<span><span class="fu">ppsr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ppsr/man/score_matrix.html">score_matrix</a></span><span class="op">(</span><span class="va">df</span>,</span>
<span>                   do_parallel <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                   n_cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt;             cyl        vs      carb</span></span>
<span><span class="co">#&gt; cyl  1.00000000 0.3982789 0.2092533</span></span>
<span><span class="co">#&gt; vs   0.02514286 1.0000000 0.2000000</span></span>
<span><span class="co">#&gt; carb 0.30798148 0.2537309 1.0000000</span></span></code></pre></div>
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">corrplot</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/corrplot/man/corrplot.html">corrplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-48-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Alternatively,</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">PerformanceAnalytics</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/PerformanceAnalytics/man/chart.Correlation.html">chart.Correlation</a></span><span class="op">(</span><span class="va">df</span>, histogram <span class="op">=</span> <span class="cn">T</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-49-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/heatmap.html">heatmap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-50-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>More general form,</p>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ppsr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ppsr/man/visualize_pps.html">visualize_pps</a></span><span class="op">(</span></span>
<span>    df <span class="op">=</span> <span class="va">iris</span>,</span>
<span>    do_parallel <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    n_cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-51-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ppsr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ppsr/man/visualize_correlations.html">visualize_correlations</a></span><span class="op">(</span></span>
<span>    df <span class="op">=</span> <span class="va">iris</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-52-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Both heat map and correlation at the same time</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ppsr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ppsr/man/visualize_both.html">visualize_both</a></span><span class="op">(</span></span>
<span>    df <span class="op">=</span> <span class="va">iris</span>,</span>
<span>    do_parallel <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    n_cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-53-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>More elaboration with <code>ggplot2</code></p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ppsr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/ppsr/man/visualize_pps.html">visualize_pps</a></span><span class="op">(</span></span>
<span>    df <span class="op">=</span> <span class="va">iris</span>,</span>
<span>    color_value_high <span class="op">=</span> <span class="st">'red'</span>,</span>
<span>    color_value_low <span class="op">=</span> <span class="st">'yellow'</span>,</span>
<span>    color_text <span class="op">=</span> <span class="st">'black'</span></span>
<span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.background <span class="op">=</span> </span>
<span>                       <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_rect</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"lightgrey"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>title <span class="op">=</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>        title <span class="op">=</span> <span class="st">'Correlation aand Heatmap'</span>,</span>
<span>        subtitle <span class="op">=</span> <span class="st">'Subtitle'</span>,</span>
<span>        caption <span class="op">=</span> <span class="st">'Caption'</span>,</span>
<span>        x <span class="op">=</span> <span class="st">'More info'</span></span>
<span>    <span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-descriptive-stat_files/figure-html/unnamed-chunk-54-1.png" width="90%" style="display: block; margin: auto;"></div>

</div>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></div>
<div class="next"><a href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#descriptive-statistics"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="nav-link" href="#numerical-measures"><span class="header-section-number">3.1</span> Numerical Measures</a></li>
<li>
<a class="nav-link" href="#graphical-measures"><span class="header-section-number">3.2</span> Graphical Measures</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#shape"><span class="header-section-number">3.2.1</span> Shape</a></li>
<li><a class="nav-link" href="#scatterplot"><span class="header-section-number">3.2.2</span> Scatterplot</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#normality-assessment"><span class="header-section-number">3.3</span> Normality Assessment</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#graphical-assessment"><span class="header-section-number">3.3.1</span> Graphical Assessment</a></li>
<li><a class="nav-link" href="#summary-statistics"><span class="header-section-number">3.3.2</span> Summary Statistics</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#bivariate-statistics"><span class="header-section-number">3.4</span> Bivariate Statistics</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#two-continuous"><span class="header-section-number">3.4.1</span> Two Continuous</a></li>
<li><a class="nav-link" href="#categorical-and-continuous"><span class="header-section-number">3.4.2</span> Categorical and Continuous</a></li>
<li><a class="nav-link" href="#two-discrete"><span class="header-section-number">3.4.3</span> Two Discrete</a></li>
<li><a class="nav-link" href="#general-approach-to-bivariate-statistics"><span class="header-section-number">3.4.4</span> General Approach to Bivariate Statistics</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/03-descriptive-stat.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/03-descriptive-stat.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2025-02-03.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
