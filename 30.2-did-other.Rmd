### Panel Match DiD Estimator with In-and-Out Treatment Conditions {#sec-panel-match-did-estimator-with-in-and-out-treatment-conditions}

As noted in @imai2021use, the [TWFE](#sec-two-way-fixed-effects) regression model is widely used but fundamentally relies on strong modeling assumptions, particularly **linearity** and **additivity**. It does not constitute a fully nonparametric estimation method and may yield biased results under model misspecification.

#### Limitations of TWFE

Researchers often prefer TWFE due to its ability to control for both unit- and time-specific unobserved confounders:

-   $\alpha_i = h(\mathbf{U}_i)$ accounts for unit-level confounders.
-   $\gamma_t = f(\mathbf{V}_t)$ adjusts for time-level confounders.

The functional forms $h(\cdot)$ and $f(\cdot)$ are left unspecified, but **additivity and separability** are assumed. TWFE is based on the model:

$$
Y_{it} = \alpha_i + \gamma_t + \beta X_{it} + \epsilon_{it}
$$

for $i = 1, \dots, N$, and $t = 1, \dots, T$. However, this formulation requires a linear specification for the treatment effect $\beta$. Contrary to popular belief, the model does require functional form assumptions for validity [@imai2021use, p. 406; @imai2019should].

------------------------------------------------------------------------

#### Matching and the Panel Match DiD Estimator

To mitigate model dependence and improve causal inference validity, @imai2021use propose a matching-based framework for panel data. This method is implemented via the `wfe` and `PanelMatch` R packages and offers **design-based identification** under relaxed assumptions.

This setting generalizes [staggered adoption](#sec-staggered-difference-in-differences), allowing units to transition in and out of treatment. The core idea is to construct matched control groups that share the same **treatment history** as treated units and then apply a [Difference-in-Differences](#sec-simple-difference-in-differences) logic. This is better than [synthetic controls]((#sec-synthetic-control)) (e.g., @xu2017generalized) because it requires less data to achieve good performance and can adapt to contexts where units switch treatment status multiple times.

**Key Properties** of PM-DiD [@imai2021matching]

-   Designed for **multiple treatment switches** over time.
-   Addresses issues of **carryover**, **reversal**, and **attenuation bias**.
-   Allows estimation of **short-term and long-term** causal effects, accounting for time dynamics.

**Key Findings** [@imai2021matching]

-   Even under favorable conditions for OLS, PM-DiD is more robust to model misspecification and omitted lags.

-   This robustness comes with a cost: reduced efficiency (larger variance).

-   Reflects the classic bias-variance tradeoff between flexible and parametric estimators.

**Data and Software Requirements**

-   Treatment variable: binary (0 = control, 1 = treated).

-   Unit and time variables: integer/numeric and ordered.

-   Input data must be in `data.frame` format.

Examples:

-   @scheve2012democracy

-   @acemoglu2019democracy

------------------------------------------------------------------------

#### Two-Way Matching Interpretation of TWFE

The least squares estimate of $\beta$ in the TWFE model can be re-expressed as a **matching estimator** that compares each treated unit to observations within:

-   The **same unit** (within-unit match),
-   The **same time period** (within-time match),
-   Adjusted by a third set of observations in neither group.

This leads to mismatches---treated observations compared to units with the same treatment status, which causes **attenuation bias**.

The adjustment factor $K$ corrects for this by weighting matches appropriately. However, even the **weighted TWFE estimator** contains some mismatches and relies on comparisons across units that differ in key characteristics.

In the simple two-period, two-group DiD setting, the TWFE and DiD estimators coincide. However, in [multi-period DiD](#sec-multiple-periods-and-variation-in-treatment-timing) with **treatment reversals**, this equivalence breaks down [@imai2021use].

-   The **unweighted TWFE** is not equivalent to multi-period DiD.
-   The [multi-period DiD](#sec-multiple-periods-and-variation-in-treatment-timing) is equivalent to a **weighted TWFE**, but some weights are **negative**---a problematic feature from a design-based perspective.

This means that justifying TWFE via DiD logic is incorrect unless the linearity assumption is satisfied.

------------------------------------------------------------------------

#### Estimation Using Panel Match DiD

**Core Estimation Steps** [@imai2021matching]:

1.  Match treated observations with control observations from the same time period and with identical treatment histories over the past $L$ periods.
2.  Use standard matching or weighting methods to refine control sets (e.g., Mahalanobis distance, propensity score).
3.  Apply a DiD estimator to compute treatment effects at time $t + F$.
4.  Evaluate match quality using covariate balance diagnostics [@ho2007matching].

**Causal Estimand**

Let $F$ be the number of **leads** (future periods) and $L$ be the number of **lags** (past treatment periods). Define the average treatment effect as:

$$
\delta(F, L) = \mathbb{E}\left[Y_{i, t+F}(1) - Y_{i, t+F}(0) \mid \text{treatment history from } t-L \text{ to } t\right]
$$

-   $F = 0$: contemporaneous effect (short-run ATT)
-   $F > 0$: future outcomes (long-run ATT)
-   $L$: adjusts for potential **carryover effects**

The estimator also allows for estimation of the **Average Reversal Treatment Effect (ART)** when treatment status switches from 1 to 0.

------------------------------------------------------------------------

#### Model Assumptions

-   **No spillover effects** across units (i.e., SUTVA holds)

-   **Carryover effects** allowed up to $L$ periods.

-   After $L$ lags, prior treatments are assumed to have no effect on $Y_{i,t+F}$.

-   The potential outcome at $t + F$ is independent of treatment assignments beyond $t - L$.

-   The key identifying assumption is a conditional parallel trends assumption. Outcome trends are assumed parallel across treated and matched control units, conditional on:

    -   Past treatment,

    -   Covariate histories,

    -   Lagged outcomes (excluding the most recent).

    Unlike standard [TWFE](#sec-simple-difference-in-differences), strong ignorability is not required.

------------------------------------------------------------------------

#### Covariate Balance Assessment

Assessing balance before estimating ATT is critical:

-   Compute the mean standardized difference between treated and matched control units.
-   Check balance across covariates and lagged outcomes for all $L$ pretreatment periods.
-   Imbalanced covariates may indicate violations of the parallel trends assumption.

------------------------------------------------------------------------

#### Implementing the Panel Match DiD Estimator

```{r}
library(PanelMatch)
```

**Treatment Variation Plot**

Visualizing the variation of treatment across space and time is essential to assess whether the treatment has sufficient heterogeneity to support credible causal identification.

```{r}
DisplayTreatment(
  panel.data = PanelData(
    panel.data = dem,
    unit.id = "wbcode2",
    time.id = "year",
    treatment = "dem",
    outcome = "y"
  ),
  legend.position = "none",
  xlab = "year",
  ylab = "Country Code"
)
```

-   This plot aids in identifying whether the treatment is broadly distributed or concentrated among a few units or time periods.

-   Insufficient treatment variation may weaken identification or reduce the precision of estimated effects.

##### Setting Parameters $F$ and $L$

1.  Select $F$: the number of leads, or time periods after treatment, for which the effect is measured.

-   $F = 0$: contemporaneous (short-term) treatment effect.

-   $F > 0$: long-term or cumulative effects.

2.  Select $L$: the number of lags (prior treatment periods) used in matching to adjust for carryover effects.

-   Increasing $L$ enhances credibility but reduces match quality and sample size.

-   This selection reflects the bias-variance tradeoff.

------------------------------------------------------------------------

##### Causal Quantity of Interest

The [ATT](#sec-average-treatment-effect-on-the-treated) is defined as:

$$
\delta(F, L) = \mathbb{E} \left[ Y_{i,t+F}(1) - Y_{i,t+F}(0) \mid X_{i,t} = 1, \text{History}_{i,t-L:t-1} \right]
$$

-   This estimator accounts for carryover history (via $L$) and post-treatment dynamics (via $F$).

-   It is also robust to treatment reversals, i.e., treatment switching back to control.

A related estimand, the **Average Reversal Treatment Effect (ART)**, measures the causal effect of switching from treatment to control.

##### Choosing $F$ and $L$

-   **Large** $L$:

    -   Improves identification of causal effect by accounting for long-term treatment confounding.

    -   Reduces sample size due to stricter matching requirements.

-   **Large** $F$:

    -   Enables analysis of delayed effects.

    -   Complicates interpretation if units switch treatment again before $t + F$.

Researchers should select $F$ and $L$ based on substantive context, theoretical considerations, and sensitivity analysis.

------------------------------------------------------------------------

##### Constructing and Refining Matched Sets

1.  **Initial Matching**

-   Each treated observation is matched to control units from other units in the same time period.

-   Matching is based on exact treatment histories from $t - L$ to $t - 1$.

Purpose

-   Controls for carryover effects.

-   Ensures matched units have similar latent propensities for treatment.

2.  **Refinement Process**

-   Refined matched sets additionally adjust for pre-treatment covariates and lagged outcomes.

-   Matching strategies:

    -   Mahalanobis distance.

    -   Propensity score.

<!-- -->

-   Up to $J$ best matches per treated unit may be used.

3.  **Weighting**

-   Assigns weights to matched controls to emphasize similarity.

-   Weighting is often done via inverse propensity scores, or other balance-enhancing metrics.

-   Can be considered a generalization of traditional matching.

------------------------------------------------------------------------

##### Difference-in-Differences Estimation

Once matched sets are constructed:

-   The counterfactual for each treated unit is a weighted average of outcomes from its matched control set.

-   The DiD estimate of ATT is:

$$
\widehat{\delta}_{\text{ATT}} = \frac{1}{|T_1|} \sum_{(i,t) \in T_1} \left[ Y_{i,t+F} - \sum_{j \in \mathcal{C}_{it}} w_{ijt} Y_{j,t+F} \right]
$$

where $T_1$ is the set of treated observations, $\mathcal{C}_{it}$ is the matched control set, and $w_{ijt}$ are normalized weights.

Considerations when $F > 0$:

-   Matched controls may themselves switch into treatment before $t + F$.

-   Some treated units may revert to control.

------------------------------------------------------------------------

##### Checking Covariate Balance

One of the main advantages of matching-based estimators is the ability to diagnose balance:

-   For each covariate and each lag, compute:

$$
\text{Standardized Difference} = \frac{\bar{X}_{\text{treated}} - \bar{X}_{\text{control}}}{\text{SD}_{\text{treated}}}
$$

-   Aggregate these over all treated observations and time periods.

-   Examine balance on:

    -   Time-varying covariates,

    -   Lagged outcomes,

    -   Baseline covariates

Balance checks provide indirect validation of the [parallel trends assumption](#prior-parallel-trends-test).

------------------------------------------------------------------------

##### Standard Error Estimation

-   Analogous to the conditional variance seen in regression models.

-   Standard errors are calculated conditional on the matching weights [@imbens2015causal].

-   SE here is a measure of sampling uncertainty given the matched design.

**Note**: They do not incorporate uncertainty from the matching procedure itself [@ho2007matching].

------------------------------------------------------------------------

##### Matching on Treatment History

-   The goal is to compare treated units transitioning into treatment to control units with comparable treatment histories.

-   Set `qoi =`:

    -   `"att"`: Average Treatment on the Treated,

    -   `"atc"`: Average Treatment on the Controls,

    -   `"art"`: Average Reversal Treatment Effect,

    -   `"ate"`: Average Treatment Effect.

```{r}
library(PanelMatch)
# All examples follow the package's vignette
# Create the matched sets
PM.results.none <-
    PanelMatch(
        lag = 4,
        refinement.method = "none",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = TRUE,
        size.match = 5,
        qoi = "att",
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        use.diagonal.variance.matrix = TRUE
    )

# visualize the treated unit and matched controls
DisplayTreatment(
    legend.position = "none",
    xlab = "year",
    ylab = "Country Code",
    panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
    matched.set = PM.results.none$att[1],
    # highlight the particular set
    show.set.only = TRUE
)
```

Control units and the treated unit have identical treatment histories over the lag window (1988-1991)

```{r}
DisplayTreatment(
    legend.position = "none",
    xlab = "year",
    ylab = "Country Code",
    panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
    matched.set = PM.results.none$att[2],
    # highlight the particular set
    show.set.only = TRUE
)
```

This set is more limited than the first one, but we can still see that we have exact past histories.

-   **Refining Matched Sets**

    -   Refinement involves assigning weights to control units.

    -   Users must:

        1.  Specify a method for calculating unit similarity/distance.

        2.  Choose variables for similarity/distance calculations.

-   **Select a Refinement Method**

    -   Users determine the refinement method via the **`refinement.method`** argument.

    -   Options include:

        -   `mahalanobis`

        -   `ps.match`

        -   `CBPS.match`

        -   `ps.weight`

        -   `CBPS.weight`

        -   `ps.msm.weight`

        -   `CBPS.msm.weight`

        -   `none`

    -   Methods with "match" in the name and Mahalanobis will assign equal weights to similar control units.

    -   "Weighting" methods give higher weights to control units more similar to treated units.

-   **Variable Selection**

    -   Users need to define which covariates will be used through the **`covs.formula`** argument, a one-sided formula object.

    -   Variables on the right side of the formula are used for calculations.

    -   "Lagged" versions of variables can be included using the format: **`I(lag(name.of.var, 0:n))`**.

-   **Understanding `PanelMatch` and `matched.set` objects**

    -   The **`PanelMatch` function** returns a **`PanelMatch` object**.

    -   The most crucial element within the `PanelMatch` object is the **matched.set object**.

    -   Within the `PanelMatch` object, the matched.set object will have names like att, art, or atc.

    -   If **`qoi = ate`**, there will be two matched.set objects: att and atc.

-   **Matched.set Object Details**

    -   matched.set is a named list with added attributes.

    -   Attributes include:

        -   Lag

        -   Names of treatment

        -   Unit and time variables

    -   Each list entry represents a matched set of treated and control units.

    -   Naming follows a structure: **`[id variable].[time variable]`**.

    -   Each list element is a vector of control unit ids that match the treated unit mentioned in the element name.

    -   Since it's a matching method, weights are only given to the **`size.match`** most similar control units based on distance calculations.

```{r}
# PanelMatch without any refinement
PM.results.none <-
    PanelMatch(
        lag = 4,
        refinement.method = "none",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = TRUE,
        size.match = 5,
        qoi = "att",
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        use.diagonal.variance.matrix = TRUE
    )

# Extract the matched.set object
msets.none <- PM.results.none$att

# PanelMatch with refinement
PM.results.maha <-
    PanelMatch(
        lag = 4,
        refinement.method = "mahalanobis", # use Mahalanobis distance
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = TRUE,
        covs.formula = ~ tradewb,
        size.match = 5,
        qoi = "att" ,
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        use.diagonal.variance.matrix = TRUE
    )
msets.maha <- PM.results.maha$att
```

```{r}
# these 2 should be identical because weights are not shown
msets.none |> head()
msets.maha |> head()
# summary(msets.none)
# summary(msets.maha)
```

**Visualizing Matched Sets with the plot method**

-   Users can visualize the distribution of the matched set sizes.

-   A red line, by default, indicates the count of matched sets where treated units had no matching control units (i.e., empty matched sets).

-   Plot adjustments can be made using **`graphics::plot`**.

```{r}
plot(
  msets.none,
  panel.data = PanelData(
    panel.data = dem,
    unit.id = "wbcode2",
    time.id = "year",
    treatment = "dem",
    outcome = "y"
  )
)
```

**Comparing Methods of Refinement**

-   Users are encouraged to:

    -   Use substantive knowledge for experimentation and evaluation.

    -   Consider the following when configuring `PanelMatch`:

        1.  The number of matched sets.

        2.  The number of controls matched to each treated unit.

        3.  Achieving covariate balance.

    -   **Note**: Large numbers of small matched sets can lead to larger standard errors during the estimation stage.

    -   Covariates that aren't well balanced can lead to undesirable comparisons between treated and control units.

    -   Aspects to consider include:

        -   Refinement method.

        -   Variables for weight calculation.

        -   Size of the lag window.

        -   Procedures for addressing missing data (refer to **`match.missing`** and **`listwise.delete`** arguments).

        -   Maximum size of matched sets (for matching methods).

-   **Supportive Features:**

    -   **`print`**, **`plot`**, and **`summary`** methods assist in understanding matched sets and their sizes.

    -   **`get_covariate_balance`** helps evaluate covariate balance:

        -   Lower values in the covariate balance calculations are preferred.

```{r}
PM.results.none <-
    PanelMatch(
        lag = 4,
        refinement.method = "none",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = TRUE,
        size.match = 5,
        qoi = "att",
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        use.diagonal.variance.matrix = TRUE
    )
PM.results.maha <-
    PanelMatch(
        lag = 4,
        refinement.method = "mahalanobis",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = TRUE,
        covs.formula = ~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)),
        size.match = 5,
        qoi = "att",
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        use.diagonal.variance.matrix = TRUE
    )

# listwise deletion used for missing data
PM.results.listwise <-
    PanelMatch(
        lag = 4,
        refinement.method = "mahalanobis",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = FALSE,
        listwise.delete = TRUE,
        covs.formula = ~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)),
        size.match = 5,
        qoi = "att",
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        use.diagonal.variance.matrix = TRUE
    )

# propensity score based weighting method
PM.results.ps.weight <-
    PanelMatch(
        lag = 4,
        refinement.method = "ps.weight",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing = FALSE,
        listwise.delete = TRUE,
        covs.formula = ~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)),
        size.match = 5,
        qoi = "att",
        lead = 0:4,
        forbid.treatment.reversal = FALSE
    )

get_covariate_balance(
    PM.results.none,
    panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
    covariates = c("tradewb", "y")
)
```


```{r}
# Compare covariate balance to refined sets
# See large improvement in balance
get_covariate_balance(
    PM.results.ps.weight,
     panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
    covariates = c("tradewb", "y")
)
```

**`PanelEstimate`**

-   **Standard Error Calculation Methods**

    -   There are different methods available:

        -   **Bootstrap** (default method with 1000 iterations).

        -   **Conditional**: Assumes independence across units, but not time.

        -   **Unconditional**: Doesn't make assumptions of independence across units or time.

    -   For **`qoi`** values set to `att`, `art`, or `atc` [@imai2021matching]:

        -   You can use analytical methods for calculating standard errors, which include both "conditional" and "unconditional" methods.

```{r}
PE.results <- PanelEstimate(
    sets              = PM.results.ps.weight,
    panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
    se.method         = "bootstrap",
    number.iterations = 1000,
    confidence.level  = .95
)

# point estimates
PE.results[["estimates"]]

# standard errors
PE.results[["standard.error"]]


# use conditional method
PE.results <- PanelEstimate(
    sets             = PM.results.ps.weight,
    panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
    se.method        = "conditional",
    confidence.level = .95
)

# point estimates
PE.results[["estimates"]]

# standard errors
PE.results[["standard.error"]]

summary(PE.results)

plot(PE.results)
```

**Moderating Variables**

```{r}
# moderating variable
dem$moderator <- 0
dem$moderator <- ifelse(dem$wbcode2 > 100, 1, 2)

PM.results <-
    PanelMatch(
        lag                          = 4,
        # time.id                      = "year",
        # unit.id                      = "wbcode2",
        # treatment                    = "dem",
        refinement.method            = "mahalanobis",
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing                = TRUE,
        covs.formula                 = ~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)),
        size.match                   = 5,
        qoi                          = "att",
        # outcome.var                  = "y",
        lead                         = 0:4,
        forbid.treatment.reversal    = FALSE,
        use.diagonal.variance.matrix = TRUE
    )
PE.results <-
    PanelEstimate(sets      = PM.results,
                  panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
                  moderator = "moderator")

# Each element in the list corresponds to a level in the moderator
plot(PE.results[[1]])

plot(PE.results[[2]])
```

<!--#To write up for journal submission, you can follow the following report:  -->

In this study, closely aligned with the research by @acemoglu2019democracy, two key effects of democracy on economic growth are estimated: the impact of democratization and that of authoritarian reversal. The treatment variable, $X_{it}$, is defined to be one if country $i$ is democratic in year $t$, and zero otherwise.

The Average Treatment Effect for the Treated (ATT) under democratization is formulated as follows:

$$
\begin{aligned}
\delta(F, L) &= \mathbb{E} \left\{ Y_{i, t + F} (X_{it} = 1, X_{i, t - 1} = 0, \{X_{i,t-l}\}_{l=2}^L) \right. \\
&\left. - Y_{i, t + F} (X_{it} = 0, X_{i, t - 1} = 0, \{X_{i,t-l}\}_{l=2}^L) | X_{it} = 1, X_{i, t - 1} = 0 \right\}
\end{aligned}
$$

In this framework, the treated observations are countries that transition from an authoritarian regime $X_{it-1} = 0$ to a democratic one $X_{it} = 1$. The variable $F$ represents the number of leads, denoting the time periods following the treatment, and $L$ signifies the number of lags, indicating the time periods preceding the treatment.

The ATT under authoritarian reversal is given by:

$$
\begin{aligned}
&\mathbb{E} \left[ Y_{i, t + F} (X_{it} = 0, X_{i, t - 1} = 1, \{ X_{i, t - l}\}_{l=2}^L ) \right. \\
&\left. - Y_{i, t + F} (X_{it} = 1, X_{it-1} = 1, \{X_{i, t - l} \}_{l=2}^L ) | X_{it} = 0, X_{i, t - 1} = 1 \right]
\end{aligned}
$$

The ATT is calculated conditioning on 4 years of lags ($L = 4$) and up to 4 years following the policy change $F = 1, 2, 3, 4$. Matched sets for each treated observation are constructed based on its treatment history, with the number of matched control units generally decreasing when considering a 4-year treatment history as compared to a 1-year history.

To enhance the quality of matched sets, methods such as Mahalanobis distance matching, propensity score matching, and propensity score weighting are utilized. These approaches enable us to evaluate the effectiveness of each refinement method. In the process of matching, we employ both up-to-five and up-to-ten matching to investigate how sensitive our empirical results are to the maximum number of allowed matches. For more information on the refinement process, please see the Web Appendix

> The Mahalanobis distance is expressed through a specific formula. We aim to pair each treated unit with a maximum of $J$ control units, permitting replacement, denoted as $| \mathcal{M}_{it} \le J|$. The average Mahalanobis distance between a treated and each control unit over time is computed as:
>
> $$ S_{it} (i') = \frac{1}{L} \sum_{l = 1}^L \sqrt{(\mathbf{V}_{i, t - l} - \mathbf{V}_{i', t -l})^T \mathbf{\Sigma}_{i, t - l}^{-1} (\mathbf{V}_{i, t - l} - \mathbf{V}_{i', t -l})} $$
>
> For a matched control unit $i' \in \mathcal{M}_{it}$, $\mathbf{V}_{it'}$ represents the time-varying covariates to adjust for, and $\mathbf{\Sigma}_{it'}$ is the sample covariance matrix for $\mathbf{V}_{it'}$. Essentially, we calculate a standardized distance using time-varying covariates and average this across different time intervals.
>
> In the context of propensity score matching, we employ a logistic regression model with balanced covariates to derive the propensity score. Defined as the conditional likelihood of treatment given pre-treatment covariates [@rosenbaum1983central], the propensity score is estimated by first creating a data subset comprised of all treated and their matched control units from the same year. This logistic regression model is then fitted as follows:
>
> $$ \begin{aligned} & e_{it} (\{\mathbf{U}_{i, t - l} \}^L_{l = 1}) \\ &= Pr(X_{it} = 1| \mathbf{U}_{i, t -1}, \ldots, \mathbf{U}_{i, t - L}) \\ &= \frac{1}{1 = \exp(- \sum_{l = 1}^L \beta_l^T \mathbf{U}_{i, t - l})} \end{aligned} $$
>
> where $\mathbf{U}_{it'} = (X_{it'}, \mathbf{V}_{it'}^T)^T$. Given this model, the estimated propensity score for all treated and matched control units is then computed. This enables the adjustment for lagged covariates via matching on the calculated propensity score, resulting in the following distance measure:
>
> $$ S_{it} (i') = | \text{logit} \{ \hat{e}_{it} (\{ \mathbf{U}_{i, t - l}\}^L_{l = 1})\} - \text{logit} \{ \hat{e}_{i't}( \{ \mathbf{U}_{i', t - l} \}^L_{l = 1})\} | $$
>
> Here, $\hat{e}_{i't} (\{ \mathbf{U}_{i, t - l}\}^L_{l = 1})$ represents the estimated propensity score for each matched control unit $i' \in \mathcal{M}_{it}$.
>
> Once the distance measure $S_{it} (i')$ has been determined for all control units in the original matched set, we fine-tune this set by selecting up to $J$ closest control units, which meet a researcher-defined caliper constraint $C$. All other control units receive zero weight. This results in a refined matched set for each treated unit $(i, t)$:
>
> $$ \mathcal{M}_{it}^* = \{i' : i' \in \mathcal{M}_{it}, S_{it} (i') < C, S_{it} \le S_{it}^{(J)}\} $$
>
> $S_{it}^{(J)}$ is the $J$th smallest distance among the control units in the original set $\mathcal{M}_{it}$.
>
> For further refinement using weighting, a weight is assigned to each control unit $i'$ in a matched set corresponding to a treated unit $(i, t)$, with greater weight accorded to more similar units. We utilize inverse propensity score weighting, based on the propensity score model mentioned earlier:
>
> $$ w_{it}^{i'} \propto \frac{\hat{e}_{i't} (\{ \mathbf{U}_{i, t-l} \}^L_{l = 1} )}{1 - \hat{e}_{i't} (\{ \mathbf{U}_{i, t-l} \}^L_{l = 1} )} $$
>
> In this model, $\sum_{i' \in \mathcal{M}_{it}} w_{it}^{i'} = 1$ and $w_{it}^{i'} = 0$ for $i' \notin \mathcal{M}_{it}$. The model is fitted to the complete sample of treated and matched control units.

> Checking Covariate Balance A distinct advantage of the proposed methodology over regression methods is the ability it offers researchers to inspect the covariate balance between treated and matched control observations. This facilitates the evaluation of whether treated and matched control observations are comparable regarding observed confounders. To investigate the mean difference of each covariate (e.g., $V_{it'j}$, representing the $j$-th variable in $\mathbf{V}_{it'}$) between the treated observation and its matched control observation at each pre-treatment time period (i.e., $t' < t$), we further standardize this difference. For any given pretreatment time period, we adjust by the standard deviation of each covariate across all treated observations in the dataset. Thus, the mean difference is quantified in terms of standard deviation units. Formally, for each treated observation $(i,t)$ where $D_{it} = 1$, we define the covariate balance for variable $j$ at the pretreatment time period $t - l$ as: \begin{equation}
> B_{it}(j, l) = \frac{V_{i, t- l,j}- \sum_{i' \in \mathcal{M}_{it}}w_{it}^{i'}V_{i', t-l,j}}{\sqrt{\frac{1}{N_1 - 1} \sum_{i'=1}^N \sum_{t' = L+1}^{T-F}D_{i't'}(V_{i', t'-l, j} - \bar{V}_{t' - l, j})^2}}
> \label{eq:covbalance}
> \end{equation} where $N_1 = \sum_{i'= 1}^N \sum_{t' = L+1}^{T-F} D_{i't'}$ denotes the total number of treated observations and $\bar{V}_{t-l,j} = \sum_{i=1}^N D_{i,t-l,j}/N$. We then aggregate this covariate balance measure across all treated observations for each covariate and pre-treatment time period:

```{=tex}
\begin{equation}
\bar{B}(j, l) = \frac{1}{N_1} \sum_{i=1}^N \sum_{t = L+ 1}^{T-F}D_{it} B_{it}(j,l)
\label{eq:aggbalance}
\end{equation}
```
> Lastly, we evaluate the balance of lagged outcome variables over several pre-treatment periods and that of time-varying covariates. This examination aids in assessing the validity of the parallel trend assumption integral to the DiD estimator justification.

In Figure for balance scatter, we demonstrate the enhancement of covariate balance thank to the refinement of matched sets. Each scatter plot contrasts the absolute standardized mean difference, as detailed in Equation \@ref(eq: ), before (horizontal axis) and after (vertical axis) this refinement. Points below the 45-degree line indicate an improved standardized mean balance for certain time-varying covariates post-refinement. The majority of variables benefit from this refinement process. Notably, the propensity score weighting (bottom panel) shows the most significant improvement, whereas Mahalanobis matching (top panel) yields a more modest improvement.

```{r, collapse=TRUE}
library(PanelMatch)
library(causalverse)

runPanelMatch <- function(method, lag, size.match=NULL, qoi="att") {
    
    # Default parameters for PanelMatch
    common.args <- list(
        lag = lag,
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        covs.formula = ~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)),
        qoi = qoi,
        lead = 0:4,
        forbid.treatment.reversal = FALSE,
        size.match = size.match  # setting size.match here for all methods
    )
    
    if(method == "mahalanobis") {
        common.args$refinement.method <- "mahalanobis"
        common.args$match.missing <- TRUE
        common.args$use.diagonal.variance.matrix <- TRUE
    } else if(method == "ps.match") {
        common.args$refinement.method <- "ps.match"
        common.args$match.missing <- FALSE
        common.args$listwise.delete <- TRUE
    } else if(method == "ps.weight") {
        common.args$refinement.method <- "ps.weight"
        common.args$match.missing <- FALSE
        common.args$listwise.delete <- TRUE
    }
    
    return(do.call(PanelMatch, common.args))
}

methods <- c("mahalanobis", "ps.match", "ps.weight")
lags <- c(1, 4)
sizes <- c(5, 10)
```

You can either do it sequentially

```{r, eval = FALSE, collapse=TRUE}
res_pm <- list()

for(method in methods) {
    for(lag in lags) {
        for(size in sizes) {
            name <- paste0(method, ".", lag, "lag.", size, "m")
            res_pm[[name]] <- runPanelMatch(method, lag, size)
        }
    }
}

# Now, you can access res_pm using res_pm[["mahalanobis.1lag.5m"]] etc.

# for treatment reversal
res_pm_rev <- list()

for(method in methods) {
    for(lag in lags) {
        for(size in sizes) {
            name <- paste0(method, ".", lag, "lag.", size, "m")
            res_pm_rev[[name]] <- runPanelMatch(method, lag, size, qoi = "art")
        }
    }
}
```

or in parallel

```{r, eval = FALSE}
library(foreach)
library(doParallel)
registerDoParallel(cores = 4)
# Initialize an empty list to store results
res_pm <- list()

# Replace nested for-loops with foreach
results <-
  foreach(
    method = methods,
    .combine = 'c',
    .multicombine = TRUE,
    .packages = c("PanelMatch", "causalverse")
  ) %dopar% {
    tmp <- list()
    for (lag in lags) {
      for (size in sizes) {
        name <- paste0(method, ".", lag, "lag.", size, "m")
        tmp[[name]] <- runPanelMatch(method, lag, size)
      }
    }
    tmp
  }

# Collate results
for (name in names(results)) {
  res_pm[[name]] <- results[[name]]
}

# Treatment reversal
# Initialize an empty list to store results
res_pm_rev <- list()

# Replace nested for-loops with foreach
results_rev <-
  foreach(
    method = methods,
    .combine = 'c',
    .multicombine = TRUE,
    .packages = c("PanelMatch", "causalverse")
  ) %dopar% {
    tmp <- list()
    for (lag in lags) {
      for (size in sizes) {
        name <- paste0(method, ".", lag, "lag.", size, "m")
        tmp[[name]] <-
          runPanelMatch(method, lag, size, qoi = "art")
      }
    }
    tmp
  }

# Collate results
for (name in names(results_rev)) {
  res_pm_rev[[name]] <- results_rev[[name]]
}


stopImplicitCluster()
```

```{r, collapse=TRUE, eval = FALSE}
library(gridExtra)

# Updated plotting function
create_balance_plot <- function(method, lag, sizes, res_pm, dem) {
    matched_set_lists <- lapply(sizes, function(size) {
        res_pm[[paste0(method, ".", lag, "lag.", size, "m")]]$att
    })
    
    return(
        balance_scatter_custom(
            matched_set_list = matched_set_lists,
            legend.title = "Possible Matches",
            set.names = as.character(sizes),
            legend.position = c(0.2, 0.8),
            
            # for compiled plot, you don't need x,y, or main labs
            x.axis.label = "",
            y.axis.label = "",
            main = "",
            data = dem,
            dot.size = 5,
            # show.legend = F,
            them_use = causalverse::ama_theme(base_size = 32),
            covariates = c("y", "tradewb")
        )
    )
}

plots <- list()

for (method in methods) {
    for (lag in lags) {
        plots[[paste0(method, ".", lag, "lag")]] <-
            create_balance_plot(method, lag, sizes, res_pm, dem)
    }
}

# # Arranging plots in a 3x2 grid
# grid.arrange(plots[["mahalanobis.1lag"]],
#              plots[["mahalanobis.4lag"]],
#              plots[["ps.match.1lag"]],
#              plots[["ps.match.4lag"]],
#              plots[["ps.weight.1lag"]],
#              plots[["ps.weight.4lag"]],
#              ncol=2, nrow=3)


# Standardized Mean Difference of Covariates
library(gridExtra)
library(grid)

# Create column and row labels using textGrob
col_labels <- c("1-year Lag", "4-year Lag")
row_labels <- c("Maha Matching", "PS Matching", "PS Weigthing")

major.axes.fontsize = 40
minor.axes.fontsize = 30

png(
    file.path(getwd(), "images", "did_balance_scatter.png"),
    width = 1200,
    height = 1000
)

# Create a list-of-lists, where each inner list represents a row
grid_list <- list(
    list(
        nullGrob(),
        textGrob(col_labels[1], gp = gpar(fontsize = minor.axes.fontsize)),
        textGrob(col_labels[2], gp = gpar(fontsize = minor.axes.fontsize))
    ),
    
    list(textGrob(
        row_labels[1],
        gp = gpar(fontsize = minor.axes.fontsize),
        rot = 90
    ), plots[["mahalanobis.1lag"]], plots[["mahalanobis.4lag"]]),
    
    list(textGrob(
        row_labels[2],
        gp = gpar(fontsize = minor.axes.fontsize),
        rot = 90
    ), plots[["ps.match.1lag"]], plots[["ps.match.4lag"]]),
    
    list(textGrob(
        row_labels[3],
        gp = gpar(fontsize = minor.axes.fontsize),
        rot = 90
    ), plots[["ps.weight.1lag"]], plots[["ps.weight.4lag"]])
)

# "Flatten" the list-of-lists into a single list of grobs
grobs <- do.call(c, grid_list)

grid.arrange(
    grobs = grobs,
    ncol = 3,
    nrow = 4,
    widths = c(0.15, 0.42, 0.42),
    heights = c(0.15, 0.28, 0.28, 0.28)
)

grid.text(
    "Before Refinement",
    x = 0.5,
    y = 0.03,
    gp = gpar(fontsize = major.axes.fontsize)
)
grid.text(
    "After Refinement",
    x = 0.03,
    y = 0.5,
    rot = 90,
    gp = gpar(fontsize = major.axes.fontsize)
)
dev.off()
```

```{r balancescatter, out.width='100%', fig.cap="Variable Balance After Matched Set Refinement", include=FALSE}
library(knitr)
include_graphics(file.path(getwd(), "images", "did_balance_scatter.png"))
```

Note: Scatter plots display the standardized mean difference of each covariate $j$ and lag year $l$ as defined in Equation \@ref(eq:aggbalance) before (x-axis) and after (y-axis) matched set refinement. Each plot includes varying numbers of possible matches for each matching method. Rows represent different matching/weighting methods, while columns indicate adjustments for various lag lengths.

```{r balancepretreat, collapse=TRUE, fig.cap="Variable Balance in Pre-Treatment Period", eval = FALSE}
# Step 1: Define configurations
configurations <- list(
    list(refinement.method = "none", qoi = "att"),
    list(refinement.method = "none", qoi = "art"),
    list(refinement.method = "mahalanobis", qoi = "att"),
    list(refinement.method = "mahalanobis", qoi = "art"),
    list(refinement.method = "ps.match", qoi = "att"),
    list(refinement.method = "ps.match", qoi = "art"),
    list(refinement.method = "ps.weight", qoi = "att"),
    list(refinement.method = "ps.weight", qoi = "art")
)

# Step 2: Use lapply or loop to generate results
results <- lapply(configurations, function(config) {
    PanelMatch(
        lag                       = 4,
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        match.missing             = FALSE,
        listwise.delete           = TRUE,
        size.match                = 5,
        lead                      = 0:4,
        forbid.treatment.reversal = FALSE,
        refinement.method         = config$refinement.method,
        covs.formula              = ~ I(lag(tradewb, 1:4)) + I(lag(y, 1:4)),
        qoi                       = config$qoi
    )
})

# Step 3: Get covariate balance and plot
plots <- mapply(function(result, config) {
    df <- get_covariate_balance(
        if (config$qoi == "att")
            result$att
        else
            result$art,
        panel.data = PanelData(panel.data = dem, 
              unit.id = "wbcode2", 
              time.id = "year", 
              treatment = "dem", 
              outcome = "y"),
        covariates = c("tradewb", "y"),
        plot = F
    )
    causalverse::plot_covariate_balance_pretrend(df, main = "", show_legend = F)
}, results, configurations, SIMPLIFY = FALSE)

# Set names for plots
names(plots) <- sapply(configurations, function(config) {
    paste(config$qoi, config$refinement.method, sep = ".")
})
```

To export

```{r, eval = FALSE}
library(gridExtra)
library(grid)

# Column and row labels
col_labels <-
    c("None",
      "Mahalanobis",
      "Propensity Score Matching",
      "Propensity Score Weighting")
row_labels <- c("ATT", "ART")

# Specify your desired fontsize for labels
minor.axes.fontsize <- 16
major.axes.fontsize <- 20

png(file.path(getwd(), "images", "p_covariate_balance.png"), width=1200, height=1000)

# Create a list-of-lists, where each inner list represents a row
grid_list <- list(
    list(
        nullGrob(),
        textGrob(col_labels[1], gp = gpar(fontsize = minor.axes.fontsize)),
        textGrob(col_labels[2], gp = gpar(fontsize = minor.axes.fontsize)),
        textGrob(col_labels[3], gp = gpar(fontsize = minor.axes.fontsize)),
        textGrob(col_labels[4], gp = gpar(fontsize = minor.axes.fontsize))
    ),
    
    list(
        textGrob(
            row_labels[1],
            gp = gpar(fontsize = minor.axes.fontsize),
            rot = 90
        ),
        plots$att.none,
        plots$att.mahalanobis,
        plots$att.ps.match,
        plots$att.ps.weight
    ),
    
    list(
        textGrob(
            row_labels[2],
            gp = gpar(fontsize = minor.axes.fontsize),
            rot = 90
        ),
        plots$art.none,
        plots$art.mahalanobis,
        plots$art.ps.match,
        plots$art.ps.weight
    )
)

# "Flatten" the list-of-lists into a single list of grobs
grobs <- do.call(c, grid_list)

# Arrange your plots with text labels
grid.arrange(
    grobs   = grobs,
    ncol    = 5,
    nrow    = 3,
    widths  = c(0.1, 0.225, 0.225, 0.225, 0.225),
    heights = c(0.1, 0.45, 0.45)
)

# Add main x and y axis titles
grid.text(
    "Refinement Methods",
    x  = 0.5,
    y  = 0.01,
    gp = gpar(fontsize = major.axes.fontsize)
)
grid.text(
    "Quantities of Interest",
    x   = 0.02,
    y   = 0.5,
    rot = 90,
    gp  = gpar(fontsize = major.axes.fontsize)
)

dev.off()
```

```{r, eval = FALSE}
library(knitr)
include_graphics(file.path(getwd(), "images", "p_covariate_balance.png"))
```

Note: Each graph displays the standardized mean difference, as outlined in Equation \@ref(eq:aggbalance), plotted on the vertical axis across a pre-treatment duration of four years represented on the horizontal axis. The leftmost column illustrates the balance prior to refinement, while the subsequent three columns depict the covariate balance post the application of distinct refinement techniques. Each individual line signifies the balance of a specific variable during the pre-treatment phase.The red line is tradewb and blue line is the lagged outcome variable.

In Figure \@ref(fig:balancepretreat), we observe a marked improvement in covariate balance due to the implemented matching procedures during the pre-treatment period. Our analysis prioritizes methods that adjust for time-varying covariates over a span of four years preceding the treatment initiation. The two rows delineate the standardized mean balance for both treatment modalities, with individual lines representing the balance for each covariate.

Across all scenarios, the refinement attributed to matched sets significantly enhances balance. Notably, using propensity score weighting considerably mitigates imbalances in confounders. While some degree of imbalance remains evident in the Mahalanobis distance and propensity score matching techniques, the standardized mean difference for the lagged outcome remains stable throughout the pre-treatment phase. This consistency lends credence to the validity of the proposed DiD estimator.

**Estimation Results**

We now detail the estimated ATTs derived from the matching techniques. Figure below offers visual representations of the impacts of treatment initiation (upper panel) and treatment reversal (lower panel) on the outcome variable for a duration of 5 years post-transition, specifically, ($F = 0, 1, …, 4$). Across the five methods (columns), it becomes evident that the point estimates of effects associated with treatment initiation consistently approximate zero over the 5-year window. In contrast, the estimated outcomes of treatment reversal are notably negative and maintain statistical significance through all refinement techniques during the initial year of transition and the 1 to 4 years that follow, provided treatment reversal is permissible. These effects are notably pronounced, pointing to an estimated reduction of roughly X% in the outcome variable.

Collectively, these findings indicate that the transition into the treated state from its absence doesn't invariably lead to a heightened outcome. Instead, the transition from the treated state back to its absence exerts a considerable negative effect on the outcome variable in both the short and intermediate terms. Hence, the positive effect of the treatment (if we were to use traditional DiD) is actually driven by the negative effect of treatment reversal.

```{r, eval = FALSE, collapse=TRUE}
# sequential
# Step 1: Apply PanelEstimate function

# Initialize an empty list to store results
res_est <- vector("list", length(res_pm))

# Iterate over each element in res_pm
for (i in 1:length(res_pm)) {
  res_est[[i]] <- PanelEstimate(
    res_pm[[i]],
    data = dem,
    se.method = "bootstrap",
    number.iterations = 1000,
    confidence.level = .95
  )
  # Transfer the name of the current element to the res_est list
  names(res_est)[i] <- names(res_pm)[i]
}

# Step 2: Apply plot_PanelEstimate function

# Initialize an empty list to store plot results
res_est_plot <- vector("list", length(res_est))

# Iterate over each element in res_est
for (i in 1:length(res_est)) {
    res_est_plot[[i]] <-
        plot_PanelEstimate(res_est[[i]],
                           main = "",
                           theme_use = causalverse::ama_theme(base_size = 14))
    # Transfer the name of the current element to the res_est_plot list
    names(res_est_plot)[i] <- names(res_est)[i]
}

# check results
# res_est_plot$mahalanobis.1lag.5m


# Step 1: Apply PanelEstimate function for res_pm_rev

# Initialize an empty list to store results
res_est_rev <- vector("list", length(res_pm_rev))

# Iterate over each element in res_pm_rev
for (i in 1:length(res_pm_rev)) {
  res_est_rev[[i]] <- PanelEstimate(
    res_pm_rev[[i]],
    data = dem,
    se.method = "bootstrap",
    number.iterations = 1000,
    confidence.level = .95
  )
  # Transfer the name of the current element to the res_est_rev list
  names(res_est_rev)[i] <- names(res_pm_rev)[i]
}

# Step 2: Apply plot_PanelEstimate function for res_est_rev

# Initialize an empty list to store plot results
res_est_plot_rev <- vector("list", length(res_est_rev))

# Iterate over each element in res_est_rev
for (i in 1:length(res_est_rev)) {
    res_est_plot_rev[[i]] <-
        plot_PanelEstimate(res_est_rev[[i]],
                           main = "",
                           theme_use = causalverse::ama_theme(base_size = 14))
  # Transfer the name of the current element to the res_est_plot_rev list
  names(res_est_plot_rev)[i] <- names(res_est_rev)[i]
}
```

```{r, eval = FALSE}
# parallel
library(doParallel)
library(foreach)

# Detect the number of cores to use for parallel processing
num_cores <- 4

# Register the parallel backend
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# Step 1: Apply PanelEstimate function in parallel
res_est <-
    foreach(i = 1:length(res_pm), .packages = "PanelMatch") %dopar% {
        PanelEstimate(
            res_pm[[i]],
            data = dem,
            se.method = "bootstrap",
            number.iterations = 1000,
            confidence.level = .95
        )
    }

# Transfer names from res_pm to res_est
names(res_est) <- names(res_pm)

# Step 2: Apply plot_PanelEstimate function in parallel
res_est_plot <-
    foreach(
        i = 1:length(res_est),
        .packages = c("PanelMatch", "causalverse", "ggplot2")
    ) %dopar% {
        plot_PanelEstimate(res_est[[i]],
                           main = "",
                           theme_use = causalverse::ama_theme(base_size = 10))
    }

# Transfer names from res_est to res_est_plot
names(res_est_plot) <- names(res_est)



# Step 1: Apply PanelEstimate function for res_pm_rev in parallel
res_est_rev <-
    foreach(i = 1:length(res_pm_rev), .packages = "PanelMatch") %dopar% {
        PanelEstimate(
            res_pm_rev[[i]],
            data = dem,
            se.method = "bootstrap",
            number.iterations = 1000,
            confidence.level = .95
        )
    }

# Transfer names from res_pm_rev to res_est_rev
names(res_est_rev) <- names(res_pm_rev)

# Step 2: Apply plot_PanelEstimate function for res_est_rev in parallel
res_est_plot_rev <-
    foreach(
        i = 1:length(res_est_rev),
        .packages = c("PanelMatch", "causalverse", "ggplot2")
    ) %dopar% {
        plot_PanelEstimate(res_est_rev[[i]],
                           main = "",
                           theme_use = causalverse::ama_theme(base_size = 10))
    }

# Transfer names from res_est_rev to res_est_plot_rev
names(res_est_plot_rev) <- names(res_est_rev)

# Stop the cluster
stopCluster(cl)
```

To export

```{r, collapse=TRUE, eval = FALSE}
library(gridExtra)
library(grid)

# Column and row labels
col_labels <- c("Mahalanobis 5m", 
                "Mahalanobis 10m", 
                "PS Matching 5m", 
                "PS Matching 10m", 
                "PS Weighting 5m")

row_labels <- c("ATT", "ART")

# Specify your desired fontsize for labels
minor.axes.fontsize <- 16
major.axes.fontsize <- 20

png(file.path(getwd(), "images", "p_did_est_in_n_out.png"), width=1200, height=1000)

# Create a list-of-lists, where each inner list represents a row
grid_list <- list(
  list(
    nullGrob(),
    textGrob(col_labels[1], gp = gpar(fontsize = minor.axes.fontsize)),
    textGrob(col_labels[2], gp = gpar(fontsize = minor.axes.fontsize)),
    textGrob(col_labels[3], gp = gpar(fontsize = minor.axes.fontsize)),
    textGrob(col_labels[4], gp = gpar(fontsize = minor.axes.fontsize)),
    textGrob(col_labels[5], gp = gpar(fontsize = minor.axes.fontsize))
  ),
  
  list(
    textGrob(row_labels[1], gp = gpar(fontsize = minor.axes.fontsize), rot = 90),
    res_est_plot$mahalanobis.1lag.5m,
    res_est_plot$mahalanobis.1lag.10m,
    res_est_plot$ps.match.1lag.5m,
    res_est_plot$ps.match.1lag.10m,
    res_est_plot$ps.weight.1lag.5m
  ),
  
  list(
    textGrob(row_labels[2], gp = gpar(fontsize = minor.axes.fontsize), rot = 90),
    res_est_plot_rev$mahalanobis.1lag.5m,
    res_est_plot_rev$mahalanobis.1lag.10m,
    res_est_plot_rev$ps.match.1lag.5m,
    res_est_plot_rev$ps.match.1lag.10m,
    res_est_plot_rev$ps.weight.1lag.5m
  )
)

# "Flatten" the list-of-lists into a single list of grobs
grobs <- do.call(c, grid_list)

# Arrange your plots with text labels
grid.arrange(
  grobs   = grobs,
  ncol    = 6,
  nrow    = 3,
  widths  = c(0.1, 0.18, 0.18, 0.18, 0.18, 0.18),
  heights = c(0.1, 0.45, 0.45)
)

# Add main x and y axis titles
grid.text(
  "Methods",
  x  = 0.5,
  y  = 0.02,
  gp = gpar(fontsize = major.axes.fontsize)
)
grid.text(
  "",
  x   = 0.02,
  y   = 0.5,
  rot = 90,
  gp  = gpar(fontsize = major.axes.fontsize)
)

dev.off()
```

```{r, eval = FALSE}
library(knitr)
include_graphics(file.path(getwd(), "images", "p_did_est_in_n_out.png"))
```

------------------------------------------------------------------------

### Counterfactual Estimators

-   Also known as **imputation approach** [@liu2024practical]
-   This class of estimator consider observation treatment as missing data. Models are built using data from the control units to impute conterfactuals for the treated observations.
-   It's called counterfactual estimators because they predict outcomes as if the treated observations had not received the treatment.
-   Advantages:
    -   Avoids negative weights and biases by not using treated observations for modeling and applying uniform weights.
    -   Supports various models, including those that may relax strict exogeneity assumptions.
-   Methods including
    -   Fixed-effects conterfactual estimator (FEct) (DiD is a special case):
        -   Based on the [Two-way Fixed-effects], where assumes linear additive functional form of unobservables based on unit and time FEs. But FEct fixes the improper weighting of TWFE by comparing within each matched pair (where each pair is the treated observation and its predicted counterfactual that is the weighted sum of all untreated observations).
    -   Interactive Fixed Effects conterfactual estimator (IFEct) [@gobillon2016regional, @xu2017generalized]:
        -   When we suspect unobserved time-varying confounder, FEct fails. Instead, IFEct uses the factor-augmented models to relax the strict exogeneity assumption where the effects of unobservables can be decomposed to unit FE + time FE + unit x time FE.
        -   Generalized Synthetic Controls are a subset of IFEct when treatments don't revert.
    -   [Matrix Completion Estimator](#sec-matrix-completion-estimator) (MC) [@athey2021matrix]:
        -   Generalization of factor-augmented models. Different from IFEct which uses hard impute, MC uses soft impute to regularize the singular values when decomposing the residual matrix.
        -   Only when latent factors (of unobservables) are strong and sparse, IFEct outperforms MC.
    -   [Synthetic Control] (case studies)

**Identifying Assumptions**:

1.  **Function Form**: Additive separability of observables, unobservables, and idiosyncratic error term.
    -   Hence, these models are scale dependent [@athey2006identification] (e.g., log-transform outcome can invadiate this assumption).
2.  **Strict Exogeneity**: Conditional on observables and unobservables, potential outcomes are independent of treatment assignment (i.e., baseline quasi-randomization)
    -   In DiD, where unobservables = unit + time FEs, this assumption is the parallel trends assumption
3.  **Low-dimensional Decomposition (Feasibility Assumption)**: Unobservable effects can be decomposed in low-dimension.
    -   For the case that $U_{it} = f_t \times \lambda_i$ where $f_t$ = common time trend (time FE), and $\lambda_i$ = unit heterogeneity (unit FE). If $U_{it} = f_t \times \lambda_i$ , DiD can satisfy this assumption. But this assumption is weaker than that of DID, and allows us to control for unobservables based on data.

**Estimation Procedure**:

1.  Using all control observations, estimate the functions of both observable and unobservable variables (relying on Assumptions 1 and 3).
2.  Predict the counterfactual outcomes for each treated unit using the obtained functions.
3.  Calculate the difference in treatment effect for each treated individual.
4.  By averaging over all treated individuals, you can obtain the Average Treatment Effect on the Treated (ATT).

Notes:

-   Use jackknife when number of treated units is small [@liu2024practical, p.166].

##### Imputation Method

@liu2024practical can also account for treatment reversals and heterogeneous treatment effects.

Other imputation estimators include

-   [@gardner2022two; @borusyak2021revisiting]

-   [@brown2023simple]

```{r, eval  = FALSE}
library(fect)

PanelMatch::dem

model.fect <-
    fect(
        Y = "y",
        D = "dem",
        X = "tradewb",
        data = na.omit(PanelMatch::dem),
        method = "fe",
        index = c("wbcode2", "year"),
        se = TRUE,
        parallel = TRUE,
        seed = 1234,
        # twfe
        force = "two-way"
    )
print(model.fect$est.avg)

plot(model.fect)

plot(model.fect, stats = "F.p")
```

F-test $H_0$: residual averages in the pre-treatment periods = 0

To see treatment reversal effects

```{r, eval = FALSE}
plot(model.fect, stats = "F.p", type = 'exit')
```

##### Placebo Test

By selecting a part of the data and excluding observations within a specified range to improve the model fitting, we then evaluate whether the estimated Average Treatment Effect (ATT) within this range significantly differs from zero. This approach helps us analyze the periods before treatment.

If this test fails, either the functional form or strict exogeneity assumption is problematic.

```{r, eval = FALSE}
out.fect.p <-
    fect(
        Y = "y",
        D = "dem",
        X = "tradewb",
        data = na.omit(PanelMatch::dem),
        method = "fe",
        index = c("wbcode2", "year"),
        se = TRUE,
        placeboTest = TRUE,
        # using 3 periods
        placebo.period = c(-2, 0)
    )
plot(out.fect.p, proportion = 0.1, stats = "placebo.p")
```

##### (No) Carryover Effects Test

The placebo test can be adapted to assess carryover effects by masking several post-treatment periods instead of pre-treatment ones. If no carryover effects are present, the average prediction error should approximate zero. For the carryover test, set `carryoverTest = TRUE`. Specify a post-treatment period range in carryover.period to exclude observations for model fitting, then evaluate if the estimated ATT significantly deviates from zero.

Even if we have carryover effects, in most cases of the staggered adoption setting, researchers are interested in the cumulative effects, or aggregated treatment effects, so it's okay.

```{r, eval = FALSE}
out.fect.c <-
    fect(
        Y = "y",
        D = "dem",
        X = "tradewb",
        data = na.omit(PanelMatch::dem),
        method = "fe",
        index = c("wbcode2", "year"),
        se = TRUE,
        carryoverTest = TRUE,
        # how many periods of carryover
        carryover.period = c(1, 3)
    )
plot(out.fect.c,  stats = "carryover.p")
```

We have evidence of carryover effects.

------------------------------------------------------------------------

### Matrix Completion Estimator {#sec-matrix-completion-estimator}

Matrix completion methods have become increasingly influential in causal inference for panel data, particularly when estimating [average treatment effects](#sec-average-treatment-effect) in business settings such as marketing experiments, customer behavior modeling, and pricing interventions. These settings often feature [staggered adoption](#sec-staggered-difference-in-differences)of treatments across units and time, leading to **structured missing data**. @athey2021matrix develop a matrix completion framework that subsumes methods based on **unconfoundedness** and [**synthetic controls**](#sec-synthetic-control), by leveraging the low-rank structure of potential outcomes matrices.

An important empirical context is consumer choice data in marketing, where missing outcomes can arise due to **intermittent treatment**, e.g., promotional campaigns delivered at varying times across different stores or consumer segments. One illustrative application is provided by @bronnenberg2020consumer, who investigates **consumer response to targeted marketing campaigns** using panel data that naturally contains missing counterfactual outcomes for treated units.

Two key literatures have historically addressed the problem of imputing missing potential outcomes:

-   **Unconfoundedness Framework** [@imbens2015causal]:
    -   Assumes [selection on observables](#sec-selection-on-observables).
    -   Imputes missing control outcomes by matching or regression using untreated units with similar characteristics or histories.
    -   Assumes time patterns are stable across units.
-   [**Synthetic Control**](#sec-synthetic-control) [@abadie2010synthetic]:
    -   Constructs counterfactual outcomes as weighted averages of control units.
    -   Assumes unit patterns are stable over time.
    -   Particularly suited for single treated unit settings.

These methods can be unified under the matrix completion framework, which interprets the panel of outcomes as a low-rank matrix plus noise, allowing for flexible imputation without strong parametric assumptions.

Contributions of @athey2021matrix

1.  Accommodates structured missingness, including staggered adoption.
2.  Adjusts for unit ($\mu_i$) and time ($\lambda_t$) fixed effects prior to low-rank estimation.
3.  Exhibits strong performance across unbalanced panels with varying dimensions:
    -   $T \gg N$: Where unconfoundedness struggles.
    -   $N \gg T$: Where synthetic control performs poorly.

**Advantages of Matrix Completion**

-   Utilizes all units and periods, even treated ones, to learn latent factors.
-   Handles complex missingness patterns and autocorrelated errors.
-   Accommodates covariates and heterogeneous treatment effects.
-   Can apply weighted loss functions to account for non-random assignment or missingness.

------------------------------------------------------------------------

#### Matrix Completion Core Assumptions

The matrix completion approach is built on the assumption that the complete outcome matrix $\mathbf{Y}$ satisfies:

1.  **Low-rank structure**: $$
    \mathbf{Y} = \mathbf{U} \mathbf{V}^T + \mathbf{E}
    $$ where $\mathbf{U} \in \mathbb{R}^{N \times R}$, $\mathbf{V} \in \mathbb{R}^{T \times R}$, and $\mathbf{E}$ is a noise matrix.
2.  [Missing Completely At Random (MCAR)](#missing-completely-at-random-mcar): The pattern of missing data is independent of unobserved outcomes, conditional on observables.

Unlike prior approaches, matrix completion does not impose a specific factorization, but rather regularizes the estimator, e.g., via nuclear norm minimization.

To identify the causal estimand, matrix completion relies on:

-   [SUTVA](#sec-sutva) **(Stable Unit Treatment Value Assumption)**: $Y_{it}(w)$ depends only on $W_{it}$, not on other units' treatments.

-   **No dynamic treatment effects**: The treatment at time $t$ does not influence outcomes in other periods.

------------------------------------------------------------------------

#### Causal Estimand

Let $Y_{it}(0)$ and $Y_{it}(1)$ denote the potential outcomes under control and treatment. We observe treated outcomes, and aim to impute unobserved control outcomes:

$$
\tau = \frac{\sum_{(i,t): W_{it} = 1} \left[ Y_{it}(1) - Y_{it}(0) \right]}{\sum_{i,t} W_{it}}
$$

Let $\mathcal{M}$ be the set of indices $(i, t)$ where $W_{it} = 1$ (treated, hence $Y_{it}(0)$ is missing), and $\mathcal{O}$ the set where $W_{it} = 0$ (control, hence $Y_{it}(0)$ is observed).

We conceptualize the data as 2 $N \times T$ matrices:

$$
\mathbf{Y} =
\begin{pmatrix}
Y_{11} & Y_{12} & ? & \cdots & Y_{1T} \\
? & ? & Y_{23} & \cdots & ? \\
Y_{31} & ? & Y_{33} & \cdots & ? \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
Y_{N1} & ? & Y_{N3} & \cdots & ?
\end{pmatrix},
\quad
\mathbf{W} =
\begin{pmatrix}
0 & 0 & 1 & \cdots & 0 \\
1 & 1 & 0 & \cdots & 1 \\
0 & 1 & 0 & \cdots & 1 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 1 & 0 & \cdots & 1
\end{pmatrix}
$$

**Matrix Shape**

+------------------------+-----------------------+------------------------------------------+
| Matrix Shape           | Pattern               | Literature / Method                      |
+------------------------+-----------------------+------------------------------------------+
| Thin ($N \gg T$)       | Single-treated-period | Horizontal regression (unconfoundedness) |
+------------------------+-----------------------+------------------------------------------+
| Fat ($T \gg N$)        | Single-treated-unit   | Vertical regression (synthetic control)  |
+------------------------+-----------------------+------------------------------------------+
| Square ($N \approx T$) | Varying patterns      | TWFE / Matrix Completion                 |
+------------------------+-----------------------+------------------------------------------+

**Special Patterns of Missingness**

-   **Block structures**:
    -   **Single-period treatment** (horizontal regression) [@imbens2015causal]
    -   **Single-unit treatment** (vertical regression) [@abadie2010synthetic]
-   **Staggered adoption**: Treatments occur at different times across units, as in many business interventions.

------------------------------------------------------------------------

#### Unified Low-Rank Model

Matrix completion generalizes these approaches using a low-rank plus noise model:

$$
\mathbf{Y} = \mathbf{U} \mathbf{V}^T + \mathbf{E}
$$

where $R = \text{rank}(\mathbf{Y})$ is typically low relative to $N$ and $T$.

-   **TWFE** assumes additivity: $\mathbf{Y}_{it} = \mu_i + \lambda_t + \epsilon_{it}$.
-   **Interactive Fixed Effects** use $R$ factors: $\mathbf{Y}_{it} = \sum_{r=1}^R \alpha_{ir} \gamma_{rt} + \epsilon_{it}$. To estimate the number of factors $R$, see @bai2002determining and @moon2015linear.
-   **Matrix Completion** estimates $\mathbf{Y}$ via regularization, avoiding the need to explicitly choose $R$.

<!-- [Specifically](https://bookdown.org/stanfordgsbsilab/ml-ci-tutorial/matrix-completion-methods.html) -->

In practical settings (e.g., marketing campaigns), it's beneficial to incorporate unit-level and time-varying covariates:

$$
Y_{it} = L_{it} + \sum_{p=1}^{P} \sum_{q=1}^{Q} X_{ip} H_{pq} Z_{qt} + \mu_i + \lambda_t + V_{it} \beta + \epsilon_{it}
$$

-   $X_{ip}$: Unit covariates (a matrix of $p$ variables for unit $i$)
-   $Z_{qt}$: Time covariates (a matrix of $q$ variables for time $t$)
-   $V_{it}$: Time-varying covariates
-   $H$: Interaction effects. Lasso-type $l_1$ norm ($||H|| = \sum_{p = 1}^p \sum_{q = 1}^Q |H_{pq}|$) is used to shrink $H \to 0$.

There are several options to regularize $L$:

+-----------------+------------------------------------+-------------------------------+---------------------------------------------+
| **Regularizer** | **Penalty**                        | **Properties**                | **Feasibility**                             |
+-----------------+------------------------------------+-------------------------------+---------------------------------------------+
| Frobenius Norm  | $\|\mathbf{L}\|_F^2$               | Ridge-type; shrinks towards 0 | Not informative                             |
|                 |                                    |                               |                                             |
| (i.e., Ridge)   |                                    |                               |                                             |
+-----------------+------------------------------------+-------------------------------+---------------------------------------------+
| Nuclear Norm    | $\|\mathbf{L}\|_* = \sum \sigma_r$ | Convex relaxation of rank     | ✔ (via SOFT-IMPUTE [@mazumder2010spectral]) |
|                 |                                    |                               |                                             |
| (i.e., Lasso)   |                                    |                               |                                             |
+-----------------+------------------------------------+-------------------------------+---------------------------------------------+
| Rank Constraint | $\text{rank}(\mathbf{L}) \le R$    | Direct low-rank control       | ✘ (NP-hard)                                 |
+-----------------+------------------------------------+-------------------------------+---------------------------------------------+

------------------------------------------------------------------------

### Reshaped Inverse Probability Weighting - TWFE Estimator {#sec-reshaped-inverse-probability-weighting-twfe-estimator}

The **Reshaped Inverse Probability Weighting (RIPW) estimator** extends the classic **TWFE** regression framework to account for arbitrary, time- and unit-varying treatment assignment mechanisms. This approach leverages an explicit model for treatment assignment to achieve **design robustness**, maintaining consistency even when traditional fixed-effects outcome models are misspecified.

The RIPW-TWFE framework is particularly relevant in panel data settings with **general treatment patterns**

-   **staggered adoption**

-   **transient treatments**.

------------------------------------------------------------------------

Setting and Notation

-   Panel data with $n$ units observed over $T$ time periods.

-   **Potential outcomes**: For each unit $i \in \{1, \dots, n\}$ and time $t \in \{1, \dots, T\}$:

    $$
    Y_{it}(1), \quad Y_{it}(0)
    $$

-   **Observed outcomes**:

    $$
    Y_{it} = W_{it} Y_{it}(1) + (1 - W_{it}) Y_{it}(0)
    $$

-   **Treatment assignment path** for unit $i$:

    $$
    \mathbf{W}_i = (W_{i1}, \dots, W_{iT}) \in \{0,1\}^T
    $$

-   **Generalized Propensity Score (GPS)**: For unit $i$, the probability distribution over treatment paths:

    $$
    \mathbf{W}_i \sim \pi_i(\cdot)
    $$

    where $\pi_i(w)$ is known or estimated.

------------------------------------------------------------------------

**Assumptions**

1.  **Binary Treatment**: $W_{it} \in \{0,1\}$ for all $i$ and $t$.

2.  **No Dynamic Effects**: Current outcomes depend only on current treatment, not past treatments.

3.  **Overlap Condition** (Assumption 2.2 from @arkhangelsky2024design):

    There exists a subset $S^* \subseteq \{0,1\}^T$, with $|S^*| \ge 2$ and $S^* \not\subseteq \{0_T, 1_T\}$, such that:

    $$
    \pi_i(w) > c > 0, \quad \forall w \in S^*, \forall i \in \{1, \dots, n\}
    $$

4.  **Maximal Correlation Decay** (Assumption 2.1): Dependence between units decays at rate $n^{-q}$ for some $q \in (0,1]$.

5.  **Bounded Second Moments** (Assumption 2.3): $\sup_{i,t,w} \mathbb{E}[Y_{it}^2(w)] < M < \infty$.

------------------------------------------------------------------------

Key Quantities of Interest

-   **Unit-Time Specific Treatment Effect**:

    $$
    \tau_{it} = Y_{it}(1) - Y_{it}(0)
    $$

-   **Time-Specific** [Average Treatment Effect]:

    $$
    \tau_t = \frac{1}{n} \sum_{i=1}^n \tau_{it}
    $$

-   **Doubly Averaged Treatment Effect (DATE)**:

    $$
    \tau(\xi) = \sum_{t=1}^T \xi_t \tau_t = \sum_{t=1}^T \xi_t \left( \frac{1}{n} \sum_{i=1}^n \tau_{it} \right)
    $$

    where $\xi = (\xi_1, \dots, \xi_T)$ is a vector of non-negative weights such that $\sum_{t=1}^T \xi_t = 1$.

-   **Special Case**: Equally weighted DATE:

    $$
    \tau_{\text{eq}} = \frac{1}{nT} \sum_{t=1}^T \sum_{i=1}^n \tau_{it}
    $$

------------------------------------------------------------------------

Inverse Probability Weighting (IPW) methods are widely used to correct for **selection bias** in treatment assignment by reweighting observations according to their probability of receiving a given treatment. In panel data settings with TWFE regression, the IPW approach can be incorporated to address non-random treatment assignments over time and across units.

We begin with the **classic TWFE regression objective**, then show how IPW modifies it, and finally generalize to the **Reshaped IPW (RIPW)** estimator.

------------------------------------------------------------------------

The **unweighted** TWFE estimator minimizes the following objective function:

$$
\min_{\tau, \mu, \{\alpha_i\}, \{\lambda_t\}} \sum_{i=1}^{n} \sum_{t=1}^{T} \left( Y_{it} - \mu - \alpha_i - \lambda_t - W_{it} \tau \right)^2
$$

where

-   $n$: Total number of units (e.g., individuals, firms, regions).
-   $T$: Total number of time periods.
-   $Y_{it}$: Observed outcome for unit $i$ at time $t$.
-   $W_{it}$: Binary treatment indicator for unit $i$ at time $t$.
    -   $W_{it} = 1$ if unit $i$ is treated at time $t$; $0$ otherwise.
-   $\tau$: Parameter of interest, representing the [Average Treatment Effect] under the TWFE model.
-   $\mu$: Common intercept, capturing the overall average outcome level across all units and times.
-   $\alpha_i$: Unit-specific fixed effects, controlling for time-invariant heterogeneity across units.
-   $\lambda_t$: Time-specific fixed effects, controlling for shocks or common trends that affect all units in time period $t$.

This standard TWFE regression assumes [parallel trends](#prior-parallel-trends-test) across units in the absence of treatment and **ignores** the treatment assignment mechanism.

------------------------------------------------------------------------

The **IPW-TWFE estimator** modifies the classic TWFE regression by **reweighting** the contribution of each observation according to the **inverse probability of the entire treatment path** for unit $i$.

The weighted objective function is:

$$
\min_{\tau, \mu, \{\alpha_i\}, \{\lambda_t\}} \sum_{i=1}^{n} \sum_{t=1}^{T} \left( Y_{it} - \mu - \alpha_i - \lambda_t - W_{it} \tau \right)^2 \cdot \frac{1}{\pi_i(\mathbf{W}_i)}
$$

where

-   $\pi_i(\mathbf{W}_i)$: The **generalized propensity score (GPS)** for unit $i$.
    -   This is the joint probability that unit $i$ follows the entire treatment assignment path $\mathbf{W}_i = (W_{i1}, W_{i2}, \dots, W_{iT})$.
    -   It represents the assignment mechanism, which may be known (in experimental designs) or estimated (in observational studies).

By weighting the squared residual for each unit-time observation by $\frac{1}{\pi_i(\mathbf{W}_i)}$, the IPW-TWFE estimator **adjusts for non-random treatment assignment**, similar to the role of IPW in cross-sectional data.

------------------------------------------------------------------------

The **Reshaped IPW (RIPW)** estimator further generalizes the IPW approach by introducing a **user-specified reshaped design distribution**, denoted by $\Pi$, over the space of treatment assignment paths.

The RIPW-TWFE estimator minimizes the following weighted objective:

$$
\hat{\tau}_{RIPW}(\Pi) = \arg \min_{\tau, \mu, \{\alpha_i\}, \{\lambda_t\}} \sum_{i=1}^{n} \sum_{t=1}^{T} \left( Y_{it} - \mu - \alpha_i - \lambda_t - W_{it} \tau \right)^2 \cdot \frac{\Pi(\mathbf{W}_i)}{\pi_i(\mathbf{W}_i)}
$$

where

-   $\Pi(\mathbf{W}_i)$: A **user-specified reshaped distribution** over the treatment assignment paths $\mathbf{W}_i$.
    -   It describes an alternative "design" the researcher wants to emulate, possibly reflecting hypothetical or target assignment mechanisms.
-   The weight $\frac{\Pi(\mathbf{W}_i)}{\pi_i(\mathbf{W}_i)}$ can be interpreted as a likelihood ratio:
    -   If $\pi_i(\cdot)$ is the true assignment distribution, reweighting by $\Pi(\cdot)$ effectively shifts the sampling design from $\pi_i$ to $\Pi$.
-   The ratio $\frac{\Pi(\mathbf{W}_i)}{\pi_i(\mathbf{W}_i)}$ adjusts for differences between the observed assignment mechanism and the target design.

------------------------------------------------------------------------

Support of $\mathbf{W}_i$

The support of the treatment assignment paths is defined as:

$$
\mathbb{S} = \bigcup_{i=1}^{n} \text{Supp}(\mathbf{W}_i)
$$

-   $\text{Supp}(\mathbf{W}_i)$: The support of the random variable $\mathbf{W}_i$, i.e., the set of all treatment paths with positive probability under $\pi_i(\cdot)$.
-   $\mathbb{S}$ represents the combined support across all units $i = 1, \dots, n$.
-   $\Pi(\cdot)$ should have support contained within $\mathbb{S}$, to ensure valid reweighting.

------------------------------------------------------------------------

**Special Cases of the RIPW Estimator**

The choice of $\Pi(\cdot)$ determines the behavior and interpretation of the RIPW estimator. Several special cases are noteworthy:

-   **Uniform Reshaped Design**:

    $$
    \Pi(\cdot) \sim \text{Uniform}(\mathbb{S})
    $$

    -   Here, $\Pi$ places equal probability mass on each possible treatment path in $\mathbb{S}$.

    -   The weight becomes:

        $$
        \frac{\Pi(\mathbf{W}_i)}{\pi_i(\mathbf{W}_i)} = \frac{1 / |\mathbb{S}|}{\pi_i(\mathbf{W}_i)}
        $$

    -   This reduces RIPW to the standard **IPW-TWFE estimator**, in which the target is a uniform treatment assignment design.

-   **Reshaped Design Equals True Assignment**:

    $$
    \Pi(\cdot) = \pi_i(\cdot)
    $$

    -   The weight simplifies to:

        $$
        \frac{\Pi(\mathbf{W}_i)}{\pi_i(\mathbf{W}_i)} = 1
        $$

    -   The RIPW estimator reduces to the **unweighted TWFE regression**, consistent with an experiment where the assignment mechanism $\pi_i$ is known and correctly specified.

------------------------------------------------------------------------

To ensure that $\hat{\tau}_{RIPW}(\Pi)$ consistently estimates the DATE $\tau(\xi)$, we solve the **DATE Equation**:

$$
\mathbb{E}_{\mathbf{W} \sim \Pi} \left[ \left( \text{diag}(\mathbf{W}) - \xi \mathbf{W}^\top \right) J \left( \mathbf{W} - \mathbb{E}_{\Pi}[\mathbf{W}] \right) \right] = 0
$$

-   $J = I_T - \frac{1}{T} \mathbf{1}_T \mathbf{1}_T^\top$ is a projection matrix removing the mean.
-   Solving this equation ensures consistency of the RIPW estimator for $\tau(\xi)$.

------------------------------------------------------------------------

Choosing the Reshaped Distribution $\Pi$

-   If the support $\mathbb{S}$ and $\pi_i(\cdot)$ are known, $\Pi$ can be specified directly.
-   Closed-form solutions for $\Pi$ are available in settings such as staggered adoption designs.
-   When closed-form solutions are unavailable, optimization algorithms (e.g., BFGS) can be employed to solve the DATE equation numerically.

------------------------------------------------------------------------

**Properties**

-   The RIPW estimator provides design-robustness:
    -   It can correct for misspecified outcome models by properly reweighting according to the assignment mechanism.
    -   It accommodates complex treatment assignment processes, such as staggered adoption and non-random assignment.
-   The flexibility to choose $\Pi(\cdot)$ allows researchers to target estimands that represent specific policy interventions or hypothetical designs.

The RIPW estimator has a **double robustness** property:

-   $\hat{\tau}_{RIPW}(\Pi)$ is consistent if **either**:

    -   The assignment model $\pi_i(\cdot)$ is correctly specified **or**

    -   The outcome regression (TWFE) model is correctly specified.

This feature is particularly valuable in [quasi-experimental designs](#sec-quasi-experimental) where the parallel trends assumption may not hold globally.

-   **Design-Robustness**: RIPW corrects for negative weighting issues identified in the TWFE literature (e.g., @goodman2021difference; @de2023two).
-   Unlike conventional TWFE regressions, which can yield biased estimands under heterogeneity, RIPW explicitly targets user-specified weighted averages (DATE).
-   In randomized experiments, RIPW ensures the **effective estimand** is interpretable as a population-level average, determined by the design $\Pi$.

------------------------------------------------------------------------

### @gardner2022two and @borusyak2024revisiting

-   Estimate the time and unit fixed effects separately

-   Known as the imputation method [@borusyak2024revisiting] or two-stage DiD [@gardner2022two]

```{r, warning=FALSE, message=FALSE}
# remotes::install_github("kylebutts/did2s")
library(did2s)
library(ggplot2)
library(fixest)
library(tidyverse)
data(base_stagg)


est <- did2s(
    data = base_stagg |> mutate(treat = if_else(time_to_treatment >= 0, 1, 0)),
    yname = "y",
    first_stage = ~ x1 | id + year,
    second_stage = ~ i(time_to_treatment, ref = c(-1,-1000)),
    treatment = "treat" ,
    cluster_var = "id"
)

fixest::esttable(est)

fixest::iplot(
    est,
    main = "Event study",
    xlab = "Time to treatment",
    ref.line = -1
)

coefplot(est)

```

```{r}
mult_est <- did2s::event_study(
    data = fixest::base_stagg |>
        dplyr::mutate(year_treated = dplyr::if_else(year_treated == 10000, 0, year_treated)),
    gname = "year_treated",
    idname = "id",
    tname = "year",
    yname = "y",
    estimator = "all"
)
did2s::plot_event_study(mult_est)
```

@borusyak2024revisiting `didimputation`

This version is currently not working

```{r, eval = FALSE}
library(didimputation)
library(fixest)
data("base_stagg")

did_imputation(
    data = base_stagg,
    yname = "y",
    gname = "year_treated",
    tname = "year",
    idname = "id"
)
```

### Dynamic Treatment Effect Estimation with Interactive Fixed Effects and Short Panels

<!-- https://www.kylebutts.com/files/JMP_slides.pdf -->

@brown2025dynamic

------------------------------------------------------------------------

### Switching Difference-in-Differences Estimator [@de2020two] {#sec-switching-difference-in-differences-estimator-de2020two}

[TWFE](#sec-two-way-fixed-effects) hinges on restrictive assumptions --- notably, the homogeneity of treatment effects across time and groups. When this assumption is violated, TWFE can yield misleading results, including estimates with signs opposite to all underlying effects.

We consider a standard panel data setup with $G$ groups and $T$ time periods. Each observation belongs to a group-period cell $(g, t)$, and treatment $D_{g,t} \in \{0,1\}$ is assigned at the group-time level.

Let $Y_{i,g,t}$ be the outcome of individual $i$ in group $g$ at time $t$, with potential outcomes $Y_{i,g,t}(1)$ and $Y_{i,g,t}(0)$. Observed outcomes satisfy:

$$
Y_{i,g,t} = D_{g,t} \cdot Y_{i,g,t}(1) + (1 - D_{g,t}) \cdot Y_{i,g,t}(0)
$$

The canonical TWFE regression is:

$$
Y_{i,g,t} = \alpha_g + \lambda_t + \beta^{fe} D_{g,t} + \varepsilon_{i,g,t}
$$

where $\alpha_g$ are group fixed effects, $\lambda_t$ are time fixed effects, and $\beta^{fe}$ is interpreted as the treatment effect **only under homogeneous treatment effects**.

#### Heterogeneous Treatment Effects and Weighting Bias

When treatment effects vary across $(g,t)$ cells, the TWFE estimator $\hat{\beta}^{fe}$ is no longer a simple average. Instead, it can be decomposed into a weighted sum of cell-specific average treatment effects:

$$
\beta^{fe} = \mathbb{E} \left[ \sum_{(g,t): D_{g,t}=1} w_{g,t} \Delta_{g,t} \right]
$$

where:

-   $\Delta_{g,t} = \mathbb{E}[Y_{g,t}(1) - Y_{g,t}(0)]$ is the average treatment effect in cell $(g,t)$
-   $w_{g,t}$ are weights that **can be negative** and sum to one.

Some weights are negative because [TWFE](#sec-two-way-fixed-effects) implicitly compares outcomes across all treated and untreated groups, even when "controls" are themselves treated. These comparisons can subtract out treatment effects, leading to negative weights.

------------------------------------------------------------------------

#### Illustration: Negative Weights Can Flip Signs

For example, suppose:

-   Group 1 is treated only in period 3: $\Delta_{1,3} = 1$
-   Group 2 is treated in periods 2 and 3:
    -   $\Delta_{2,2} = 1$
    -   $\Delta_{2,3} = 4$

Then TWFE produces:

$$
\beta^{fe} = \frac{1}{2} \Delta_{1,3} + \Delta_{2,2} - \frac{1}{2} \Delta_{2,3} = \frac{1}{2} + 1 - 2 = -0.5
$$

All $\Delta_{g,t}$s are positive, but the TWFE estimate is **negative**.

------------------------------------------------------------------------

To assess the extent to which TWFE may be misleading, compute the **robustness ratio**:

$$
\sigma^{fe}_\_ = \frac{|\hat{\beta}^{fe}|}{\hat{\sigma}(w)}
$$

Where:

-   $\hat{\sigma}(w)$ is the standard deviation of the TWFE weights across treated cells.
-   A **small** $\sigma^{fe}_\_$ indicates that minor heterogeneity can reverse the sign of the estimate.

This can be estimated directly from data and helps determine whether TWFE is reliable in your context.

------------------------------------------------------------------------

#### DID_M Estimator: A Robust Alternative

@de2020two propose the **DID_M** estimator, which is valid under heterogeneous treatment effects. It focuses only on **switching groups**, using non-switchers as controls in a local difference-in-differences design.

Let $S$ denote the set of all $(g,t)$ cells where treatment status changes between $t-1$ and $t$. The DID_M estimator is:

$$
\text{DID}_M = \sum_{t=2}^{T} \left( \frac{N_{1,0,t}}{N_S} \cdot \text{DID}^+_t + \frac{N_{0,1,t}}{N_S} \cdot \text{DID}^-_t \right)
$$

Where:

-   $\text{DID}^+_t$ compares joiners to stable untreated groups
-   $\text{DID}^-_t$ compares leavers to stable treated groups
-   $N_S$ is the total number of observations in switching cells

DID_M requires:

1.  **Common trends** for both treated and untreated potential outcomes
2.  **Existence of stable groups** at every $t$ (i.e., some groups don't change treatment status)
3.  **No Ashenfelter dip** (treatment not triggered by negative shocks)

These assumptions are **weaker** than those required for TWFE to be unbiased.

@de2020two also propose a placebo version of DID_M using pre-treatment periods. If pre-treatment differences exist between switchers and non-switchers, this indicates violation of the parallel trends assumption. This test is analogous to pre-trend checks in event-study designs.

```{r}
# Load required packages
library(fixest)            # For TWFE model and dataset
library(TwoWayFEWeights)   # For decomposing TWFE weights
library(DIDmultiplegt)     # For robust SDID estimator

# Load the sample staggered adoption dataset
data("base_stagg")

# Preview the data
head(base_stagg)
```

1.  Estimate TWFE Model

```{r}
# Run standard TWFE using fixest
twfe <- feols(y ~ treatment | id + year,
                    data = base_stagg |>
                        dplyr::mutate(treatment = dplyr::if_else(time_to_treatment < 0, 0, 1)))
summary(twfe)

```

2.  Decompose Weights with `TwoWayFEWeights`

```{r}
twfe_weights <- twowayfeweights(
    data = base_stagg |> dplyr::mutate(treatment = dplyr::if_else(time_to_treatment < 0, 0, 1)),
    Y = "y",
    G = "year_treated",
    T = "year",
    D = "treatment", 
    summary_measures = T
)

# Show summary
twfe_weights
```

3.  Estimate DID_M (Switching DID Estimator) with `DIDmultiplegt`

```{r}
# Estimate robust SDID estimator (DID_M)
did_m <- did_multiplegt(
        mode = "dyn",
        df = base_stagg |>
            dplyr::mutate(treatment = dplyr::if_else(time_to_treatment < 0, 0, 1)),
        outcome = "y",
        group = "year_treated",
        time = "year",
        treatment = "treatment",
        effects = 5,
        # controls = c("x1"),
        placebo = 2
    )

summary(did_m)
```

------------------------------------------------------------------------

### Augmented/Forward DID

-   DID Methods for Limited Pre-Treatment Periods:

+--------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------+
| **Method**         | **Scenario**                                            | **Approach**                                                                            |
+====================+=========================================================+=========================================================================================+
| **Augmented DID**  | Treatment outcome is outside the range of control units | Constructs the treatment counterfactual using a scaled average of control units         |
|                    |                                                         |                                                                                         |
| [@li2023augmented] |                                                         |                                                                                         |
+--------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------+
| **Forward DID**    | Treatment outcome is within the range of control units  | Uses a forward selection algorithm to choose relevant control units before applying DID |
|                    |                                                         |                                                                                         |
| [@li2024frontiers] |                                                         |                                                                                         |
+--------------------+---------------------------------------------------------+-----------------------------------------------------------------------------------------+

------------------------------------------------------------------------

### Doubly Robust Difference-in-Differences Estimators

In its simplest "canonical" form, DID compares the before-and-after outcomes of one group that eventually receives a treatment (the "treated" group) with the before-and-after outcomes of another group that never receives the treatment (the "comparison" group). Under the parallel trends assumption, DID can recover the [average treatment effect on the treated](#sec-average-treatment-effect-on-the-treated) (ATT).

Practitioners often enrich DID analyses by conditioning on observed covariates to mitigate violations of the unconditional parallel trends assumption. Once conditioning on covariates, the DID framework remains attractive, provided that *conditional* parallel trends hold.

Historically, two main approaches have emerged for DID estimation in the presence of covariates:

1.  **Outcome Regression (OR)** [@heckman1997matching]. Model the outcome evolution for the comparison group (and possibly for the treated group), and then plug these fitted outcome equations into the DID formula.
2.  **Inverse Probability Weighting (IPW)** [@abadie2005semiparametric]. Model the probability of treatment conditional on covariates (the "propensity score") and use inverse-probability reweighting to reconstruct appropriate counterfactuals for the treated group.

A key insight in semiparametric causal inference is that one can *combine* these two approaches---modeling the outcome regression and the propensity score in tandem---to form an estimator that remains consistent if *either* the outcome-regression equations are correctly specified *or* the propensity-score equation is correctly specified. Such an estimator is called **doubly robust** [@sant2020doubly].

This section covers both cases of (i) panel data (where we observe each unit in both pre- and post-treatment periods) and (ii) repeated cross-section data (where, in each period, we observe a new random sample of units).

Under suitable conditions, the proposed doubly robust estimators not only exhibit desirable robustness properties to misspecification but can also attain the semiparametric efficiency bound, making them *locally efficient* if all working models are correct.

------------------------------------------------------------------------

#### Notation and set-up

-   **Two-time-period design.** We consider a setting with two time periods: $t = 0$ (pre-treatment) and $t = 1$ (post-treatment). A subset of units receives the treatment only at $t = 1$. Hence for a unit $i$:

    -   $D_i = D_{i1} \in \{0, 1\}$ is an indicator for receiving treatment by time 1 (so $D_{i0} = 0$ for all $i$).
    -   $Y_{it}$ is the observed outcome at time $t$.

-   **Potential outcomes.** We adopt the potential outcomes framework. Let $$
       Y_{it}(1) \;=\; \text{potential outcome of unit }i \text{ at time } t \text{ if treated,}
    $$ $$
       Y_{it}(0) \;=\; \text{potential outcome of unit }i \text{ at time } t \text{ if not treated.}
    $$ Then the observed outcome satisfies $Y_{it} = D_i \, Y_{it}(1) + (1-D_i)\, Y_{it}(0)$.

-   **Covariates.** A vector of observed pre-treatment covariates is denoted $X_i$. Throughout, we assume the first component of $X_i$ is a constant (intercept).

-   **Data structures.**

    1.  **Panel data.** We observe $\{(Y_{i0}, Y_{i1}, D_i, X_i)\}_{i=1}^n$, a sample of size $n$ drawn i.i.d. from an underlying population.
    2.  **Repeated cross-sections.** In period $t$, we observe a fresh random sample of units. Let $T_i\in \{0,1\}$ be an indicator for whether an observation is drawn in the post-treatment period $(T_i=1)$ or the pre-treatment period $(T_i=0)$. Write $\{(Y_i, D_i, X_i, T_i)\}_{i=1}^n$. Here, if $T_i=1$, then $Y_i \equiv Y_{i1}$; if $T_i=0$, then $Y_i \equiv Y_{i0}$. We typically assume a stationarity condition, namely that the distribution of $(D, X)$ is stable across the two periods.

Let $n_1$ and $n_0$ be the respective sample sizes for the post- and pre-treatment periods, so $n_1 + n_0 = n$. Often we let $\lambda = P(T=1)\approx n_1/n.$

The focus is on the ATT: $$
    \tau \;=\; \mathbb{E}\bigl[Y_{i1}(1) - Y_{i1}(0)\,\big|\; D_i=1\bigr].
$$ Because we only observe $Y_{i1}(1)$ for the treated group, the central challenge is to recover $\mathbb{E}[Y_{i1}(0)\mid D_i=1]$. Under standard DID assumptions, we identify $\tau$ by comparing the treated group's evolution in outcomes to the comparison group's evolution in outcomes.

We require two key assumptions:

1.  **Conditional parallel trends**\
    For $t=0,1$, let $$
        \mathbb{E}[\,Y_{1}(0) - Y_{0}(0)\,\mid D=1,\, X] 
        \;=\;
        \mathbb{E}[\,Y_{1}(0) - Y_{0}(0)\,\mid D=0,\, X].
    $$ This means that---conditional on $X$---in the *absence* of treatment, the treated and comparison groups would have had *parallel outcome evolutions*.

2.  **Overlap**\
    There exists $\varepsilon>0$ such that $$
      P(D=1)\;>\;\varepsilon, 
      \quad\text{and}\quad
      P(D=1\,\vert\,X)\;\le\;1-\varepsilon
    $$ That is, we require that a nontrivial fraction of the population is treated, and for each $X$, there is a nontrivial probability of being in the untreated group ($D=0$).

Under these assumptions, we can identify $\mathbb{E}[\,Y_{1}(0)\mid D=1]$ in a semiparametric fashion, either by modeling the outcome regressions (the OR approach) or by modeling the propensity score (the IPW approach).

------------------------------------------------------------------------

#### Two Traditional DID Approaches

We briefly outline the classical DID estimators that rely solely on either outcome regressions or inverse probability weighting, to motivate the doubly robust idea.

##### Outcome-regression (OR) approach

Define $$
   m_{d,t}(x) \;=\; \mathbb{E}[\,Y_t \,\mid\,D=d,\; X=x\,].
$$ Under the conditional parallel trends assumption, $$
  \mathbb{E}[\,Y_{1}(0)\mid D=1 \,]
  \;=\;
   \mathbb{E}[\,Y_{0}(0)\mid D=1\,]
   \;+\; 
   \mathbb{E}[\,m_{0,1}(X) - m_{0,0}(X)\,\big\vert\,D=1\,].
$$ Hence an OR-based DID estimator (for panel or repeated cross-section) typically looks like $$
  \hat{\tau}^{\mathrm{reg}}
  \;=\;
  \Bigl(\overline{Y}_{1,1}\Bigr)
  \;-\;
  \Bigl(\,\overline{Y}_{1,0}
        \;+\;
        \frac{1}{n_{\mathrm{treat}}}
        \sum_{i:D_i=1}
         \bigl[\,
             \hat{m}_{0,1}(X_i) \;-\; \hat{m}_{0,0}(X_i)
         \bigr]
   \Bigr),
$$

where $\overline{Y}_{d,t}$ is the sample mean of $Y_t$ among units with $D=d$, and $\hat{m}_{0,t}$ is some fitted model (e.g., linear or semiparametric) for $\mathbb{E}[\,Y_t \mid D=0,\,X\,]$.

This OR estimator is consistent if (and only if) we have *correctly specified* the two outcome-regression functions $m_{0,1}(x)$ and $m_{0,0}(x)$. If these regressions are misspecified, the estimator will generally be biased.

##### IPW approach

An alternative is to model the propensity score $$
   p(x)\;=\; P(D=1\mid X=x),
$$ and use a Horvitz--Thompson-type reweighting [@horvitz1952generalization] to reconstruct what "would have happened" to the treated group under no treatment. In the panel-data case, @abadie2005semiparametric show that the ATT can be identified via $$
  \tau 
  \;=\;
  \frac{1}{\mathbb{E}[D]}
  \,\mathbb{E}\Bigl[\,
    \frac{D - p(X)}{1 - p(X)}
    \Bigl(Y_1 - Y_0\Bigr)
  \Bigr].
$$ Hence an IPW estimator for panel data is $$
  \hat{\tau}^{\mathrm{ipw,p}}
  \;=\;
  \frac{1}{\overline{D}}
  \sum_{i=1}^n
    \Bigl[
       \frac{D_i - \hat{p}(X_i)}{1-\hat{p}(X_i)}
    \Bigr]
    \,\frac{1}{n}\bigl(Y_{i1} - Y_{i0}\bigr),
$$ where $\hat{p}(\cdot)$ is a fitted propensity score model. Similar expressions exist for repeated cross-sections, with small modifications to handle the fact that we observe $Y_1$ only if $T=1$, etc.

This IPW estimator is consistent if (and only if) the propensity score is correctly specified, i.e., $\hat{p}(x)\approx p(x)$. If the propensity-score model is incorrect, the estimator may be severely biased.

------------------------------------------------------------------------

#### Doubly Robust DID: Main Identification

The **doubly robust (DR) idea** is to combine the OR and IPW approaches so that the resulting estimator is consistent if *either* the OR model is correct *or* the propensity-score model is correct. Formally, consider two generic "working" models:

-   $\pi(X)$ for $p(X)$, i.e., a model for the propensity score,

-   $\mu_{0,t}(X)$ for the outcome regressions $m_{0,t}(X)=\mathbb{E}[Y_t \mid D=0,X]$.

We define two "DR moments" for each data structure.

##### DR estimand for panel data

When panel data are available, define $$
   \Delta Y \;=\; Y_1 \,-\, Y_0,
   \quad
   \mu_{0,\Delta}(X)\;=\;\mu_{0,1}(X)\;-\;\mu_{0,0}(X).
$$ Then a DR moment for $\tau$ is: $$
   \tau^{\mathrm{dr,p}} 
   \;=\;
   \mathbb{E}\Bigl[
    \Bigl(\,w_{1}^{\mathrm{p}}(D)\,-\,w_{0}^{\mathrm{p}}(D,X;\,\pi)\Bigr)\,
    \Bigl(\,\Delta Y \;-\;\mu_{0,\Delta}(X)\Bigr)
   \Bigr],
$$ where $$
   w_{1}^{\mathrm{p}}(D)\;=\;\frac{D}{\mathbb{E}[D]},
   \quad\quad
   w_{0}^{\mathrm{p}}(D,X;\,\pi)\;=\;\frac{\pi(X)\,(1-D)}{(1-\pi(X))\,\mathbb{E}\bigl[\tfrac{\pi(X)\,(1-D)}{1-\pi(X)}\bigr]}.
$$ It can be shown that $\tau^{\mathrm{dr,p}} = \tau$ provided *either* $\pi(x)=p(x)$ almost surely (a.s.) *or* $\mu_{0,\Delta}(x)=m_{0,\Delta}(x)$ a.s. (the latter meaning that at least the regression for the comparison group is correct).

##### DR estimands for repeated cross-sections

When we only have repeated cross-sections, the DR construction must account for the fact that $Y_0, Y_1$ are not observed jointly on the same individuals. Let $\lambda = P(T=1)$. Then two valid DR estimands are:

1.  $$
      \tau^{\mathrm{dr,rc}}_{1}
      \;=\;
      \mathbb{E}\Bigl[
       \bigl(\,w_{1}^{\mathrm{rc}}(D,T)\,-\,w_{0}^{\mathrm{rc}}(D,T,X;\,\pi)\bigr)\,
       \bigl(Y \;-\;\mu_{0,Y}(T,X)\bigr)
      \Bigr],
    $$ where $$
      w_{1}^{\mathrm{rc}}(D,T)
      \;=\;
      \frac{D\,1\{T=1\}}
           {\mathbb{E}[D\,1\{T=1\}]}
      \;-\;
      \frac{D\,1\{T=0\}}
           {\mathbb{E}[D\,1\{T=0\}]},
    $$ and $$
      w_{0}^{\mathrm{rc}}(D,T,X;\,\pi)
      \;=\;
      \frac{\pi(X)\,(1-D)\,1\{T=1\}}{(1-\pi(X))\,\mathbb{E}\bigl[\tfrac{\pi(X)\,(1-D)\,1\{T=1\}}{(1-\pi(X))}\bigr]}
      \;-\;
      \frac{\pi(X)\,(1-D)\,1\{T=0\}}{(1-\pi(X))\,\mathbb{E}\bigl[\tfrac{\pi(X)\,(1-D)\,1\{T=0\}}{(1-\pi(X))}\bigr]},
    $$ and $\mu_{0,Y}(T,X)=T\cdot\mu_{0,1}(X)+(1-T)\cdot\mu_{0,0}(X)$.

2.  $$
    \tau^{\mathrm{dr,rc}}_{2} \;=\; \tau^{\mathrm{dr,rc}}_{1}\;+\;\Bigl[    \mathbb{E}\bigl(\mu_{1,1}(X) - \mu_{0,1}(X)\,\big|\,D=1\bigr)    \;-\;    \mathbb{E}\bigl(\mu_{1,1}(X) - \mu_{0,1}(X)\,\big|\,D=1,\,T=1\bigr)    \Bigr]\\\;-\;\Bigl[    \mathbb{E}\bigl(\mu_{1,0}(X) - \mu_{0,0}(X)\,\big|\,D=1\bigr)    \;-\;    \mathbb{E}\bigl(\mu_{1,0}(X) - \mu_{0,0}(X)\,\big|\,D=1,\,T=0\bigr)    \Bigr]
    $$ where $\mu_{d,t}(x)$ is a model for $m_{d,t}(x)=\mathbb{E}[Y \mid D=d,\,T=t,\,X=x]$.

One can show $\tau^{\mathrm{dr,rc}}_1 = \tau^{\mathrm{dr,rc}}_2 = \tau$ as long as the stationarity of $(D,X)$ across time holds and *either* the propensity score model $\pi(x)=p(x)$ is correct *or* the comparison-group outcome regressions are correct [@sant2020doubly]. Notably, $\tau^{\mathrm{dr,rc}}_2$ also includes explicit modeling of the treated group's outcomes. However, in terms of identification alone, $\tau^{\mathrm{dr,rc}}_1$ and $\tau^{\mathrm{dr,rc}}_2$ share the same double-robust property.

------------------------------------------------------------------------

#### Semiparametric Efficiency Bounds and Local Efficiency

An important concept in semiparametric inference is the **semiparametric efficiency bound**, which is the infimum of the asymptotic variance across *all* regular estimators that exploit only the imposed assumptions (parallel trends, overlap, stationarity). Equivalently, one can think of it as the variance of the "efficient influence function" (EIF).

We highlight key results:

1.  **Efficient influence function for panel data**

Under the above mentioned assumptions (i.i.d. data generating process, overlap, and conditional parallel trends) and *without* imposing further parametric constraints on $(m_{d,t},p)$, one can derive that the **EIF** for $\tau$ in the panel-data setting is

$$
\eta^{e,\mathrm{p}}(Y_1, Y_0, D, X) \;=\;\frac{D}{\mathbb{E}[D]}\Bigl[m_{1,\Delta}(X) - m_{0,\Delta}(X) - \tau\Bigr]\\\;+\;\frac{D}{\mathbb{E}[D]}\Bigl[\Delta Y - m_{1,\Delta}(X)\Bigr]\\\;-\;\frac{\pi(X)\,(1-D)}{(1 - \pi(X))\,\mathbb{E}\bigl[\tfrac{\pi(X)\,(1-D)}{1 - \pi(X)}\bigr]}\Bigl[\Delta Y - m_{0,\Delta}(X)\Bigr]
$$

where $\Delta Y = Y_1 - Y_0$ and $m_{d,\Delta}(X) \equiv m_{d,1}(X) - m_{d,0}(X)$.

The associated **semiparametric efficiency bound** is $$
   \mathbb{E}\bigl[\,\eta^{e,\mathrm{p}}(Y_1,Y_0,D,X)^2\bigr].
$$ It can be shown that a DR DID estimator can *attain* this bound if (1) the propensity score is correctly modeled, and (2) the comparison-group outcome regressions are correctly modeled.

2.  **Efficient influence function for repeated cross-sections**

Similarly, when only repeated cross-sections are available, the EIF becomes

$$
\eta^{e,\mathrm{rc}}(Y,D,T,X) \;=\;\frac{D}{\mathbb{E}[D]}\Bigl[m_{1,\Delta}(X) - m_{0,\Delta}(X) - \tau\Bigr]\\\;+\;\Bigl[    w_{1,1}^{\mathrm{rc}}(D,T)\bigl(Y - m_{1,1}(X)\bigr)    \;-\;    w_{1,0}^{\mathrm{rc}}(D,T)\bigl(Y - m_{1,0}(X)\bigr)    \Bigr]\\\;-\;\Bigl[    w_{0,1}^{\mathrm{rc}}(D,T,X;p)\bigl(Y - m_{0,1}(X)\bigr)    \;-\;    w_{0,0}^{\mathrm{rc}}(D,T,X;p)\bigl(Y - m_{0,0}(X)\bigr)    \Bigr]
$$

with $\,m_{d,\Delta}(X)=m_{d,1}(X)-m_{d,0}(X)$. The resulting efficiency bound is $\mathbb{E}\bigl[\eta^{e,\mathrm{rc}}(Y,D,T,X)^2\bigr]$.

One can further show that having access to *panel* data can be strictly more informative (i.e., yields a *smaller* semiparametric variance bound) than repeated cross-sections. This difference can grow if the pre- and post-treatment samples are highly unbalanced.

------------------------------------------------------------------------

#### Construction of Doubly Robust DID Estimators

1.  **Generic two-step approach**

Building upon the DR moment expressions, a natural approach to estimation is:

1.  **First-stage modeling (nuisance parameters).**
    -   Estimate $\hat{\pi}(X)$ for the propensity score, e.g. via logistic regression or other parametric or semiparametric methods.
    -   Estimate $\hat{m}_{0,t}(X)$ for $t=0,1$. One might also estimate $\hat{m}_{1,t}(X)$ if using the second DR estimator for repeated cross-sections.
2.  **Plug into the DR moment.**\
    Replace $p$ with $\hat{\pi}$ and $m_{d,t}$ with $\hat{m}_{d,t}$ in the chosen DR formula (panel or repeated cross-sections).

Because these estimators are DR, if either the propensity score is well specified or the outcome regressions for the comparison group are well specified, consistency is assured.

2.  **Improving efficiency and inference: special parametric choices**

It is sometimes desirable to construct DR DID estimators that are *also* "DR for inference," meaning that the asymptotic variance does not depend on which portion of the model is correct. Achieving that typically requires carefully choosing first-stage estimators so that the extra "estimation effect" vanishes in the influence-function calculations. Concretely:

-   **Propensity score:** Use a logistic regression (and a special *inverse probability tilting* estimator) proposed by @graham2012inverse.
-   **Outcome regressions:** Use linear regressions with specific weights (or with OLS for the treated group).

One then obtains:

-   **For panel data:** $$
        \hat{\tau}^{\mathrm{dr,p}}_{\mathrm{imp}}
        \;=\;
        \frac1n \sum_{i=1}^n
          \Bigl[
             w_{1}^{\mathrm{p}}(D_i) \;-\; w_{0}^{\mathrm{p}}\bigl(D_i,X_i;\,\hat{\gamma}^{\mathrm{ipt}}\bigr)
          \Bigr]
          \Bigl[
            \bigl(Y_{i1}-Y_{i0}\bigr)
            \;-\;
            \hat{\mu}^{\mathrm{lin,p}}_{0,\Delta}\bigl(X_i;\,\hat{\beta}^{\mathrm{wls,p}}_{0,\Delta}\bigr)
          \Bigr],
      $$ where $\hat{\gamma}^{\mathrm{ipt}}$ is the "inverse probability tilting" estimate for the logit propensity score, and $\hat{\beta}^{\mathrm{wls,p}}_{0,\Delta}$ is a weighted least squares estimate for the difference regressions of the comparison group. Under suitable regularity conditions, this estimator:

    1.  Remains consistent if either the logit model or the linear outcome model for $\Delta Y$ in the control group is correct.

    2.  Has an asymptotic distribution that does *not* depend on which model is correct (thus simplifying inference).

    3.  Achieves the semiparametric efficiency bound if both models are correct.

<!-- -->

-   **For repeated cross-sections**, one can analogously use logistic-based tilting for the propensity score and weighted/ordinary least squares for the control/treated outcome regressions. The *second* DR estimator $\hat{\tau}^{\mathrm{dr,rc}}_{2}$ that models the treated group's outcomes as well can, under correct specification of *all* models, achieve local efficiency.

------------------------------------------------------------------------

#### Large-Sample Properties

Assume mild regularity conditions for consistency and asymptotic normality (e.g., overlapping support, identifiability of the pseudo-true parameters for the first-step models, and suitable rates of convergence) [@sant2020doubly].

1.  **Double Robust Consistency.**\
    Each proposed DR DID estimator is consistent for $\tau$ if either (a) $\hat{p}(X)$ is consistent for $p(X)$, or (b) the relevant outcome regressions $\hat{m}_{0,t}(X)$ are consistent for $m_{0,t}(X)$. Thus, we say the estimator is *doubly robust* to misspecification.

2.  **Asymptotic Normality.**\
    $$
        \sqrt{n}\bigl(\,\hat{\tau}^{\mathrm{dr}} \,-\, \tau \bigr)
        \;\;\xrightarrow{d}\;\;
        N\bigl(\,0,\;\mathrm{Var}(\text{IF})\bigr),
    $$ where $\mathrm{Var}(\text{IF})$ depends on which part(s) of the nuisance models are consistently estimated. In general, one must account for the variance contribution of the first-stage estimation. But under certain special constructions (the "improved DR" approaches with inverse probability tilting and specialized weighting), the first-stage does not contribute additional variance, making inference simpler.

3.  **Local Semiparametric Efficiency.**\
    If *both* the propensity score model and the outcome-regression models are correct, the estimator's influence function matches the *efficient influence function*, hence achieving the semiparametric efficiency bound. In repeated cross-sections, the DR estimator that also models the treated group's outcomes (namely $\tau^{\mathrm{dr,rc}}_2$) is the one that can achieve local efficiency.

------------------------------------------------------------------------

#### Practical Implementation

In practice, the recommended workflow is:

1.  **Specify (and estimate) a flexible working model** for the propensity score. A logistic regression with the inverse-probability-tilting approach is often a good default, as it simplifies subsequent steps if one wants DR inference.
2.  **Model the outcome of the comparison group** over time. For panel data, one can directly model $\Delta Y$. For repeated cross-sections, one typically models $\{m_{0,t}(X)\}_{t=0,1}$.
3.  **(Optional) Model the outcome of the treated group** if seeking the local-efficiency version of DR DID in repeated cross-sections.
4.  **Form the DR DID estimator** by plugging the fitted models from steps (1)--(3) into the chosen DR moment expression.

**Inference** can often be carried out by taking the empirical variance of the estimated influence function: $$
   \hat{V} \;=\; \frac{1}{n}\sum_{i=1}^n \hat{\eta}_i^2,
$$ where $\hat{\eta}_i$ is the evaluator's best estimate of the influence function for observation $i$. Under certain "improved DR" constructions, the same $\hat{\eta}_i$ works regardless of which part of the model is correct.

------------------------------------------------------------------------

```{r}
data('base_stagg')

library(did)

drdid_result <- att_gt(
    yname = "y",
    tname = "year",
    idname = "id",
    gname = "year_treated",
    xformla = ~ x1,
    data = base_stagg
)


aggte(drdid_result, type = "simple")
agg.es <- aggte(drdid_result, type = "dynamic")

ggdid(agg.es)

agg.gs <- aggte(drdid_result, type = "group")

ggdid(agg.gs)
```

------------------------------------------------------------------------

